{"func": "static void PixarLogCleanup(TIFF* tif) { PixarLogState* sp = (PixarLogState*) tif->tif_data; assert(sp != 0); (void)TIFFPredictorCleanup(tif); tif->tif_tagmethods.vgetfield = sp->vgetparent; tif->tif_tagmethods.vsetfield = sp->vsetparent; if (sp->FromLT2) _TIFFfree(sp->FromLT2); if (sp->From14) _TIFFfree(sp->From14); if (sp->From8) _TIFFfree(sp->From8); if (sp->ToLinearF) _TIFFfree(sp->ToLinearF); if (sp->ToLinear16) _TIFFfree(sp->ToLinear16); if (sp->ToLinear8) _TIFFfree(sp->ToLinear8); if (sp->state&PLSTATE_INIT) { if (tif->tif_mode == O_RDONLY) inflateEnd(&sp->stream); else deflateEnd(&sp->stream); } if (sp->tbuf) _TIFFfree(sp->tbuf); _TIFFfree(sp); tif->tif_data = NULL; _TIFFSetDefaultCompressionState(tif); }", "target": 1, "idx": 100803, "project": "LibTIFF"}
{"func": "static int do_control_help(void *ctx, struct connection *conn,  char **vec, int num) { int cmd, len = 0; char *resp; if (num) return EINVAL; for (cmd = 0; cmd < ARRAY_SIZE(cmds); cmd++) { len += strlen(cmds[cmd].cmd) + 1; len += strlen(cmds[cmd].pars) + 1; } len++; resp = talloc_array(ctx, char, len); if (!resp) return ENOMEM; len = 0; for (cmd = 0; cmd < ARRAY_SIZE(cmds); cmd++) { strcpy(resp + len, cmds[cmd].cmd); len += strlen(cmds[cmd].cmd); resp[len] = '\\t'; len++; strcpy(resp + len, cmds[cmd].pars); len += strlen(cmds[cmd].pars); resp[len] = '\\n'; len++; } resp[len] = 0; send_reply(conn, XS_CONTROL, resp, len); return 0; }", "target": 0, "idx": 108433, "project": "Xen"}
{"func": "int libxl_device_nic_getinfo(libxl_ctx *ctx, uint32_t domid, libxl_device_nic *nic, libxl_nicinfo *nicinfo) { GC_INIT(ctx); char *dompath, *nicpath; char *val; dompath = libxl__xs_get_dompath(gc, domid); nicinfo->devid = nic->devid; nicpath = libxl__sprintf(gc, \"%s/device/vif/%d\", dompath, nicinfo->devid); nicinfo->backend = xs_read(ctx->xsh, XBT_NULL, libxl__sprintf(gc, \"%s/backend\", nicpath), NULL); if (!nicinfo->backend) { GC_FREE; return ERROR_FAIL; } val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/backend-id\", nicpath)); nicinfo->backend_id = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/state\", nicpath)); nicinfo->state = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/event-channel\", nicpath)); nicinfo->evtch = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/tx-ring-ref\", nicpath)); nicinfo->rref_tx = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/rx-ring-ref\", nicpath)); nicinfo->rref_rx = val ? strtoul(val, NULL, 10) : -1; nicinfo->frontend = xs_read(ctx->xsh, XBT_NULL,  libxl__sprintf(gc, \"%s/frontend\", nicinfo->backend), NULL); val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/frontend-id\", nicinfo->backend)); nicinfo->frontend_id = val ? strtoul(val, NULL, 10) : -1; GC_FREE; return 0; }", "target": 1, "idx": 109378, "project": "Xen"}
{"func": "int ept_p2m_init(struct p2m_domain *p2m) { struct ept_data *ept = &p2m->ept; p2m->set_entry = ept_set_entry; p2m->get_entry = ept_get_entry; p2m->recalc = resolve_misconfig; p2m->change_entry_type_global = ept_change_entry_type_global; p2m->change_entry_type_range = ept_change_entry_type_range; p2m->memory_type_changed = ept_memory_type_changed; p2m->audit_p2m = NULL; p2m->tlb_flush = ept_tlb_flush;  ept->mt = EPT_DEFAULT_MT;  ept->wl = 3; if ( cpu_has_vmx_pml ) { p2m->enable_hardware_log_dirty = ept_enable_pml; p2m->disable_hardware_log_dirty = ept_disable_pml; p2m->flush_hardware_cached_dirty = ept_flush_pml_buffers; } if ( !zalloc_cpumask_var(&ept->invalidate) ) return -ENOMEM;  cpumask_setall(ept->invalidate); return 0; }", "target": 0, "idx": 105004, "project": "Xen"}
{"func": "void viridian_apic_assist_clear(struct vcpu *v) { uint32_t *va = v->arch.hvm_vcpu.viridian.vp_assist.va; if ( !va ) return; *va &= ~1u; v->arch.hvm_vcpu.viridian.vp_assist.pending = false; }", "target": 0, "idx": 106896, "project": "Xen"}
{"func": "static void zero_mem(u32 s, u32 bytes) { while ( bytes-- ) *(char *)s++ = 0; }", "target": 0, "idx": 105380, "project": "Xen"}
{"func": "static int apply_microcode(unsigned int cpu) { unsigned long flags; struct ucode_cpu_info *uci = &per_cpu(ucode_cpu_info, cpu); uint32_t rev; struct microcode_amd *mc_amd = uci->mc.mc_amd; struct microcode_header_amd *hdr; int hw_err;  BUG_ON(raw_smp_processor_id() != cpu); if ( mc_amd == NULL ) return -EINVAL; hdr = mc_amd->mpb; if ( hdr == NULL ) return -EINVAL; spin_lock_irqsave(&microcode_update_lock, flags); hw_err = wrmsr_safe(MSR_AMD_PATCHLOADER, (unsigned long)hdr);  rdmsrl(MSR_AMD_PATCHLEVEL, rev); spin_unlock_irqrestore(&microcode_update_lock, flags);  if ( hw_err || (rev != hdr->patch_id) ) { printk(KERN_ERR \"microcode: CPU%d update from revision \"  \"%#x to %#x failed\\n\", cpu, rev, hdr->patch_id); return -EIO; } printk(KERN_WARNING \"microcode: CPU%d updated from revision %#x to %#x\\n\",  cpu, uci->cpu_sig.rev, hdr->patch_id); uci->cpu_sig.rev = rev; return 0; }", "target": 0, "idx": 104542, "project": "Xen"}
{"func": "static struct rt_vcpu * q_elem(struct list_head *elem) { return list_entry(elem, struct rt_vcpu, q_elem); } static struct rt_vcpu * replq_elem(struct list_head *elem) { return list_entry(elem, struct rt_vcpu, replq_elem); }", "target": 0, "idx": 105615, "project": "Xen"}
{"func": "struct libxenvchan *libxenvchan_client_init(struct xentoollog_logger *logger, int domain, const char* xs_path) { struct libxenvchan *ctrl = malloc(sizeof(struct libxenvchan)); struct xs_handle *xs = NULL; char buf[64]; char *ref; int ring_ref; unsigned int len; if (!ctrl) return 0; ctrl->ring = NULL; ctrl->event = NULL; ctrl->gnttab = NULL; ctrl->write.order = ctrl->read.order = 0; ctrl->is_server = 0; xs = xs_daemon_open(); if (!xs) xs = xs_domain_open(); if (!xs) goto fail; snprintf(buf, sizeof buf, \"%s/ring-ref\", xs_path); ref = xs_read(xs, 0, buf, &len); if (!ref) goto fail; ring_ref = atoi(ref); free(ref); if (!ring_ref) goto fail; snprintf(buf, sizeof buf, \"%s/event-channel\", xs_path); ref = xs_read(xs, 0, buf, &len); if (!ref) goto fail; ctrl->event_port = atoi(ref); free(ref); if (!ctrl->event_port) goto fail; ctrl->gnttab = xengnttab_open(logger, 0); if (!ctrl->gnttab) goto fail; if (init_evt_cli(ctrl, domain, logger)) goto fail; if (init_gnt_cli(ctrl, domain, ring_ref)) goto fail; ctrl->ring->cli_live = 1; ctrl->ring->srv_notify = VCHAN_NOTIFY_WRITE;  out: if (xs) xs_daemon_close(xs); return ctrl;  fail: libxenvchan_close(ctrl); ctrl = NULL; goto out; }", "target": 0, "idx": 102718, "project": "Xen"}
{"func": "void reset_field_widths(void) { fields[FIELD_NET_TX-1].default_width = 8; fields[FIELD_NET_RX-1].default_width = 8; fields[FIELD_VBD_RD-1].default_width = 8; fields[FIELD_VBD_WR-1].default_width = 8; fields[FIELD_VBD_RSECT-1].default_width = 10; fields[FIELD_VBD_WSECT-1].default_width = 10; }", "target": 0, "idx": 108545, "project": "Xen"}
{"func": "static int __init livepatch_init(void) { register_keyhandler('x', livepatch_printall, \"print livepatch info\", 1); arch_livepatch_init(); return 0; }", "target": 0, "idx": 104246, "project": "Xen"}
{"func": "static void tapdisk_stream_enqueue(event_id_t id, char mode, void *arg) { struct tapdisk_stream *s = (struct tapdisk_stream *)arg; tapdisk_stream_poll_clear(&s->poll); if (tapdisk_diff_done()) { tapdisk_diff_stop(); return; } if (s == &stream1)  tapdisk_stream_enqueue1(); else if (s == &stream2) tapdisk_stream_enqueue2(); else assert(0); if (tapdisk_diff_done()) {   tapdisk_diff_stop(); return; } }", "target": 0, "idx": 106117, "project": "Xen"}
{"func": "void CreateXImage() { XGCValues gc_values; GC bitmap_gc; xOffset = yOffset = 0; grabX = grabY = -1; xImage = XCreateImage(xDisplay, xVisual, xImageDepth, xImageDepth == 1 ? XYBitmap : ZPixmap,0, (char *) imageMemory, tfImageWidth, tfImageHeight,  8,0);  if (xImageDepth == 1) xImage->bitmap_bit_order = MSBFirst; if (xImageDepth <= 8) xImage->byte_order = MSBFirst;  gc_values.function = GXcopy; gc_values.plane_mask = AllPlanes; if (tfPhotometricInterpretation == PHOTOMETRIC_MINISBLACK) { gc_values.foreground = XWhitePixel(xDisplay, xScreen); gc_values.background = XBlackPixel(xDisplay, xScreen); } else { gc_values.foreground = XBlackPixel(xDisplay, xScreen); gc_values.background = XWhitePixel(xDisplay, xScreen); } xWinGc = XCreateGC(xDisplay, XtWindow(shellWidget), GCFunction | GCPlaneMask | GCForeground | GCBackground, &gc_values);  if (appData.usePixmap == True) { xImagePixmap = XCreatePixmap(xDisplay, RootWindow(xDisplay, xScreen), xImage->width, xImage->height, xImageDepth);  if (xImageDepth == 1) {  gc_values.foreground = 1;  gc_values.background = 0;  bitmap_gc = XCreateGC(xDisplay, xImagePixmap, GCForeground | GCBackground, &gc_values); XPutImage(xDisplay, xImagePixmap, bitmap_gc, xImage, 0, 0, 0, 0, xImage->width, xImage->height); } else XPutImage(xDisplay, xImagePixmap, xWinGc, xImage, 0, 0, 0, 0, xImage->width, xImage->height); XDestroyImage(xImage); free(imageMemory); } }", "target": 0, "idx": 100541, "project": "LibTIFF"}
{"func": "const char *__init parse_pci_seg(const char *s, unsigned int *seg_p,  unsigned int *bus_p, unsigned int *dev_p,  unsigned int *func_p, bool *def_seg) { unsigned long seg = simple_strtoul(s, &s, 16), bus, dev, func; if ( *s != ':' ) return NULL; bus = simple_strtoul(s + 1, &s, 16); *def_seg = false; if ( *s == ':' ) dev = simple_strtoul(s + 1, &s, 16); else { dev = bus; bus = seg; seg = 0; *def_seg = true; } if ( func_p ) { if ( *s != '.' ) return NULL; func = simple_strtoul(s + 1, &s, 0); } else func = 0; if ( seg != (seg_p ? (u16)seg : 0) ||  bus != PCI_BUS(PCI_BDF2(bus, 0)) ||  dev != PCI_SLOT(PCI_DEVFN(dev, 0)) ||  func != PCI_FUNC(PCI_DEVFN(0, func)) ) return NULL; if ( seg_p ) *seg_p = seg; *bus_p = bus; *dev_p = dev; if ( func_p ) *func_p = func; return s; }", "target": 0, "idx": 105028, "project": "Xen"}
{"func": "static long gnttab_transfer( XEN_GUEST_HANDLE_PARAM(gnttab_transfer_t) uop, unsigned int count) { struct domain *d = current->domain; struct domain *e; struct page_info *page; int i; struct gnttab_transfer gop; unsigned long mfn; unsigned int max_bitsize; struct active_grant_entry *act; for ( i = 0; i < count; i++ ) { bool_t okay; if (i && hypercall_preempt_check()) return i;  if ( unlikely(__copy_from_guest(&gop, uop, 1)) ) { gdprintk(XENLOG_INFO, \"gnttab_transfer: error reading req %d/%d\\n\", i, count); return -EFAULT; } #ifdef CONFIG_X86 { p2m_type_t __p2mt; mfn = mfn_x(get_gfn_unshare(d, gop.mfn, &__p2mt)); if ( p2m_is_shared(__p2mt) || !p2m_is_valid(__p2mt) ) mfn = mfn_x(INVALID_MFN); } #else mfn = mfn_x(gfn_to_mfn(d, _gfn(gop.mfn))); #endif  if ( unlikely(!mfn_valid(mfn)) ) {  put_gfn(d, gop.mfn); gdprintk(XENLOG_INFO, \"gnttab_transfer: out-of-range %lx\\n\", (unsigned long)gop.mfn); gop.status = GNTST_bad_page; goto copyback; } page = mfn_to_page(mfn); if ( unlikely(is_xen_heap_page(page)) ) {  put_gfn(d, gop.mfn); gdprintk(XENLOG_INFO, \"gnttab_transfer: xen frame %lx\\n\", (unsigned long)gop.mfn); gop.status = GNTST_bad_page; goto copyback; } if ( steal_page(d, page, 0) < 0 ) { put_gfn(d, gop.mfn); gop.status = GNTST_bad_page; goto copyback; } guest_physmap_remove_page(d, _gfn(gop.mfn), _mfn(mfn), 0); gnttab_flush_tlb(d);  if ( unlikely((e = rcu_lock_domain_by_id(gop.domid)) == NULL) ) { put_gfn(d, gop.mfn); gdprintk(XENLOG_INFO, \"gnttab_transfer: can't find domain %d\\n\", gop.domid); page->count_info &= ~(PGC_count_mask|PGC_allocated); free_domheap_page(page); gop.status = GNTST_bad_domain; goto copyback; } if ( xsm_grant_transfer(XSM_HOOK, d, e) ) { put_gfn(d, gop.mfn); gop.status = GNTST_permission_denied; unlock_and_copyback: rcu_unlock_domain(e); page->count_info &= ~(PGC_count_mask|PGC_allocated); free_domheap_page(page); goto copyback; } max_bitsize = domain_clamp_alloc_bitsize( e, e->grant_table->gt_version > 1 || paging_mode_translate(e)  ? BITS_PER_LONG + PAGE_SHIFT : 32 + PAGE_SHIFT); if ( max_bitsize < BITS_PER_LONG + PAGE_SHIFT &&  (mfn >> (max_bitsize - PAGE_SHIFT)) ) { struct page_info *new_page; new_page = alloc_domheap_page(e, MEMF_no_owner |  MEMF_bits(max_bitsize)); if ( new_page == NULL ) { gop.status = GNTST_address_too_big; goto unlock_and_copyback; } copy_domain_page(_mfn(page_to_mfn(new_page)), _mfn(mfn)); page->count_info &= ~(PGC_count_mask|PGC_allocated); free_domheap_page(page); page = new_page; } spin_lock(&e->page_alloc_lock);  if ( unlikely(e->is_dying) ||  unlikely(e->tot_pages >= e->max_pages) ) { spin_unlock(&e->page_alloc_lock); if ( e->is_dying ) gdprintk(XENLOG_INFO, \"gnttab_transfer: \"  \"Transferee (d%d) is dying\\n\", e->domain_id); else gdprintk(XENLOG_INFO, \"gnttab_transfer: \"  \"Transferee (d%d) has no headroom (tot %u, max %u)\\n\",  e->domain_id, e->tot_pages, e->max_pages); rcu_unlock_domain(e); put_gfn(d, gop.mfn); page->count_info &= ~(PGC_count_mask|PGC_allocated); free_domheap_page(page); gop.status = GNTST_general_error; goto copyback; }  if ( unlikely(domain_adjust_tot_pages(e, 1) == 1) ) get_knownalive_domain(e);  spin_unlock(&e->page_alloc_lock); okay = gnttab_prepare_for_transfer(e, d, gop.ref); spin_lock(&e->page_alloc_lock); if ( unlikely(!okay) || unlikely(e->is_dying) ) { bool_t drop_dom_ref = !domain_adjust_tot_pages(e, -1); spin_unlock(&e->page_alloc_lock); if ( okay) gdprintk(XENLOG_INFO, \"gnttab_transfer: \"  \"Transferee (d%d) is now dying\\n\", e->domain_id); if ( drop_dom_ref ) put_domain(e); rcu_unlock_domain(e); put_gfn(d, gop.mfn); page->count_info &= ~(PGC_count_mask|PGC_allocated); free_domheap_page(page); gop.status = GNTST_general_error; goto copyback; } page_list_add_tail(page, &e->page_list); page_set_owner(page, e); spin_unlock(&e->page_alloc_lock); put_gfn(d, gop.mfn); TRACE_1D(TRC_MEM_PAGE_GRANT_TRANSFER, e->domain_id);  grant_read_lock(e->grant_table); act = active_entry_acquire(e->grant_table, gop.ref); if ( e->grant_table->gt_version == 1 ) { grant_entry_v1_t *sha = &shared_entry_v1(e->grant_table, gop.ref); guest_physmap_add_page(e, _gfn(sha->frame), _mfn(mfn), 0); if ( !paging_mode_translate(e) ) sha->frame = mfn; } else { grant_entry_v2_t *sha = &shared_entry_v2(e->grant_table, gop.ref); guest_physmap_add_page(e, _gfn(sha->full_page.frame),  _mfn(mfn), 0); if ( !paging_mode_translate(e) ) sha->full_page.frame = mfn; } smp_wmb(); shared_entry_header(e->grant_table, gop.ref)->flags |= GTF_transfer_completed; active_entry_release(act); grant_read_unlock(e->grant_table); rcu_unlock_domain(e); gop.status = GNTST_okay; copyback: if ( unlikely(__copy_field_to_guest(uop, &gop, status)) ) { gdprintk(XENLOG_INFO, \"gnttab_transfer: error writing resp \"  \"%d/%d\\n\", i, count); return -EFAULT; } guest_handle_add_offset(uop, 1); } return 0; }", "target": 1, "idx": 109470, "project": "Xen"}
{"func": "int passive_domain_do_wrmsr(unsigned int msr, uint64_t msr_content) { int type, index; if ( !passive_domain_msr_op_checks(msr, &type, &index)) return 0; model->save_msr(current, type, index, msr_content); return 1; }", "target": 0, "idx": 104859, "project": "Xen"}
{"func": "int main_networkattach(int argc, char **argv) { uint32_t domid; int opt; libxl_device_nic nic; XLU_Config *config = 0; SWITCH_FOREACH_OPT(opt, \"\", NULL, \"network-attach\", 1) {  } domid = find_domain(argv[optind]); config= xlu_cfg_init(stderr, \"command line\"); if (!config) { fprintf(stderr, \"Failed to allocate for configuration\\n\"); return 1; } libxl_device_nic_init(&nic); set_default_nic_values(&nic); for (argv += optind+1, argc -= optind+1; argc > 0; ++argv, --argc) { if (parse_nic_config(&nic, &config, *argv)) return 1; } if (dryrun_only) { char *json = libxl_device_nic_to_json(ctx, &nic); printf(\"vif: %s\\n\", json); free(json); libxl_device_nic_dispose(&nic); if (ferror(stdout) || fflush(stdout)) { perror(\"stdout\"); exit(-1); } return 0; } if (libxl_device_nic_add(ctx, domid, &nic, 0)) { fprintf(stderr, \"libxl_device_nic_add failed.\\n\"); return 1; } libxl_device_nic_dispose(&nic); xlu_cfg_destroy(config); return 0; }", "target": 0, "idx": 108721, "project": "Xen"}
{"func": "int xc_hvm_map_io_range_to_ioreq_server( xc_interface *xch, uint32_t domid, ioservid_t id, int is_mmio, uint64_t start, uint64_t end) { return xendevicemodel_map_io_range_to_ioreq_server(xch->dmod, domid,  id, is_mmio, start,  end); }", "target": 0, "idx": 107365, "project": "Xen"}
{"func": "static int fuzz_write_segment( enum x86_segment seg, const struct segment_register *reg, struct x86_emulate_ctxt *ctxt) { struct fuzz_state *s = ctxt->data; struct fuzz_corpus *c = s->corpus; int rc; assert(is_x86_user_segment(seg) || is_x86_system_segment(seg)); rc = maybe_fail(ctxt, \"write_segment\", true); if ( rc == X86EMUL_OKAY ) c->segments[seg] = *reg; return rc; }", "target": 0, "idx": 102239, "project": "Xen"}
{"func": " */ static enum xz_ret INIT crc32_validate(struct xz_dec *s, struct xz_buf *b) { do { if (b->in_pos == b->in_size) return XZ_OK; if (((s->crc32 >> s->pos) & 0xFF) != b->in[b->in_pos++]) return XZ_DATA_ERROR; s->pos += 8; } while (s->pos < 32); s->crc32 = 0; s->pos = 0; return XZ_STREAM_END; }", "target": 0, "idx": 101624, "project": "Xen"}
{"func": "static bool __init ram_range_valid(unsigned long smfn, unsigned long emfn) { unsigned long sz = pfn_to_pdx(emfn - 1) / PDX_GROUP_COUNT + 1; return !(smfn & pfn_hole_mask) &&  find_next_bit(pdx_group_valid, sz,  pfn_to_pdx(smfn) / PDX_GROUP_COUNT) < sz; }", "target": 0, "idx": 101247, "project": "Xen"}
{"func": "struct expr *expr_copy(const struct expr *org) { struct expr *e; if (!org) return NULL; e = xmalloc(sizeof(*org)); memcpy(e, org, sizeof(*org)); switch (org->type) { case E_SYMBOL: e->left = org->left; break; case E_NOT: e->left.expr = expr_copy(org->left.expr); break; case E_EQUAL: case E_GEQ: case E_GTH: case E_LEQ: case E_LTH: case E_UNEQUAL: e->left.sym = org->left.sym; e->right.sym = org->right.sym; break; case E_AND: case E_OR: case E_LIST: e->left.expr = expr_copy(org->left.expr); e->right.expr = expr_copy(org->right.expr); break; default: printf(\"can't copy type %d\\n\", e->type); free(e); e = NULL; break; } return e; }", "target": 0, "idx": 101936, "project": "Xen"}
{"func": "void mctelem_ack(mctelem_class_t which, mctelem_cookie_t cookie) { mctelem_class_t target = (which == MC_URGENT) ? MC_URGENT : MC_NONURGENT; struct mctelem_ent *tep = COOKIE2MCTE(cookie); if (tep == NULL) return; spin_lock(&processing_lock); if (tep == mctctl.mctc_processing_head[target]) mctelem_processing_release(tep); spin_unlock(&processing_lock); }", "target": 0, "idx": 104431, "project": "Xen"}
{"func": "int libxl__restore_emulator_xenstore_data(libxl__domain_create_state *dcs, const char *ptr, uint32_t size) { STATE_AO_GC(dcs->ao); const char *next = ptr, *end = ptr + size, *key, *val; int rc; const uint32_t domid = dcs->guest_domid; const uint32_t dm_domid = libxl_get_stubdom_id(CTX, domid); const char *xs_root = DEVICE_MODEL_XS_PATH(gc, dm_domid, domid, \"\"); while (next < end) { key = next; next = next_string(next, end);  if (!next) { rc = ERROR_FAIL; LOGD(ERROR, domid, \"Key in xenstore data not NUL terminated\"); goto out; } if (key[0] == '\\0') { rc = ERROR_FAIL; LOGD(ERROR, domid, \"empty key found in xenstore data\"); goto out; } if (key[0] == '/') { rc = ERROR_FAIL; LOGD(ERROR, domid, \"Key in xenstore data not relative\"); goto out; } val = next; next = next_string(next, end);  if (!next) { rc = ERROR_FAIL; LOGD(ERROR, domid, \"Val in xenstore data not NUL terminated\"); goto out; } libxl__xs_printf(gc, XBT_NULL,  GCSPRINTF(\"%s/%s\", xs_root, key),  \"%s\", val); } rc = 0;  out: return rc; }", "target": 0, "idx": 103570, "project": "Xen"}
{"func": "void rcu_idle_timer_stop() { struct rcu_data *rdp = &this_cpu(rcu_data); if (likely(!rdp->idle_timer_active)) return; rdp->idle_timer_active = false;  if ( !timer_is_expired(&rdp->idle_timer) ) stop_timer(&rdp->idle_timer); }", "target": 0, "idx": 105353, "project": "Xen"}
{"func": "static int avtab_insertf(struct avtab *a, struct avtab_key *k, struct avtab_datum *d, void *p) { return avtab_insert(a, k, d); }", "target": 0, "idx": 100935, "project": "Xen"}
{"func": "int TIFFReadDirectory(TIFF* tif) { static const char module[] = \"TIFFReadDirectory\"; int n; TIFFDirectory* td; TIFFDirEntry *dp, *dir = NULL; uint16 iv; uint32 v; const TIFFFieldInfo* fip; size_t fix; uint16 dircount; int diroutoforderwarning = 0, compressionknown = 0; tif->tif_diroff = tif->tif_nextdiroff;  if (!TIFFCheckDirOffset(tif, tif->tif_nextdiroff)) return 0;  (*tif->tif_cleanup)(tif); tif->tif_curdir++; dircount = TIFFFetchDirectory(tif, tif->tif_nextdiroff, &dir, &tif->tif_nextdiroff); if (!dircount) { TIFFErrorExt(tif->tif_clientdata, module,  \"%s: Failed to read directory at offset %u\",  tif->tif_name, tif->tif_nextdiroff); return 0; } tif->tif_flags &= ~TIFF_BEENWRITING;  td = &tif->tif_dir;  TIFFFreeDirectory(tif); TIFFDefaultDirectory(tif);  TIFFSetField(tif, TIFFTAG_PLANARCONFIG, PLANARCONFIG_CONTIG);  for (dp = dir, n = dircount; n > 0; n--, dp++) { if (tif->tif_flags & TIFF_SWAB) { TIFFSwabArrayOfShort(&dp->tdir_tag, 2); TIFFSwabArrayOfLong(&dp->tdir_count, 2); } if (dp->tdir_tag == TIFFTAG_SAMPLESPERPIXEL) { if (!TIFFFetchNormalTag(tif, dp)) goto bad; dp->tdir_tag = IGNORE; } }  fix = 0; for (dp = dir, n = dircount; n > 0; n--, dp++) { if (fix >= tif->tif_nfields || dp->tdir_tag == IGNORE) continue;  if (dp->tdir_tag < tif->tif_fieldinfo[fix]->field_tag) { if (!diroutoforderwarning) { TIFFWarningExt(tif->tif_clientdata, module, \"%s: invalid TIFF directory; tags are not sorted in ascending order\", tif->tif_name); diroutoforderwarning = 1; } fix = 0; } while (fix < tif->tif_nfields && tif->tif_fieldinfo[fix]->field_tag < dp->tdir_tag) fix++; if (fix >= tif->tif_nfields || tif->tif_fieldinfo[fix]->field_tag != dp->tdir_tag) { TIFFWarningExt(tif->tif_clientdata,  module, \"%s: unknown field with tag %d (0x%x) encountered\",  tif->tif_name,  dp->tdir_tag,  dp->tdir_tag); if (!_TIFFMergeFieldInfo(tif, _TIFFCreateAnonFieldInfo(tif, dp->tdir_tag, (TIFFDataType) dp->tdir_type), 1)) { TIFFWarningExt(tif->tif_clientdata,  module, \"Registering anonymous field with tag %d (0x%x) failed\",  dp->tdir_tag,  dp->tdir_tag); goto ignore; } fix = 0; while (fix < tif->tif_nfields &&  tif->tif_fieldinfo[fix]->field_tag < dp->tdir_tag) fix++; }  if (tif->tif_fieldinfo[fix]->field_bit == FIELD_IGNORE) { ignore: dp->tdir_tag = IGNORE; continue; }  fip = tif->tif_fieldinfo[fix]; while (dp->tdir_type != (unsigned short) fip->field_type && fix < tif->tif_nfields) { if (fip->field_type == TIFF_ANY) break; fip = tif->tif_fieldinfo[++fix]; if (fix >= tif->tif_nfields || fip->field_tag != dp->tdir_tag) { TIFFWarningExt(tif->tif_clientdata, module, \"%s: wrong data type %d for \\\"%s\\\"; tag ignored\", tif->tif_name, dp->tdir_type, tif->tif_fieldinfo[fix-1]->field_name); goto ignore; } }  if (fip->field_readcount != TIFF_VARIABLE && fip->field_readcount != TIFF_VARIABLE2) { uint32 expected = (fip->field_readcount == TIFF_SPP) ? (uint32) td->td_samplesperpixel : (uint32) fip->field_readcount; if (!CheckDirCount(tif, dp, expected)) goto ignore; } switch (dp->tdir_tag) { case TIFFTAG_COMPRESSION:  if (dp->tdir_count == 1) { v = TIFFExtractData(tif, dp->tdir_type, dp->tdir_offset); if (!TIFFSetField(tif, dp->tdir_tag, (uint16)v)) goto bad; else compressionknown = 1; break;  } else if (dp->tdir_type == TIFF_LONG) { if (!TIFFFetchPerSampleLongs(tif, dp, &v) || !TIFFSetField(tif, dp->tdir_tag, (uint16)v)) goto bad; } else { if (!TIFFFetchPerSampleShorts(tif, dp, &iv) || !TIFFSetField(tif, dp->tdir_tag, iv)) goto bad; } dp->tdir_tag = IGNORE; break; case TIFFTAG_STRIPOFFSETS: case TIFFTAG_STRIPBYTECOUNTS: case TIFFTAG_TILEOFFSETS: case TIFFTAG_TILEBYTECOUNTS: TIFFSetFieldBit(tif, fip->field_bit); break; case TIFFTAG_IMAGEWIDTH: case TIFFTAG_IMAGELENGTH: case TIFFTAG_IMAGEDEPTH: case TIFFTAG_TILELENGTH: case TIFFTAG_TILEWIDTH: case TIFFTAG_TILEDEPTH: case TIFFTAG_PLANARCONFIG: case TIFFTAG_ROWSPERSTRIP: case TIFFTAG_EXTRASAMPLES: if (!TIFFFetchNormalTag(tif, dp)) goto bad; dp->tdir_tag = IGNORE; break; } }  if ((td->td_compression==COMPRESSION_OJPEG) && (td->td_planarconfig==PLANARCONFIG_SEPARATE)) { dp = TIFFReadDirectoryFind(dir,dircount,TIFFTAG_STRIPOFFSETS); if ((dp!=0) && (dp->tdir_count==1)) { dp = TIFFReadDirectoryFind(dir, dircount,  TIFFTAG_STRIPBYTECOUNTS); if ((dp!=0) && (dp->tdir_count==1)) { td->td_planarconfig=PLANARCONFIG_CONTIG; TIFFWarningExt(tif->tif_clientdata,  \"TIFFReadDirectory\", \"Planarconfig tag value assumed incorrect, \" \"assuming data is contig instead of chunky\"); } } }  if (!TIFFFieldSet(tif, FIELD_IMAGEDIMENSIONS)) { MissingRequired(tif, \"ImageLength\"); goto bad; }  if (!TIFFFieldSet(tif, FIELD_TILEDIMENSIONS)) { td->td_nstrips = TIFFNumberOfStrips(tif); td->td_tilewidth = td->td_imagewidth; td->td_tilelength = td->td_rowsperstrip; td->td_tiledepth = td->td_imagedepth; tif->tif_flags &= ~TIFF_ISTILED; } else { td->td_nstrips = TIFFNumberOfTiles(tif); tif->tif_flags |= TIFF_ISTILED; } if (!td->td_nstrips) { TIFFErrorExt(tif->tif_clientdata, module,  \"%s: cannot handle zero number of %s\",  tif->tif_name, isTiled(tif) ? \"tiles\" : \"strips\"); goto bad; } td->td_stripsperimage = td->td_nstrips; if (td->td_planarconfig == PLANARCONFIG_SEPARATE) td->td_stripsperimage /= td->td_samplesperpixel; if (!TIFFFieldSet(tif, FIELD_STRIPOFFSETS)) { if ((td->td_compression==COMPRESSION_OJPEG) && (isTiled(tif)==0) && (td->td_nstrips==1)) {  TIFFSetFieldBit(tif, FIELD_STRIPOFFSETS); } else { MissingRequired(tif, isTiled(tif) ? \"TileOffsets\" : \"StripOffsets\"); goto bad; } }  for (dp = dir, n = dircount; n > 0; n--, dp++) { if (dp->tdir_tag == IGNORE) continue; switch (dp->tdir_tag) { case TIFFTAG_MINSAMPLEVALUE: case TIFFTAG_MAXSAMPLEVALUE: case TIFFTAG_BITSPERSAMPLE: case TIFFTAG_DATATYPE: case TIFFTAG_SAMPLEFORMAT:  if (dp->tdir_count == 1) { v = TIFFExtractData(tif, dp->tdir_type, dp->tdir_offset); if (!TIFFSetField(tif, dp->tdir_tag, (uint16)v)) goto bad;  } else if (dp->tdir_tag == TIFFTAG_BITSPERSAMPLE  && dp->tdir_type == TIFF_LONG) { if (!TIFFFetchPerSampleLongs(tif, dp, &v) || !TIFFSetField(tif, dp->tdir_tag, (uint16)v)) goto bad; } else { if (!TIFFFetchPerSampleShorts(tif, dp, &iv) || !TIFFSetField(tif, dp->tdir_tag, iv)) goto bad; } break; case TIFFTAG_SMINSAMPLEVALUE: case TIFFTAG_SMAXSAMPLEVALUE: { double dv = 0.0; if (!TIFFFetchPerSampleAnys(tif, dp, &dv) || !TIFFSetField(tif, dp->tdir_tag, dv)) goto bad; } break; case TIFFTAG_STRIPOFFSETS: case TIFFTAG_TILEOFFSETS: if (!TIFFFetchStripThing(tif, dp, td->td_nstrips, &td->td_stripoffset)) goto bad; break; case TIFFTAG_STRIPBYTECOUNTS: case TIFFTAG_TILEBYTECOUNTS: if (!TIFFFetchStripThing(tif, dp, td->td_nstrips, &td->td_stripbytecount)) goto bad; break; case TIFFTAG_COLORMAP: case TIFFTAG_TRANSFERFUNCTION: { char* cp;  v = 1L<<td->td_bitspersample; if (dp->tdir_tag == TIFFTAG_COLORMAP || dp->tdir_count != v) { if (!CheckDirCount(tif, dp, 3 * v)) break; } v *= sizeof(uint16); cp = (char *)_TIFFCheckMalloc(tif, dp->tdir_count, sizeof (uint16), \"to read \\\"TransferFunction\\\" tag\"); if (cp != NULL) { if (TIFFFetchData(tif, dp, cp)) {  uint32 c = 1L << td->td_bitspersample; if (dp->tdir_count == c) v = 0L; TIFFSetField(tif, dp->tdir_tag, cp, cp+v, cp+2*v); } _TIFFfree(cp); } break; } case TIFFTAG_PAGENUMBER: case TIFFTAG_HALFTONEHINTS: case TIFFTAG_YCBCRSUBSAMPLING: case TIFFTAG_DOTRANGE: (void) TIFFFetchShortPair(tif, dp); break; case TIFFTAG_REFERENCEBLACKWHITE: (void) TIFFFetchRefBlackWhite(tif, dp); break; case TIFFTAG_OSUBFILETYPE: v = 0L; switch (TIFFExtractData(tif, dp->tdir_type, dp->tdir_offset)) { case OFILETYPE_REDUCEDIMAGE: v = FILETYPE_REDUCEDIMAGE; break; case OFILETYPE_PAGE: v = FILETYPE_PAGE; break; } if (v) TIFFSetField(tif, TIFFTAG_SUBFILETYPE, v); break; default: (void) TIFFFetchNormalTag(tif, dp); break; } }  if (td->td_compression==COMPRESSION_OJPEG) { if (!TIFFFieldSet(tif,FIELD_PHOTOMETRIC)) { TIFFWarningExt(tif->tif_clientdata, \"TIFFReadDirectory\", \"Photometric tag is missing, assuming data is YCbCr\"); if (!TIFFSetField(tif,TIFFTAG_PHOTOMETRIC,PHOTOMETRIC_YCBCR)) goto bad; } else if (td->td_photometric==PHOTOMETRIC_RGB) { td->td_photometric=PHOTOMETRIC_YCBCR; TIFFWarningExt(tif->tif_clientdata, \"TIFFReadDirectory\", \"Photometric tag value assumed incorrect, \" \"assuming data is YCbCr instead of RGB\"); } if (!TIFFFieldSet(tif,FIELD_BITSPERSAMPLE)) { TIFFWarningExt(tif->tif_clientdata,\"TIFFReadDirectory\", \"BitsPerSample tag is missing, assuming 8 bits per sample\"); if (!TIFFSetField(tif,TIFFTAG_BITSPERSAMPLE,8)) goto bad; } if (!TIFFFieldSet(tif,FIELD_SAMPLESPERPIXEL)) { if ((td->td_photometric==PHOTOMETRIC_RGB) || (td->td_photometric==PHOTOMETRIC_YCBCR)) { TIFFWarningExt(tif->tif_clientdata,  \"TIFFReadDirectory\", \"SamplesPerPixel tag is missing, \" \"assuming correct SamplesPerPixel value is 3\"); if (!TIFFSetField(tif,TIFFTAG_SAMPLESPERPIXEL,3)) goto bad; } else if ((td->td_photometric==PHOTOMETRIC_MINISWHITE)  || (td->td_photometric==PHOTOMETRIC_MINISBLACK)) { TIFFWarningExt(tif->tif_clientdata,  \"TIFFReadDirectory\", \"SamplesPerPixel tag is missing, \" \"assuming correct SamplesPerPixel value is 1\"); if (!TIFFSetField(tif,TIFFTAG_SAMPLESPERPIXEL,1)) goto bad; } } }  if (td->td_photometric == PHOTOMETRIC_PALETTE && !TIFFFieldSet(tif, FIELD_COLORMAP)) { MissingRequired(tif, \"Colormap\"); goto bad; }  if (td->td_compression!=COMPRESSION_OJPEG) {  if (!TIFFFieldSet(tif, FIELD_STRIPBYTECOUNTS)) {  if ((td->td_planarconfig == PLANARCONFIG_CONTIG && td->td_nstrips > 1) || (td->td_planarconfig == PLANARCONFIG_SEPARATE &&  td->td_nstrips != td->td_samplesperpixel)) { MissingRequired(tif, \"StripByteCounts\"); goto bad; } TIFFWarningExt(tif->tif_clientdata, module, \"%s: TIFF directory is missing required \" \"\\\"%s\\\" field, calculating from imagelength\", tif->tif_name, _TIFFFieldWithTag(tif,TIFFTAG_STRIPBYTECOUNTS)->field_name); if (EstimateStripByteCounts(tif, dir, dircount) < 0) goto bad;  #defineBYTECOUNTLOOKSBAD \\ ( (td->td_stripbytecount[0] == 0 && td->td_stripoffset[0] != 0) || \\ (td->td_compression == COMPRESSION_NONE && \\  td->td_stripbytecount[0] > TIFFGetFileSize(tif) - td->td_stripoffset[0]) || \\ (tif->tif_mode == O_RDONLY && \\  td->td_compression == COMPRESSION_NONE && \\  td->td_stripbytecount[0] < TIFFScanlineSize(tif) * td->td_imagelength) ) } else if (td->td_nstrips == 1  && td->td_stripoffset[0] != 0  && BYTECOUNTLOOKSBAD) {  TIFFWarningExt(tif->tif_clientdata, module, \"%s: Bogus \\\"%s\\\" field, ignoring and calculating from imagelength\", tif->tif_name, _TIFFFieldWithTag(tif,TIFFTAG_STRIPBYTECOUNTS)->field_name); if(EstimateStripByteCounts(tif, dir, dircount) < 0) goto bad; } else if (td->td_planarconfig == PLANARCONFIG_CONTIG  && td->td_nstrips > 2  && td->td_compression == COMPRESSION_NONE  && td->td_stripbytecount[0] != td->td_stripbytecount[1]  && td->td_stripbytecount[0] != 0   && td->td_stripbytecount[1] != 0 ) {  TIFFWarningExt(tif->tif_clientdata, module, \"%s: Wrong \\\"%s\\\" field, ignoring and calculating from imagelength\", tif->tif_name, _TIFFFieldWithTag(tif,TIFFTAG_STRIPBYTECOUNTS)->field_name); if (EstimateStripByteCounts(tif, dir, dircount) < 0) goto bad; } } if (dir) { _TIFFfree((char *)dir); dir = NULL; } if (!TIFFFieldSet(tif, FIELD_MAXSAMPLEVALUE)) td->td_maxsamplevalue = (uint16)((1L<<td->td_bitspersample)-1);   if (td->td_nstrips > 1) { tstrip_t strip; td->td_stripbytecountsorted = 1; for (strip = 1; strip < td->td_nstrips; strip++) { if (td->td_stripoffset[strip - 1] > td->td_stripoffset[strip]) { td->td_stripbytecountsorted = 0; break; } } } if (!TIFFFieldSet(tif, FIELD_COMPRESSION)) TIFFSetField(tif, TIFFTAG_COMPRESSION, COMPRESSION_NONE);  if (td->td_nstrips == 1 && td->td_compression == COMPRESSION_NONE && (tif->tif_flags & (TIFF_STRIPCHOP|TIFF_ISTILED)) == TIFF_STRIPCHOP) ChopUpSingleUncompressedStrip(tif);  tif->tif_row = (uint32) -1; tif->tif_curstrip = (tstrip_t) -1; tif->tif_col = (uint32) -1; tif->tif_curtile = (ttile_t) -1; tif->tif_tilesize = (tsize_t) -1; tif->tif_scanlinesize = TIFFScanlineSize(tif); if (!tif->tif_scanlinesize) { TIFFErrorExt(tif->tif_clientdata, module,  \"%s: cannot handle zero scanline size\",  tif->tif_name); return (0); } if (isTiled(tif)) { tif->tif_tilesize = TIFFTileSize(tif); if (!tif->tif_tilesize) { TIFFErrorExt(tif->tif_clientdata, module,  \"%s: cannot handle zero tile size\",  tif->tif_name); return (0); } } else { if (!TIFFStripSize(tif)) { TIFFErrorExt(tif->tif_clientdata, module,  \"%s: cannot handle zero strip size\",  tif->tif_name); return (0); } } return (1); bad: if (dir) _TIFFfree(dir); return (0); }", "target": 1, "idx": 100756, "project": "LibTIFF"}
{"func": "void domain_vgic_free(struct domain *d) { struct vgic_dist *dist = &d->arch.vgic; int i, ret; for ( i = 0; i < dist->nr_spis; i++ ) { struct vgic_irq *irq = vgic_get_irq(d, NULL, 32 + i); if ( !irq->hw ) continue; ret = release_guest_irq(d, irq->hwintid); if ( ret ) dprintk(XENLOG_G_WARNING, \"d%u: Failed to release virq %u ret = %d\\n\", d->domain_id, 32 + i, ret); } dist->ready = false; dist->initialized = false; xfree(dist->spis); xfree(dist->allocated_irqs); dist->nr_spis = 0; }", "target": 0, "idx": 106672, "project": "Xen"}
{"func": "static void message__print_file_lineno(struct message *self) { struct file_line *fl = self->files; putchar('\\n'); if (self->option != NULL) printf(\"# %s:00000\\n\", self->option); printf(\"#: %s:%d\", fl->file, fl->lineno); fl = fl->next; while (fl != NULL) { printf(\", %s:%d\", fl->file, fl->lineno); fl = fl->next; } putchar('\\n'); }", "target": 0, "idx": 103013, "project": "Xen"}
{"func": "void xenstat_free_node(xenstat_node * node) { int i; if (node) { if (node->domains) { for (i = 0; i < node->num_domains; i++) free(node->domains[i].name); for (i = 0; i < NUM_COLLECTORS; i++) if((node->flags & collectors[i].flag)  == collectors[i].flag) collectors[i].free(node); free(node->domains); } free(node); } }", "target": 0, "idx": 108361, "project": "Xen"}
{"func": "int xc_memshr_debug_gfn(xc_interface *xch, uint32_t domid, unsigned long gfn) { xen_mem_sharing_op_t mso; memset(&mso, 0, sizeof(mso)); mso.op = XENMEM_sharing_op_debug_gfn; mso.u.debug.u.gfn = gfn;  return xc_memshr_memop(xch, domid, &mso); }", "target": 0, "idx": 107541, "project": "Xen"}
{"func": "static int computeOutputPixelOffsets (struct crop_mask *crop, struct image_data *image,  struct pagedef *page, struct pageseg *sections,  struct dump_opts* dump) { double scale; double pwidth, plength; uint32 iwidth, ilength; uint32 owidth, olength; uint32 orows, ocols;  uint32 hmargin, vmargin;  uint32 x1, x2, y1, y2, line_bytes;  uint32 i, j, k; scale = 1.0; if (page->res_unit == RESUNIT_NONE) page->res_unit = image->res_unit; switch (image->res_unit) { case RESUNIT_CENTIMETER:  if (page->res_unit == RESUNIT_INCH)  scale = 1.0/2.54;  break; case RESUNIT_INCH:  if (page->res_unit == RESUNIT_CENTIMETER)  scale = 2.54;  break; case RESUNIT_NONE:  default: break; }  if (crop->combined_width > 0) iwidth = crop->combined_width; else iwidth = image->width; if (crop->combined_length > 0) ilength = crop->combined_length; else ilength = image->length; if (page->hres <= 1.0) page->hres = image->xres; if (page->vres <= 1.0) page->vres = image->yres; if ((page->hres < 1.0) || (page->vres < 1.0)) { TIFFError(\"computeOutputPixelOffsets\", \"Invalid horizontal or vertical resolution specified or read from input image\"); return (1); }  if (page->width <= 0) pwidth = iwidth; else pwidth = page->width; if (page->length <= 0) plength = ilength; else plength = page->length; if (dump->debug) { TIFFError(\"\", \"Page size: %s, Vres: %3.2f, Hres: %3.2f, \"  \"Hmargin: %3.2f, Vmargin: %3.2f\",  page->name, page->vres, page->hres,  page->hmargin, page->vmargin); TIFFError(\"\", \"Res_unit: %d, Scale: %3.2f, Page width: %3.2f, length: %3.2f\",   page->res_unit, scale, pwidth, plength); }  if (page->mode & PAGE_MODE_MARGINS) { if (page->res_unit == RESUNIT_INCH || page->res_unit == RESUNIT_CENTIMETER) {  hmargin = (uint32)(page->hmargin * scale * page->hres * ((image->bps + 7)/ 8)); vmargin = (uint32)(page->vmargin * scale * page->vres * ((image->bps + 7)/ 8)); } else {  hmargin = (uint32)(page->hmargin * scale * ((image->bps + 7)/ 8)); vmargin = (uint32)(page->vmargin * scale * ((image->bps + 7)/ 8)); } if ((hmargin * 2.0) > (pwidth * page->hres)) { TIFFError(\"computeOutputPixelOffsets\",  \"Combined left and right margins exceed page width\"); hmargin = (uint32) 0; return (-1); } if ((vmargin * 2.0) > (plength * page->vres)) { TIFFError(\"computeOutputPixelOffsets\",  \"Combined top and bottom margins exceed page length\");  vmargin = (uint32) 0;  return (-1); } } else { hmargin = 0; vmargin = 0; } if (page->mode & PAGE_MODE_ROWSCOLS ) {  if (page->mode & PAGE_MODE_MARGINS) TIFFError(\"computeOutputPixelOffsets\",  \"Output margins cannot be specified with rows and columns\");  owidth= TIFFhowmany(iwidth, page->cols); olength = TIFFhowmany(ilength, page->rows); } else { if (page->mode & PAGE_MODE_PAPERSIZE ) { owidth= (uint32)((pwidth * page->hres) - (hmargin * 2)); olength = (uint32)((plength * page->vres) - (vmargin * 2)); } else { owidth = (uint32)(iwidth - (hmargin * 2 * page->hres)); olength = (uint32)(ilength - (vmargin * 2 * page->vres)); } } if (owidth > iwidth) owidth = iwidth; if (olength > ilength) olength = ilength;  switch (page->orient) { case ORIENTATION_NONE: case ORIENTATION_PORTRAIT:  ocols = TIFFhowmany(iwidth, owidth);  orows = TIFFhowmany(ilength, olength);    break; case ORIENTATION_LANDSCAPE:  ocols = TIFFhowmany(iwidth, olength);  orows = TIFFhowmany(ilength, owidth);  x1 = olength;  olength = owidth;  owidth = x1;    break; case ORIENTATION_AUTO: default:  x1 = TIFFhowmany(iwidth, owidth);  x2 = TIFFhowmany(ilength, olength);   y1 = TIFFhowmany(iwidth, olength);  y2 = TIFFhowmany(ilength, owidth);   if ( (x1 * x2) < (y1 * y2))  {   ocols = x1;  orows = x2;    }  else  {   ocols = y1;  orows = y2;  x1 = olength;  olength = owidth;  owidth = x1;    } } if (ocols < 1) ocols = 1; if (orows < 1) orows = 1;  if (page->rows < 1) page->rows = orows; if (page->cols < 1) page->cols = ocols; line_bytes = TIFFhowmany8(owidth * image->bps) * image->spp; if ((page->rows * page->cols) > MAX_SECTIONS)  {  TIFFError(\"computeOutputPixelOffsets\",  \"Rows and Columns exceed maximum sections\\nIncrease resolution or reduce sections\");  return (-1);  }  for (k = 0, i = 0 && k <= MAX_SECTIONS; i < orows; i++) { y1 = (uint32)(olength * i); y2 = (uint32)(olength * (i +1) - 1); if (y2 >= ilength) y2 = ilength - 1; for (j = 0; j < ocols; j++, k++) { x1 = (uint32)(owidth * j);  x2 = (uint32)(owidth * (j + 1) - 1); if (x2 >= iwidth) x2 = iwidth - 1; sections[k].x1 = x1; sections[k].x2 = x2; sections[k].y1 = y1; sections[k].y2 = y2; sections[k].buffsize = line_bytes * olength; sections[k].position = k + 1; sections[k].total = orows * ocols; }  }  return (0); } ", "target": 0, "idx": 100434, "project": "LibTIFF"}
{"func": "static int iso9660_mount (fsi_file_t *ffi, const char *options) { unsigned int sector;  #if 0 if ((current_partition != 0xFFFFFF) && !IS_PC_SLICE_TYPE_BSD_WITH_FS(current_slice, FS_ISO9660)) return 0; #endif  for (sector = 16 ; sector < 32 ; sector++) { if (!iso9660_devread(ffi, sector, 0, sizeof(*PRIMDESC), (char *)PRIMDESC))  break;  if (PRIMDESC->type.l == ISO_VD_PRIMARY && !memcmp(PRIMDESC->id, ISO_STANDARD_ID, sizeof(PRIMDESC->id))) { ISO_SUPER->vol_sector = sector; INODE->file_start = 0; #if 0 fsmax = PRIMDESC->volume_space_size.l; #endif return 1; } } return 0; }", "target": 0, "idx": 102147, "project": "Xen"}
{"func": "void libxl__ev_fd_deregister(libxl__gc *gc, libxl__ev_fd *ev) { CTX_LOCK; libxl__poller *poller; if (!libxl__ev_fd_isregistered(ev)) { DBG(\"ev_fd=%p deregister unregistered\",ev); goto out; } DBG(\"ev_fd=%p deregister fd=%d\", ev, ev->fd); OSEVENT_HOOK_VOID(fd,deregister, release, ev->fd, ev->nexus->for_app_reg); LIBXL_LIST_REMOVE(ev, entry); ev->fd = -1; LIBXL_LIST_FOREACH(poller, &CTX->pollers_fds_changed, fds_changed_entry) poller->fds_changed = 1;  out: CTX_UNLOCK; }", "target": 0, "idx": 103642, "project": "Xen"}
{"func": "value add_event(value event_list, short event) { CAMLparam1(event_list); CAMLlocal1(new_list); new_list = caml_alloc(2, 0); Store_field(new_list, 0, Val_poll(event)); Store_field(new_list, 1, event_list); CAMLreturn(new_list); }", "target": 0, "idx": 108211, "project": "Xen"}
{"func": " */ void xlu__disk_yypush_buffer_state (YY_BUFFER_STATE new_buffer , yyscan_t yyscanner) { struct yyguts_t * yyg = (struct yyguts_t*)yyscanner; if (new_buffer == NULL) return; xlu__disk_yyensure_buffer_stack(yyscanner);  if ( YY_CURRENT_BUFFER ) {  *yyg->yy_c_buf_p = yyg->yy_hold_char; YY_CURRENT_BUFFER_LVALUE->yy_buf_pos = yyg->yy_c_buf_p; YY_CURRENT_BUFFER_LVALUE->yy_n_chars = yyg->yy_n_chars; }  if (YY_CURRENT_BUFFER) yyg->yy_buffer_stack_top++; YY_CURRENT_BUFFER_LVALUE = new_buffer;  xlu__disk_yy_load_buffer_state(yyscanner ); yyg->yy_did_buffer_switch_on_eof = 1; }", "target": 0, "idx": 103268, "project": "Xen"}
{"func": "int xc_core_arch_memory_map_get(xc_interface *xch, struct xc_core_arch_context *unused, xc_dominfo_t *info, shared_info_any_t *live_shinfo, xc_core_memory_map_t **mapp, unsigned int *nr_entries) { xen_pfn_t p2m_size = 0; xc_core_memory_map_t *map; if ( xc_domain_nr_gpfns(xch, info->domid, &p2m_size) < 0 ) return -1; map = malloc(sizeof(*map)); if ( map == NULL ) { PERROR(\"Could not allocate memory\"); return -1; } map->addr = 0; map->size = ((uint64_t)p2m_size) << PAGE_SHIFT; *mapp = map; *nr_entries = 1; return 0; }", "target": 0, "idx": 107330, "project": "Xen"}
{"func": "int hvm_mmio_intercept(ioreq_t *p) { struct vcpu *v = current; int i; for ( i = 0; i < HVM_MMIO_HANDLER_NR; i++ ) if ( hvm_mmio_handlers[i]->check_handler(v, p->addr) ) return hvm_mmio_access( v, p, hvm_mmio_handlers[i]->read_handler, hvm_mmio_handlers[i]->write_handler); return X86EMUL_UNHANDLEABLE; }", "target": 1, "idx": 109237, "project": "Xen"}
{"func": "void libxl__ev_xswatch_deregister(libxl__gc *gc, libxl__ev_xswatch *w) {  CTX_LOCK; if (w->slotnum >= 0) { const char *token = watch_token(gc, w->slotnum, w->counterval); LOG(DEBUG, \"watch w=%p wpath=%s token=%s: deregister slotnum=%d\", w, w->path, token, w->slotnum); if (!xs_unwatch(CTX->xsh, w->path, token))  LOGEV(ERROR, errno, \"remove watch for path %s\", w->path); libxl__ev_watch_slot *slot = &CTX->watch_slots[w->slotnum]; LIBXL_SLIST_INSERT_HEAD(&CTX->watch_freeslots, slot, empty); w->slotnum = -1; CTX->nwatches--; watches_check_fd_deregister(gc); } else { LOG(DEBUG, \"watch w=%p: deregister unregistered\", w); } free(w->path); w->path = NULL; CTX_UNLOCK; }", "target": 0, "idx": 103648, "project": "Xen"}
{"func": "int xc_hvm_set_mem_type( xc_interface *xch, uint32_t domid, hvmmem_type_t type, uint64_t first_pfn, uint32_t nr) { return xendevicemodel_set_mem_type(xch->dmod, domid, type, first_pfn,  nr); }", "target": 0, "idx": 107370, "project": "Xen"}
{"func": " */ void gicv3_do_LPI(unsigned int lpi) { struct domain *d; union host_lpi *hlpip, hlpi; irq_enter();  WRITE_SYSREG32(lpi, ICC_EOIR1_EL1);  hlpip = gic_get_host_lpi(lpi); if ( !hlpip ) goto out; hlpi.data = read_u64_atomic(&hlpip->data);  if ( hlpi.virt_lpi == INVALID_LPI ) goto out; d = rcu_lock_domain_by_id(hlpi.dom_id); if ( !d ) goto out;  vgic_vcpu_inject_lpi(d, hlpi.virt_lpi); rcu_unlock_domain(d); out: irq_exit(); }", "target": 0, "idx": 102475, "project": "Xen"}
{"func": "static void bootloader_stop(libxl__egc *egc,  libxl__bootloader_state *bl, int rc) { STATE_AO_GC(bl->ao); int r; libxl__datacopier_kill(&bl->keystrokes); libxl__datacopier_kill(&bl->display); if (libxl__ev_child_inuse(&bl->child)) { r = kill(bl->child.pid, SIGTERM); if (r) LOGED(WARN, bl->domid, \"%sfailed to kill bootloader [%lu]\",  rc ? \"after failure, \" : \"\", (unsigned long)bl->child.pid); } if (!bl->rc) bl->rc = rc; }", "target": 0, "idx": 103369, "project": "Xen"}
{"func": "static void doexec(const char *cmd, const char *arg1, const char *arg2) { dodebug(\"exec %s %s %s\", cmd, arg1, arg2); switch(vfork()) { case -1: dolog(LOG_ERR, \"can't vfork: %s\", strerror(errno)); break; case 0: execl(cmd, cmd, arg1, arg2, NULL); dolog(LOG_ERR, \"can't exec %s: %s\", cmd, strerror(errno)); exit(EXIT_FAILURE);  break; default: wait(NULL); break; } }", "target": 0, "idx": 108134, "project": "Xen"}
{"func": "static int __acquire_grant_for_copy( struct domain *rd, unsigned long gref, domid_t ldom, int readonly, unsigned long *frame, struct page_info **page,  unsigned *page_off, unsigned *length, unsigned allow_transitive) { struct grant_table *rgt = rd->grant_table; grant_entry_v1_t *sha1; grant_entry_v2_t *sha2; grant_entry_header_t *shah; struct active_grant_entry *act; grant_status_t *status; uint32_t old_pin; domid_t trans_domid; grant_ref_t trans_gref; struct domain *td; unsigned long grant_frame; unsigned trans_page_off; unsigned trans_length; int is_sub_page; s16 rc = GNTST_okay; *page = NULL; spin_lock(&rgt->lock); if ( rgt->gt_version == 0 ) PIN_FAIL(unlock_out, GNTST_general_error,  \"remote grant table not ready\\n\"); if ( unlikely(gref >= nr_grant_entries(rgt)) ) PIN_FAIL(unlock_out, GNTST_bad_gntref,  \"Bad grant reference %ld\\n\", gref); act = &active_entry(rgt, gref); shah = shared_entry_header(rgt, gref); if ( rgt->gt_version == 1 ) { sha1 = &shared_entry_v1(rgt, gref); sha2 = NULL; status = &shah->flags; } else { sha1 = NULL; sha2 = &shared_entry_v2(rgt, gref); status = &status_entry(rgt, gref); }  if ( act->pin && ((act->domid != ldom) || (act->pin & 0x80808080U) != 0) ) PIN_FAIL(unlock_out, GNTST_general_error,  \"Bad domain (%d != %d), or risk of counter overflow %08x\\n\",  act->domid, ldom, act->pin); old_pin = act->pin; if ( !act->pin ||  (!readonly && !(act->pin & (GNTPIN_devw_mask|GNTPIN_hstw_mask))) ) { if ( (rc = _set_status(rgt->gt_version, ldom,  readonly, 0, shah, act,  status) ) != GNTST_okay )  goto unlock_out; td = rd; trans_gref = gref; if ( sha2 && (shah->flags & GTF_type_mask) == GTF_transitive ) { if ( !allow_transitive ) PIN_FAIL(unlock_out_clear, GNTST_general_error,  \"transitive grant when transitivity not allowed\\n\"); trans_domid = sha2->transitive.trans_domid; trans_gref = sha2->transitive.gref; barrier();  if ( trans_domid == rd->domain_id ) PIN_FAIL(unlock_out_clear, GNTST_general_error,  \"transitive grants cannot be self-referential\\n\");   td = rcu_lock_domain_by_id(trans_domid); if ( td == NULL ) PIN_FAIL(unlock_out_clear, GNTST_general_error,  \"transitive grant referenced bad domain %d\\n\",  trans_domid); spin_unlock(&rgt->lock); rc = __acquire_grant_for_copy(td, trans_gref, rd->domain_id, readonly, &grant_frame, page, &trans_page_off, &trans_length, 0); spin_lock(&rgt->lock); if ( rc != GNTST_okay ) { __fixup_status_for_copy_pin(act, status); rcu_unlock_domain(td); spin_unlock(&rgt->lock); return rc; }  if ( act->pin != old_pin ) { __fixup_status_for_copy_pin(act, status); rcu_unlock_domain(td); spin_unlock(&rgt->lock); put_page(*page); return __acquire_grant_for_copy(rd, gref, ldom, readonly, frame, page, page_off, length, allow_transitive); }  is_sub_page = 1; act->gfn = -1ul; } else if ( sha1 ) { rc = __get_paged_frame(sha1->frame, &grant_frame, page, readonly, rd); if ( rc != GNTST_okay ) goto unlock_out_clear; act->gfn = sha1->frame; is_sub_page = 0; trans_page_off = 0; trans_length = PAGE_SIZE; } else if ( !(sha2->hdr.flags & GTF_sub_page) ) { rc = __get_paged_frame(sha2->full_page.frame, &grant_frame, page, readonly, rd); if ( rc != GNTST_okay ) goto unlock_out_clear; act->gfn = sha2->full_page.frame; is_sub_page = 0; trans_page_off = 0; trans_length = PAGE_SIZE; } else { rc = __get_paged_frame(sha2->sub_page.frame, &grant_frame, page, readonly, rd); if ( rc != GNTST_okay ) goto unlock_out_clear; act->gfn = sha2->sub_page.frame; is_sub_page = 1; trans_page_off = sha2->sub_page.page_off; trans_length = sha2->sub_page.length; } if ( !act->pin ) { act->domid = ldom; act->is_sub_page = is_sub_page; act->start = trans_page_off; act->length = trans_length; act->trans_domain = td; act->trans_gref = trans_gref; act->frame = grant_frame; } } else { ASSERT(mfn_valid(act->frame)); *page = mfn_to_page(act->frame); (void)page_get_owner_and_reference(*page); } act->pin += readonly ? GNTPIN_hstr_inc : GNTPIN_hstw_inc; *page_off = act->start; *length = act->length; *frame = act->frame; spin_unlock(&rgt->lock); return rc;    unlock_out_clear: if ( !(readonly) &&  !(act->pin & GNTPIN_hstw_mask) ) gnttab_clear_flag(_GTF_writing, status); if ( !act->pin ) gnttab_clear_flag(_GTF_reading, status);  unlock_out: spin_unlock(&rgt->lock); return rc; }", "target": 1, "idx": 109549, "project": "Xen"}
{"func": "int get_cpufreq_ondemand_para(uint32_t *sampling_rate_max, uint32_t *sampling_rate_min, uint32_t *sampling_rate, uint32_t *up_threshold) { if (!sampling_rate_max || !sampling_rate_min || !sampling_rate || !up_threshold) return -EINVAL; *sampling_rate_max = MAX_SAMPLING_RATE/MICROSECS(1); *sampling_rate_min = MIN_SAMPLING_RATE/MICROSECS(1); *sampling_rate = dbs_tuners_ins.sampling_rate / MICROSECS(1); *up_threshold = dbs_tuners_ins.up_threshold; return 0; }", "target": 0, "idx": 101523, "project": "Xen"}
{"func": "static set_debug_port_t __read_mostly set_debug_port = default_set_debug_port; static void nvidia_set_debug_port(struct ehci_dbgp *dbgp, unsigned int port) { u32 dword = pci_conf_read32(0, dbgp->bus, dbgp->slot, dbgp->func, 0x74); dword &= ~(0x0f << 12); dword |= (port & 0x0f) << 12; pci_conf_write32(0, dbgp->bus, dbgp->slot, dbgp->func, 0x74, dword); dbgp_printk(\"set debug port to %u\\n\", port); }", "target": 0, "idx": 101853, "project": "Xen"}
{"func": "void libxl_device_nic_list_free(libxl_device_nic* list, int num) { libxl__device_list_free(&libxl__nic_devtype, list, num); }", "target": 0, "idx": 103791, "project": "Xen"}
{"func": "void helper_transmitmsg(unsigned char *msg_freed, int len_in, void *user) { assert(len_in < 64*1024); uint16_t len = len_in; transmit((const void*)&len, sizeof(len), user); transmit(msg_freed, len, user); free(msg_freed); }", "target": 0, "idx": 103960, "project": "Xen"}
{"func": "static int amd_vpmu_load(struct vcpu *v, bool_t from_guest) { struct vpmu_struct *vpmu = vcpu_vpmu(v); struct xen_pmu_amd_ctxt *ctxt; uint64_t *ctrl_regs; unsigned int i; vpmu_reset(vpmu, VPMU_FROZEN); if ( !from_guest && vpmu_is_set(vpmu, VPMU_CONTEXT_LOADED) ) { ctxt = vpmu->context; ctrl_regs = vpmu_reg_pointer(ctxt, ctrls); for ( i = 0; i < num_counters; i++ ) wrmsrl(ctrls[i], ctrl_regs[i]); return 0; } if ( from_guest ) { bool_t is_running = 0; struct xen_pmu_amd_ctxt *guest_ctxt = &vpmu->xenpmu_data->pmu.c.amd; ASSERT(!has_vlapic(v->domain)); ctxt = vpmu->context; ctrl_regs = vpmu_reg_pointer(ctxt, ctrls); memcpy(&ctxt->regs[0], &guest_ctxt->regs[0], regs_sz); for ( i = 0; i < num_counters; i++ ) { if ( (ctrl_regs[i] & CTRL_RSVD_MASK) != ctrl_rsvd[i] ) {  amd_vpmu_init_regs(ctxt); return -EINVAL; } if ( is_pmu_enabled(ctrl_regs[i]) ) is_running = 1; } if ( is_running ) vpmu_set(vpmu, VPMU_RUNNING); else vpmu_reset(vpmu, VPMU_RUNNING); } vpmu_set(vpmu, VPMU_CONTEXT_LOADED); context_load(v); return 0; }", "target": 0, "idx": 107110, "project": "Xen"}
{"func": "static void feature_detect(void *info) { struct cpufreq_policy *policy = info; unsigned int edx; if ( cpu_has_aperfmperf ) { policy->aperf_mperf = 1; powernow_cpufreq_driver.getavg = get_measured_perf; } edx = cpuid_edx(CPUID_FREQ_VOLT_CAPABILITIES); if ((edx & CPB_CAPABLE) == CPB_CAPABLE) { policy->turbo = CPUFREQ_TURBO_ENABLED; if (cpufreq_verbose) printk(XENLOG_INFO  \"CPU%u: Core Boost/Turbo detected and enabled\\n\",  smp_processor_id()); } }", "target": 0, "idx": 105152, "project": "Xen"}
{"func": "int libxl_domain_sched_params_set(libxl_ctx *ctx, uint32_t domid, const libxl_domain_sched_params *scinfo) { GC_INIT(ctx); libxl_scheduler sched = scinfo->sched; int ret; if (sched == LIBXL_SCHEDULER_UNKNOWN) sched = libxl__domain_scheduler(gc, domid); switch (sched) { case LIBXL_SCHEDULER_SEDF: LOGD(ERROR, domid, \"SEDF scheduler no longer available\"); ret=ERROR_FEATURE_REMOVED; break; case LIBXL_SCHEDULER_CREDIT: ret=sched_credit_domain_set(gc, domid, scinfo); break; case LIBXL_SCHEDULER_CREDIT2: ret=sched_credit2_domain_set(gc, domid, scinfo); break; case LIBXL_SCHEDULER_ARINC653: ret=sched_arinc653_domain_set(gc, domid, scinfo); break; case LIBXL_SCHEDULER_RTDS: ret=sched_rtds_domain_set(gc, domid, scinfo); break; case LIBXL_SCHEDULER_NULL: ret=sched_null_domain_set(gc, domid, scinfo); break; default: LOGD(ERROR, domid, \"Unknown scheduler\"); ret=ERROR_INVAL; break; } GC_FREE; return ret; }", "target": 0, "idx": 103971, "project": "Xen"}
{"func": "int xc_evtchn_fd(xc_evtchn *xce) { return xenevtchn_fd(xce); }", "target": 0, "idx": 107470, "project": "Xen"}
{"func": "EXPORT_SYMBOL_GPL(balloon_update_driver_allowance); void balloon_release_driver_page(struct page *page) {  }", "target": 0, "idx": 108594, "project": "Xen"}
{"func": "unsigned int xenstat_domain_num_vcpus(xenstat_domain * domain) { return domain->num_vcpus; }", "target": 0, "idx": 108352, "project": "Xen"}
{"func": "int main() { TIFF*tif; size_ti; unsigned charbuf[SPP] = { 0, 127, 255 };  tif = TIFFOpen(filename, \"w\"); if (!tif) { fprintf (stderr, \"Can't create test TIFF file %s.\\n\", filename); return 1; } if (!TIFFSetField(tif, TIFFTAG_IMAGEWIDTH, width)) { fprintf (stderr, \"Can't set ImageWidth tag.\\n\"); goto failure; } if (!TIFFSetField(tif, TIFFTAG_IMAGELENGTH, length)) { fprintf (stderr, \"Can't set ImageLength tag.\\n\"); goto failure; } if (!TIFFSetField(tif, TIFFTAG_BITSPERSAMPLE, bps)) { fprintf (stderr, \"Can't set BitsPerSample tag.\\n\"); goto failure; } if (!TIFFSetField(tif, TIFFTAG_SAMPLESPERPIXEL, SPP)) { fprintf (stderr, \"Can't set SamplesPerPixel tag.\\n\"); goto failure; } if (!TIFFSetField(tif, TIFFTAG_ROWSPERSTRIP, rows_per_strip)) { fprintf (stderr, \"Can't set SamplesPerPixel tag.\\n\"); goto failure; } if (!TIFFSetField(tif, TIFFTAG_PLANARCONFIG, planarconfig)) { fprintf (stderr, \"Can't set PlanarConfiguration tag.\\n\"); goto failure; } if (!TIFFSetField(tif, TIFFTAG_PHOTOMETRIC, photometric)) { fprintf (stderr, \"Can't set PhotometricInterpretation tag.\\n\"); goto failure; } for (i = 0; i < NSINGLETAGS; i++) { if (!TIFFSetField(tif, short_single_tags[i].tag, short_single_tags[i].value)) { fprintf(stderr, \"Can't set tag %lu.\\n\", (unsigned long)short_single_tags[i].tag); goto failure; } } for (i = 0; i < NPAIREDTAGS; i++) { if (!TIFFSetField(tif, short_paired_tags[i].tag, short_paired_tags[i].values[0], short_paired_tags[i].values[1])) { fprintf(stderr, \"Can't set tag %lu.\\n\", (unsigned long)short_paired_tags[i].tag); goto failure; } }  if (TIFFWriteScanline(tif, buf, 0, 0) == -1) { fprintf (stderr, \"Can't write image data.\\n\"); goto failure; } TIFFClose(tif);  tif = TIFFOpen(filename, \"r\"); if (!tif) { fprintf (stderr, \"Can't open test TIFF file %s.\\n\", filename); return 1; } if (CheckLongField(tif, TIFFTAG_IMAGEWIDTH, width) < 0) goto failure; if (CheckLongField(tif, TIFFTAG_IMAGELENGTH, length) < 0) goto failure; if (CheckShortField(tif, TIFFTAG_BITSPERSAMPLE, bps) < 0) goto failure; if (CheckShortField(tif, TIFFTAG_PHOTOMETRIC, photometric) < 0) goto failure; if (CheckShortField(tif, TIFFTAG_SAMPLESPERPIXEL, SPP) < 0) goto failure; if (CheckLongField(tif, TIFFTAG_ROWSPERSTRIP, rows_per_strip) < 0) goto failure; if (CheckShortField(tif, TIFFTAG_PLANARCONFIG, planarconfig) < 0) goto failure; for (i = 0; i < NSINGLETAGS; i++) { if (CheckShortField(tif, short_single_tags[i].tag, short_single_tags[i].value) < 0) goto failure; } for (i = 0; i < NPAIREDTAGS; i++) { if (CheckShortPairedField(tif, short_paired_tags[i].tag, short_paired_tags[i].values) < 0) goto failure; } TIFFClose(tif);  unlink(filename); return 0; failure:  TIFFClose(tif); return 1; }", "target": 0, "idx": 100065, "project": "LibTIFF"}
{"func": "static void colo_suspend_primary_vm_done(libxl__egc *egc,  libxl__domain_suspend_state *dsps,  int rc) { libxl__domain_save_state *dss = CONTAINER_OF(dsps, *dss, dsps); EGC_GC; if (rc) { LOGD(ERROR, dss->domid, \"cannot suspend primary vm\"); goto out; }  libxl__checkpoint_devices_state *const cds = &dss->cds; cds->callback = colo_postsuspend_cb; libxl__checkpoint_devices_postsuspend(egc, cds); return; out: dss->rc = rc; libxl__xc_domain_saverestore_async_callback_done(egc, &dss->sws.shs, !rc); }", "target": 0, "idx": 103456, "project": "Xen"}
{"func": "static int __init proliant_quirk(struct dmi_system_id *d) { ioemul_handle_quirk = ioemul_handle_proliant_quirk; return 0; }", "target": 0, "idx": 102832, "project": "Xen"}
{"func": "static void nestedsvm_fpu_vmexit(struct vmcb_struct *n1vmcb, struct vmcb_struct *n2vmcb, uint64_t n1cr0, uint64_t guest_cr0) { if ( !(guest_cr0 & X86_CR0_TS) && (n2vmcb->_cr0 & X86_CR0_TS) ) {  n1vmcb->_cr0 |= X86_CR0_TS; n1vmcb->_exception_intercepts |= (1U << TRAP_no_device); } else if ( !(n1cr0 & X86_CR0_TS) && (n1vmcb->_cr0 & X86_CR0_TS) ) {  n1vmcb->_cr0 &= ~X86_CR0_TS; n1vmcb->_exception_intercepts &= ~(1U << TRAP_no_device); } }", "target": 0, "idx": 104772, "project": "Xen"}
{"func": "void xl_ctx_alloc(void) { if (libxl_ctx_alloc(&ctx, LIBXL_VERSION, 0, (xentoollog_logger*)logger)) { fprintf(stderr, \"cannot init xl context\\n\"); exit(1); } libxl_childproc_setmode(ctx, &childproc_hooks, 0); } }; void xl_ctx_alloc(void) { if (libxl_ctx_alloc(&ctx, LIBXL_VERSION, 0, (xentoollog_logger*)logger)) { fprintf(stderr, \"cannot init xl context\\n\"); exit(1); } libxl_childproc_setmode(ctx, &childproc_hooks, 0); }", "target": 0, "idx": 108648, "project": "Xen"}
{"func": "static inline void context_save(struct vcpu *v) { unsigned int i; struct vpmu_struct *vpmu = vcpu_vpmu(v); struct xen_pmu_amd_ctxt *ctxt = vpmu->context; uint64_t *counter_regs = vpmu_reg_pointer(ctxt, counters);  for ( i = 0; i < num_counters; i++ ) rdmsrl(counters[i], counter_regs[i]); }", "target": 0, "idx": 107114, "project": "Xen"}
{"func": "int main(int argc, char *argv[]) { int i, ret; if (argc < 2) { show_help(); return 0; } xch = xc_interface_open(0,0,0); if ( !xch ) { fprintf(stderr, \"failed to get the handler\\n\"); return 0; } for ( i = 0; i < ARRAY_SIZE(main_options); i++ ) if (!strncmp(main_options[i].name, argv[1], strlen(argv[1]))) break; if ( i == ARRAY_SIZE(main_options) ) { fprintf(stderr, \"Unrecognised command '%s' -- try \" \"'xen-hptool help'\\n\", argv[1]); return 1; } ret = main_options[i].function(argc -2, argv + 2); xc_interface_close(xch); return !!ret; }", "target": 0, "idx": 107860, "project": "Xen"}
{"func": "static int _wbinvd(struct x86_emulate_ctxt *ctxt) {  if ( !cache_flush_permitted(current->domain) )  ; else wbinvd(); return X86EMUL_OKAY; }", "target": 0, "idx": 101882, "project": "Xen"}
{"func": "void mem_pod_populate_process(struct pcpu_info *p) { struct record_info *ri = &p->ri; struct { uint64_t gfn, mfn; int d:16,order:16; } *r = (typeof(r))ri->d; if ( opt.dump_all ) { printf(\" %s pod_populate d%d o%d g %llx m %llx\\n\",  ri->dump_header,  r->d, r->order,  (unsigned long long)r->gfn, (unsigned long long)r->mfn); } if ( opt.summary_info ) { struct vcpu_data *v = p->current; struct domain_data *d; if ( v && (d=v->d) ) { int order; order = p2m_canonical_order(r->order); d->pod.populate_order[order]++; } } }", "target": 0, "idx": 108044, "project": "Xen"}
{"func": "static void colo_save_setup_failed(libxl__egc *egc,  libxl__checkpoint_devices_state *cds,  int rc) { libxl__colo_save_state *css = cds->concrete_data; libxl__domain_save_state *dss = CONTAINER_OF(css, *dss, css); STATE_AO_GC(cds->ao); if (rc) LOGD(ERROR, cds->domid,  \"COLO: failed to teardown device after setup failed\"  \" for guest, rc %d\", rc); cleanup_device_subkind(cds); dss->callback(egc, dss, rc); }", "target": 0, "idx": 103454, "project": "Xen"}
{"func": "static void __init __maybe_unused free_ebmalloc_unused_mem(void) { #if 0  unsigned long start, end; start = (unsigned long)ebmalloc_mem + PAGE_ALIGN(ebmalloc_allocated); end = (unsigned long)ebmalloc_mem + sizeof(ebmalloc_mem); destroy_xen_mappings(start, end); init_xenheap_pages(__pa(start), __pa(end)); printk(XENLOG_INFO \"Freed %lukB unused BSS memory\\n\", (end - start) >> 10); #endif }", "target": 0, "idx": 101239, "project": "Xen"}
{"func": "static int handle_pit_io( int dir, uint32_t port, uint32_t bytes, uint32_t *val) { struct PITState *vpit = vcpu_vpit(current); if ( bytes != 1 ) { gdprintk(XENLOG_WARNING, \"PIT bad access\\n\"); return X86EMUL_OKAY; } if ( dir == IOREQ_WRITE ) { pit_ioport_write(vpit, port, *val); } else { if ( (port & 3) != 3 ) *val = pit_ioport_read(vpit, port); else gdprintk(XENLOG_WARNING, \"PIT: read A1:A0=3!\\n\"); } return X86EMUL_OKAY; }", "target": 1, "idx": 109274, "project": "Xen"}
{"func": " */ static int its_handle_invall(struct virt_its *its, uint64_t *cmdptr) { uint32_t collid = its_cmd_get_collection(cmdptr); struct vcpu *vcpu; struct pending_irq *pirqs[16]; uint64_t vlpi = 0; unsigned int nr_lpis, i; unsigned long flags; int ret = 0;  ASSERT(is_hardware_domain(its->d));  if ( !its->d->arch.vgic.rdists_enabled ) return 0; spin_lock(&its->its_lock); vcpu = get_vcpu_from_collection(its, collid); spin_unlock(&its->its_lock); spin_lock_irqsave(&vcpu->arch.vgic.lock, flags); read_lock(&its->d->arch.vgic.pend_lpi_tree_lock); do { int err; nr_lpis = radix_tree_gang_lookup(&its->d->arch.vgic.pend_lpi_tree,  (void **)pirqs, vlpi,  ARRAY_SIZE(pirqs)); for ( i = 0; i < nr_lpis; i++ ) {  if ( pirqs[i]->lpi_vcpu_id != vcpu->vcpu_id ) continue; vlpi = pirqs[i]->irq;  err = update_lpi_property(its->d, pirqs[i]); if ( !err ) update_lpi_vgic_status(vcpu, pirqs[i]); else ret = err; }  } while ( (++vlpi < its->d->arch.vgic.nr_lpis) && (nr_lpis == ARRAY_SIZE(pirqs)) ); read_unlock(&its->d->arch.vgic.pend_lpi_tree_lock); spin_unlock_irqrestore(&vcpu->arch.vgic.lock, flags); return ret; }", "target": 0, "idx": 106720, "project": "Xen"}
{"func": " */ int mls_convert_context(struct policydb *oldp, struct policydb *newp, struct context *c) { struct level_datum *levdatum; struct cat_datum *catdatum; struct ebitmap bitmap; struct ebitmap_node *node; int l, i; if ( !flask_mls_enabled ) return 0; for ( l = 0; l < 2; l++ ) { levdatum = hashtab_search(newp->p_levels.table, oldp->p_sens_val_to_name[c->range.level[l].sens - 1]); if ( !levdatum ) return -EINVAL; c->range.level[l].sens = levdatum->level->sens; ebitmap_init(&bitmap); ebitmap_for_each_positive_bit(&c->range.level[l].cat, node, i) { int rc; catdatum = hashtab_search(newp->p_cats.table, oldp->p_cat_val_to_name[i]); if ( !catdatum ) return -EINVAL; rc = ebitmap_set_bit(&bitmap, catdatum->value - 1, 1); if ( rc ) return rc; } ebitmap_destroy(&c->range.level[l].cat); c->range.level[l].cat = bitmap; } return 0; }", "target": 0, "idx": 104615, "project": "Xen"}
{"func": "static void qos_kill_thread(int domid); static void init_current(int ncpu) { running = calloc(ncpu, sizeof(int)); NCPU = ncpu; printf(\"Initialized with %d %s\\n\", ncpu, (ncpu == 1) ? \"cpu\" : \"cpu's\"); }", "target": 0, "idx": 108150, "project": "Xen"}
{"func": "void discard_file_cache(xc_interface *xch, int fd, int flush) { off_t cur = 0; int saved_errno = errno; if ( flush && (fsync(fd) < 0) ) goto out;  if ( !flush ) { if ( (cur = lseek(fd, 0, SEEK_CUR)) == (off_t)-1 ) cur = 0; cur &= ~(XC_PAGE_SIZE-1); }  if ( posix_fadvise(fd, 0, cur, POSIX_FADV_DONTNEED) < 0 ) goto out;  out: errno = saved_errno; }", "target": 0, "idx": 107505, "project": "Xen"}
{"func": "static int _TIFFVGetField(TIFF* tif, uint32 tag, va_list ap) { TIFFDirectory* td = &tif->tif_dir; int ret_val = 1; uint32 standard_tag = tag; const TIFFField* fip = TIFFFindField(tif, tag, TIFF_ANY); if( fip == NULL )  return 0;   if (fip->field_bit == FIELD_CUSTOM) { standard_tag = 0; } switch (standard_tag) { case TIFFTAG_SUBFILETYPE: *va_arg(ap, uint32*) = td->td_subfiletype; break; case TIFFTAG_IMAGEWIDTH: *va_arg(ap, uint32*) = td->td_imagewidth; break; case TIFFTAG_IMAGELENGTH: *va_arg(ap, uint32*) = td->td_imagelength; break; case TIFFTAG_BITSPERSAMPLE: *va_arg(ap, uint16*) = td->td_bitspersample; break; case TIFFTAG_COMPRESSION: *va_arg(ap, uint16*) = td->td_compression; break; case TIFFTAG_PHOTOMETRIC: *va_arg(ap, uint16*) = td->td_photometric; break; case TIFFTAG_THRESHHOLDING: *va_arg(ap, uint16*) = td->td_threshholding; break; case TIFFTAG_FILLORDER: *va_arg(ap, uint16*) = td->td_fillorder; break; case TIFFTAG_ORIENTATION: *va_arg(ap, uint16*) = td->td_orientation; break; case TIFFTAG_SAMPLESPERPIXEL: *va_arg(ap, uint16*) = td->td_samplesperpixel; break; case TIFFTAG_ROWSPERSTRIP: *va_arg(ap, uint32*) = td->td_rowsperstrip; break; case TIFFTAG_MINSAMPLEVALUE: *va_arg(ap, uint16*) = td->td_minsamplevalue; break; case TIFFTAG_MAXSAMPLEVALUE: *va_arg(ap, uint16*) = td->td_maxsamplevalue; break; case TIFFTAG_SMINSAMPLEVALUE: if (tif->tif_flags & TIFF_PERSAMPLE) *va_arg(ap, double**) = td->td_sminsamplevalue; else {  uint16 i; double v = td->td_sminsamplevalue[0]; for (i=1; i < td->td_samplesperpixel; ++i) if( td->td_sminsamplevalue[i] < v ) v = td->td_sminsamplevalue[i]; *va_arg(ap, double*) = v; } break; case TIFFTAG_SMAXSAMPLEVALUE: if (tif->tif_flags & TIFF_PERSAMPLE) *va_arg(ap, double**) = td->td_smaxsamplevalue; else {  uint16 i; double v = td->td_smaxsamplevalue[0]; for (i=1; i < td->td_samplesperpixel; ++i) if( td->td_smaxsamplevalue[i] > v ) v = td->td_smaxsamplevalue[i]; *va_arg(ap, double*) = v; } break; case TIFFTAG_XRESOLUTION: *va_arg(ap, float*) = td->td_xresolution; break; case TIFFTAG_YRESOLUTION: *va_arg(ap, float*) = td->td_yresolution; break; case TIFFTAG_PLANARCONFIG: *va_arg(ap, uint16*) = td->td_planarconfig; break; case TIFFTAG_XPOSITION: *va_arg(ap, float*) = td->td_xposition; break; case TIFFTAG_YPOSITION: *va_arg(ap, float*) = td->td_yposition; break; case TIFFTAG_RESOLUTIONUNIT: *va_arg(ap, uint16*) = td->td_resolutionunit; break; case TIFFTAG_PAGENUMBER: *va_arg(ap, uint16*) = td->td_pagenumber[0]; *va_arg(ap, uint16*) = td->td_pagenumber[1]; break; case TIFFTAG_HALFTONEHINTS: *va_arg(ap, uint16*) = td->td_halftonehints[0]; *va_arg(ap, uint16*) = td->td_halftonehints[1]; break; case TIFFTAG_COLORMAP: *va_arg(ap, uint16**) = td->td_colormap[0]; *va_arg(ap, uint16**) = td->td_colormap[1]; *va_arg(ap, uint16**) = td->td_colormap[2]; break; case TIFFTAG_STRIPOFFSETS: case TIFFTAG_TILEOFFSETS: _TIFFFillStriles( tif ); *va_arg(ap, uint64**) = td->td_stripoffset; break; case TIFFTAG_STRIPBYTECOUNTS: case TIFFTAG_TILEBYTECOUNTS: _TIFFFillStriles( tif ); *va_arg(ap, uint64**) = td->td_stripbytecount; break; case TIFFTAG_MATTEING: *va_arg(ap, uint16*) = (td->td_extrasamples == 1 && td->td_sampleinfo[0] == EXTRASAMPLE_ASSOCALPHA); break; case TIFFTAG_EXTRASAMPLES: *va_arg(ap, uint16*) = td->td_extrasamples; *va_arg(ap, uint16**) = td->td_sampleinfo; break; case TIFFTAG_TILEWIDTH: *va_arg(ap, uint32*) = td->td_tilewidth; break; case TIFFTAG_TILELENGTH: *va_arg(ap, uint32*) = td->td_tilelength; break; case TIFFTAG_TILEDEPTH: *va_arg(ap, uint32*) = td->td_tiledepth; break; case TIFFTAG_DATATYPE: switch (td->td_sampleformat) { case SAMPLEFORMAT_UINT: *va_arg(ap, uint16*) = DATATYPE_UINT; break; case SAMPLEFORMAT_INT: *va_arg(ap, uint16*) = DATATYPE_INT; break; case SAMPLEFORMAT_IEEEFP: *va_arg(ap, uint16*) = DATATYPE_IEEEFP; break; case SAMPLEFORMAT_VOID: *va_arg(ap, uint16*) = DATATYPE_VOID; break; } break; case TIFFTAG_SAMPLEFORMAT: *va_arg(ap, uint16*) = td->td_sampleformat; break; case TIFFTAG_IMAGEDEPTH: *va_arg(ap, uint32*) = td->td_imagedepth; break; case TIFFTAG_SUBIFD: *va_arg(ap, uint16*) = td->td_nsubifd; *va_arg(ap, uint64**) = td->td_subifd; break; case TIFFTAG_YCBCRPOSITIONING: *va_arg(ap, uint16*) = td->td_ycbcrpositioning; break; case TIFFTAG_YCBCRSUBSAMPLING: *va_arg(ap, uint16*) = td->td_ycbcrsubsampling[0]; *va_arg(ap, uint16*) = td->td_ycbcrsubsampling[1]; break; case TIFFTAG_TRANSFERFUNCTION: *va_arg(ap, uint16**) = td->td_transferfunction[0]; if (td->td_samplesperpixel - td->td_extrasamples > 1) { *va_arg(ap, uint16**) = td->td_transferfunction[1]; *va_arg(ap, uint16**) = td->td_transferfunction[2]; } break; case TIFFTAG_REFERENCEBLACKWHITE: *va_arg(ap, float**) = td->td_refblackwhite; break; case TIFFTAG_INKNAMES: *va_arg(ap, char**) = td->td_inknames; break; default: { int i;  if( fip->field_bit != FIELD_CUSTOM ) { TIFFErrorExt(tif->tif_clientdata, \"_TIFFVGetField\", \"%s: Invalid %stag \\\"%s\\\" \" \"(not supported by codec)\", tif->tif_name, isPseudoTag(tag) ? \"pseudo-\" : \"\", fip->field_name); ret_val = 0; break; }  ret_val = 0; for (i = 0; i < td->td_customValueCount; i++) { TIFFTagValue *tv = td->td_customValues + i; if (tv->info->field_tag != tag) continue; if (fip->field_passcount) { if (fip->field_readcount == TIFF_VARIABLE2) *va_arg(ap, uint32*) = (uint32)tv->count; else *va_arg(ap, uint16*) = (uint16)tv->count; *va_arg(ap, void **) = tv->value; ret_val = 1; } else if (fip->field_tag == TIFFTAG_DOTRANGE  && strcmp(fip->field_name,\"DotRange\") == 0) {  *va_arg(ap, uint16*) = ((uint16 *)tv->value)[0]; *va_arg(ap, uint16*) = ((uint16 *)tv->value)[1]; ret_val = 1; } else { if (fip->field_type == TIFF_ASCII || fip->field_readcount == TIFF_VARIABLE || fip->field_readcount == TIFF_VARIABLE2 || fip->field_readcount == TIFF_SPP || tv->count > 1) { *va_arg(ap, void **) = tv->value; ret_val = 1; } else { char *val = (char *)tv->value; assert( tv->count == 1 ); switch (fip->field_type) { case TIFF_BYTE: case TIFF_UNDEFINED: *va_arg(ap, uint8*) = *(uint8 *)val; ret_val = 1; break; case TIFF_SBYTE: *va_arg(ap, int8*) = *(int8 *)val; ret_val = 1; break; case TIFF_SHORT: *va_arg(ap, uint16*) = *(uint16 *)val; ret_val = 1; break; case TIFF_SSHORT: *va_arg(ap, int16*) = *(int16 *)val; ret_val = 1; break; case TIFF_LONG: case TIFF_IFD: *va_arg(ap, uint32*) = *(uint32 *)val; ret_val = 1; break; case TIFF_SLONG: *va_arg(ap, int32*) = *(int32 *)val; ret_val = 1; break; case TIFF_LONG8: case TIFF_IFD8: *va_arg(ap, uint64*) = *(uint64 *)val; ret_val = 1; break; case TIFF_SLONG8: *va_arg(ap, int64*) = *(int64 *)val; ret_val = 1; break; case TIFF_RATIONAL: case TIFF_SRATIONAL: case TIFF_FLOAT: *va_arg(ap, float*) = *(float *)val; ret_val = 1; break; case TIFF_DOUBLE: *va_arg(ap, double*) = *(double *)val; ret_val = 1; break; default: ret_val = 0; break; } } } break; } } } return(ret_val); }", "target": 1, "idx": 100792, "project": "LibTIFF"}
{"func": "static int write_vtpmblk_raw(uint8_t *data, size_t data_length, int slot) {  int rc;  uint32_t lenbuf;  debug(\"Begin Write data=%p len=%u slot=%u ssize=%u\", data, data_length, slot, slot_size);  if (data_length > slot_size - 4) { error(\"vtpm data cannot fit in data slot (%d/%d).\", data_length, slot_size - 4); return -1;  }  lenbuf = cpu_to_be32((uint32_t)data_length);  lseek(blkfront_fd, slot * slot_size, SEEK_SET);  if((rc = write(blkfront_fd, (uint8_t*)&lenbuf, 4)) != 4) { error(\"write(length) failed! error was %s\", strerror(errno)); return -1;  }  if((rc = write(blkfront_fd, data, data_length)) != data_length) { error(\"write(data) failed! error was %s\", strerror(errno)); return -1;  }  info(\"Wrote %u bytes to NVM persistent storage\", data_length);  return 0; }", "target": 0, "idx": 107198, "project": "Xen"}
{"func": "static inline bool_t INIT rc_limit_exceeded(const struct rc_dec *rc) { return rc->in_pos > rc->in_limit; }", "target": 0, "idx": 101616, "project": "Xen"}
{"func": "static type_of_addr kernel_addr(guest_word_t addr) { if ( symbol_table == NULL ) { if ( addr > kernel_start ) return KERNEL_TEXT_ADDR; else return NOT_KERNEL_ADDR; } if (addr >= kernel_stext && addr <= kernel_etext) return KERNEL_TEXT_ADDR; if ( kernel_hypercallpage &&  (addr >= kernel_hypercallpage && addr <= kernel_hypercallpage + 4096) ) return KERNEL_TEXT_ADDR; if (addr >= kernel_sinittext && addr <= kernel_einittext) return KERNEL_TEXT_ADDR; if ( xenctx.kernel_start_set ) { if ( addr > kernel_start ) return KERNEL_TEXT_ADDR; } else { if ( addr >= kernel_text &&  addr <= kernel_end ) return KERNEL_DATA_ADDR; if ( addr >= kernel_start &&  addr <= kernel_end ) return KERNEL_TEXT_ADDR; } return NOT_KERNEL_ADDR; }", "target": 0, "idx": 108183, "project": "Xen"}
{"func": "static int load_payload_data(struct payload *payload, void *raw, size_t len) { struct livepatch_elf elf = { .name = payload->name, .len = len }; int rc = 0; rc = livepatch_elf_load(&elf, raw); if ( rc ) goto out; rc = move_payload(payload, &elf); if ( rc ) goto out; rc = livepatch_elf_resolve_symbols(&elf); if ( rc ) goto out; rc = livepatch_elf_perform_relocs(&elf); if ( rc ) goto out; rc = check_special_sections(&elf); if ( rc ) goto out; rc = prepare_payload(payload, &elf); if ( rc ) goto out; rc = build_symbol_table(payload, &elf); if ( rc ) goto out; rc = secure_payload(payload, &elf);  out: if ( rc ) free_payload_data(payload);  livepatch_elf_free(&elf); return rc; }", "target": 0, "idx": 104253, "project": "Xen"}
{"func": "void libxl__event_occurred(libxl__egc *egc, libxl_event *event) { EGC_GC; if (CTX->event_hooks && (CTX->event_hooks->event_occurs_mask & (1UL << event->type))) {  LIBXL_TAILQ_INSERT_TAIL(&egc->occurred_for_callback, event, link); return; } else { libxl__poller *poller; LIBXL_TAILQ_INSERT_TAIL(&CTX->occurred, event, link); LIBXL_LIST_FOREACH(poller, &CTX->pollers_event, entry) libxl__poller_wakeup(egc, poller); } }", "target": 0, "idx": 103638, "project": "Xen"}
{"func": "int get_driver_type(char *type) { int i; if (strnlen(type, 25) >= 25) return -ENAMETOOLONG; for (i = 0; i < TD_TYPE_INVALID; i++) if (!strcmp(type, td_disk_types[i])) return i; return -TD_TYPE_INVALID; }", "target": 0, "idx": 106358, "project": "Xen"}
{"func": "static TPM_RESULT vtpmmgr_GroupList(tpmcmd_t* tpmcmd) { CMD_BEGIN; UNPACK_DONE(); PACK_OUT(UINT32, g_mgr->nr_groups); CMD_END; }", "target": 0, "idx": 107217, "project": "Xen"}
{"func": "void gicv3_lpi_update_host_entry(uint32_t host_lpi, int domain_id,  uint32_t virt_lpi) { union host_lpi *hlpip, hlpi; ASSERT(host_lpi >= LPI_OFFSET); host_lpi -= LPI_OFFSET; hlpip = &lpi_data.host_lpis[host_lpi / HOST_LPIS_PER_PAGE][host_lpi % HOST_LPIS_PER_PAGE]; hlpi.virt_lpi = virt_lpi; hlpi.dom_id = domain_id; write_u64_atomic(&hlpip->data, hlpi.data); }", "target": 0, "idx": 102482, "project": "Xen"}
{"func": "static uint32_t vpci_ignored_read(const struct pci_dev *pdev, unsigned int reg, void *data) { return ~(uint32_t)0; }", "target": 0, "idx": 107083, "project": "Xen"}
{"func": "void console_start_log_everything(void) { serial_start_log_everything(sercon_handle); atomic_inc(&print_everything); }", "target": 0, "idx": 101414, "project": "Xen"}
{"func": "static void _print_IO_APIC_keyhandler(unsigned char key) { __print_IO_APIC(0); }", "target": 0, "idx": 102898, "project": "Xen"}
{"func": "static char *pointer(char *str, char *end, const char **fmt_ptr,  const void *arg, int field_width, int precision,  int flags) { const char *fmt = *fmt_ptr, *s;  switch ( fmt[1] ) { case 'h':  { const uint8_t *hex_buffer = arg; char sep = ' ';  unsigned int i;  ++*fmt_ptr;  if ( field_width <= 0 ) return str; if ( field_width > 64 ) field_width = 64;  switch ( fmt[2] ) { case 'C':  ++*fmt_ptr; sep = ':'; break; case 'D':  ++*fmt_ptr; sep = '-'; break; case 'N':  ++*fmt_ptr; sep = 0; break; } for ( i = 0; ; ) {  str = number(str, end, hex_buffer[i], 16, 2, -1, ZEROPAD); if ( ++i == field_width ) return str; if ( sep ) { if ( str < end ) *str = sep; ++str; } } } case 's':  case 'S':  { unsigned long sym_size, sym_offset; char namebuf[KSYM_NAME_LEN+1];  ++*fmt_ptr; s = symbols_lookup((unsigned long)arg, &sym_size, &sym_offset, namebuf);  if ( !s ) break;  str = string(str, end, s, -1, -1, 0); if ( fmt[1] == 'S' || sym_offset != 0 ) {  str = number(str, end, sym_offset, 16, -1, -1, SPECIAL|SIGN|PLUS); if ( str < end ) *str = '/'; ++str; str = number(str, end, sym_size, 16, -1, -1, SPECIAL); }  if ( namebuf != s ) { str = string(str, end, \" [\", -1, -1, 0); str = string(str, end, namebuf, -1, -1, 0); str = string(str, end, \"]\", -1, -1, 0); } return str; } case 'v':  { const struct vcpu *v = arg; ++*fmt_ptr; if ( unlikely(v->domain->domain_id == DOMID_IDLE) ) str = string(str, end, \"IDLE\", -1, -1, 0); else { if ( str < end ) *str = 'd'; str = number(str + 1, end, v->domain->domain_id, 10, -1, -1, 0); } if ( str < end ) *str = 'v'; return number(str + 1, end, v->vcpu_id, 10, -1, -1, 0); } } if ( field_width == -1 ) { field_width = 2 * sizeof(void *); flags |= ZEROPAD; } return number(str, end, (unsigned long)arg, 16, field_width, precision, flags); }", "target": 0, "idx": 107143, "project": "Xen"}
{"func": "int xc_get_cpuidle_max_cstate(xc_interface *xch, uint32_t *value) { int rc; DECLARE_SYSCTL; if ( !xch || !value ) { errno = EINVAL; return -1; } sysctl.cmd = XEN_SYSCTL_pm_op; sysctl.u.pm_op.cmd = XEN_SYSCTL_pm_op_get_max_cstate; sysctl.u.pm_op.cpuid = 0; sysctl.u.pm_op.u.get_max_cstate = 0; rc = do_sysctl(xch, &sysctl); *value = sysctl.u.pm_op.u.get_max_cstate; return rc; }", "target": 0, "idx": 107628, "project": "Xen"}
{"func": " */ static void wait_for_event_or_timeout(unsigned long milliseconds) { int rc; struct pollfd fd = { .fd = xenevtchn_fd(xce_handle),  .events = POLLIN | POLLERR }; int port; rc = poll(&fd, 1, milliseconds); if (rc == -1) { if (errno == EINTR) return; PERROR(\"poll exitted with an error\"); exit(EXIT_FAILURE); } if (rc == 1) { port = xenevtchn_pending(xce_handle); if (port == -1) { PERROR(\"failed to read port from evtchn\"); exit(EXIT_FAILURE); } if (port != virq_port) { fprintf(stderr, \"unexpected port returned from evtchn (got %d vs expected %d)\\n\", port, virq_port); exit(EXIT_FAILURE); } rc = xenevtchn_unmask(xce_handle, port); if (rc == -1) { PERROR(\"failed to write port to evtchn\"); exit(EXIT_FAILURE); } } }", "target": 0, "idx": 108576, "project": "Xen"}
{"func": "int xc_evtchn_status(xc_interface *xch, xc_evtchn_status_t *status) { return do_evtchn_op(xch, EVTCHNOP_status, status, sizeof(*status), 1); }", "target": 0, "idx": 107465, "project": "Xen"}
{"func": "int readextension(void) { int count; char buf[255]; int status = 1; (void) getc(infile); while ((count = getc(infile)) && count <= 255) if (fread(buf, 1, count, infile) != (size_t) count) { fprintf(stderr, \"short read from file %s (%s)\\n\", filename, strerror(errno)); status = 0; break; } return status; }", "target": 1, "idx": 100783, "project": "LibTIFF"}
{"func": "void tapdisk_server_add_vbd(td_vbd_t *vbd) { list_add_tail(&vbd->next, &server.vbds); }", "target": 0, "idx": 106221, "project": "Xen"}
{"func": "static int flush_mmu_updates(xc_interface *xch, struct xc_mmu *mmu) { int rc, err = 0; DECLARE_NAMED_HYPERCALL_BOUNCE(updates, mmu->updates, mmu->idx*sizeof(*mmu->updates), XC_HYPERCALL_BUFFER_BOUNCE_BOTH); if ( mmu->idx == 0 ) return 0; if ( xc_hypercall_bounce_pre(xch, updates) ) { PERROR(\"flush_mmu_updates: bounce buffer failed\"); err = 1; goto out; } rc = xencall4(xch->xcall, __HYPERVISOR_mmu_update, HYPERCALL_BUFFER_AS_ARG(updates), mmu->idx, 0, mmu->subject); if ( rc < 0 ) { ERROR(\"Failure when submitting mmu updates\"); err = 1; } mmu->idx = 0; xc_hypercall_bounce_post(xch, updates);  out: return err; }", "target": 0, "idx": 107641, "project": "Xen"}
{"func": "void td_prep_write(struct tiocb *tiocb, int fd, char *buf, size_t bytes, long long offset, td_queue_callback_t cb, void *arg) { tapdisk_prep_tiocb(tiocb, fd, 1, buf, bytes, offset, cb, arg); }", "target": 0, "idx": 106167, "project": "Xen"}
{"func": "static void end_8259A_irq(struct irq_desc *desc, u8 vector) { if (!(desc->status & (IRQ_DISABLED|IRQ_INPROGRESS))) enable_8259A_irq(desc); }", "target": 0, "idx": 102683, "project": "Xen"}
{"func": "static void hpet_set_timer(HPETState *h, unsigned int tn,  uint64_t guest_time) { uint64_t tn_cmp, cur_tick, diff; unsigned int irq; unsigned int oneshot; ASSERT(tn < HPET_TIMER_NUM); ASSERT(rw_is_write_locked(&h->lock)); if ( (tn == 0) && (h->hpet.config & HPET_CFG_LEGACY) ) {  pit_stop_channel0_irq(&vhpet_domain(h)->arch.vpit); } if ( !timer_enabled(h, tn) ) return; tn_cmp = hpet_get_comparator(h, tn, guest_time); cur_tick = hpet_read_maincounter(h, guest_time); if ( timer_is_32bit(h, tn) ) { tn_cmp = (uint32_t)tn_cmp; cur_tick = (uint32_t)cur_tick; } diff = tn_cmp - cur_tick;  if ( (int64_t)diff < 0 ) diff = (timer_is_32bit(h, tn) && (-diff > HPET_TINY_TIME_SPAN)) ? (uint32_t)diff : 0; if ( (tn <= 1) && (h->hpet.config & HPET_CFG_LEGACY) )  irq = (tn == 0) ? 0 : 8; else irq = timer_int_route(h, tn);  oneshot = !timer_is_periodic(h, tn); TRACE_2_LONG_4D(TRC_HVM_EMUL_HPET_START_TIMER, tn, irq, TRC_PAR_LONG(hpet_tick_to_ns(h, diff)), TRC_PAR_LONG(oneshot ? 0LL :  hpet_tick_to_ns(h, h->hpet.period[tn]))); create_periodic_time(vhpet_vcpu(h), &h->pt[tn],  hpet_tick_to_ns(h, diff),  oneshot ? 0 : hpet_tick_to_ns(h, h->hpet.period[tn]),  irq, NULL, NULL); }", "target": 1, "idx": 109576, "project": "Xen"}
{"func": "int map_domain_pirq( struct domain *d, int pirq, int irq, int type, void *data) { int ret = 0; int old_irq, old_pirq; struct pirq *info; struct irq_desc *desc; unsigned long flags; ASSERT(spin_is_locked(&d->event_lock)); if ( !IS_PRIV(current->domain) &&  !(IS_PRIV_FOR(current->domain, d) &&  irq_access_permitted(current->domain, pirq))) return -EPERM; if ( pirq < 0 || pirq >= d->nr_pirqs || irq < 0 || irq >= nr_irqs ) { dprintk(XENLOG_G_ERR, \"dom%d: invalid pirq %d or irq %d\\n\", d->domain_id, pirq, irq); return -EINVAL; } old_irq = domain_pirq_to_irq(d, pirq); old_pirq = domain_irq_to_pirq(d, irq); if ( (old_irq > 0 && (old_irq != irq) ) ||  (old_pirq && (old_pirq != pirq)) ) { dprintk(XENLOG_G_WARNING, \"dom%d: pirq %d or irq %d already mapped\\n\", d->domain_id, pirq, irq); return 0; } ret = xsm_map_domain_pirq(d, irq, data); if ( ret ) { dprintk(XENLOG_G_ERR, \"dom%d: could not permit access to irq %d mapping to pirq %d\\n\", d->domain_id, irq, pirq); return ret; } ret = irq_permit_access(d, pirq); if ( ret ) { dprintk(XENLOG_G_ERR, \"dom%d: could not permit access to irq %d\\n\", d->domain_id, pirq); return ret; } ret = prepare_domain_irq_pirq(d, irq, pirq, &info); if ( ret ) return ret; desc = irq_to_desc(irq); if ( type == MAP_PIRQ_TYPE_MSI ) { struct msi_info *msi = (struct msi_info *)data; struct msi_desc *msi_desc; struct pci_dev *pdev; ASSERT(spin_is_locked(&pcidevs_lock)); ret = -ENODEV; if ( !cpu_has_apic ) goto done; pdev = pci_get_pdev(msi->seg, msi->bus, msi->devfn); ret = pci_enable_msi(msi, &msi_desc); if ( ret ) goto done; spin_lock_irqsave(&desc->lock, flags); if ( desc->handler != &no_irq_type ) dprintk(XENLOG_G_ERR, \"dom%d: irq %d in use\\n\", d->domain_id, irq); setup_msi_handler(desc, msi_desc); if ( opt_irq_vector_map == OPT_IRQ_VECTOR_MAP_PERDEV  && !desc->arch.used_vectors ) { desc->arch.used_vectors = &pdev->arch.used_vectors; if ( desc->arch.vector != IRQ_VECTOR_UNASSIGNED ) { int vector = desc->arch.vector; ASSERT(!test_bit(vector, desc->arch.used_vectors)); set_bit(vector, desc->arch.used_vectors); } } set_domain_irq_pirq(d, irq, info); setup_msi_irq(desc); spin_unlock_irqrestore(&desc->lock, flags); } else { spin_lock_irqsave(&desc->lock, flags); set_domain_irq_pirq(d, irq, info); spin_unlock_irqrestore(&desc->lock, flags); if ( opt_irq_vector_map == OPT_IRQ_VECTOR_MAP_PERDEV ) printk(XENLOG_INFO \"Per-device vector maps for GSIs not implemented yet.\\n\"); } done: if ( ret ) cleanup_domain_irq_pirq(d, irq, info); return ret; }", "target": 1, "idx": 109057, "project": "Xen"}
{"func": "void __init set_nr_sockets(void) { nr_sockets = last_physid(phys_cpu_present_map)  / boot_cpu_data.x86_max_cores  / boot_cpu_data.x86_num_siblings + 1; if (disabled_cpus) nr_sockets += (disabled_cpus - 1) / boot_cpu_data.x86_max_cores / boot_cpu_data.x86_num_siblings + 1; printk(XENLOG_DEBUG \"nr_sockets: %u\\n\", nr_sockets); }", "target": 0, "idx": 104675, "project": "Xen"}
{"func": "int libxl_vcpu_sched_params_set_all(libxl_ctx *ctx, uint32_t domid, const libxl_vcpu_sched_params *scinfo) { GC_INIT(ctx); libxl_scheduler sched = scinfo->sched; int rc; if (sched == LIBXL_SCHEDULER_UNKNOWN) sched = libxl__domain_scheduler(gc, domid); switch (sched) { case LIBXL_SCHEDULER_SEDF: LOGD(ERROR, domid, \"SEDF scheduler no longer available\"); rc = ERROR_FEATURE_REMOVED; break; case LIBXL_SCHEDULER_CREDIT: case LIBXL_SCHEDULER_CREDIT2: case LIBXL_SCHEDULER_ARINC653: case LIBXL_SCHEDULER_NULL: LOGD(ERROR, domid, \"per-VCPU parameter setting not supported for this scheduler\"); rc = ERROR_INVAL; break; case LIBXL_SCHEDULER_RTDS: rc = sched_rtds_vcpu_set_all(gc, domid, scinfo); break; default: LOGD(ERROR, domid, \"Unknown scheduler\"); rc = ERROR_INVAL; break; } GC_FREE; return rc; }", "target": 0, "idx": 103983, "project": "Xen"}
{"func": "static void dump_vp_assist(const struct vcpu *v) { const union viridian_vp_assist *va; va = &v->arch.hvm_vcpu.viridian.vp_assist.msr; printk(XENLOG_G_INFO \"%pv: VIRIDIAN VP_ASSIST_PAGE: enabled: %x pfn: %lx\\n\",  v, va->fields.enabled, (unsigned long)va->fields.pfn); }", "target": 0, "idx": 106891, "project": "Xen"}
{"func": "int xc_monitor_resume(xc_interface *xch, uint32_t domain_id) { return xc_vm_event_control(xch, domain_id,  XEN_VM_EVENT_RESUME,  XEN_DOMCTL_VM_EVENT_OP_MONITOR,  NULL); }", "target": 0, "idx": 107602, "project": "Xen"}
{"func": "unsigned long long xenstat_tmem_succ_pers_puts(xenstat_tmem *tmem) { return tmem->succ_pers_puts; }", "target": 0, "idx": 108385, "project": "Xen"}
{"func": "int fdt_appendprop(void *fdt, int nodeoffset, const char *name,  const void *val, int len) { struct fdt_property *prop; int err, oldlen, newlen; FDT_RW_CHECK_HEADER(fdt); prop = fdt_get_property_w(fdt, nodeoffset, name, &oldlen); if (prop) { newlen = len + oldlen; err = _fdt_splice_struct(fdt, prop->data,  FDT_TAGALIGN(oldlen),  FDT_TAGALIGN(newlen)); if (err) return err; prop->len = cpu_to_fdt32(newlen); memcpy(prop->data + oldlen, val, len); } else { err = _fdt_add_property(fdt, nodeoffset, name, len, &prop); if (err) return err; memcpy(prop->data, val, len); } return 0; }", "target": 0, "idx": 102029, "project": "Xen"}
{"func": "int check_extra_words(struct record_info *ri,  int expected_size,  const char *record) { static int off_by_one = 0; int expected_extra = expected_size / sizeof(unsigned int); if(ri->extra_words != expected_extra  && !(off_by_one && ri->extra_words == expected_extra + 1) ) { if ( !off_by_one && ri->extra_words == expected_extra + 1 ) { fprintf(warn, \"Detected off-by-one bug; relaxing expectations\\n\"); off_by_one=1; } else { fprintf(warn, \"ERROR: %s extra_words %d, expected %d!\\n\", record, ri->extra_words, expected_extra); error(ERR_RECORD, ri); return 1; } } return 0; }", "target": 0, "idx": 107933, "project": "Xen"}
{"func": "static CHAR16 *__init FormatDec(UINT64 Val, CHAR16 *Buffer) { if ( Val >= 10 ) Buffer = FormatDec(Val / 10, Buffer); *Buffer = (CHAR16)(L'0' + Val % 10); return Buffer + 1; }", "target": 0, "idx": 101237, "project": "Xen"}
{"func": " *********************************************************************/ int cpufreq_frequency_table_cpuinfo(struct cpufreq_policy *policy, struct cpufreq_frequency_table *table) { unsigned int min_freq = ~0; unsigned int max_freq = 0; unsigned int second_max_freq = 0; unsigned int i; for (i=0; (table[i].frequency != CPUFREQ_TABLE_END); i++) { unsigned int freq = table[i].frequency; if (freq == CPUFREQ_ENTRY_INVALID) continue; if (freq < min_freq) min_freq = freq; if (freq > max_freq) max_freq = freq; } for (i=0; (table[i].frequency != CPUFREQ_TABLE_END); i++) { unsigned int freq = table[i].frequency; if (freq == CPUFREQ_ENTRY_INVALID || freq == max_freq) continue; if (freq > second_max_freq) second_max_freq = freq; } if (second_max_freq == 0) second_max_freq = max_freq; if (cpufreq_verbose) printk(\"max_freq: %usecond_max_freq: %u\\n\",  max_freq, second_max_freq); policy->min = policy->cpuinfo.min_freq = min_freq; policy->max = policy->cpuinfo.max_freq = max_freq; policy->cpuinfo.second_max_freq = second_max_freq; if (policy->min == ~0) return -EINVAL; else return 0; }", "target": 0, "idx": 106611, "project": "Xen"}
{"func": "static int hvm_map_io_range_to_ioreq_server(struct domain *d, ioservid_t id, uint32_t type, uint64_t start, uint64_t end) { struct hvm_ioreq_server *s; int rc; spin_lock(&d->arch.hvm_domain.ioreq_server.lock); rc = -ENOENT; list_for_each_entry ( s, &d->arch.hvm_domain.ioreq_server.list, list_entry ) { if ( s == d->arch.hvm_domain.default_ioreq_server ) continue; if ( s->id == id ) { struct rangeset *r; switch ( type ) { case HVMOP_IO_RANGE_PORT: case HVMOP_IO_RANGE_MEMORY: case HVMOP_IO_RANGE_PCI: r = s->range[type]; break; default: r = NULL; break; } rc = -EINVAL; if ( !r ) break; rc = -EEXIST; if ( rangeset_overlaps_range(r, start, end) ) break; rc = rangeset_add_range(r, start, end); break; } } spin_unlock(&d->arch.hvm_domain.ioreq_server.lock); return rc; }", "target": 1, "idx": 109524, "project": "Xen"}
{"func": "int write_ondemand_up_threshold(unsigned int up_threshold) { if ( (up_threshold > MAX_FREQUENCY_UP_THRESHOLD) ||  (up_threshold < MIN_FREQUENCY_UP_THRESHOLD) ) return -EINVAL; dbs_tuners_ins.up_threshold = up_threshold; return 0; }", "target": 0, "idx": 101525, "project": "Xen"}
{"func": "static int TIFFFetchLongArray(TIFF* tif, TIFFDirEntry* dir, uint32* v) { if (dir->tdir_count == 1) { v[0] = dir->tdir_offset; return (1); } else return (TIFFFetchData(tif, dir, (char*) v) != 0); }", "target": 0, "idx": 100247, "project": "LibTIFF"}
{"func": "static void talloc_report_null(void) { if (talloc_total_size(null_context) != 0) { talloc_report(null_context, stderr); } }", "target": 0, "idx": 105980, "project": "Xen"}
{"func": "static void ovmf_setup_bios_info(void) { struct ovmf_info *info = (void *)OVMF_INFO_PHYSICAL_ADDRESS; *info = (struct ovmf_info) { .signature = \"XenHVMOVMF\", .length = sizeof(*info) }; }", "target": 0, "idx": 104990, "project": "Xen"}
{"func": "void tdaio_queue_write(td_driver_t *driver, td_request_t treq) { int size; uint64_t offset; struct aio_request *aio; struct tdaio_state *prv; prv = (struct tdaio_state *)driver->data; size= treq.secs * driver->info.sector_size; offset= treq.sec* (uint64_t)driver->info.sector_size; if (prv->aio_free_count == 0) goto fail; aio= prv->aio_free_list[--prv->aio_free_count]; aio->treq= treq; aio->state = prv; td_prep_write(&aio->tiocb, prv->fd, treq.buf, size, offset, tdaio_complete, aio); td_queue_tiocb(driver, &aio->tiocb); return; fail: td_complete_request(treq, -EBUSY); }", "target": 0, "idx": 101028, "project": "Xen"}
{"func": "void libxl__ao_create_fail(libxl__ao *ao) { AO_GC; LOG(DEBUG,\"ao %p: create fail\",ao); assert(ao->magic == LIBXL__AO_MAGIC); assert(ao->in_initiator); assert(!ao->complete); assert(!ao->progress_reports_outstanding); assert(!ao->aborting); LIBXL_LIST_REMOVE(ao, inprogress_entry); libxl__ao__destroy(CTX, ao); }", "target": 0, "idx": 103627, "project": "Xen"}
{"func": "int libxl_psr_cmt_domain_attached(libxl_ctx *ctx, uint32_t domid) { int rc; uint32_t rmid; rc = xc_psr_cmt_get_domain_rmid(ctx->xch, domid, &rmid); if (rc < 0) return 0; return !!rmid; }", "target": 0, "idx": 103841, "project": "Xen"}
{"func": "void register_virtual_region(struct virtual_region *r) { ASSERT(!local_irq_is_enabled()); list_add_tail_rcu(&r->list, &virtual_region_list); }", "target": 0, "idx": 106909, "project": "Xen"}
{"func": "void __init setup_IO_APIC(void) { enable_IO_APIC(); if (acpi_ioapic) io_apic_irqs = ~0; else io_apic_irqs = ~PIC_IRQS; printk(\"ENABLING IO-APIC IRQs\\n\"); printk(\" -> Using %s ACK method\\n\", ioapic_ack_new ? \"new\" : \"old\"); if (ioapic_ack_new) { ioapic_level_type.ack = irq_complete_move; ioapic_level_type.end = end_level_ioapic_irq_new; }  if (!acpi_ioapic) setup_ioapic_ids_from_mpc(); sync_Arb_IDs(); setup_IO_APIC_irqs(); init_IO_APIC_traps(); check_timer(); print_IO_APIC(); ioapic_pm_state_alloc(); register_keyhandler('z', _print_IO_APIC_keyhandler, \"dump IOAPIC info\", 1); }", "target": 0, "idx": 102890, "project": "Xen"}
{"func": "byte chksum_pmid_get_value( byte* data, long offset ) { check((offset + PMID_CHKSUM) <= (bios_len - 1), \"PMID checksum out of bounds\" ); return(*( data + offset + PMID_CHKSUM ) ); }", "target": 0, "idx": 100993, "project": "Xen"}
{"func": "static int block_cache_validate_parent(td_driver_t *driver, td_driver_t *pdriver, td_flag_t flags) { block_cache_t *cache; if (!td_flag_test(pdriver->state, TD_DRIVER_RDONLY)) return -EINVAL; cache = (block_cache_t *)driver->data; if (strcmp(driver->name, pdriver->name)) return -EINVAL; return 0; }", "target": 0, "idx": 101042, "project": "Xen"}
{"func": "bool efi_rs_using_pgtables(void) { return efi_l4_pgtable &&  (smp_processor_id() == efi_rs_on_cpu) &&  (read_cr3() == virt_to_maddr(efi_l4_pgtable)); }", "target": 0, "idx": 105437, "project": "Xen"}
{"func": "int xenforeignmemory_restrict(xenforeignmemory_handle *fmem, domid_t domid) { return osdep_xenforeignmemory_restrict(fmem, domid); }", "target": 0, "idx": 101459, "project": "Xen"}
{"func": "static int LZWPostEncode(TIFF* tif) { register LZWCodecState *sp = EncoderState(tif); uint8* op = tif->tif_rawcp; long nextbits = sp->lzw_nextbits; unsigned long nextdata = sp->lzw_nextdata; long outcount = sp->enc_outcount; int nbits = sp->lzw_nbits; if (op > sp->enc_rawlimit) { tif->tif_rawcc = (tmsize_t)(op - tif->tif_rawdata); if( !TIFFFlushData1(tif) ) return 0; op = tif->tif_rawdata; } if (sp->enc_oldcode != (hcode_t) -1) { int free_ent = sp->lzw_free_ent; PutNextCode(op, sp->enc_oldcode); sp->enc_oldcode = (hcode_t) -1; free_ent ++; if (free_ent == CODE_MAX-1) {  outcount = 0; PutNextCode(op, CODE_CLEAR); nbits = BITS_MIN; } else {  if (free_ent > sp->lzw_maxcode) { nbits++; assert(nbits <= BITS_MAX); } } } PutNextCode(op, CODE_EOI);  if (nextbits > 0)  *op++ = (unsigned char)((nextdata << (8-nextbits))&0xff); tif->tif_rawcc = (tmsize_t)(op - tif->tif_rawdata); return (1); }", "target": 0, "idx": 100210, "project": "LibTIFF"}
{"func": "void passive_domain_destroy(struct vcpu *v) { struct vpmu_struct *vpmu = vcpu_vpmu(v); if ( vpmu_is_set(vpmu, VPMU_PASSIVE_DOMAIN_ALLOCATED) ) model->free_msr(v); }", "target": 0, "idx": 104857, "project": "Xen"}
{"func": "void hvm_close_vmexit(struct hvm_data *h, tsc_t tsc) { if(h->exit_tsc) { if(h->exit_tsc > tsc) h->arc_cycles = 0; else { h->arc_cycles = tsc - h->exit_tsc; if(opt.summary_info) { update_cycles(&h->summary.exit_reason[h->exit_reason],  h->arc_cycles); h->summary_info = 1; } if ( opt.scatterplot_extint_cycles  && h->exit_reason == EXIT_REASON_EXTERNAL_INTERRUPT  && h->inflight.intr.vec == opt.scatterplot_extint_cycles_vector ) { struct time_struct t; abs_cycles_to_time(tsc, &t); printf(\"d%dv%d %u.%09u %lld\\n\",  h->v->d->did,  h->v->vid,  t.s, t.ns,  h->arc_cycles); } } } if(h->post_process) (h->post_process)(h); if(h->arc_cycles) { if(opt.summary_info && !h->short_summary_done) { switch(h->event_handler) { case HVM_EVENT_HANDLER_VMCALL: hvm_update_short_summary(h, HVM_SHORT_SUMMARY_VMCALL); break; case HVM_EVENT_HANDLER_INTR: hvm_update_short_summary(h, HVM_SHORT_SUMMARY_INTERRUPT); break; case HVM_EVENT_HANDLER_HLT: hvm_update_short_summary(h, HVM_SHORT_SUMMARY_HLT); break; default: hvm_update_short_summary(h, HVM_SHORT_SUMMARY_OTHER); break; } } if(h->v->cr3.data) { h->v->cr3.data->run_time += h->arc_cycles; if(opt.summary_info) update_cycles(&h->v->cr3.data->hv_time, h->arc_cycles); } } h->exit_tsc = 0; h->vmexit_valid = 0; h->post_process = NULL; } } void hvm_close_vmexit(struct hvm_data *h, tsc_t tsc) { if(h->exit_tsc) { if(h->exit_tsc > tsc) h->arc_cycles = 0; else { h->arc_cycles = tsc - h->exit_tsc; if(opt.summary_info) { update_cycles(&h->summary.exit_reason[h->exit_reason],  h->arc_cycles); h->summary_info = 1; } if ( opt.scatterplot_extint_cycles  && h->exit_reason == EXIT_REASON_EXTERNAL_INTERRUPT  && h->inflight.intr.vec == opt.scatterplot_extint_cycles_vector ) { struct time_struct t; abs_cycles_to_time(tsc, &t); printf(\"d%dv%d %u.%09u %lld\\n\",  h->v->d->did,  h->v->vid,  t.s, t.ns,  h->arc_cycles); } } } if(h->post_process) (h->post_process)(h); if(h->arc_cycles) { if(opt.summary_info && !h->short_summary_done) { switch(h->event_handler) { case HVM_EVENT_HANDLER_VMCALL: hvm_update_short_summary(h, HVM_SHORT_SUMMARY_VMCALL); break; case HVM_EVENT_HANDLER_INTR: hvm_update_short_summary(h, HVM_SHORT_SUMMARY_INTERRUPT); break; case HVM_EVENT_HANDLER_HLT: hvm_update_short_summary(h, HVM_SHORT_SUMMARY_HLT); break; default: hvm_update_short_summary(h, HVM_SHORT_SUMMARY_OTHER); break; } } if(h->v->cr3.data) { h->v->cr3.data->run_time += h->arc_cycles; if(opt.summary_info) update_cycles(&h->v->cr3.data->hv_time, h->arc_cycles); } } h->exit_tsc = 0; h->vmexit_valid = 0; h->post_process = NULL; }", "target": 0, "idx": 107968, "project": "Xen"}
{"func": "static void dbgp_breathe(void) {  dbgp_mdelay(1); }", "target": 0, "idx": 101817, "project": "Xen"}
{"func": "static void fill_mpfps(struct mp_floating_pointer_struct *mpfps, uint32_t mpct) { int i; uint8_t checksum; mpfps->signature[0] = '_'; mpfps->signature[1] = 'M'; mpfps->signature[2] = 'P'; mpfps->signature[3] = '_'; mpfps->mp_table = mpct;  mpfps->length = 1; mpfps->revision = 4; mpfps->checksum = 0; for (i = 0; i < 5; ++i) mpfps->feature[i] = 0;  checksum = 0; for ( i = 0; i < sizeof(struct mp_floating_pointer_struct); i++ ) checksum += ((uint8_t *)(mpfps))[i]; mpfps->checksum = -checksum; }", "target": 0, "idx": 104679, "project": "Xen"}
{"func": "int vmce_intel_rdmsr(const struct vcpu *v, uint32_t msr, uint64_t *val) { unsigned int bank = msr - MSR_IA32_MC0_CTL2; if ( bank < GUEST_MC_BANK_NUM ) { *val = v->arch.vmce.bank[bank].mci_ctl2; mce_printk(MCE_VERBOSE, \"MCE: rd MC%u_CTL2 %#\"PRIx64\"\\n\", bank, *val); } return 1; }", "target": 0, "idx": 104411, "project": "Xen"}
{"func": "static void *cache_alloc(xencall_handle *xcall, size_t nr_pages) { void *p = NULL; cache_lock(xcall); xcall->buffer_total_allocations++; xcall->buffer_current_allocations++; if ( xcall->buffer_current_allocations > xcall->buffer_maximum_allocations ) xcall->buffer_maximum_allocations = xcall->buffer_current_allocations; if ( nr_pages > 1 ) { xcall->buffer_cache_toobig++; } else if ( xcall->buffer_cache_nr > 0 ) { p = xcall->buffer_cache[--xcall->buffer_cache_nr]; xcall->buffer_cache_hits++; } else { xcall->buffer_cache_misses++; } cache_unlock(xcall); return p; }", "target": 0, "idx": 101276, "project": "Xen"}
{"func": "int xc_domain_restore(xc_interface *xch, int io_fd, uint32_t dom, unsigned int store_evtchn, unsigned long *store_mfn, uint32_t store_domid, unsigned int console_evtchn, unsigned long *console_mfn, uint32_t console_domid, unsigned int hvm, unsigned int pae, xc_migration_stream_t stream_type, struct restore_callbacks *callbacks, int send_back_fd) { errno = ENOSYS; return -1; }", "target": 0, "idx": 107608, "project": "Xen"}
{"func": "unsigned int xen_minor_version(void) { return XEN_SUBVERSION; }", "target": 0, "idx": 106650, "project": "Xen"}
{"func": "int findPage(TIFF* tif, uint16 pageNumber) { uint16 pn = (uint16) -1; uint16 ptotal = (uint16) -1; if (GetPageNumber(tif)) { while (pn != (pageNumber-1) && TIFFReadDirectory(tif) && GetPageNumber(tif)) ; return (pn == (pageNumber-1)); } else return (TIFFSetDirectory(tif, (tdir_t)(pageNumber-1))); }", "target": 0, "idx": 100053, "project": "LibTIFF"}
{"func": "static int vhd_journal_read_batmap_header(vhd_journal_t *j, vhd_batmap_t *batmap) { int err; char *buf; size_t size; vhd_journal_entry_t entry; size = vhd_bytes_padded(sizeof(struct dd_batmap_hdr)); err= vhd_journal_read_entry(j, &entry); if (err) return err; if (entry.type != VHD_JOURNAL_ENTRY_TYPE_BATMAP_H) return -EINVAL; if (entry.size != size) return -EINVAL; err = posix_memalign((void **)&buf, VHD_SECTOR_SIZE, size); if (err) return err; err = vhd_journal_read(j, buf, entry.size); if (err) { free(buf); return err; } memcpy(&batmap->header, buf, sizeof(batmap->header)); vhd_batmap_header_in(batmap); return vhd_validate_batmap_header(batmap); }", "target": 0, "idx": 103081, "project": "Xen"}
{"func": "static void Fax3Cleanup(TIFF* tif) { Fax3CodecState* sp = DecoderState(tif); assert(sp != 0); tif->tif_tagmethods.vgetfield = sp->b.vgetparent; tif->tif_tagmethods.vsetfield = sp->b.vsetparent; if (sp->runs) _TIFFfree(sp->runs); if (sp->refline) _TIFFfree(sp->refline); if (Fax3State(tif)->subaddress) _TIFFfree(Fax3State(tif)->subaddress); _TIFFfree(tif->tif_data); tif->tif_data = NULL; _TIFFSetDefaultCompressionState(tif); }", "target": 0, "idx": 100178, "project": "LibTIFF"}
{"func": "fsi_plugin_ops_t * fsig_init(fsi_plugin_t *plugin, fsig_plugin_ops_t *ops) { if (ops->fpo_version > FSIMAGE_PLUGIN_VERSION) return (NULL); plugin->fp_data = ops; return (&fsig_grub_ops); }", "target": 0, "idx": 102111, "project": "Xen"}
{"func": "void _read_unlock_irq(rwlock_t *lock) { preempt_enable(); _raw_read_unlock(&lock->raw); local_irq_enable(); }", "target": 1, "idx": 109253, "project": "Xen"}
{"func": "int mfs_size (int fd) { int ret; if (fds[fd] == -1) { ret = -1; errno = EBADF; } else ret = buf_size[fd]; return (ret); }", "target": 0, "idx": 100033, "project": "LibTIFF"}
{"func": "static inline void recover_fault(struct tfilter *filter, struct iocb *io) { struct fiocb *fio = (struct fiocb *)io->data; io->u.c.nbytes = fio->bytes; io->data = fio->data; memset(fio, 0, sizeof(struct fiocb)); filter->flist[filter->ffree++] = fio; }", "target": 0, "idx": 106150, "project": "Xen"}
{"func": "void xenbus_notify_running(void) { }", "target": 0, "idx": 108450, "project": "Xen"}
{"func": "bool xc_dom_translated(const struct xc_dom_image *dom) {  return dom->container_type == XC_DOM_HVM_CONTAINER; }", "target": 0, "idx": 107461, "project": "Xen"}
{"func": "static int extend_mem_file (int fd, int size) { void *new_mem; int ret; if ((new_mem = realloc (buf[fd], size)) == (void *) NULL) ret = -1; else { buf[fd] = (char *) new_mem; ret = 0; } return (ret); }", "target": 0, "idx": 100130, "project": "LibTIFF"}
{"func": "static void csched2_vcpu_sleep(const struct scheduler *ops, struct vcpu *vc) { struct csched2_vcpu * const svc = csched2_vcpu(vc); ASSERT(!is_idle_vcpu(vc)); SCHED_STAT_CRANK(vcpu_sleep); if ( curr_on_cpu(vc->processor) == vc ) { tickle_cpu(vc->processor, svc->rqd); } else if ( vcpu_on_runq(svc) ) { ASSERT(svc->rqd == c2rqd(ops, vc->processor)); update_load(ops, svc->rqd, svc, -1, NOW()); runq_remove(svc); } else __clear_bit(__CSFLAG_delayed_runq_add, &svc->flags); }", "target": 0, "idx": 105551, "project": "Xen"}
{"func": "int emul_test_read_xcr( unsigned int reg, uint64_t *val, struct x86_emulate_ctxt *ctxt) { uint32_t lo, hi; ASSERT(cpu_has_xsave); switch ( reg ) { case 0: break; case 1: if ( cpu_has_xgetbv1 ) break;  default: x86_emul_hw_exception(13 , 0, ctxt); return X86EMUL_EXCEPTION; } asm ( \"xgetbv\" : \"=a\" (lo), \"=d\" (hi) : \"c\" (reg) ); *val = lo | ((uint64_t)hi << 32); return X86EMUL_OKAY; }", "target": 0, "idx": 107282, "project": "Xen"}
{"func": " */ int rangeset_add_range( struct rangeset *r, unsigned long s, unsigned long e) { struct range *x, *y; int rc = 0; ASSERT(s <= e); write_lock(&r->lock); x = find_range(r, s); y = find_range(r, e); if ( x == y ) { if ( (x == NULL) || ((x->e < s) && ((x->e + 1) != s)) ) { x = alloc_range(r); if ( x == NULL ) { rc = -ENOMEM; goto out; } x->s = s; x->e = e; insert_range(r, y, x); } else if ( x->e < e ) x->e = e; } else { if ( x == NULL ) { x = first_range(r); x->s = s; } else if ( (x->e < s) && ((x->e + 1) != s) ) { x = next_range(r, x); x->s = s; } x->e = (y->e > e) ? y->e : e; for ( ; ; ) { y = next_range(r, x); if ( (y == NULL) || (y->e > x->e) ) break; destroy_range(r, y); } } y = next_range(r, x); if ( (y != NULL) && ((x->e + 1) == y->s) ) { x->e = y->e; destroy_range(r, y); }  out: write_unlock(&r->lock); return rc; }", "target": 0, "idx": 105309, "project": "Xen"}
{"func": "long do_sysctl(XEN_GUEST_HANDLE_PARAM(xen_sysctl_t) u_sysctl) { long ret = 0; int copyback = -1; struct xen_sysctl curop, *op = &curop; static DEFINE_SPINLOCK(sysctl_lock); if ( copy_from_guest(op, u_sysctl, 1) ) return -EFAULT; if ( op->interface_version != XEN_SYSCTL_INTERFACE_VERSION ) return -EACCES; ret = xsm_sysctl(XSM_PRIV, op->cmd); if ( ret ) return ret;  while ( !spin_trylock(&sysctl_lock) ) if ( hypercall_preempt_check() ) return hypercall_create_continuation( __HYPERVISOR_sysctl, \"h\", u_sysctl); switch ( op->cmd ) { case XEN_SYSCTL_readconsole: ret = xsm_readconsole(XSM_HOOK, op->u.readconsole.clear); if ( ret ) break; ret = read_console_ring(&op->u.readconsole); break; case XEN_SYSCTL_tbuf_op: ret = tb_control(&op->u.tbuf_op); break;  case XEN_SYSCTL_sched_id: op->u.sched_id.sched_id = sched_id(); break; case XEN_SYSCTL_getdomaininfolist: {  struct domain *d; struct xen_domctl_getdomaininfo info; u32 num_domains = 0; rcu_read_lock(&domlist_read_lock); for_each_domain ( d ) { if ( d->domain_id < op->u.getdomaininfolist.first_domain ) continue; if ( num_domains == op->u.getdomaininfolist.max_domains ) break; ret = xsm_getdomaininfo(XSM_HOOK, d); if ( ret ) continue; getdomaininfo(d, &info); if ( copy_to_guest_offset(op->u.getdomaininfolist.buffer, num_domains, &info, 1) ) { ret = -EFAULT; break; }  num_domains++; }  rcu_read_unlock(&domlist_read_lock);  if ( ret != 0 ) break;  op->u.getdomaininfolist.num_domains = num_domains; } break; #ifdef PERF_COUNTERS case XEN_SYSCTL_perfc_op: ret = perfc_control(&op->u.perfc_op); break; #endif #ifdef LOCK_PROFILE case XEN_SYSCTL_lockprof_op: ret = spinlock_profile_control(&op->u.lockprof_op); break; #endif case XEN_SYSCTL_debug_keys: { char c; uint32_t i; ret = -EFAULT; for ( i = 0; i < op->u.debug_keys.nr_keys; i++ ) { if ( copy_from_guest_offset(&c, op->u.debug_keys.keys, i, 1) ) goto out; handle_keypress(c, guest_cpu_user_regs()); } ret = 0; copyback = 0; } break; case XEN_SYSCTL_getcpuinfo: { uint32_t i, nr_cpus; struct xen_sysctl_cpuinfo cpuinfo; nr_cpus = min(op->u.getcpuinfo.max_cpus, nr_cpu_ids); ret = -EFAULT; for ( i = 0; i < nr_cpus; i++ ) { cpuinfo.idletime = get_cpu_idle_time(i); if ( copy_to_guest_offset(op->u.getcpuinfo.info, i, &cpuinfo, 1) ) goto out; } op->u.getcpuinfo.nr_cpus = i; ret = 0; } break; case XEN_SYSCTL_availheap: op->u.availheap.avail_bytes = avail_domheap_pages_region( op->u.availheap.node, op->u.availheap.min_bitwidth, op->u.availheap.max_bitwidth); op->u.availheap.avail_bytes <<= PAGE_SHIFT; break; #ifdef HAS_ACPI case XEN_SYSCTL_get_pmstat: ret = do_get_pm_info(&op->u.get_pmstat); break; case XEN_SYSCTL_pm_op: ret = do_pm_op(&op->u.pm_op); if ( ret == -EAGAIN ) copyback = 1; break; #endif case XEN_SYSCTL_page_offline_op: { uint32_t *status, *ptr; unsigned long pfn; ret = xsm_page_offline(XSM_HOOK, op->u.page_offline.cmd); if ( ret ) break; ptr = status = xmalloc_bytes( sizeof(uint32_t) * (op->u.page_offline.end - op->u.page_offline.start + 1)); if ( !status ) { dprintk(XENLOG_WARNING, \"Out of memory for page offline op\\n\"); ret = -ENOMEM; break; } memset(status, PG_OFFLINE_INVALID, sizeof(uint32_t) * (op->u.page_offline.end - op->u.page_offline.start + 1)); for ( pfn = op->u.page_offline.start; pfn <= op->u.page_offline.end; pfn ++ ) { switch ( op->u.page_offline.cmd ) {  case sysctl_page_offline: ret = offline_page(pfn, 0, ptr++); break; case sysctl_page_online: ret = online_page(pfn, ptr++); break; case sysctl_query_page_offline: ret = query_page_offline(pfn, ptr++); break; default: ret = -EINVAL; break; } if (ret) break; } if ( copy_to_guest(  op->u.page_offline.status, status,  op->u.page_offline.end - op->u.page_offline.start + 1) ) ret = -EFAULT; xfree(status); copyback = 0; } break; case XEN_SYSCTL_cpupool_op: ret = cpupool_do_sysctl(&op->u.cpupool_op); break; case XEN_SYSCTL_scheduler_op: ret = sched_adjust_global(&op->u.scheduler_op); break; case XEN_SYSCTL_physinfo: { xen_sysctl_physinfo_t *pi = &op->u.physinfo; memset(pi, 0, sizeof(*pi)); pi->threads_per_core = cpumask_weight(per_cpu(cpu_sibling_mask, 0)); pi->cores_per_socket = cpumask_weight(per_cpu(cpu_core_mask, 0)) / pi->threads_per_core; pi->nr_cpus = num_online_cpus(); pi->nr_nodes = num_online_nodes(); pi->max_node_id = MAX_NUMNODES-1; pi->max_cpu_id = nr_cpu_ids - 1; pi->total_pages = total_pages;  get_outstanding_claims(&pi->free_pages, &pi->outstanding_pages); pi->scrub_pages = 0; pi->cpu_khz = cpu_khz; arch_do_physinfo(pi); if ( copy_to_guest(u_sysctl, op, 1) ) ret = -EFAULT; } break; case XEN_SYSCTL_numainfo: { uint32_t i, j, max_node_index, last_online_node; xen_sysctl_numainfo_t *ni = &op->u.numainfo; last_online_node = last_node(node_online_map); max_node_index = min_t(uint32_t, ni->max_node_index, last_online_node); ni->max_node_index = last_online_node; for ( i = 0; i <= max_node_index; i++ ) { if ( !guest_handle_is_null(ni->node_to_memsize) ) { uint64_t memsize = node_online(i) ?  node_spanned_pages(i) << PAGE_SHIFT : 0ul; if ( copy_to_guest_offset(ni->node_to_memsize, i, &memsize, 1) ) break; } if ( !guest_handle_is_null(ni->node_to_memfree) ) { uint64_t memfree = node_online(i) ?  avail_node_heap_pages(i) << PAGE_SHIFT : 0ul; if ( copy_to_guest_offset(ni->node_to_memfree, i, &memfree, 1) ) break; } if ( !guest_handle_is_null(ni->node_to_node_distance) ) { for ( j = 0; j <= max_node_index; j++) { uint32_t distance = ~0u; if ( node_online(i) && node_online(j) ) distance = __node_distance(i, j); if ( copy_to_guest_offset( ni->node_to_node_distance, i*(max_node_index+1) + j, &distance, 1) ) break; } if ( j <= max_node_index ) break; } } ret = ((i <= max_node_index) || copy_to_guest(u_sysctl, op, 1)) ? -EFAULT : 0; } break; case XEN_SYSCTL_topologyinfo: { uint32_t i, max_cpu_index, last_online_cpu; xen_sysctl_topologyinfo_t *ti = &op->u.topologyinfo; last_online_cpu = cpumask_last(&cpu_online_map); max_cpu_index = min_t(uint32_t, ti->max_cpu_index, last_online_cpu); ti->max_cpu_index = last_online_cpu; for ( i = 0; i <= max_cpu_index; i++ ) { if ( !guest_handle_is_null(ti->cpu_to_core) ) { uint32_t core = cpu_online(i) ? cpu_to_core(i) : ~0u; if ( copy_to_guest_offset(ti->cpu_to_core, i, &core, 1) ) break; } if ( !guest_handle_is_null(ti->cpu_to_socket) ) { uint32_t socket = cpu_online(i) ? cpu_to_socket(i) : ~0u; if ( copy_to_guest_offset(ti->cpu_to_socket, i, &socket, 1) ) break; } if ( !guest_handle_is_null(ti->cpu_to_node) ) { uint32_t node = cpu_online(i) ? cpu_to_node(i) : ~0u; if ( copy_to_guest_offset(ti->cpu_to_node, i, &node, 1) ) break; } } ret = ((i <= max_cpu_index) || copy_to_guest(u_sysctl, op, 1)) ? -EFAULT : 0; } break; #ifdef TEST_COVERAGE case XEN_SYSCTL_coverage_op: ret = sysctl_coverage_op(&op->u.coverage_op); break; #endif default: ret = arch_do_sysctl(op, u_sysctl); copyback = 0; break; }  out: spin_unlock(&sysctl_lock); if ( copyback && (!ret || copyback > 0) &&  __copy_to_guest(u_sysctl, op, 1) ) ret = -EFAULT; return ret; }", "target": 1, "idx": 109291, "project": "Xen"}
{"func": "static void intel_mce_post_reset(void) { mctelem_cookie_t mctc; struct mca_summary bs; mctc = mcheck_mca_logout(MCA_RESET, mca_allbanks, &bs, NULL);  if ( bs.errcnt && mctc != NULL ) { x86_mcinfo_dump(mctelem_dataptr(mctc)); mctelem_commit(mctc); } return; }", "target": 0, "idx": 104401, "project": "Xen"}
{"func": "static void __init efi_console_set_mode(void) { UINTN cols, rows, size; unsigned int best, i; for ( i = 0, size = 0, best = StdOut->Mode->Mode; i < StdOut->Mode->MaxMode; ++i ) { if ( StdOut->QueryMode(StdOut, i, &cols, &rows) == EFI_SUCCESS &&  cols * rows > size ) { size = cols * rows; best = i; } } if ( best != StdOut->Mode->Mode ) StdOut->SetMode(StdOut, best); }", "target": 0, "idx": 101226, "project": "Xen"}
{"func": "int psr_set_val(struct domain *d, unsigned int socket, uint64_t new_val, enum psr_type type) { unsigned int old_cos, array_len; int cos, ret; unsigned int *ref; uint32_t *val_array, val; struct psr_socket_info *info = get_socket_info(socket); enum psr_feat_type feat_type; if ( IS_ERR(info) ) return PTR_ERR(info); val = new_val; if ( new_val != val ) return -EINVAL; feat_type = psr_type_to_feat_type(type); if ( feat_type >= ARRAY_SIZE(info->features) ||  !info->features[feat_type] ) return -ENOENT;  domain_lock(d); if ( !test_and_set_bit(d->domain_id, info->dom_set) ) d->arch.psr_cos_ids[socket] = 0; old_cos = d->arch.psr_cos_ids[socket]; domain_unlock(d); ASSERT(old_cos < MAX_COS_REG_CNT); ref = info->cos_ref;  array_len = get_cos_num(); val_array = xzalloc_array(uint32_t, array_len); if ( !val_array ) return -ENOMEM; if ( (ret = gather_val_array(val_array, array_len, info, old_cos)) != 0 ) goto free_array; if ( (ret = insert_val_into_array(val_array, array_len, info, feat_type, type, val)) != 0 ) goto free_array; spin_lock(&info->ref_lock);  cos = find_cos(val_array, array_len, feat_type, info); if ( cos == old_cos ) { ret = 0; goto unlock_free_array; }  if ( cos < 0 ) { cos = pick_avail_cos(info, val_array, array_len, old_cos, feat_type); if ( cos < 0 ) { ret = cos; goto unlock_free_array; }  ret = write_psr_msrs(socket, cos, val_array, array_len, feat_type); if ( ret ) goto unlock_free_array; }  ref[cos]++; ASSERT(!cos || ref[cos]); ASSERT(!old_cos || ref[old_cos]); ref[old_cos]--; spin_unlock(&info->ref_lock);  domain_lock(d); d->arch.psr_cos_ids[socket] = cos; domain_unlock(d); goto free_array;  unlock_free_array: spin_unlock(&info->ref_lock);  free_array: xfree(val_array); return ret; }", "target": 0, "idx": 105220, "project": "Xen"}
{"func": "static int build(xc_interface *xch) { char cmdline[512]; uint32_t ssid; xen_domain_handle_t handle = { 0 }; int rv, xs_fd; struct xc_dom_image *dom = NULL; int limit_kb = (maxmem ? : (memory + 1)) * 1024; xs_fd = open(\"/dev/xen/xenbus_backend\", O_RDWR); if ( xs_fd == -1 ) { fprintf(stderr, \"Could not open /dev/xen/xenbus_backend\\n\"); return -1; } if ( flask ) { rv = xc_flask_context_to_sid(xch, flask, strlen(flask), &ssid); if ( rv ) { fprintf(stderr, \"xc_flask_context_to_sid failed\\n\"); goto err; } } else { ssid = SECINITSID_DOMU; } rv = xc_domain_create(xch, ssid, handle, XEN_DOMCTL_CDF_xs_domain, &domid, NULL); if ( rv ) { fprintf(stderr, \"xc_domain_create failed\\n\"); goto err; } rv = xc_domain_max_vcpus(xch, domid, 1); if ( rv ) { fprintf(stderr, \"xc_domain_max_vcpus failed\\n\"); goto err; } rv = xc_domain_setmaxmem(xch, domid, limit_kb); if ( rv ) { fprintf(stderr, \"xc_domain_setmaxmem failed\\n\"); goto err; }  rv = xc_domain_set_gnttab_limits(xch, domid, 4, 128); if ( rv ) { fprintf(stderr, \"xc_domain_set_gnttab_limits failed\\n\"); goto err; } rv = xc_domain_set_memmap_limit(xch, domid, limit_kb); if ( rv ) { fprintf(stderr, \"xc_domain_set_memmap_limit failed\\n\"); goto err; } rv = ioctl(xs_fd, IOCTL_XENBUS_BACKEND_SETUP, domid); if ( rv < 0 ) { fprintf(stderr, \"Xenbus setup ioctl failed\\n\"); goto err; } if ( param ) snprintf(cmdline, 512, \"--event %d --internal-db %s\", rv, param); else snprintf(cmdline, 512, \"--event %d --internal-db\", rv); dom = xc_dom_allocate(xch, cmdline, NULL); rv = xc_dom_kernel_file(dom, kernel); if ( rv ) { fprintf(stderr, \"xc_dom_kernel_file failed\\n\"); goto err; } if ( ramdisk ) { rv = xc_dom_module_file(dom, ramdisk, NULL); if ( rv ) { fprintf(stderr, \"xc_dom_module_file failed\\n\"); goto err; } } rv = xc_dom_boot_xen_init(dom, xch, domid); if ( rv ) { fprintf(stderr, \"xc_dom_boot_xen_init failed\\n\"); goto err; } rv = xc_dom_parse_image(dom); if ( rv ) { fprintf(stderr, \"xc_dom_parse_image failed\\n\"); goto err; } rv = xc_dom_mem_init(dom, memory); if ( rv ) { fprintf(stderr, \"xc_dom_mem_init failed\\n\"); goto err; } rv = xc_dom_boot_mem_init(dom); if ( rv ) { fprintf(stderr, \"xc_dom_boot_mem_init failed\\n\"); goto err; } rv = xc_dom_build_image(dom); if ( rv ) { fprintf(stderr, \"xc_dom_build_image failed\\n\"); goto err; } rv = xc_dom_boot_image(dom); if ( rv ) { fprintf(stderr, \"xc_dom_boot_image failed\\n\"); goto err; } rv = xc_domain_set_virq_handler(xch, domid, VIRQ_DOM_EXC); if ( rv ) { fprintf(stderr, \"xc_domain_set_virq_handler failed\\n\"); goto err; } rv = xc_domain_unpause(xch, domid); if ( rv ) { fprintf(stderr, \"xc_domain_unpause failed\\n\"); goto err; } rv = 0; err: if ( dom ) xc_dom_release(dom); if ( xs_fd >= 0 ) close(xs_fd);  if ( rv && domid != ~0 ) xc_domain_destroy(xch, domid); return rv; }", "target": 0, "idx": 102707, "project": "Xen"}
{"func": "static char **get_hotplug_env(libxl__gc *gc, char *script, libxl__device *dev) { const char *type = libxl__device_kind_to_string(dev->backend_kind); char *be_path = libxl__device_backend_path(gc, dev); char **env; int nr = 0; const int arraysize = 15; GCNEW_ARRAY(env, arraysize); env[nr++] = \"script\"; env[nr++] = script; env[nr++] = \"XENBUS_TYPE\"; env[nr++] = (char *) type; env[nr++] = \"XENBUS_PATH\"; env[nr++] = GCSPRINTF(\"backend/%s/%u/%d\", type, dev->domid, dev->devid); env[nr++] = \"XENBUS_BASE_PATH\"; env[nr++] = \"backend\"; if (dev->backend_kind == LIBXL__DEVICE_KIND_VIF) { libxl_nic_type nictype; char *gatewaydev; gatewaydev = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/%s\", be_path, \"gatewaydev\")); env[nr++] = \"netdev\"; env[nr++] = gatewaydev ? : \"\"; if (libxl__nic_type(gc, dev, &nictype)) { LOGD(ERROR, dev->domid, \"unable to get nictype\"); return NULL; } switch (nictype) { case LIBXL_NIC_TYPE_VIF_IOEMU: env[nr++] = \"INTERFACE\"; env[nr++] = (char *) libxl__device_nic_devname(gc, dev->domid, dev->devid, LIBXL_NIC_TYPE_VIF_IOEMU);  case LIBXL_NIC_TYPE_VIF: env[nr++] = \"vif\"; env[nr++] = (char *) libxl__device_nic_devname(gc, dev->domid, dev->devid, LIBXL_NIC_TYPE_VIF); break; default: return NULL; } } env[nr++] = NULL; assert(nr <= arraysize); return env; }", "target": 0, "idx": 103754, "project": "Xen"}
{"func": "static void colo_enable_logdirty_done(libxl__egc *egc, libxl__logdirty_switch *lds, int rc) { libxl__colo_restore_checkpoint_state *crcs = CONTAINER_OF(lds, *crcs, lds);  libxl__colo_restore_state *const crs = crcs->crs; EGC_GC; if (rc) {  lds->callback = colo_reenable_logdirty; colo_disable_logdirty(crs, egc); return; } colo_setup_checkpoint_devices(egc, crs); }", "target": 0, "idx": 103412, "project": "Xen"}
{"func": "int zfs_mount(void) { char *stack; int label = 0; uberblock_phys_t *ub_array, *ubbest; objset_phys_t *osp; char tmp_bootpath[MAXNAMELEN]; char tmp_devid[MAXNAMELEN]; uint64_t tmp_guid; uint64_t adjpl = (uint64_t)part_length << SPA_MINBLOCKSHIFT; int err = errnum;   if (best_drive == 0 && best_part == 0 && find_best_root) { grub_memset(&current_uberblock, 0, sizeof (uberblock_t)); pool_guid = 0; } stackbase = ZFS_SCRATCH; stack = stackbase; ub_array = (uberblock_phys_t *)stack; stack += VDEV_UBERBLOCK_RING; osp = (objset_phys_t *)stack; stack += sizeof (objset_phys_t); adjpl = P2ALIGN(adjpl, (uint64_t)sizeof (vdev_label_t)); for (label = 0; label < VDEV_LABELS; label++) { uint64_t sector;  if (part_length == MAXUINT && label == 2) break; sector = vdev_label_start(adjpl, label) >> SPA_MINBLOCKSHIFT;  if (devread(sector+ ((VDEV_SKIP_SIZE + VDEV_PHYS_SIZE) >> SPA_MINBLOCKSHIFT), 0, VDEV_UBERBLOCK_RING, (char *)ub_array) == 0) continue; if ((ubbest = find_bestub(ub_array, sector)) != NULL && zio_read(&ubbest->ubp_uberblock.ub_rootbp, osp, stack) == 0) { VERIFY_OS_TYPE(osp, DMU_OST_META); if (check_pool_label(sector, stack, tmp_devid, tmp_bootpath, &tmp_guid)) continue; if (pool_guid == 0) pool_guid = tmp_guid; if (find_best_root && ((pool_guid != tmp_guid) || vdev_uberblock_compare(&ubbest->ubp_uberblock, &(current_uberblock)) <= 0)) continue;  grub_memmove(MOS, &osp->os_meta_dnode, DNODE_SIZE); grub_memmove(&current_uberblock, &ubbest->ubp_uberblock, sizeof (uberblock_t)); grub_memmove(current_bootpath, tmp_bootpath, MAXNAMELEN); grub_memmove(current_devid, tmp_devid, grub_strlen(tmp_devid)); is_zfs_mount = 1; return (1); } }  errnum = err; return (0); }", "target": 0, "idx": 102215, "project": "Xen"}
{"func": "static void iommu_page_fault(int irq, void *dev_id,  struct cpu_user_regs *regs) { struct iommu *iommu = dev_id; int reg, fault_index; u32 fault_status; unsigned long flags; fault_status = dmar_readl(iommu->reg, DMAR_FSTS_REG); iommu_fault_status(fault_status);  if ( !(fault_status & DMA_FSTS_PPF) ) goto clear_overflow; fault_index = dma_fsts_fault_record_index(fault_status); reg = cap_fault_reg_offset(iommu->cap); while (1) { u8 fault_reason; u16 source_id; u32 data; u64 guest_addr; int type;  spin_lock_irqsave(&iommu->register_lock, flags); data = dmar_readl(iommu->reg, reg + fault_index * PRIMARY_FAULT_REG_LEN + 12); if ( !(data & DMA_FRCD_F) ) { spin_unlock_irqrestore(&iommu->register_lock, flags); break; } fault_reason = dma_frcd_fault_reason(data); type = dma_frcd_type(data); data = dmar_readl(iommu->reg, reg + fault_index * PRIMARY_FAULT_REG_LEN + 8); source_id = dma_frcd_source_id(data); guest_addr = dmar_readq(iommu->reg, reg + fault_index * PRIMARY_FAULT_REG_LEN); guest_addr = dma_frcd_page_addr(guest_addr);  dmar_writel(iommu->reg, reg + fault_index * PRIMARY_FAULT_REG_LEN + 12, DMA_FRCD_F); spin_unlock_irqrestore(&iommu->register_lock, flags); iommu_page_fault_do_one(iommu, type, fault_reason, source_id, guest_addr); fault_index++; if ( fault_index > cap_num_fault_regs(iommu->cap) ) fault_index = 0; } clear_overflow:  fault_status = readl(iommu->reg + DMAR_FSTS_REG); if ( fault_status & DMA_FSTS_PFO ) { spin_lock_irqsave(&iommu->register_lock, flags); dmar_writel(iommu->reg, DMAR_FSTS_REG, DMA_FSTS_PFO); spin_unlock_irqrestore(&iommu->register_lock, flags); } }", "target": 1, "idx": 108998, "project": "Xen"}
{"func": "static uberblock_phys_t * find_bestub(uberblock_phys_t *ub_array, uint64_t sector) { uberblock_phys_t *ubbest = NULL; uint64_t offset; int i; for (i = 0; i < (VDEV_UBERBLOCK_RING >> VDEV_UBERBLOCK_SHIFT); i++) { offset = (sector << SPA_MINBLOCKSHIFT) + VDEV_UBERBLOCK_OFFSET(i); if (uberblock_verify(&ub_array[i], offset) == 0) { if (ubbest == NULL) { ubbest = &ub_array[i]; } else if (vdev_uberblock_compare( &(ub_array[i].ubp_uberblock), &(ubbest->ubp_uberblock)) > 0) { ubbest = &ub_array[i]; } } } return (ubbest); }", "target": 0, "idx": 102196, "project": "Xen"}
{"func": "static int vhd_journal_read_footer_copy(vhd_journal_t *j, vhd_footer_t *footer) { return __vhd_journal_read_footer(j, footer,  VHD_JOURNAL_ENTRY_TYPE_FOOTER_C); }", "target": 0, "idx": 103085, "project": "Xen"}
{"func": "value stub_libxl_domain_create_new(value ctx, value domain_config, value async, value unit) { CAMLparam4(ctx, async, domain_config, unit); int ret; libxl_domain_config c_dconfig; uint32_t c_domid; libxl_asyncop_how *ao_how; libxl_domain_config_init(&c_dconfig); ret = domain_config_val(CTX, &c_dconfig, domain_config); if (ret != 0) { libxl_domain_config_dispose(&c_dconfig); failwith_xl(ret, \"domain_create_new\"); } ao_how = aohow_val(async); caml_enter_blocking_section(); ret = libxl_domain_create_new(CTX, &c_dconfig, &c_domid, ao_how, NULL); caml_leave_blocking_section(); free(ao_how); libxl_domain_config_dispose(&c_dconfig); if (ret != 0) failwith_xl(ret, \"domain_create_new\"); CAMLreturn(Val_int(c_domid)); }", "target": 0, "idx": 108232, "project": "Xen"}
{"func": "void xc_report_progress_step(xc_interface *xch,  unsigned long done, unsigned long total) { assert(xch->currently_progress_reporting); xtl_progress(xch->error_handler, \"xc\",  xch->currently_progress_reporting, done, total); }", "target": 0, "idx": 107666, "project": "Xen"}
{"func": "static int  tapdisk_result_compare(struct tapdisk_stream_request *sreq1, struct tapdisk_stream_request*sreq2) { unsigned long idx1, idx2; char *buf1, *buf2; int result; assert(sreq1->seqno == sreq2->seqno); assert(sreq1->secs == sreq2->secs); idx1 = (unsigned long)tapdisk_stream_request_idx(&stream1,  sreq1); idx2 = (unsigned long)tapdisk_stream_request_idx(&stream2, sreq2); buf1 = (char *)MMAP_VADDR(stream1.vbd->ring.vstart, idx1, 0); buf2 = (char *)MMAP_VADDR(stream2.vbd->ring.vstart, idx2, 0); result = memcmp(buf1, buf2, sreq1->secs << SECTOR_SHIFT); return result; }", "target": 0, "idx": 106114, "project": "Xen"}
{"func": "static int apei_write_mem(u64 paddr, u64 val, u32 width) { void __iomem *addr; u32 tmpval; addr = __apei_ioremap_fast(paddr, width); switch (width) { case 8: writeb(val, addr); break; case 16: writew(val, addr); break; case 32: writel(val, addr); break; case 64: tmpval = (u32)val; writel(tmpval, addr); tmpval = (u32)(val >> 32); writel(tmpval, addr+4); break; default: return -EINVAL; } return 0; }", "target": 0, "idx": 100899, "project": "Xen"}
{"func": "static void qos_kill_thread(int domid) { int cpu; for (cpu=0; cpu<NCPU; cpu++) { cpu_qos_data[cpu]->domain_info[indexof(domid)].in_use = 0; } }", "target": 0, "idx": 108160, "project": "Xen"}
{"func": "static int reassign_device_ownership( struct domain *source, struct domain *target, u8 bus, u8 devfn) { struct pci_dev *pdev; int ret; ASSERT(spin_is_locked(&pcidevs_lock)); pdev = pci_get_pdev_by_domain(source, bus, devfn); if (!pdev) return -ENODEV; ret = domain_context_unmap(source, bus, devfn); if ( ret ) return ret; ret = domain_context_mapping(target, bus, devfn); if ( ret ) return ret; list_move(&pdev->domain_list, &target->arch.pdev_list); pdev->domain = target; return ret; }", "target": 1, "idx": 108994, "project": "Xen"}
{"func": "int main_debug_keys(int argc, char **argv) { int opt; char *keys; SWITCH_FOREACH_OPT(opt, \"\", NULL, \"debug-keys\", 1) {  } keys = argv[optind]; if (libxl_send_debug_keys(ctx, keys)) { fprintf(stderr, \"cannot send debug keys: %s\\n\", keys); return EXIT_FAILURE; } return EXIT_SUCCESS; }", "target": 0, "idx": 108713, "project": "Xen"}
{"func": "static int xc_try_lzma_decode( struct xc_dom_image *dom, void **blob, size_t *size) { lzma_stream stream = LZMA_STREAM_INIT; lzma_ret ret; lzma_action action = LZMA_RUN; unsigned char *out_buf; unsigned char *tmp_buf; int retval = -1; int outsize; const char *msg; ret = lzma_alone_decoder(&stream, 128*1024*1024); if ( ret != LZMA_OK ) { DOMPRINTF(\"LZMA: Failed to init stream decoder\"); return -1; }  outsize = dom->kernel_size; out_buf = malloc(outsize); if ( out_buf == NULL ) { DOMPRINTF(\"LZMA: Failed to alloc memory\"); goto lzma_cleanup; } stream.next_in = dom->kernel_blob; stream.avail_in = dom->kernel_size; stream.next_out = out_buf; stream.avail_out = dom->kernel_size; for ( ; ; ) { ret = lzma_code(&stream, action); if ( (stream.avail_out == 0) || (ret != LZMA_OK) ) { tmp_buf = realloc(out_buf, outsize * 2); if ( tmp_buf == NULL ) { DOMPRINTF(\"LZMA: Failed to realloc memory\"); free(out_buf); goto lzma_cleanup; } out_buf = tmp_buf; stream.next_out = out_buf + outsize; stream.avail_out = (outsize * 2) - outsize; outsize *= 2; } if ( ret != LZMA_OK ) { if ( ret == LZMA_STREAM_END ) { DOMPRINTF(\"LZMA: Saw data stream end\"); retval = 0; break; } switch ( ret ) { case LZMA_MEM_ERROR: msg = strerror(ENOMEM); break; case LZMA_MEMLIMIT_ERROR: msg = \"Memory usage limit reached\"; break; case LZMA_FORMAT_ERROR: msg = \"File format not recognized\"; break; case LZMA_OPTIONS_ERROR:  msg = \"Unsupported compression options\"; break; case LZMA_DATA_ERROR: msg = \"File is corrupt\"; break; case LZMA_BUF_ERROR: msg = \"Unexpected end of input\"; break; default: msg = \"Internal program error (bug)\"; break; } DOMPRINTF(\"%s: LZMA decompression error %s\", __FUNCTION__, msg); break; } } DOMPRINTF(\"%s: LZMA decompress OK, 0x%zx -> 0x%zx\", __FUNCTION__, *size, (size_t)stream.total_out); *blob = out_buf; *size = stream.total_out;  lzma_cleanup: lzma_end(&stream); return retval; }", "target": 1, "idx": 108990, "project": "Xen"}
{"func": "static void map_colortable(void) { register uint32 *histp = &histogram[0][0][0]; register C_cell *cell; register int j, tmp, d2, dist; int ir, ig, ib, i; for (ir = 0; ir < B_LEN; ++ir) for (ig = 0; ig < B_LEN; ++ig) for (ib = 0; ib < B_LEN; ++ib, histp++) { if (*histp == 0) { *histp = -1; continue; } cell = *(ColorCells + (((ir>>(B_DEPTH-C_DEPTH)) << C_DEPTH*2) + ((ig>>(B_DEPTH-C_DEPTH)) << C_DEPTH) + (ib>>(B_DEPTH-C_DEPTH)))); if (cell == NULL ) cell = create_colorcell( ir << COLOR_SHIFT, ig << COLOR_SHIFT, ib << COLOR_SHIFT); dist = 9999999; for (i = 0; i < cell->num_ents && dist > cell->entries[i][1]; ++i) { j = cell->entries[i][0]; d2 = rm[j] - (ir << COLOR_SHIFT); d2 *= d2; tmp = gm[j] - (ig << COLOR_SHIFT); d2 += tmp*tmp; tmp = bm[j] - (ib << COLOR_SHIFT); d2 += tmp*tmp; if (d2 < dist) { dist = d2; *histp = j; } } } }", "target": 0, "idx": 100525, "project": "LibTIFF"}
{"func": "static int watchpoint_stop(void) { return 0; }", "target": 0, "idx": 102618, "project": "Xen"}
{"func": "static void seabios_finish_bios_info(void) { struct seabios_info *info = (void *)BIOS_INFO_PHYSICAL_ADDRESS; uint32_t i; uint8_t checksum; checksum = 0; for ( i = 0; i < info->length; i++ ) checksum += ((uint8_t *)(info))[i]; info->checksum = -checksum; }", "target": 0, "idx": 105664, "project": "Xen"}
{"func": "unsigned long long xenstat_network_tpackets(xenstat_network * network) { return network->tpackets; }", "target": 0, "idx": 108374, "project": "Xen"}
{"func": "static int vm_event_wait_slot(struct vm_event_domain *ved) { int rc = -EBUSY; wait_event(ved->wq, vm_event_wait_try_grab(ved, &rc) != -EBUSY); return rc; }", "target": 0, "idx": 107073, "project": "Xen"}
{"func": "static int hvm_emulate_write(enum x86_segment seg, unsigned long offset, void *p_data, unsigned int bytes, struct x86_emulate_ctxt *ctxt) { struct sh_emulate_ctxt *sh_ctxt = container_of(ctxt, struct sh_emulate_ctxt, ctxt); struct vcpu *v = current; unsigned long addr; int rc; if ( !is_x86_user_segment(seg) ) return X86EMUL_UNHANDLEABLE;  if ( seg == x86_seg_ss ) perfc_incr(shadow_fault_emulate_stack); rc = hvm_translate_linear_addr( seg, offset, bytes, hvm_access_write, sh_ctxt, &addr); if ( rc ) return rc; return v->arch.paging.mode->shadow.x86_emulate_write( v, addr, p_data, bytes, sh_ctxt); }", "target": 1, "idx": 109405, "project": "Xen"}
{"func": " kernel boot-time. */ static inline void setup_num_counters(void) { if (boot_cpu_data.x86_num_siblings == 2)  num_counters = NUM_COUNTERS_HT2; }", "target": 0, "idx": 104964, "project": "Xen"}
{"func": "static Colorbox * largest_box(void) { register Colorbox *p, *b; register uint32 size; b = NULL; size = 0; for (p = usedboxes; p != NULL; p = p->next) if ((p->rmax > p->rmin || p->gmax > p->gmin || p->bmax > p->bmin) &&p->total > size) size = (b = p)->total; return (b); }", "target": 0, "idx": 100720, "project": "LibTIFF"}
{"func": "static int __devinit platform_pci_init(struct pci_dev *pdev,  const struct pci_device_id *ent) { int i, ret; long ioaddr, iolen; long mmio_addr, mmio_len; if (xen_platform_pdev) return -EBUSY; xen_platform_pdev = pdev; i = pci_enable_device(pdev); if (i) return i; ioaddr = pci_resource_start(pdev, 0); iolen = pci_resource_len(pdev, 0); mmio_addr = pci_resource_start(pdev, 1); mmio_len = pci_resource_len(pdev, 1); callback_via = get_callback_via(pdev); if (mmio_addr == 0 || ioaddr == 0 || callback_via == 0) { printk(KERN_WARNING DRV_NAME \":no resources found\\n\"); return -ENOENT; } ret = pci_request_region(pdev, 1, DRV_NAME); if (ret < 0) return ret; ret = pci_request_region(pdev, 0, DRV_NAME); if (ret < 0) goto mem_out; platform_mmio = mmio_addr; platform_mmiolen = mmio_len; ret = init_hypercall_stubs(); if (ret < 0) goto out; ret = check_platform_magic(&pdev->dev, ioaddr, iolen); if (ret < 0) goto out; if ((ret = init_xen_info())) goto out; if ((ret = gnttab_init())) goto out; if ((ret = xen_irq_init(pdev))) goto out; if ((ret = set_callback_via(callback_via))) goto out; if ((ret = xenbus_init())) goto out; if ((ret = xen_reboot_init())) goto out; if ((ret = xen_panic_handler_init())) goto out; #ifdef HAVE_OLDMEM_PFN_IS_RAM register_oldmem_pfn_is_ram(&xen_oldmem_pfn_is_ram); #endif  out: if (ret) { pci_release_region(pdev, 0); mem_out: pci_release_region(pdev, 1); } return ret; }", "target": 0, "idx": 105072, "project": "Xen"}
{"func": "static int OJPEGReadHeaderInfoSecTablesDcTable(TIFF* tif) { static const char module[]=\"OJPEGReadHeaderInfoSecTablesDcTable\"; OJPEGState* sp=(OJPEGState*)tif->tif_data; uint8 m; uint8 n; uint8 o[16]; uint32 p; uint32 q; uint32 ra; uint8* rb; if (sp->dctable_offset[0]==0) { TIFFErrorExt(tif->tif_clientdata,module,\"Missing JPEG tables\"); return(0); } sp->in_buffer_file_pos_log=0; for (m=0; m<sp->samples_per_pixel; m++) { if ((sp->dctable_offset[m]!=0) && ((m==0) || (sp->dctable_offset[m]!=sp->dctable_offset[m-1]))) { for (n=0; n<m-1; n++) { if (sp->dctable_offset[m]==sp->dctable_offset[n]) { TIFFErrorExt(tif->tif_clientdata,module,\"Corrupt JpegDcTables tag value\"); return(0); } } TIFFSeekFile(tif,sp->dctable_offset[m],SEEK_SET); p=(uint32)TIFFReadFile(tif,o,16); if (p!=16) return(0); q=0; for (n=0; n<16; n++) q+=o[n]; ra=sizeof(uint32)+21+q; rb=_TIFFmalloc(ra); if (rb==0) { TIFFErrorExt(tif->tif_clientdata,module,\"Out of memory\"); return(0); } *(uint32*)rb=ra; rb[sizeof(uint32)]=255; rb[sizeof(uint32)+1]=JPEG_MARKER_DHT; rb[sizeof(uint32)+2]=(uint8)((19+q)>>8); rb[sizeof(uint32)+3]=((19+q)&255); rb[sizeof(uint32)+4]=m; for (n=0; n<16; n++) rb[sizeof(uint32)+5+n]=o[n]; p=(uint32)TIFFReadFile(tif,&(rb[sizeof(uint32)+21]),q); if (p!=q) return(0); sp->dctable[m]=rb; sp->sos_tda[m]=(m<<4); } else sp->sos_tda[m]=sp->sos_tda[m-1]; } return(1); }", "target": 1, "idx": 100829, "project": "LibTIFF"}
{"func": "static void switch_logdirty_done(libxl__egc *egc,  libxl__logdirty_switch *lds,  int rc) { STATE_AO_GC(lds->ao); libxl__ev_xswatch_deregister(gc, &lds->watch); libxl__ev_time_deregister(gc, &lds->timeout); lds->callback(egc, lds, rc); }", "target": 0, "idx": 103574, "project": "Xen"}
{"func": "static inline void atomic_inc(uint32_t *v) { unsigned long tmp; int result; __asm__ __volatile__(\"@ atomic_inc\\n\" \"1: ldrex %0, [%3]\\n\" \" add %0, %0, #1\\n\" \" strex %1, %0, [%3]\\n\" \" teq %1, #0\\n\" \" bne 1b\" : \"=&r\" (result), \"=&r\" (tmp), \"+Qo\" (*v) : \"r\" (v) : \"cc\"); } #elif defined(__aarch64__) static inline void atomic_inc(uint32_t *v) { unsigned long tmp; int result; asm volatile(\"// atomic_inc\\n\" \"1: ldxr%w0, [%3]\\n\" \" add %w0, %w0, #1\\n\" \" stxr%w1, %w0, [%3]\\n\" \" cbnz%w1, 1b\" : \"=&r\" (result), \"=&r\" (tmp), \"+o\" (v) : \"r\" (v) : \"cc\"); } #else  static inline void atomic_inc(uint32_t *v) { asm volatile ( \"lock ; incl %0\" : \"=m\" (*(volatile uint32_t *)v) : \"m\" (*(volatile uint32_t *)v) ); }", "target": 0, "idx": 100959, "project": "Xen"}
{"func": " */ struct rb_node *rb_first(const struct rb_root *root) { struct rb_node*n; n = root->rb_node; if (!n) return NULL; while (n->rb_left) n = n->rb_left; return n; }", "target": 0, "idx": 105328, "project": "Xen"}
{"func": "const char *fdt_get_name(const void *fdt, int nodeoffset, int *len) { const struct fdt_node_header *nh = _fdt_offset_ptr(fdt, nodeoffset); int err; if (((err = fdt_check_header(fdt)) != 0) || ((err = _fdt_check_node_offset(fdt, nodeoffset)) < 0)) goto fail; if (len) *len = strlen(nh->name); return nh->name;  fail: if (len) *len = err; return NULL; }", "target": 0, "idx": 102003, "project": "Xen"}
{"func": "bool elf_is_elfbinary(const void *image_start, size_t image_size) { const Elf32_Ehdr *ehdr = image_start; if ( image_size < sizeof(*ehdr) ) return 0; return IS_ELF(*ehdr); }", "target": 0, "idx": 103041, "project": "Xen"}
{"func": "static void __trace_multicall_call(multicall_entry_t *call) { xen_ulong_t args[6]; int i; for ( i = 0; i < ARRAY_SIZE(args); i++ ) args[i] = call->args[i]; __trace_hypercall(TRC_PV_HYPERCALL_SUBCALL, call->op, args); }", "target": 0, "idx": 104695, "project": "Xen"}
{"func": "void altp2m_vcpu_reset(struct vcpu *v) { struct altp2mvcpu *av = &vcpu_altp2m(v); av->p2midx = INVALID_ALTP2M; av->veinfo_gfn = INVALID_GFN; }", "target": 0, "idx": 100872, "project": "Xen"}
{"func": "static void set_x2apic_id(struct vlapic *vlapic) { u32 id = vlapic_vcpu(vlapic)->vcpu_id; u32 ldr = ((id & ~0xf) << 12) | (1 << (id & 0xf)); vlapic_set_reg(vlapic, APIC_ID, id * 2); vlapic_set_reg(vlapic, APIC_LDR, ldr); }", "target": 0, "idx": 106924, "project": "Xen"}
{"func": "int xc_sched_credit_domain_get( xc_interface *xch, uint32_t domid, struct xen_domctl_sched_credit *sdom) { DECLARE_DOMCTL; domctl.cmd = XEN_DOMCTL_scheduler_op; domctl.domain = domid; domctl.u.scheduler_op.sched_id = XEN_SCHEDULER_CREDIT; domctl.u.scheduler_op.cmd = XEN_DOMCTL_SCHEDOP_getinfo; if ( do_domctl(xch, &domctl) ) return -1; *sdom = domctl.u.scheduler_op.u.credit; return 0; }", "target": 0, "idx": 107352, "project": "Xen"}
{"func": "static void guest_iommu_process_command(unsigned long _d) { unsigned long opcode, tail, head, entries_per_page, cmd_mfn; cmd_entry_t *cmd, *cmd_base; struct domain *d = (struct domain *)_d; struct guest_iommu *iommu; iommu = domain_iommu(d); if ( !iommu->enabled ) return; head = iommu_get_rb_pointer(iommu->cmd_buffer.reg_head.lo); tail = iommu_get_rb_pointer(iommu->cmd_buffer.reg_tail.lo);  if ( tail >= iommu->cmd_buffer.entries ||  head >= iommu->cmd_buffer.entries ) { AMD_IOMMU_DEBUG(\"Error: guest iommu cmd buffer overflows\\n\"); guest_iommu_disable(iommu); return; } entries_per_page = PAGE_SIZE / sizeof(cmd_entry_t); while ( head != tail ) { int ret = 0; cmd_mfn = guest_iommu_get_table_mfn(d, reg_to_u64(iommu->cmd_buffer.reg_base), sizeof(cmd_entry_t), head); ASSERT(mfn_valid(_mfn(cmd_mfn))); cmd_base = map_domain_page(_mfn(cmd_mfn)); cmd = cmd_base + head % entries_per_page; opcode = get_field_from_reg_u32(cmd->data[1], IOMMU_CMD_OPCODE_MASK, IOMMU_CMD_OPCODE_SHIFT); switch ( opcode ) { case IOMMU_CMD_COMPLETION_WAIT: ret = do_completion_wait(d, cmd); break; case IOMMU_CMD_INVALIDATE_DEVTAB_ENTRY: ret = do_invalidate_dte(d, cmd); break; case IOMMU_CMD_INVALIDATE_IOMMU_PAGES: ret = do_invalidate_pages(d, cmd); break; case IOMMU_CMD_INVALIDATE_IOTLB_PAGES: ret = do_invalidate_iotlb_pages(d, cmd); break; case IOMMU_CMD_INVALIDATE_INT_TABLE: break; case IOMMU_CMD_COMPLETE_PPR_REQUEST: ret = do_complete_ppr_request(d, cmd); break; case IOMMU_CMD_INVALIDATE_IOMMU_ALL: ret = do_invalidate_all(d, cmd); break; default: AMD_IOMMU_DEBUG(\"CMD: Unknown command cmd_type = %lx \" \"head = %ld\\n\", opcode, head); break; } unmap_domain_page(cmd_base); if ( ++head >= iommu->cmd_buffer.entries ) head = 0; if ( ret ) guest_iommu_disable(iommu); }  iommu_set_rb_pointer(&iommu->cmd_buffer.reg_head.lo, head); return; }", "target": 0, "idx": 102822, "project": "Xen"}
{"func": "static int yy_flex_strlen (yyconst char * s , yyscan_t yyscanner) { register int n; for ( n = 0; s[n]; ++n ) ; return n; }", "target": 0, "idx": 103271, "project": "Xen"}
{"func": "void vmx_clear_msr_intercept(struct vcpu *v, unsigned int msr,  enum vmx_msr_intercept_type type) { struct vmx_msr_bitmap *msr_bitmap = v->arch.hvm_vmx.msr_bitmap; struct domain *d = v->domain;  if ( msr_bitmap == NULL ) return; if ( unlikely(monitored_msr(d, msr)) ) return; if ( msr <= 0x1fff ) { if ( type & VMX_MSR_R ) clear_bit(msr, msr_bitmap->read_low); if ( type & VMX_MSR_W ) clear_bit(msr, msr_bitmap->write_low); } else if ( (msr >= 0xc0000000) && (msr <= 0xc0001fff) ) { msr &= 0x1fff; if ( type & VMX_MSR_R ) clear_bit(msr, msr_bitmap->read_high); if ( type & VMX_MSR_W ) clear_bit(msr, msr_bitmap->write_high); } else ASSERT(!\"MSR out of range for interception\\n\"); }", "target": 0, "idx": 107019, "project": "Xen"}
{"func": "void xenstat_uninit(xenstat_handle * handle) { unsigned int i; if (handle) { for (i = 0; i < NUM_COLLECTORS; i++) collectors[i].uninit(handle); xc_interface_close(handle->xc_handle); xs_daemon_close(handle->xshandle); free(handle->priv); free(handle); } }", "target": 0, "idx": 108386, "project": "Xen"}
{"func": " */ static void update_schedule_vcpus(const struct scheduler *ops) { unsigned int i, n_entries = SCHED_PRIV(ops)->num_schedule_entries; for ( i = 0; i < n_entries; i++ ) SCHED_PRIV(ops)->schedule[i].vc = find_vcpu(ops, SCHED_PRIV(ops)->schedule[i].dom_handle, SCHED_PRIV(ops)->schedule[i].vcpu_id); }", "target": 0, "idx": 105470, "project": "Xen"}
{"func": "static bool iopl_ok(const struct vcpu *v, const struct cpu_user_regs *regs) { unsigned int cpl = guest_kernel_mode(v, regs) ? (VM_ASSIST(v->domain, architectural_iopl) ? 0 : 1) : 3; ASSERT((v->arch.pv_vcpu.iopl & ~X86_EFLAGS_IOPL) == 0); return IOPL(cpl) <= v->arch.pv_vcpu.iopl; }", "target": 0, "idx": 101865, "project": "Xen"}
{"func": "Bit8u inhibit_mouse_int_and_events() { Bit8u command_byte, prev_command_byte;  if ( inb(0x64) & 0x02 ) BX_PANIC(panic_msg_keyb_buffer_full,\"inhibmouse\"); outb(0x64, 0x20);  while ( (inb(0x64) & 0x01) != 0x01 ); prev_command_byte = inb(0x60); command_byte = prev_command_byte;  if ( inb(0x64) & 0x02 ) BX_PANIC(panic_msg_keyb_buffer_full,\"inhibmouse\"); command_byte &= 0xfd;  command_byte |= 0x20;  outb(0x64, 0x60);  outb(0x60, command_byte); return(prev_command_byte); }", "target": 0, "idx": 105416, "project": "Xen"}
{"func": "void sidtab_destroy(struct sidtab *s) { int i; struct sidtab_node *cur, *temp; if ( !s ) return; for ( i = 0; i < SIDTAB_SIZE; i++ ) { cur = s->htable[i]; while ( cur != NULL ) { temp = cur; cur = cur->next; context_destroy(&temp->context); xfree(temp); } s->htable[i] = NULL; } xfree(s->htable); s->htable = NULL; s->nel = 0; s->next_sid = 1; }", "target": 0, "idx": 105759, "project": "Xen"}
{"func": "static int __init initialise_gdb(void) { if ( *opt_gdb == '\\0' ) return 0; gdb_ctx->serhnd = serial_parse_handle(opt_gdb); if ( gdb_ctx->serhnd == -1 ) { printk(\"Bad gdb= option '%s'\\n\", opt_gdb); return 0; } serial_start_sync(gdb_ctx->serhnd); printk(\"GDB stub initialised.\\n\"); return 0; }", "target": 0, "idx": 102352, "project": "Xen"}
{"func": " */ static int xenpaging_evict_page(struct xenpaging *paging, unsigned long gfn, int slot) { xc_interface *xch = paging->xc_handle; void *page; xen_pfn_t victim = gfn; int ret; DECLARE_DOMCTL;  ret = xc_mem_paging_nominate(xch, paging->vm_event.domain_id, gfn); if ( ret < 0 ) {  if ( errno == EBUSY ) ret = 1; else PERROR(\"Error nominating page %lx\", gfn); goto out; }  page = xc_map_foreign_pages(xch, paging->vm_event.domain_id, PROT_READ, &victim, 1); if ( page == NULL ) { PERROR(\"Error mapping page %lx\", gfn); ret = -1; goto out; }  ret = write_page(paging->fd, page, slot); if ( ret < 0 ) { PERROR(\"Error copying page %lx\", gfn); munmap(page, PAGE_SIZE); ret = -1; goto out; }  munmap(page, PAGE_SIZE);  ret = xc_mem_paging_evict(xch, paging->vm_event.domain_id, gfn); if ( ret < 0 ) {  if ( errno == EBUSY ) { ret = 1; DPRINTF(\"Nominated page %lx busy\", gfn); } else PERROR(\"Error evicting page %lx\", gfn); goto out; } DPRINTF(\"evict_page > gfn %lx pageslot %d\\n\", gfn, slot);  policy_notify_paged_out(gfn);  paging->slot_to_gfn[slot] = gfn; paging->gfn_to_slot[gfn] = slot;  paging->num_paged_out++; ret = 0;  out: return ret; }", "target": 0, "idx": 108289, "project": "Xen"}
{"func": "static int _TIFFVSetField(TIFF* tif, uint32 tag, va_list ap) { static const char module[] = \"_TIFFVSetField\"; TIFFDirectory* td = &tif->tif_dir; int status = 1; uint32 v32, i, v; double dblval; char* s; const TIFFField *fip = TIFFFindField(tif, tag, TIFF_ANY); uint32 standard_tag = tag; if( fip == NULL )  return 0;  if (fip->field_bit == FIELD_CUSTOM) { standard_tag = 0; } switch (standard_tag) { case TIFFTAG_SUBFILETYPE: td->td_subfiletype = (uint32) va_arg(ap, uint32); break; case TIFFTAG_IMAGEWIDTH: td->td_imagewidth = (uint32) va_arg(ap, uint32); break; case TIFFTAG_IMAGELENGTH: td->td_imagelength = (uint32) va_arg(ap, uint32); break; case TIFFTAG_BITSPERSAMPLE: td->td_bitspersample = (uint16) va_arg(ap, uint16_vap);  if (tif->tif_flags & TIFF_SWAB) { if (td->td_bitspersample == 8) tif->tif_postdecode = _TIFFNoPostDecode; else if (td->td_bitspersample == 16) tif->tif_postdecode = _TIFFSwab16BitData; else if (td->td_bitspersample == 24) tif->tif_postdecode = _TIFFSwab24BitData; else if (td->td_bitspersample == 32) tif->tif_postdecode = _TIFFSwab32BitData; else if (td->td_bitspersample == 64) tif->tif_postdecode = _TIFFSwab64BitData; else if (td->td_bitspersample == 128)  tif->tif_postdecode = _TIFFSwab64BitData; } break; case TIFFTAG_COMPRESSION: v = (uint16) va_arg(ap, uint16_vap);  if (TIFFFieldSet(tif, FIELD_COMPRESSION)) { if ((uint32)td->td_compression == v) break; (*tif->tif_cleanup)(tif); tif->tif_flags &= ~TIFF_CODERSETUP; }  if( (status = TIFFSetCompressionScheme(tif, v)) != 0 ) td->td_compression = (uint16) v; else status = 0; break; case TIFFTAG_PHOTOMETRIC: td->td_photometric = (uint16) va_arg(ap, uint16_vap); break; case TIFFTAG_THRESHHOLDING: td->td_threshholding = (uint16) va_arg(ap, uint16_vap); break; case TIFFTAG_FILLORDER: v = (uint16) va_arg(ap, uint16_vap); if (v != FILLORDER_LSB2MSB && v != FILLORDER_MSB2LSB) goto badvalue; td->td_fillorder = (uint16) v; break; case TIFFTAG_ORIENTATION: v = (uint16) va_arg(ap, uint16_vap); if (v < ORIENTATION_TOPLEFT || ORIENTATION_LEFTBOT < v) goto badvalue; else td->td_orientation = (uint16) v; break; case TIFFTAG_SAMPLESPERPIXEL: v = (uint16) va_arg(ap, uint16_vap); if (v == 0) goto badvalue; td->td_samplesperpixel = (uint16) v; break; case TIFFTAG_ROWSPERSTRIP: v32 = (uint32) va_arg(ap, uint32); if (v32 == 0) goto badvalue32; td->td_rowsperstrip = v32; if (!TIFFFieldSet(tif, FIELD_TILEDIMENSIONS)) { td->td_tilelength = v32; td->td_tilewidth = td->td_imagewidth; } break; case TIFFTAG_MINSAMPLEVALUE: td->td_minsamplevalue = (uint16) va_arg(ap, uint16_vap); break; case TIFFTAG_MAXSAMPLEVALUE: td->td_maxsamplevalue = (uint16) va_arg(ap, uint16_vap); break; case TIFFTAG_SMINSAMPLEVALUE: if (tif->tif_flags & TIFF_PERSAMPLE) _TIFFsetDoubleArray(&td->td_sminsamplevalue, va_arg(ap, double*), td->td_samplesperpixel); else setDoubleArrayOneValue(&td->td_sminsamplevalue, va_arg(ap, double), td->td_samplesperpixel); break; case TIFFTAG_SMAXSAMPLEVALUE: if (tif->tif_flags & TIFF_PERSAMPLE) _TIFFsetDoubleArray(&td->td_smaxsamplevalue, va_arg(ap, double*), td->td_samplesperpixel); else setDoubleArrayOneValue(&td->td_smaxsamplevalue, va_arg(ap, double), td->td_samplesperpixel); break; case TIFFTAG_XRESOLUTION: dblval = va_arg(ap, double); if( dblval < 0 ) goto badvaluedouble; td->td_xresolution = (float) dblval; break; case TIFFTAG_YRESOLUTION: dblval = va_arg(ap, double); if( dblval < 0 ) goto badvaluedouble; td->td_yresolution = (float) dblval; break; case TIFFTAG_PLANARCONFIG: v = (uint16) va_arg(ap, uint16_vap); if (v != PLANARCONFIG_CONTIG && v != PLANARCONFIG_SEPARATE) goto badvalue; td->td_planarconfig = (uint16) v; break; case TIFFTAG_XPOSITION: td->td_xposition = (float) va_arg(ap, double); break; case TIFFTAG_YPOSITION: td->td_yposition = (float) va_arg(ap, double); break; case TIFFTAG_RESOLUTIONUNIT: v = (uint16) va_arg(ap, uint16_vap); if (v < RESUNIT_NONE || RESUNIT_CENTIMETER < v) goto badvalue; td->td_resolutionunit = (uint16) v; break; case TIFFTAG_PAGENUMBER: td->td_pagenumber[0] = (uint16) va_arg(ap, uint16_vap); td->td_pagenumber[1] = (uint16) va_arg(ap, uint16_vap); break; case TIFFTAG_HALFTONEHINTS: td->td_halftonehints[0] = (uint16) va_arg(ap, uint16_vap); td->td_halftonehints[1] = (uint16) va_arg(ap, uint16_vap); break; case TIFFTAG_COLORMAP: v32 = (uint32)(1L<<td->td_bitspersample); _TIFFsetShortArray(&td->td_colormap[0], va_arg(ap, uint16*), v32); _TIFFsetShortArray(&td->td_colormap[1], va_arg(ap, uint16*), v32); _TIFFsetShortArray(&td->td_colormap[2], va_arg(ap, uint16*), v32); break; case TIFFTAG_EXTRASAMPLES: if (!setExtraSamples(td, ap, &v)) goto badvalue; break; case TIFFTAG_MATTEING: td->td_extrasamples =(((uint16) va_arg(ap, uint16_vap)) != 0); if (td->td_extrasamples) { uint16 sv = EXTRASAMPLE_ASSOCALPHA; _TIFFsetShortArray(&td->td_sampleinfo, &sv, 1); } break; case TIFFTAG_TILEWIDTH: v32 = (uint32) va_arg(ap, uint32); if (v32 % 16) { if (tif->tif_mode != O_RDONLY) goto badvalue32; TIFFWarningExt(tif->tif_clientdata, tif->tif_name, \"Nonstandard tile width %d, convert file\", v32); } td->td_tilewidth = v32; tif->tif_flags |= TIFF_ISTILED; break; case TIFFTAG_TILELENGTH: v32 = (uint32) va_arg(ap, uint32); if (v32 % 16) { if (tif->tif_mode != O_RDONLY) goto badvalue32; TIFFWarningExt(tif->tif_clientdata, tif->tif_name, \"Nonstandard tile length %d, convert file\", v32); } td->td_tilelength = v32; tif->tif_flags |= TIFF_ISTILED; break; case TIFFTAG_TILEDEPTH: v32 = (uint32) va_arg(ap, uint32); if (v32 == 0) goto badvalue32; td->td_tiledepth = v32; break; case TIFFTAG_DATATYPE: v = (uint16) va_arg(ap, uint16_vap); switch (v) { case DATATYPE_VOID:v = SAMPLEFORMAT_VOID;break; case DATATYPE_INT:v = SAMPLEFORMAT_INT;break; case DATATYPE_UINT:v = SAMPLEFORMAT_UINT;break; case DATATYPE_IEEEFP:v = SAMPLEFORMAT_IEEEFP;break; default:goto badvalue; } td->td_sampleformat = (uint16) v; break; case TIFFTAG_SAMPLEFORMAT: v = (uint16) va_arg(ap, uint16_vap); if (v < SAMPLEFORMAT_UINT || SAMPLEFORMAT_COMPLEXIEEEFP < v) goto badvalue; td->td_sampleformat = (uint16) v;  if( td->td_sampleformat == SAMPLEFORMAT_COMPLEXINT && td->td_bitspersample == 32 && tif->tif_postdecode == _TIFFSwab32BitData ) tif->tif_postdecode = _TIFFSwab16BitData; else if( (td->td_sampleformat == SAMPLEFORMAT_COMPLEXINT || td->td_sampleformat == SAMPLEFORMAT_COMPLEXIEEEFP)  && td->td_bitspersample == 64  && tif->tif_postdecode == _TIFFSwab64BitData ) tif->tif_postdecode = _TIFFSwab32BitData; break; case TIFFTAG_IMAGEDEPTH: td->td_imagedepth = (uint32) va_arg(ap, uint32); break; case TIFFTAG_SUBIFD: if ((tif->tif_flags & TIFF_INSUBIFD) == 0) { td->td_nsubifd = (uint16) va_arg(ap, uint16_vap); _TIFFsetLong8Array(&td->td_subifd, (uint64*) va_arg(ap, uint64*), (long) td->td_nsubifd); } else { TIFFErrorExt(tif->tif_clientdata, module,  \"%s: Sorry, cannot nest SubIFDs\",  tif->tif_name); status = 0; } break; case TIFFTAG_YCBCRPOSITIONING: td->td_ycbcrpositioning = (uint16) va_arg(ap, uint16_vap); break; case TIFFTAG_YCBCRSUBSAMPLING: td->td_ycbcrsubsampling[0] = (uint16) va_arg(ap, uint16_vap); td->td_ycbcrsubsampling[1] = (uint16) va_arg(ap, uint16_vap); break; case TIFFTAG_TRANSFERFUNCTION: v = (td->td_samplesperpixel - td->td_extrasamples) > 1 ? 3 : 1; for (i = 0; i < v; i++) _TIFFsetShortArray(&td->td_transferfunction[i], va_arg(ap, uint16*), 1L<<td->td_bitspersample); break; case TIFFTAG_REFERENCEBLACKWHITE:  _TIFFsetFloatArray(&td->td_refblackwhite, va_arg(ap, float*), 6); break; case TIFFTAG_INKNAMES: v = (uint16) va_arg(ap, uint16_vap); s = va_arg(ap, char*); v = checkInkNamesString(tif, v, s); status = v > 0; if( v > 0 ) { _TIFFsetNString(&td->td_inknames, s, v); td->td_inknameslen = v; } break; case TIFFTAG_PERSAMPLE: v = (uint16) va_arg(ap, uint16_vap); if( v == PERSAMPLE_MULTI ) tif->tif_flags |= TIFF_PERSAMPLE; else tif->tif_flags &= ~TIFF_PERSAMPLE; break; default: { TIFFTagValue *tv; int tv_size, iCustom;  if(fip->field_bit != FIELD_CUSTOM) { TIFFErrorExt(tif->tif_clientdata, module, \"%s: Invalid %stag \\\"%s\\\" (not supported by codec)\", tif->tif_name, isPseudoTag(tag) ? \"pseudo-\" : \"\", fip->field_name); status = 0; break; }  tv = NULL; for (iCustom = 0; iCustom < td->td_customValueCount; iCustom++) { if (td->td_customValues[iCustom].info->field_tag == tag) { tv = td->td_customValues + iCustom; if (tv->value != NULL) { _TIFFfree(tv->value); tv->value = NULL; } break; } }  if(tv == NULL) { TIFFTagValue *new_customValues; td->td_customValueCount++; new_customValues = (TIFFTagValue *) _TIFFrealloc(td->td_customValues, sizeof(TIFFTagValue) * td->td_customValueCount); if (!new_customValues) { TIFFErrorExt(tif->tif_clientdata, module, \"%s: Failed to allocate space for list of custom values\", tif->tif_name); status = 0; goto end; } td->td_customValues = new_customValues; tv = td->td_customValues + (td->td_customValueCount - 1); tv->info = fip; tv->value = NULL; tv->count = 0; }  tv_size = _TIFFDataSize(fip->field_type); if (tv_size == 0) { status = 0; TIFFErrorExt(tif->tif_clientdata, module, \"%s: Bad field type %d for \\\"%s\\\"\", tif->tif_name, fip->field_type, fip->field_name); goto end; } if (fip->field_type == TIFF_ASCII) { uint32 ma; char* mb; if (fip->field_passcount) { assert(fip->field_writecount==TIFF_VARIABLE2); ma=(uint32)va_arg(ap,uint32); mb=(char*)va_arg(ap,char*); } else { mb=(char*)va_arg(ap,char*); ma=(uint32)(strlen(mb)+1); } tv->count=ma; setByteArray(&tv->value,mb,ma,1); } else { if (fip->field_passcount) { if (fip->field_writecount == TIFF_VARIABLE2) tv->count = (uint32) va_arg(ap, uint32); else tv->count = (int) va_arg(ap, int); } else if (fip->field_writecount == TIFF_VARIABLE  || fip->field_writecount == TIFF_VARIABLE2) tv->count = 1; else if (fip->field_writecount == TIFF_SPP) tv->count = td->td_samplesperpixel; else tv->count = fip->field_writecount; if (tv->count == 0) { status = 0; TIFFErrorExt(tif->tif_clientdata, module,  \"%s: Null count for \\\"%s\\\" (type \"  \"%d, writecount %d, passcount %d)\",  tif->tif_name,  fip->field_name,  fip->field_type,  fip->field_writecount,  fip->field_passcount); goto end; } tv->value = _TIFFCheckMalloc(tif, tv->count, tv_size, \"custom tag binary object\"); if (!tv->value) { status = 0; goto end; } if (fip->field_tag == TIFFTAG_DOTRANGE  && strcmp(fip->field_name,\"DotRange\") == 0) {  uint16 v[2]; v[0] = (uint16)va_arg(ap, int); v[1] = (uint16)va_arg(ap, int); _TIFFmemcpy(tv->value, &v, 4); } else if (fip->field_passcount || fip->field_writecount == TIFF_VARIABLE || fip->field_writecount == TIFF_VARIABLE2 || fip->field_writecount == TIFF_SPP || tv->count > 1) { _TIFFmemcpy(tv->value, va_arg(ap, void *), tv->count * tv_size); } else { char *val = (char *)tv->value; assert( tv->count == 1 ); switch (fip->field_type) { case TIFF_BYTE: case TIFF_UNDEFINED: { uint8 v = (uint8)va_arg(ap, int); _TIFFmemcpy(val, &v, tv_size); } break; case TIFF_SBYTE: { int8 v = (int8)va_arg(ap, int); _TIFFmemcpy(val, &v, tv_size); } break; case TIFF_SHORT: { uint16 v = (uint16)va_arg(ap, int); _TIFFmemcpy(val, &v, tv_size); } break; case TIFF_SSHORT: { int16 v = (int16)va_arg(ap, int); _TIFFmemcpy(val, &v, tv_size); } break; case TIFF_LONG: case TIFF_IFD: { uint32 v = va_arg(ap, uint32); _TIFFmemcpy(val, &v, tv_size); } break; case TIFF_SLONG: { int32 v = va_arg(ap, int32); _TIFFmemcpy(val, &v, tv_size); } break; case TIFF_LONG8: case TIFF_IFD8: { uint64 v = va_arg(ap, uint64); _TIFFmemcpy(val, &v, tv_size); } break; case TIFF_SLONG8: { int64 v = va_arg(ap, int64); _TIFFmemcpy(val, &v, tv_size); } break; case TIFF_RATIONAL: case TIFF_SRATIONAL: case TIFF_FLOAT: { float v = (float)va_arg(ap, double); _TIFFmemcpy(val, &v, tv_size); } break; case TIFF_DOUBLE: { double v = va_arg(ap, double); _TIFFmemcpy(val, &v, tv_size); } break; default: _TIFFmemset(val, 0, tv_size); status = 0; break; } } } } } if (status) { const TIFFField* fip=TIFFFieldWithTag(tif,tag); if (fip) TIFFSetFieldBit(tif, fip->field_bit); tif->tif_flags |= TIFF_DIRTYDIRECT; } end: va_end(ap); return (status); badvalue: { const TIFFField* fip=TIFFFieldWithTag(tif,tag); TIFFErrorExt(tif->tif_clientdata, module,  \"%s: Bad value %u for \\\"%s\\\" tag\",  tif->tif_name, v,  fip ? fip->field_name : \"Unknown\"); va_end(ap); } return (0); badvalue32: { const TIFFField* fip=TIFFFieldWithTag(tif,tag); TIFFErrorExt(tif->tif_clientdata, module,  \"%s: Bad value %u for \\\"%s\\\" tag\",  tif->tif_name, v32,  fip ? fip->field_name : \"Unknown\"); va_end(ap); } return (0); badvaluedouble: { const TIFFField* fip=TIFFFieldWithTag(tif,tag); TIFFErrorExt(tif->tif_clientdata, module,  \"%s: Bad value %f for \\\"%s\\\" tag\",  tif->tif_name, dblval,  fip ? fip->field_name : \"Unknown\"); va_end(ap); } return (0); }", "target": 1, "idx": 100809, "project": "LibTIFF"}
{"func": "static int PixarLogEncode(TIFF* tif, uint8* bp, tmsize_t cc, uint16 s) { static const char module[] = \"PixarLogEncode\"; TIFFDirectory *td = &tif->tif_dir; PixarLogState *sp = EncoderState(tif); tmsize_t i; tmsize_t n; int llen; unsigned short * up; (void) s; switch (sp->user_datafmt) { case PIXARLOGDATAFMT_FLOAT: n = cc / sizeof(float); break; case PIXARLOGDATAFMT_16BIT: case PIXARLOGDATAFMT_12BITPICIO: case PIXARLOGDATAFMT_11BITLOG: n = cc / sizeof(uint16); break; case PIXARLOGDATAFMT_8BIT: case PIXARLOGDATAFMT_8BITABGR: n = cc; break; default: TIFFErrorExt(tif->tif_clientdata, module, \"%d bit input not supported in PixarLog\", td->td_bitspersample); return 0; } llen = sp->stride * td->td_imagewidth;  if( n > (tmsize_t)(td->td_rowsperstrip * llen) ) { TIFFErrorExt(tif->tif_clientdata, module,  \"Too many input bytes provided\"); return 0; } for (i = 0, up = sp->tbuf; i < n; i += llen, up += llen) { switch (sp->user_datafmt){ case PIXARLOGDATAFMT_FLOAT: horizontalDifferenceF((float *)bp, llen,  sp->stride, up, sp->FromLT2); bp += llen * sizeof(float); break; case PIXARLOGDATAFMT_16BIT: horizontalDifference16((uint16 *)bp, llen,  sp->stride, up, sp->From14); bp += llen * sizeof(uint16); break; case PIXARLOGDATAFMT_8BIT: horizontalDifference8((unsigned char *)bp, llen,  sp->stride, up, sp->From8); bp += llen * sizeof(unsigned char); break; default: TIFFErrorExt(tif->tif_clientdata, module, \"%d bit input not supported in PixarLog\", td->td_bitspersample); return 0; } } sp->stream.next_in = (unsigned char *) sp->tbuf; assert(sizeof(sp->stream.avail_in)==4); sp->stream.avail_in = (uInt) (n * sizeof(uint16)); if ((sp->stream.avail_in / sizeof(uint16)) != (uInt) n) { TIFFErrorExt(tif->tif_clientdata, module,  \"ZLib cannot deal with buffers this size\"); return (0); } do { if (deflate(&sp->stream, Z_NO_FLUSH) != Z_OK) { TIFFErrorExt(tif->tif_clientdata, module, \"Encoder error: %s\", sp->stream.msg ? sp->stream.msg : \"(null)\"); return (0); } if (sp->stream.avail_out == 0) { tif->tif_rawcc = tif->tif_rawdatasize; TIFFFlushData1(tif); sp->stream.next_out = tif->tif_rawdata; sp->stream.avail_out = (uInt) tif->tif_rawdatasize; } } while (sp->stream.avail_in > 0); return (1); }", "target": 0, "idx": 100616, "project": "LibTIFF"}
{"func": "static int _fdt_blocks_misordered(const void *fdt, int mem_rsv_size, int struct_size) { return (fdt_off_mem_rsvmap(fdt) < FDT_ALIGN(sizeof(struct fdt_header), 8)) || (fdt_off_dt_struct(fdt) < (fdt_off_mem_rsvmap(fdt) + mem_rsv_size)) || (fdt_off_dt_strings(fdt) < (fdt_off_dt_struct(fdt) + struct_size)) || (fdt_totalsize(fdt) < (fdt_off_dt_strings(fdt) + fdt_size_dt_strings(fdt))); }", "target": 0, "idx": 102038, "project": "Xen"}
{"func": "static void childproc_reaped_ours(libxl__egc *egc, libxl__ev_child *ch,  int status) { pid_t pid = ch->pid; LIBXL_LIST_REMOVE(ch, entry); ch->pid = -1; ch->callback(egc, ch, pid, status); }", "target": 0, "idx": 103693, "project": "Xen"}
{"func": "static inline int convert_context_handle_invalid_context(struct context *context) { int rc = 0; if ( flask_enforcing ) rc = -EINVAL; else { char *s; u32 len; context_struct_to_string(context, &s, &len); printk(KERN_ERR \"Flask:context %s is invalid\\n\", s); xfree(s); } return rc; }", "target": 0, "idx": 105698, "project": "Xen"}
{"func": "static void prnt_64regs(struct xg_gdb_regs64 *r64p) { printf(\"rip:\"XGF64\" rsp:\"XGF64\" flags:\"XGF64\"\\n\", r64p->rip, r64p->rsp,  r64p->rflags); printf(\"rax:\"XGF64\" rbx:\"XGF64\" rcx:\"XGF64\"\\n\", r64p->rax, r64p->rbx,  r64p->rcx); printf(\"rdx:\"XGF64\" rsi:\"XGF64\" rdi:\"XGF64\"\\n\", r64p->rdx, r64p->rsi,  r64p->rdi); printf(\"r08:\"XGF64\" r09:\"XGF64\" r10:\"XGF64\"\\n\", r64p->r8, r64p->r9,  r64p->r10); printf(\"r11:\"XGF64\" r12:\"XGF64\" r13:\"XGF64\"\\n\", r64p->r11, r64p->r12,  r64p->r13); printf(\"r14:\"XGF64\" r15:\"XGF64\" rbp:\"XGF64\"\\n\", r64p->r14, r64p->r15,  r64p->rbp); printf(\"cs:\"XGF64\" ds:\"XGF64\" fs:\"XGF64\" gs:\"XGF64\"\\n\", r64p->cs,   r64p->ds, r64p->fs, r64p->gs); printf(\"\\n\"); }", "target": 0, "idx": 102601, "project": "Xen"}
{"func": "int xc_cputopoinfo(xc_interface *xch, unsigned *max_cpus,  xc_cputopo_t *cputopo) { int ret; DECLARE_SYSCTL; DECLARE_HYPERCALL_BOUNCE(cputopo, *max_cpus * sizeof(*cputopo),  XC_HYPERCALL_BUFFER_BOUNCE_OUT); if ( (ret = xc_hypercall_bounce_pre(xch, cputopo)) ) goto out; sysctl.u.cputopoinfo.num_cpus = *max_cpus; set_xen_guest_handle(sysctl.u.cputopoinfo.cputopo, cputopo); sysctl.cmd = XEN_SYSCTL_cputopoinfo; if ( (ret = do_sysctl(xch, &sysctl)) != 0 ) goto out; *max_cpus = sysctl.u.cputopoinfo.num_cpus; out: xc_hypercall_bounce_post(xch, cputopo); return ret; }", "target": 0, "idx": 107565, "project": "Xen"}
{"func": "int TPM_disk_nvchange(be32_t nvram_slot, struct tpm_authdata old, struct tpm_authdata noo) {  return 0; }", "target": 0, "idx": 101702, "project": "Xen"}
{"func": "static void search_conf(void) { struct symbol **sym_arr; struct gstr res; struct gstr title; char *dialog_input; int dres, vscroll = 0, hscroll = 0; bool again; struct gstr sttext; struct subtitle_part stpart; title = str_new(); str_printf( &title, _(\"Enter (sub)string or regexp to search for \" \"(with or without \\\"%s\\\")\"), CONFIG_); again: dialog_clear(); dres = dialog_inputbox(_(\"Search Configuration Parameter\"), str_get(&title), 10, 75, \"\"); switch (dres) { case 0: break; case 1: show_helptext(_(\"Search Configuration\"), search_help); goto again; default: str_free(&title); return; }  dialog_input = dialog_input_result; if (strncasecmp(dialog_input_result, CONFIG_, strlen(CONFIG_)) == 0) dialog_input += strlen(CONFIG_); sttext = str_new(); str_printf(&sttext, \"Search (%s)\", dialog_input_result); stpart.text = str_get(&sttext); list_add_tail(&stpart.entries, &trail); sym_arr = sym_re_search(dialog_input); do { LIST_HEAD(head); struct menu *targets[JUMP_NB]; int keys[JUMP_NB + 1], i; struct search_data data = { .head = &head, .targets = targets, .keys = keys, }; struct jump_key *pos, *tmp; res = get_relations_str(sym_arr, &head); set_subtitle(); dres = show_textbox_ext(_(\"Search Results\"), (char *) str_get(&res), 0, 0, keys, &vscroll, &hscroll, &update_text, (void *) &data); again = false; for (i = 0; i < JUMP_NB && keys[i]; i++) if (dres == keys[i]) { conf(targets[i]->parent, targets[i]); again = true; } str_free(&res); list_for_each_entry_safe(pos, tmp, &head, entries) free(pos); } while (again); free(sym_arr); str_free(&title); list_del(trail.prev); str_free(&sttext); }", "target": 0, "idx": 104422, "project": "Xen"}
{"func": "static int cpu_callback( struct notifier_block *nfb, unsigned long action, void *hcpu) { unsigned int cpu = (unsigned long)hcpu; struct rcu_data *rdp = &per_cpu(rcu_data, cpu); switch ( action ) { case CPU_UP_PREPARE: rcu_init_percpu_data(cpu, &rcu_ctrlblk, rdp); break; case CPU_UP_CANCELED: case CPU_DEAD: rcu_offline_cpu(&this_cpu(rcu_data), &rcu_ctrlblk, rdp); break; default: break; } return NOTIFY_DONE; }", "target": 0, "idx": 105340, "project": "Xen"}
{"func": " */ void *xs_read(struct xs_handle *h, xs_transaction_t t, const char *path, unsigned int *len) { return xs_single(h, t, XS_READ, path, len); }", "target": 0, "idx": 108938, "project": "Xen"}
{"func": "int gx_getpkt (char *buf) { char *bp; unsigned char csum, c1, c2; int c; while (1) { csum = 0; while (1) { c = readchar(); if (c == '$') break; if (gx_remote_dbg) gxprt(\"[getpkt: discarding char '%c']\\n\", c); if (c < 0) return -1; } bp = buf; while (1) { c = readchar (); if (c < 0) return -1; if (c == '#') break; *bp++ = c; csum += c; } *bp = 0; c1 = gx_fromhex(readchar()); c2 = gx_fromhex(readchar()); if (csum == (c1 << 4) + c2) break; gxprt(\"Bad checksum, sentsum=0x%x, csum=0x%x, buf=%s\\n\", (c1 << 4) + c2, csum, buf); if (write(remote_fd, \"-\", 1) != 1) { perror(\"write\"); return -1; } } if (gx_remote_dbg) { gxprt(\"getpkt (\\\"%s\\\");[sending ack] \\n\", buf); } if (write(remote_fd, \"+\", 1) != 1) { perror(\"write\"); return -1; } if (gx_remote_dbg) { gxprt(\"[sent ack]\\n\"); } return bp - buf; }", "target": 0, "idx": 102593, "project": "Xen"}
{"func": " */ static void disk_populate_used_mgr(const struct mem_tpm_mgr *mgr) { int i;  for(i=0; i < mgr->nr_groups; i++) disk_populate_used_group(&mgr->groups[i], mgr); }", "target": 0, "idx": 101707, "project": "Xen"}
{"func": "static inline void __csched_set_tslice(struct csched_private *prv, unsigned int timeslice_ms) { prv->tslice = MILLISECS(timeslice_ms); prv->ticks_per_tslice = CSCHED_TICKS_PER_TSLICE; if ( timeslice_ms < prv->ticks_per_tslice ) prv->ticks_per_tslice = 1; prv->tick_period_us = timeslice_ms * 1000 / prv->ticks_per_tslice; prv->credits_per_tslice = CSCHED_CREDITS_PER_MSEC * timeslice_ms; prv->credit = prv->credits_per_tslice * prv->ncpus; }", "target": 0, "idx": 105507, "project": "Xen"}
{"func": "static void all_devices_setup_cb(libxl__egc *egc,  libxl__multidev *multidev,  int rc) { STATE_AO_GC(multidev->ao);  libxl__checkpoint_devices_state *const cds = CONTAINER_OF(multidev, *cds, multidev); cds->callback(egc, cds, rc); }", "target": 0, "idx": 103374, "project": "Xen"}
{"func": "static int tapdisk_lio_check_resfd(void) { #if defined(__linux__) return tapdisk_linux_version() >= KERNEL_VERSION(2, 6, 22); #else return 1; #endif }", "target": 0, "idx": 106190, "project": "Xen"}
{"func": "int __init erst_init(void) { int rc = 0; acpi_status status; acpi_physical_address erst_addr; acpi_native_uint erst_len; struct apei_exec_context ctx; if (acpi_disabled) return -ENODEV; status = acpi_get_table_phys(ACPI_SIG_ERST, 0, &erst_addr, &erst_len); if (status == AE_NOT_FOUND) { printk(KERN_INFO \"ERST table was not found\\n\"); return -ENODEV; } if (ACPI_FAILURE(status)) { const char *msg = acpi_format_exception(status); printk(KERN_WARNING \"Failed to get ERST table: %s\\n\", msg); return -EINVAL; } map_pages_to_xen((unsigned long)__va(erst_addr), maddr_to_mfn(erst_addr),  PFN_UP(erst_addr + erst_len) - PFN_DOWN(erst_addr),  PAGE_HYPERVISOR); erst_tab = __va(erst_addr); rc = erst_check_table(erst_tab); if (rc) { printk(KERN_ERR \"ERST table is invalid\\n\"); return rc; } erst_exec_ctx_init(&ctx); rc = apei_exec_pre_map_gars(&ctx); if (rc) return rc; rc = erst_get_erange(&erst_erange); if (rc) { if (rc == -ENODEV) printk(KERN_INFO \"The corresponding hardware device or firmware \" \"implementation is not available.\\n\"); else printk(KERN_ERR  \"Failed to get Error Log Address Range.\\n\"); goto err_unmap_reg; } erst_erange.vaddr = apei_pre_map(erst_erange.base, erst_erange.size); if (!erst_erange.vaddr) { rc = -ENOMEM; goto err_unmap_reg; } printk(KERN_INFO \"Xen ERST support is initialized.\\n\"); erst_enabled = 1; return 0; err_unmap_reg: apei_exec_post_unmap_gars(&ctx); return rc; }", "target": 0, "idx": 101900, "project": "Xen"}
{"func": "void td_forward_request(td_request_t treq) { tapdisk_vbd_forward_request(treq); }", "target": 0, "idx": 106162, "project": "Xen"}
{"func": " */ static int __init find_isa_irq_pin(int irq, int type) { int i; for (i = 0; i < mp_irq_entries; i++) { int lbus = mp_irqs[i].mpc_srcbus; if ((mp_bus_id_to_type[lbus] == MP_BUS_ISA ||  mp_bus_id_to_type[lbus] == MP_BUS_EISA ||  mp_bus_id_to_type[lbus] == MP_BUS_MCA ||  mp_bus_id_to_type[lbus] == MP_BUS_NEC98 ) && (mp_irqs[i].mpc_irqtype == type) && (mp_irqs[i].mpc_srcbusirq == irq)) return mp_irqs[i].mpc_dstirq; } return -1; }", "target": 0, "idx": 102855, "project": "Xen"}
{"func": "int tapdisk_cancel_all_tiocbs(struct tqueue *queue) { int cancelled = 0; do { cancelled += tapdisk_cancel_tiocbs(queue); } while (!tapdisk_queue_empty(queue)); return cancelled; }", "target": 0, "idx": 106184, "project": "Xen"}
{"func": "acpi_status acpi_os_write_port(acpi_io_address port, u32 value, u32 width) { if (width <= 8) { outb(value, port); } else if (width <= 16) { outw(value, port); } else if (width <= 32) { outl(value, port); } else { BUG(); } return AE_OK; }", "target": 0, "idx": 104985, "project": "Xen"}
{"func": "int main_psr_cat_cbm_set(int argc, char **argv) { uint32_t domid; libxl_psr_cbm_type type; uint64_t cbm; int ret, opt = 0; int opt_data = 0, opt_code = 0; libxl_bitmap target_map; char *value; libxl_string_list socket_list; unsigned long start, end; unsigned int i, j, len; unsigned int lvl = 3; static struct option opts[] = { {\"socket\", 1, 0, 's'}, {\"data\", 0, 0, 'd'}, {\"code\", 0, 0, 'c'}, {\"level\", 1, 0, 'l'}, COMMON_LONG_OPTS }; libxl_socket_bitmap_alloc(ctx, &target_map, 0); libxl_bitmap_set_none(&target_map); SWITCH_FOREACH_OPT(opt, \"s:l:cd\", opts, \"psr-cat-set\", 2) { case 's': trim(isspace, optarg, &value); split_string_into_string_list(value, \",\", &socket_list); len = libxl_string_list_length(&socket_list); for (i = 0; i < len; i++) { parse_range(socket_list[i], &start, &end); for (j = start; j <= end; j++) libxl_bitmap_set(&target_map, j); } libxl_string_list_dispose(&socket_list); free(value); break; case 'd': opt_data = 1; break; case 'c': opt_code = 1; break; case 'l': lvl = atoi(optarg); break; } if (lvl == 2) type = LIBXL_PSR_CBM_TYPE_L2_CBM; else if (lvl == 3) { if (opt_data && opt_code) { fprintf(stderr, \"Cannot handle -c and -d at the same time\\n\"); return EXIT_FAILURE; } else if (opt_data) { type = LIBXL_PSR_CBM_TYPE_L3_CBM_DATA; } else if (opt_code) { type = LIBXL_PSR_CBM_TYPE_L3_CBM_CODE; } else { type = LIBXL_PSR_CBM_TYPE_L3_CBM; } } else { type = LIBXL_PSR_CBM_TYPE_L3_CBM; fprintf(stderr, \"Input lvl %d is wrong\\n\", lvl); return EXIT_FAILURE; } if (libxl_bitmap_is_empty(&target_map)) libxl_bitmap_set_any(&target_map); if (argc != optind + 2) { help(\"psr-cat-set\"); return 2; } domid = find_domain(argv[optind]); cbm = strtoll(argv[optind + 1], NULL , 0); ret = libxl_psr_cat_set_cbm(ctx, domid, type, &target_map, cbm); libxl_bitmap_dispose(&target_map); return ret; }", "target": 0, "idx": 108759, "project": "Xen"}
{"func": "void *xengntshr_share_page_notify(xengntshr_handle *xcg, uint32_t domid, uint32_t *ref, int writable, uint32_t notify_offset, evtchn_port_t notify_port) { return osdep_gntshr_share_pages(xcg, domid, 1, ref, writable, notify_offset, notify_port); }", "target": 0, "idx": 102565, "project": "Xen"}
{"func": "static DEFINE_SPINLOCK(microcode_update_lock); static int collect_cpu_info(unsigned int cpu_num, struct cpu_signature *csig) { struct cpuinfo_x86 *c = &cpu_data[cpu_num]; uint64_t msr_content; BUG_ON(cpu_num != smp_processor_id()); memset(csig, 0, sizeof(*csig)); if ( (c->x86_vendor != X86_VENDOR_INTEL) || (c->x86 < 6) ) { printk(KERN_ERR \"microcode: CPU%d not a capable Intel \"  \"processor\\n\", cpu_num); return -1; } csig->sig = cpuid_eax(0x00000001); if ( (c->x86_model >= 5) || (c->x86 > 6) ) {  rdmsrl(MSR_IA32_PLATFORM_ID, msr_content); csig->pf = 1 << ((msr_content >> 50) & 7); } wrmsrl(MSR_IA32_UCODE_REV, 0x0ULL);  cpuid_eax(1);  rdmsrl(MSR_IA32_UCODE_REV, msr_content); csig->rev = (uint32_t)(msr_content >> 32); pr_debug(\"microcode: collect_cpu_info : sig=%#x, pf=%#x, rev=%#x\\n\",  csig->sig, csig->pf, csig->rev); return 0; }", "target": 0, "idx": 104553, "project": "Xen"}
{"func": "static void tap_cli_spawn_usage(FILE *stream) { fprintf(stream, \"usage: spawn\\n\"); }", "target": 0, "idx": 106068, "project": "Xen"}
{"func": "static void *read_reply( struct xs_handle *h, enum xsd_sockmsg_type *type, unsigned int *len) { struct xs_stored_msg *msg; char *body; int read_from_thread; read_from_thread = read_thread_exists(h);  if (!read_from_thread && (read_message(h, 0) == -1)) return NULL; mutex_lock(&h->reply_mutex); #ifdef USE_PTHREAD while (list_empty(&h->reply_list) && read_from_thread && h->fd != -1) condvar_wait(&h->reply_condvar, &h->reply_mutex); #endif if (list_empty(&h->reply_list)) { mutex_unlock(&h->reply_mutex); errno = EINVAL; return NULL; } msg = list_top(&h->reply_list, struct xs_stored_msg, list); list_del(&msg->list); assert(list_empty(&h->reply_list)); mutex_unlock(&h->reply_mutex); *type = msg->hdr.type; if (len) *len = msg->hdr.len; body = msg->body; free(msg); return body; }", "target": 0, "idx": 108912, "project": "Xen"}
{"func": "static int libxl__set_vcpuaffinity(libxl_ctx *ctx, uint32_t domid,  uint32_t vcpuid,  const libxl_bitmap *cpumap_hard,  const libxl_bitmap *cpumap_soft,  unsigned flags) { GC_INIT(ctx); libxl_bitmap hard, soft; int rc; libxl_bitmap_init(&hard); libxl_bitmap_init(&soft); if (!cpumap_hard && !cpumap_soft && !flags) { rc = ERROR_INVAL; goto out; }  if (cpumap_hard) { rc = libxl_cpu_bitmap_alloc(ctx, &hard, 0); if (rc) goto out; libxl__bitmap_copy_best_effort(gc, &hard, cpumap_hard); flags |= XEN_VCPUAFFINITY_HARD; } if (cpumap_soft) { rc = libxl_cpu_bitmap_alloc(ctx, &soft, 0); if (rc) goto out; libxl__bitmap_copy_best_effort(gc, &soft, cpumap_soft); flags |= XEN_VCPUAFFINITY_SOFT; } if (xc_vcpu_setaffinity(ctx->xch, domid, vcpuid, cpumap_hard ? hard.map : NULL, cpumap_soft ? soft.map : NULL, flags)) { LOGED(ERROR, domid, \"Setting vcpu affinity\"); rc = ERROR_FAIL; goto out; }  if (cpumap_hard && !libxl_bitmap_equal(cpumap_hard, &hard, 0)) LOGD(DEBUG, domid, \"New hard affinity for vcpu %d has unreachable cpus\", vcpuid);  if (cpumap_soft) { if (!libxl_bitmap_equal(cpumap_soft, &soft, 0)) LOGD(DEBUG, domid, \"New soft affinity for vcpu %d has unreachable cpus\",  vcpuid); if (libxl_bitmap_is_empty(&soft)) LOGD(WARN, domid, \"All cpus in soft affinity of vcpu %d are unreachable.\"  \" Only hard affinity will be considered for scheduling\",  vcpuid); } rc = 0;  out: libxl_bitmap_dispose(&hard); libxl_bitmap_dispose(&soft); GC_FREE; return rc; }", "target": 0, "idx": 103984, "project": "Xen"}
{"func": "static int interrupted; static void unlink_pagefile(void) { if ( filename && filename[0] ) { unlink(filename); filename[0] = '\\0'; } }", "target": 0, "idx": 108287, "project": "Xen"}
{"func": "int tapdisk_uring_disconnect(td_uring_t *ring) { tapdisk_uring_disconnect_shmem(ring); tapdisk_uring_disconnect_ctlfd(ring); return 0; }", "target": 0, "idx": 106216, "project": "Xen"}
{"func": "static void scif_uart_resume(struct serial_port *port) { BUG(); }", "target": 0, "idx": 105656, "project": "Xen"}
{"func": "static void qos_state_sleeping(int cpu, int domid, uint64_t now)  { int idx; if (!domain_runnable(domid)) return; idx = indexof(domid); new_qos->domain_info[idx].runnable = 0; new_qos->domain_info[idx].blocked_start_time = now; new_qos->domain_info[idx].runnable_start_time = 0;   qos_update_thread_stats(cpu, domid, now); }", "target": 0, "idx": 108162, "project": "Xen"}
{"func": "static void BadPPM(char* file) { fprintf(stderr, \"%s: Not a PPM file.\\n\", file); exit(-2); }", "target": 0, "idx": 100196, "project": "LibTIFF"}
{"func": "void hvm_io_read_postprocess(struct hvm_data *h) { if(opt.with_pio_enumeration) update_io_address(&h->summary.io.pio, h->inflight.io.port, 0, h->arc_cycles, 0); if(opt.scatterplot_io && h->inflight.io.port == opt.scatterplot_io_port) scatterplot_vs_time(h->exit_tsc, P.now - h->exit_tsc); }", "target": 0, "idx": 107983, "project": "Xen"}
{"func": "void bitmap_byte_to_long(unsigned long *lp, const uint8_t *bp, int nbits) { unsigned long l; int i, j, b; for (i = 0, b = 0; nbits > 0; i++, b += sizeof(l)) { l = 0; for (j = 0; (j < sizeof(l)) && (nbits > 0); j++) { l |= (unsigned long)bp[b+j] << (j*8); nbits -= 8; } lp[i] = l; } } } void bitmap_byte_to_long(unsigned long *lp, const uint8_t *bp, int nbits) {  if (nbits & (BITS_PER_LONG-1)) lp[BITS_TO_LONGS(nbits)-1] = 0; memcpy(lp, bp, (nbits+7)/8); }", "target": 0, "idx": 100996, "project": "Xen"}
{"func": "static int collect_cpu_info(unsigned int cpu, struct cpu_signature *csig) { struct cpuinfo_x86 *c = &cpu_data[cpu]; memset(csig, 0, sizeof(*csig)); if ( (c->x86_vendor != X86_VENDOR_AMD) || (c->x86 < 0x10) ) { printk(KERN_ERR \"microcode: CPU%d not a capable AMD processor\\n\",  cpu); return -EINVAL; } rdmsrl(MSR_AMD_PATCHLEVEL, csig->rev); pr_debug(\"microcode: CPU%d collect_cpu_info: patch_id=%#x\\n\",  cpu, csig->rev); return 0; }", "target": 0, "idx": 104544, "project": "Xen"}
{"func": "static size_t pv_ring_puts(const char *buf) { XENCONS_RING_IDX cons, prod; size_t sent = 0, avail; bool put_r = false; while ( buf[sent] != '\\0' || put_r ) { cons = ACCESS_ONCE(cons_ring->out_cons); prod = cons_ring->out_prod;  smp_rmb(); ASSERT((prod - cons) <= sizeof(cons_ring->out)); avail = sizeof(cons_ring->out) - (prod - cons); if ( avail == 0 ) {  xen_hypercall_sched_op(SCHEDOP_yield, NULL); continue; } while ( avail && (buf[sent] != '\\0' || put_r) ) { if ( put_r ) { cons_ring->out[MASK_XENCONS_IDX(prod++, cons_ring->out)] = '\\r'; put_r = false; } else { cons_ring->out[MASK_XENCONS_IDX(prod++, cons_ring->out)] = buf[sent];  if ( buf[sent] == '\\n' ) put_r = true; sent++; } avail--; }  smp_wmb(); ACCESS_ONCE(cons_ring->out_prod) = prod; notify_daemon(); } return sent; }", "target": 0, "idx": 108592, "project": "Xen"}
{"func": "char *libxl__sprintf(libxl__gc *gc, const char *fmt, ...) { char *s; va_list ap; va_start(ap, fmt); s = libxl__vsprintf(gc, fmt, ap); va_end(ap); return s; }", "target": 0, "idx": 103746, "project": "Xen"}
{"func": "int compat_grant_table_op(unsigned int cmd, XEN_GUEST_HANDLE(void) cmp_uop, unsigned int count) { int rc = 0; unsigned int i; XEN_GUEST_HANDLE(void) cnt_uop; set_xen_guest_handle(cnt_uop, NULL); switch ( cmd ) { #define CASE(name) \\ case GNTTABOP_##name: \\ if ( unlikely(!guest_handle_okay(guest_handle_cast(cmp_uop, \\  gnttab_##name##_compat_t), \\  count)) ) \\ rc = -EFAULT; \\ break #ifndef CHECK_gnttab_map_grant_ref CASE(map_grant_ref); #endif #ifndef CHECK_gnttab_unmap_grant_ref CASE(unmap_grant_ref); #endif #ifndef CHECK_gnttab_unmap_and_replace CASE(unmap_and_replace); #endif #ifndef CHECK_gnttab_setup_table CASE(setup_table); #endif #ifndef CHECK_gnttab_transfer CASE(transfer); #endif #ifndef CHECK_gnttab_copy CASE(copy); #endif #ifndef CHECK_gnttab_dump_table CASE(dump_table); #endif #ifndef CHECK_gnttab_get_status_frames CASE(get_status_frames); #endif #ifndef CHECK_gnttab_swap_grant_ref CASE(swap_grant_ref); #endif #undef CASE default: return do_grant_table_op(cmd, cmp_uop, count); } if ( (int)count < 0 ) rc = -EINVAL; for ( i = 0; i < count && rc == 0; ) { unsigned int n; union { XEN_GUEST_HANDLE(void) uop; struct gnttab_setup_table *setup; struct gnttab_transfer *xfer; struct gnttab_copy *copy; struct gnttab_get_status_frames *get_status; } nat; union { struct compat_gnttab_setup_table setup; struct compat_gnttab_transfer xfer; struct compat_gnttab_copy copy; struct compat_gnttab_get_status_frames get_status; } cmp; set_xen_guest_handle(nat.uop, COMPAT_ARG_XLAT_VIRT_BASE); switch ( cmd ) { case GNTTABOP_setup_table: if ( unlikely(count > 1) ) rc = -EINVAL; else if ( unlikely(__copy_from_guest(&cmp.setup, cmp_uop, 1)) ) rc = -EFAULT; else if ( unlikely(!compat_handle_okay(cmp.setup.frame_list, cmp.setup.nr_frames)) ) rc = -EFAULT; else { unsigned int max_frame_list_size_in_page = (COMPAT_ARG_XLAT_SIZE - sizeof(*nat.setup)) / sizeof(*nat.setup->frame_list.p); if ( max_frame_list_size_in_page < max_nr_grant_frames ) { gdprintk(XENLOG_WARNING,  \"max_nr_grant_frames is too large (%u,%u)\\n\",  max_nr_grant_frames, max_frame_list_size_in_page); rc = -EINVAL; } else { #define XLAT_gnttab_setup_table_HNDL_frame_list(_d_, _s_) \\ set_xen_guest_handle((_d_)->frame_list, (unsigned long *)(nat.setup + 1)) XLAT_gnttab_setup_table(nat.setup, &cmp.setup); #undef XLAT_gnttab_setup_table_HNDL_frame_list rc = gnttab_setup_table(guest_handle_cast(nat.uop, gnttab_setup_table_t), 1); } } ASSERT(rc <= 0); if ( rc == 0 ) { #define XLAT_gnttab_setup_table_HNDL_frame_list(_d_, _s_) \\ do \\ { \\ if ( (_s_)->status == GNTST_okay ) \\ { \\ for ( i = 0; i < (_s_)->nr_frames; ++i ) \\ { \\ unsigned int frame = (_s_)->frame_list.p[i]; \\ (void)__copy_to_compat_offset((_d_)->frame_list, i, &frame, 1); \\ } \\ } \\ } while (0) XLAT_gnttab_setup_table(&cmp.setup, nat.setup); #undef XLAT_gnttab_setup_table_HNDL_frame_list if ( unlikely(__copy_to_guest(cmp_uop, &cmp.setup, 1)) ) rc = -EFAULT; else i = 1; } break; case GNTTABOP_transfer: for ( n = 0; n < COMPAT_ARG_XLAT_SIZE / sizeof(*nat.xfer) && i < count && rc == 0; ++i, ++n ) { if ( unlikely(__copy_from_guest_offset(&cmp.xfer, cmp_uop, i, 1)) ) rc = -EFAULT; else { XLAT_gnttab_transfer(nat.xfer + n, &cmp.xfer); } } if ( rc == 0 ) rc = gnttab_transfer(guest_handle_cast(nat.uop, gnttab_transfer_t), n); if ( rc > 0 ) { ASSERT(rc < n); i -= n - rc; n = rc; } if ( rc >= 0 ) { XEN_GUEST_HANDLE(gnttab_transfer_compat_t) xfer; xfer = guest_handle_cast(cmp_uop, gnttab_transfer_compat_t); guest_handle_add_offset(xfer, i); cnt_uop = guest_handle_cast(xfer, void); while ( n-- ) { guest_handle_add_offset(xfer, -1); if ( __copy_field_to_guest(xfer, nat.xfer + n, status) ) rc = -EFAULT; } } break; case GNTTABOP_copy: for ( n = 0; n < COMPAT_ARG_XLAT_SIZE / sizeof(*nat.copy) && i < count && rc == 0; ++i, ++n ) { if ( unlikely(__copy_from_guest_offset(&cmp.copy, cmp_uop, i, 1)) ) rc = -EFAULT; else { enum XLAT_gnttab_copy_source_u source_u; enum XLAT_gnttab_copy_dest_u dest_u; if ( cmp.copy.flags & GNTCOPY_source_gref ) source_u = XLAT_gnttab_copy_source_u_ref; else source_u = XLAT_gnttab_copy_source_u_gmfn; if ( cmp.copy.flags & GNTCOPY_dest_gref ) dest_u = XLAT_gnttab_copy_dest_u_ref; else dest_u = XLAT_gnttab_copy_dest_u_gmfn; XLAT_gnttab_copy(nat.copy + n, &cmp.copy); } } if ( rc == 0 ) rc = gnttab_copy(guest_handle_cast(nat.uop, gnttab_copy_t), n); if ( rc > 0 ) { ASSERT(rc < n); i -= n - rc; n = rc; } if ( rc >= 0 ) { XEN_GUEST_HANDLE(gnttab_copy_compat_t) copy; copy = guest_handle_cast(cmp_uop, gnttab_copy_compat_t); guest_handle_add_offset(copy, i); cnt_uop = guest_handle_cast(copy, void); while ( n-- ) { guest_handle_add_offset(copy, -1); if ( __copy_field_to_guest(copy, nat.copy + n, status) ) rc = -EFAULT; } } break; case GNTTABOP_get_status_frames: { unsigned int max_frame_list_size_in_pages = (COMPAT_ARG_XLAT_SIZE - sizeof(*nat.get_status)) / sizeof(*nat.get_status->frame_list.p); if ( count != 1) { rc = -EINVAL; break; } if ( unlikely(__copy_from_guest(&cmp.get_status, cmp_uop, 1) || !compat_handle_okay(cmp.get_status.frame_list, cmp.get_status.nr_frames)) ) { rc = -EFAULT; break; } if ( max_frame_list_size_in_pages <  grant_to_status_frames(max_nr_grant_frames) ) { gdprintk(XENLOG_WARNING,  \"grant_to_status_frames(max_nr_grant_frames) is too large (%u,%u)\\n\",  grant_to_status_frames(max_nr_grant_frames),  max_frame_list_size_in_pages); rc = -EINVAL; break; } #define XLAT_gnttab_get_status_frames_HNDL_frame_list(_d_, _s_) \\ set_xen_guest_handle((_d_)->frame_list, (uint64_t *)(nat.get_status + 1)) XLAT_gnttab_get_status_frames(nat.get_status, &cmp.get_status); #undef XLAT_gnttab_get_status_frames_HNDL_frame_list rc = gnttab_get_status_frames( guest_handle_cast(nat.uop, gnttab_get_status_frames_t), count); if ( rc >= 0 ) { #define XLAT_gnttab_get_status_frames_HNDL_frame_list(_d_, _s_) \\ do \\ { \\ if ( (_s_)->status == GNTST_okay ) \\ { \\ for ( i = 0; i < (_s_)->nr_frames; ++i ) \\ { \\ uint64_t frame = (_s_)->frame_list.p[i]; \\ (void)__copy_to_compat_offset((_d_)->frame_list, i, &frame, 1); \\ } \\ } \\ } while (0) XLAT_gnttab_get_status_frames(&cmp.get_status, nat.get_status); #undef XLAT_gnttab_get_status_frames_HNDL_frame_list if ( unlikely(__copy_to_guest(cmp_uop, &cmp.get_status, 1)) ) rc = -EFAULT; } break; } default: domain_crash(current->domain); break; } } if ( rc > 0 ) { ASSERT(i < count); ASSERT(!guest_handle_is_null(cnt_uop)); rc = hypercall_create_continuation(__HYPERVISOR_grant_table_op,  \"ihi\", cmd, cnt_uop, count - i); } return rc; }", "target": 1, "idx": 109012, "project": "Xen"}
{"func": "static void __gnttab_copy( struct gnttab_copy *op) { struct domain *sd = NULL, *dd = NULL; unsigned long s_frame, d_frame; struct page_info *s_pg = NULL, *d_pg = NULL; char *sp, *dp; s16 rc = GNTST_okay; int have_d_grant = 0, have_s_grant = 0; int src_is_gref, dest_is_gref; if ( ((op->source.offset + op->len) > PAGE_SIZE) ||  ((op->dest.offset + op->len) > PAGE_SIZE) ) PIN_FAIL(error_out, GNTST_bad_copy_arg, \"copy beyond page area.\\n\"); src_is_gref = op->flags & GNTCOPY_source_gref; dest_is_gref = op->flags & GNTCOPY_dest_gref; if ( (op->source.domid != DOMID_SELF && !src_is_gref ) ||  (op->dest.domid != DOMID_SELF && !dest_is_gref) ) PIN_FAIL(error_out, GNTST_permission_denied,  \"only allow copy-by-mfn for DOMID_SELF.\\n\"); if ( op->source.domid == DOMID_SELF ) sd = rcu_lock_current_domain(); else if ( (sd = rcu_lock_domain_by_id(op->source.domid)) == NULL ) PIN_FAIL(error_out, GNTST_bad_domain,  \"couldn't find %d\\n\", op->source.domid); if ( op->dest.domid == DOMID_SELF ) dd = rcu_lock_current_domain(); else if ( (dd = rcu_lock_domain_by_id(op->dest.domid)) == NULL ) PIN_FAIL(error_out, GNTST_bad_domain,  \"couldn't find %d\\n\", op->dest.domid); rc = xsm_grant_copy(XSM_HOOK, sd, dd); if ( rc ) { rc = GNTST_permission_denied; goto error_out; } if ( src_is_gref ) { unsigned source_off, source_len; rc = __acquire_grant_for_copy(sd, op->source.u.ref, current->domain->domain_id, 1, &s_frame, &s_pg, &source_off, &source_len, 1); if ( rc != GNTST_okay ) goto error_out; have_s_grant = 1; if ( op->source.offset < source_off ||  op->len > source_len ) PIN_FAIL(error_out, GNTST_general_error,  \"copy source out of bounds: %d < %d || %d > %d\\n\",  op->source.offset, source_off,  op->len, source_len); } else { rc = __get_paged_frame(op->source.u.gmfn, &s_frame, &s_pg, 1, sd); if ( rc != GNTST_okay ) PIN_FAIL(error_out, rc,  \"source frame %lx invalid.\\n\", s_frame); } if ( dest_is_gref ) { unsigned dest_off, dest_len; rc = __acquire_grant_for_copy(dd, op->dest.u.ref, current->domain->domain_id, 0, &d_frame, &d_pg, &dest_off, &dest_len, 1); if ( rc != GNTST_okay ) goto error_out; have_d_grant = 1; if ( op->dest.offset < dest_off ||  op->len > dest_len ) PIN_FAIL(error_out, GNTST_general_error,  \"copy dest out of bounds: %d < %d || %d > %d\\n\",  op->dest.offset, dest_off,  op->len, dest_len); } else { rc = __get_paged_frame(op->dest.u.gmfn, &d_frame, &d_pg, 0, dd); if ( rc != GNTST_okay ) PIN_FAIL(error_out, rc,  \"destination frame %lx invalid.\\n\", d_frame); } if ( !get_page_type(d_pg, PGT_writable_page) ) { if ( !dd->is_dying ) gdprintk(XENLOG_WARNING, \"Could not get dst frame %lx\\n\", d_frame); rc = GNTST_general_error; goto error_out; } sp = map_domain_page(s_frame); dp = map_domain_page(d_frame); memcpy(dp + op->dest.offset, sp + op->source.offset, op->len); unmap_domain_page(dp); unmap_domain_page(sp); gnttab_mark_dirty(dd, d_frame); put_page_type(d_pg);  error_out: if ( d_pg ) put_page(d_pg); if ( s_pg ) put_page(s_pg); if ( have_s_grant ) __release_grant_for_copy(sd, op->source.u.ref, 1); if ( have_d_grant ) __release_grant_for_copy(dd, op->dest.u.ref, 0); if ( sd ) rcu_unlock_domain(sd); if ( dd ) rcu_unlock_domain(dd); op->status = rc; }", "target": 1, "idx": 109550, "project": "Xen"}
{"func": "void on_load_clicked(GtkButton * button, gpointer user_data) { on_load1_activate(NULL, user_data); }", "target": 0, "idx": 102292, "project": "Xen"}
{"func": "const cpumask_t *target_cpus_all(void) { return &cpu_online_map; }", "target": 0, "idx": 101642, "project": "Xen"}
{"func": "static inline void free_vhd_request(struct vhd_state *s, struct vhd_request *req) { memset(req, 0, sizeof(struct vhd_request)); s->vreq_free[s->vreq_free_count++] = req; }", "target": 0, "idx": 101170, "project": "Xen"}
{"func": "static void cpSeparateBufToContigBuf(uint8* out, uint8* in, uint32 rows, uint32 cols, int outskew, int inskew, tsample_t spp, int bytes_per_sample) { while (rows-- > 0) { uint32 j = cols; while (j-- > 0) { int n = bytes_per_sample; while( n-- ) { *out++ = *in++; } out += (spp-1)*bytes_per_sample; } out += outskew; in += inskew; } }", "target": 1, "idx": 100840, "project": "LibTIFF"}
{"func": "static int variable_period = 1; static void mce_checkregs (void *info) { mctelem_cookie_t mctc; struct mca_summary bs; static uint64_t dumpcount = 0; mctc = mcheck_mca_logout(MCA_POLLER, __get_cpu_var(poll_bankmask), &bs, NULL); if (bs.errcnt && mctc != NULL) { adjust++;  if (dom0_vmce_enabled()) { mctelem_commit(mctc); send_global_virq(VIRQ_MCA); } else if (++dumpcount >= 10) { x86_mcinfo_dump((struct mc_info *)mctelem_dataptr(mctc)); mctelem_dismiss(mctc); } else { mctelem_dismiss(mctc); } } else if (mctc != NULL) { mctelem_dismiss(mctc); } }", "target": 0, "idx": 104873, "project": "Xen"}
{"func": "static bool_t find_equiv_cpu_id(const struct equiv_cpu_entry *equiv_cpu_table, unsigned int current_cpu_id, unsigned int *equiv_cpu_id) { unsigned int i; if ( !equiv_cpu_table ) return 0; for ( i = 0; equiv_cpu_table[i].installed_cpu != 0; i++ ) { if ( current_cpu_id == equiv_cpu_table[i].installed_cpu ) { *equiv_cpu_id = equiv_cpu_table[i].equiv_cpu & 0xffff; return 1; } } return 0; }", "target": 0, "idx": 104547, "project": "Xen"}
{"func": "TDB_CONTEXT *tdb_open_ex(const char *name, int hash_size, int tdb_flags,  int open_flags, mode_t mode,  tdb_log_func log_fn,  tdb_hash_func hash_fn) { TDB_CONTEXT *tdb; struct stat st; int rev = 0, locked = 0; uint8_t *vp; uint32_t vertest; if (!(tdb = talloc_zero(name, TDB_CONTEXT))) {  errno = ENOMEM; goto fail; } tdb->fd = -1; tdb->name = NULL; tdb->map_ptr = NULL; tdb->flags = tdb_flags; tdb->open_flags = open_flags; tdb->log_fn = log_fn?log_fn:null_log_fn; tdb->hash_fn = hash_fn ? hash_fn : default_tdb_hash; if ((open_flags & O_ACCMODE) == O_WRONLY) { TDB_LOG((tdb, 0, \"tdb_open_ex: can't open tdb %s write-only\\n\",  name)); errno = EINVAL; goto fail; } if (hash_size == 0) hash_size = DEFAULT_HASH_SIZE; if ((open_flags & O_ACCMODE) == O_RDONLY) { tdb->read_only = 1;  tdb->flags |= TDB_NOLOCK; tdb->flags &= ~TDB_CLEAR_IF_FIRST; }  if (tdb->flags & TDB_INTERNAL) { tdb->flags |= (TDB_NOLOCK | TDB_NOMMAP); tdb->flags &= ~TDB_CLEAR_IF_FIRST; if (tdb_new_database(tdb, hash_size) != 0) { TDB_LOG((tdb, 0, \"tdb_open_ex: tdb_new_database failed!\")); goto fail; } goto internal; } if ((tdb->fd = open(name, open_flags, mode)) == -1) { TDB_LOG((tdb, 5, \"tdb_open_ex: could not open file %s: %s\\n\",  name, strerror(errno))); goto fail; }  if (tdb_brlock(tdb, GLOBAL_LOCK, F_WRLCK, F_SETLKW, 0) == -1) { TDB_LOG((tdb, 0, \"tdb_open_ex: failed to get global lock on %s: %s\\n\",  name, strerror(errno))); goto fail; }  if ((tdb_flags & TDB_CLEAR_IF_FIRST) && (locked = (tdb_brlock(tdb, ACTIVE_LOCK, F_WRLCK, F_SETLK, 0) == 0))) { open_flags |= O_CREAT; if (ftruncate(tdb->fd, 0) == -1) { TDB_LOG((tdb, 0, \"tdb_open_ex: \"  \"failed to truncate %s: %s\\n\",  name, strerror(errno))); goto fail;  } } if (read(tdb->fd, &tdb->header, sizeof(tdb->header)) != sizeof(tdb->header) || strcmp(tdb->header.magic_food, TDB_MAGIC_FOOD) != 0 || (tdb->header.version != TDB_VERSION && !(rev = (tdb->header.version==TDB_BYTEREV(TDB_VERSION))))) {  if (!(open_flags & O_CREAT) || tdb_new_database(tdb, hash_size) == -1) { errno = EIO;  goto fail; } rev = (tdb->flags & TDB_CONVERT); } vp = (uint8_t *)&tdb->header.version; vertest = (((uint32_t)vp[0]) << 24) | (((uint32_t)vp[1]) << 16) | (((uint32_t)vp[2]) << 8) | (uint32_t)vp[3]; tdb->flags |= (vertest==TDB_VERSION) ? TDB_BIGENDIAN : 0; if (!rev) tdb->flags &= ~TDB_CONVERT; else { tdb->flags |= TDB_CONVERT; convert(&tdb->header, sizeof(tdb->header)); } if (fstat(tdb->fd, &st) == -1) goto fail;  if (tdb_already_open(st.st_dev, st.st_ino)) { TDB_LOG((tdb, 2, \"tdb_open_ex: \"  \"%s (%d,%d) is already open in this process\\n\",  name, (int)st.st_dev, (int)st.st_ino)); errno = EBUSY; goto fail; } if (!(tdb->name = (char *)talloc_strdup(tdb, name))) { errno = ENOMEM; goto fail; } tdb->map_size = st.st_size; tdb->device = st.st_dev; tdb->inode = st.st_ino; tdb->locked = talloc_zero_array(tdb, struct tdb_lock_type, tdb->header.hash_size+1); if (!tdb->locked) { TDB_LOG((tdb, 2, \"tdb_open_ex: \"  \"failed to allocate lock structure for %s\\n\",  name)); errno = ENOMEM; goto fail; } tdb_mmap(tdb); if (locked) { if (tdb_brlock(tdb, ACTIVE_LOCK, F_UNLCK, F_SETLK, 0) == -1) { TDB_LOG((tdb, 0, \"tdb_open_ex: \"  \"failed to take ACTIVE_LOCK on %s: %s\\n\",  name, strerror(errno))); goto fail; } }  if (tdb_flags & TDB_CLEAR_IF_FIRST) {  if (tdb_brlock(tdb, ACTIVE_LOCK, F_RDLCK, F_SETLKW, 0) == -1) goto fail; }  internal:  if (tdb_brlock(tdb, GLOBAL_LOCK, F_UNLCK, F_SETLKW, 0) == -1) goto fail; tdb->next = tdbs; tdbs = tdb; return tdb;  fail: { int save_errno = errno; if (!tdb) return NULL; if (tdb->map_ptr) { if (tdb->flags & TDB_INTERNAL) SAFE_FREE(tdb->map_ptr); else tdb_munmap(tdb); } SAFE_FREE(tdb->name); if (tdb->fd != -1) if (close(tdb->fd) != 0) TDB_LOG((tdb, 5, \"tdb_open_ex: failed to close tdb->fd on error!\\n\")); SAFE_FREE(tdb->locked); SAFE_FREE(tdb); errno = save_errno; return NULL; } }", "target": 0, "idx": 106398, "project": "Xen"}
{"func": "static void * smbios_type_17_init(void *start, uint32_t memory_size_mb, int instance) { char buf[16]; struct smbios_type_17 *p = (struct smbios_type_17 *)start; memset(p, 0, sizeof(*p)); p->header.type = 17; p->header.length = sizeof(struct smbios_type_17); p->header.handle = SMBIOS_HANDLE_TYPE17 + instance; p->physical_memory_array_handle = 0x1000; p->total_width = 64; p->data_width = 64; ASSERT((memory_size_mb & ~0x7fff) == 0); p->size = memory_size_mb; p->form_factor = 0x09;  p->device_set = 0; p->device_locator_str = 1; p->bank_locator_str = 0; p->memory_type = 0x07;  p->type_detail = 0; start += sizeof(struct smbios_type_17); strcpy(start, \"DIMM \"); start += strlen(\"DIMM \"); itoa(buf, instance); strcpy(start, buf); start += strlen(buf) + 1; *((uint8_t *)start) = 0; return start+1; }", "target": 0, "idx": 105782, "project": "Xen"}
{"func": "static int vhd_fixed_resize(vhd_journal_t *journal, uint64_t size) { int err; vhd_context_t *vhd; uint64_t cur_secs, new_secs; vhd= &journal->vhd; cur_secs = vhd->footer.curr_size >> VHD_SECTOR_SHIFT; new_secs = size << (20 - VHD_SECTOR_SHIFT); if (cur_secs == new_secs) return 0; else if (cur_secs > new_secs) err = vhd_fixed_shrink(journal, cur_secs - new_secs); else err = vhd_fixed_grow(journal, new_secs - cur_secs); return err; }", "target": 0, "idx": 106807, "project": "Xen"}
{"func": "int xc_gntshr_munmap(xc_gntshr *xcg, void *start_address, uint32_t count) { return xengntshr_unshare(xcg, start_address, count); }", "target": 0, "idx": 107512, "project": "Xen"}
{"func": "int gnttab_map_frame(struct domain *d, unsigned long idx, gfn_t gfn,  mfn_t *mfn) { int rc = 0; struct grant_table *gt = d->grant_table; grant_write_lock(gt); if ( gt->gt_version == 0 ) gt->gt_version = 1; if ( gt->gt_version == 2 &&  (idx & XENMAPIDX_grant_table_status) ) { idx &= ~XENMAPIDX_grant_table_status; if ( idx < nr_status_frames(gt) ) *mfn = _mfn(virt_to_mfn(gt->status[idx])); else rc = -EINVAL; } else { if ( (idx >= nr_grant_frames(gt)) && (idx < gt->max_grant_frames) ) gnttab_grow_table(d, idx + 1); if ( idx < nr_grant_frames(gt) ) *mfn = _mfn(virt_to_mfn(gt->shared_raw[idx])); else rc = -EINVAL; } if ( !rc ) gnttab_set_frame_gfn(gt, idx, gfn); grant_write_unlock(gt); return rc; }", "target": 1, "idx": 109640, "project": "Xen"}
{"func": "static bool _raw_copy_from_guest_buf_offset(void *dst, const struct dmop_args *args, unsigned int buf_idx, size_t offset_bytes, size_t dst_bytes) { size_t buf_bytes; if ( buf_idx >= args->nr_bufs ) return false; buf_bytes =args->buf[buf_idx].size; if ( (offset_bytes + dst_bytes) < offset_bytes ||  (offset_bytes + dst_bytes) > buf_bytes ) return false; return !copy_from_guest_offset(dst, args->buf[buf_idx].h,  offset_bytes, dst_bytes); }", "target": 0, "idx": 101727, "project": "Xen"}
{"func": " */ int xlu__disk_yylex_init(yyscan_t* ptr_yy_globals) { if (ptr_yy_globals == NULL){ errno = EINVAL; return 1; } *ptr_yy_globals = (yyscan_t) xlu__disk_yyalloc ( sizeof( struct yyguts_t ), NULL ); if (*ptr_yy_globals == NULL){ errno = ENOMEM; return 1; }  memset(*ptr_yy_globals,0x00,sizeof(struct yyguts_t)); return yy_init_globals ( *ptr_yy_globals ); }", "target": 0, "idx": 103266, "project": "Xen"}
{"func": "int main_cpupoolcpuremove(int argc, char **argv) { int opt; const char *pool; uint32_t poolid; libxl_bitmap cpumap; int rc = EXIT_FAILURE; libxl_bitmap_init(&cpumap); if (libxl_cpu_bitmap_alloc(ctx, &cpumap, 0)) { fprintf(stderr, \"Unable to allocate cpumap\"); return EXIT_FAILURE; } SWITCH_FOREACH_OPT(opt, \"\", NULL, \"cpupool-cpu-remove\", 2) {  } pool = argv[optind++]; if (parse_cpurange(argv[optind], &cpumap)) goto out; if (libxl_cpupool_qualifier_to_cpupoolid(ctx, pool, &poolid, NULL) || !libxl_cpupoolid_is_valid(ctx, poolid)) { fprintf(stderr, \"unknown cpupool \\'%s\\'\\n\", pool); goto out; } if (libxl_cpupool_cpuremove_cpumap(ctx, poolid, &cpumap)) { fprintf(stderr, \"Some cpus may have not or only partially been removed from '%s'.\\n\", pool); fprintf(stderr, \"If a cpu can't be added to another cpupool, add it to '%s' again and retry.\\n\", pool); } rc = EXIT_SUCCESS; out: libxl_bitmap_dispose(&cpumap); return rc; }", "target": 0, "idx": 108665, "project": "Xen"}
{"func": "int libxl_nodemap_to_cpumap(libxl_ctx *ctx, const libxl_bitmap *nodemap, libxl_bitmap *cpumap) { libxl_cputopology *tinfo = NULL; int nr_cpus = 0, i, rc = 0; tinfo = libxl_get_cpu_topology(ctx, &nr_cpus); if (tinfo == NULL) { rc = ERROR_FAIL; goto out; } libxl_bitmap_set_none(cpumap); for (i = 0; i < nr_cpus; i++) { if (libxl_bitmap_test(nodemap, tinfo[i].node)) libxl_bitmap_set(cpumap, i); }  out: libxl_cputopology_list_free(tinfo, nr_cpus); return rc; }", "target": 0, "idx": 104132, "project": "Xen"}
{"func": "static vcpuid_t _vcpu_in_bp(void) { memset(&domctl.u, 0, sizeof(domctl.u)); if (_domctl_hcall(XEN_DOMCTL_gdbsx_domstatus, NULL, 0)) { XGERR(\"ERROR: Unable to check vcpu bp status:%d errno:%d\\n\",  _dom_id, errno); return -1; }  return domctl.u.gdbsx_domstatus.vcpu_id; }", "target": 0, "idx": 108635, "project": "Xen"}
{"func": "static int  hvm_emulate_cmpxchg(enum x86_segment seg, unsigned long offset, void *p_old, void *p_new, unsigned int bytes, struct x86_emulate_ctxt *ctxt) { struct sh_emulate_ctxt *sh_ctxt = container_of(ctxt, struct sh_emulate_ctxt, ctxt); struct vcpu *v = current; unsigned long addr, old[2], new[2]; int rc; if ( !is_x86_user_segment(seg) ) return X86EMUL_UNHANDLEABLE; rc = hvm_translate_linear_addr( seg, offset, bytes, hvm_access_write, sh_ctxt, &addr); if ( rc ) return rc; old[0] = new[0] = 0; memcpy(old, p_old, bytes); memcpy(new, p_new, bytes); if ( bytes <= sizeof(long) ) return v->arch.paging.mode->shadow.x86_emulate_cmpxchg( v, addr, old[0], new[0], bytes, sh_ctxt); return X86EMUL_UNHANDLEABLE; }", "target": 1, "idx": 109406, "project": "Xen"}
{"func": "static void gicv3_clear_lr(int lr) { gicv3_ich_write_lr(lr, 0); }", "target": 0, "idx": 102487, "project": "Xen"}
{"func": "EXPORT_SYMBOL(mask_evtchn); void unmask_evtchn(int port) { evtchn_unmask_t op = { .port = port }; VOID(HYPERVISOR_event_channel_op(EVTCHNOP_unmask, &op)); }", "target": 0, "idx": 101925, "project": "Xen"}
{"func": "void set_sched_smt_func(int argc, char *argv[]) { int value; if ( argc != 1 ) { fprintf(stderr, \"Missing or invalid argument(s)\\n\"); exit(EINVAL); } if ( !strcasecmp(argv[0], \"disable\") ) value = 0; else if ( !strcasecmp(argv[0], \"enable\") ) value = 1; else { fprintf(stderr, \"Invalid argument: %s\\n\", argv[0]); exit(EINVAL); } if ( !xc_set_sched_opt_smt(xc_handle, value) ) printf(\"%s sched_smt_power_savings succeeded\\n\", argv[0]); else fprintf(stderr, \"%s sched_smt_power_savings failed (%d - %s)\\n\", argv[0], errno, strerror(errno)); }", "target": 0, "idx": 108317, "project": "Xen"}
{"func": "static int __init nestedhvm_setup(void) {  unsigned nr = cpu_has_vmx ? 2 : 3; unsigned int i, order = get_order_from_pages(nr); if ( !hvm_funcs.name ) return 0;  for ( i = 0; i < ARRAY_SIZE(shadow_io_bitmap); i++ ) { shadow_io_bitmap[i] = alloc_xenheap_pages(order, 0); if ( !shadow_io_bitmap[i] ) { while ( i-- ) { free_xenheap_pages(shadow_io_bitmap[i], order); shadow_io_bitmap[i] = NULL; } return -ENOMEM; } memset(shadow_io_bitmap[i], ~0U, nr << PAGE_SHIFT); } __clear_bit(0x80, shadow_io_bitmap[0]); __clear_bit(0xed, shadow_io_bitmap[1]); return 0; }", "target": 0, "idx": 104766, "project": "Xen"}
{"func": "static void vmcb_dump(unsigned char ch) { struct domain *d; struct vcpu *v; printk(\"*********** VMCB Areas **************\\n\"); rcu_read_lock(&domlist_read_lock); for_each_domain ( d ) { if ( !is_hvm_domain(d) ) continue; printk(\"\\n>>> Domain %d <<<\\n\", d->domain_id); for_each_vcpu ( d, v ) { printk(\"\\tVCPU %d\\n\", v->vcpu_id); svm_vmcb_dump(\"key_handler\", v->arch.hvm_svm.vmcb); } } rcu_read_unlock(&domlist_read_lock); printk(\"**************************************\\n\"); }", "target": 0, "idx": 106987, "project": "Xen"}
{"func": "void _TIFFprintAscii(FILE* fd, const char* cp) { _TIFFprintAsciiBounded( fd, cp, strlen(cp)); }", "target": 0, "idx": 100304, "project": "LibTIFF"}
{"func": "void guest_iommu_destroy(struct domain *d) { struct guest_iommu *iommu; iommu = domain_iommu(d); if ( !iommu ) return; tasklet_kill(&iommu->cmd_buffer_tasklet); xfree(iommu); dom_iommu(d)->arch.g_iommu = NULL; }", "target": 0, "idx": 102814, "project": "Xen"}
{"func": "static void conf(struct menu *menu) { struct symbol *sym; struct property *prop; struct menu *child; if (!menu_is_visible(menu)) return; sym = menu->sym; prop = menu->prompt; if (prop) { const char *prompt; switch (prop->type) { case P_MENU: if ((input_mode == silentoldconfig ||  input_mode == listnewconfig ||  input_mode == olddefconfig) && rootEntry != menu) { check_conf(menu); return; }  case P_COMMENT: prompt = menu_get_prompt(menu); if (prompt) printf(\"%*c\\n%*c %s\\n%*c\\n\", indent, '*', indent, '*', _(prompt), indent, '*'); default: ; } } if (!sym) goto conf_childs; if (sym_is_choice(sym)) { conf_choice(menu); if (sym->curr.tri != mod) return; goto conf_childs; } switch (sym->type) { case S_INT: case S_HEX: case S_STRING: conf_string(menu); break; default: conf_sym(menu); break; } conf_childs: if (sym) indent += 2; for (child = menu->list; child; child = child->next) conf(child); if (sym) indent -= 2; }", "target": 0, "idx": 101362, "project": "Xen"}
{"func": "static void rcu_offline_cpu(struct rcu_data *this_rdp, struct rcu_ctrlblk *rcp, struct rcu_data *rdp) { kill_timer(&rdp->idle_timer);  spin_lock(&rcp->lock); if (rcp->cur != rcp->completed) cpu_quiet(rdp->cpu, rcp); spin_unlock(&rcp->lock); rcu_move_batch(this_rdp, rdp->donelist, rdp->donetail); rcu_move_batch(this_rdp, rdp->curlist, rdp->curtail); rcu_move_batch(this_rdp, rdp->nxtlist, rdp->nxttail); local_irq_disable(); this_rdp->qlen += rdp->qlen; local_irq_enable(); }", "target": 0, "idx": 105357, "project": "Xen"}
{"func": "int libxl__arch_build_dom_finish(libxl__gc *gc,  libxl_domain_build_info *info,  struct xc_dom_image *dom,  libxl__domain_build_state *state) { return 0; }", "target": 0, "idx": 104187, "project": "Xen"}
{"func": " */ static int perm_read(struct policydb *p, struct hashtab *h, void *fp) { char *key = NULL; struct perm_datum *perdatum; int rc; __le32 buf[2]; u32 len; perdatum = xzalloc(struct perm_datum); if ( !perdatum ) { rc = -ENOMEM; goto out; } rc = next_entry(buf, fp, sizeof buf); if ( rc < 0 ) goto bad; len = le32_to_cpu(buf[0]); perdatum->value = le32_to_cpu(buf[1]); key = xmalloc_array(char, len + 1); if ( !key ) { rc = -ENOMEM; goto bad; } rc = next_entry(key, fp, len); if ( rc < 0 ) goto bad; key[len] = 0; rc = hashtab_insert(h, key, perdatum); if ( rc ) goto bad; out: return rc; bad: perm_destroy(key, perdatum, NULL); goto out; }", "target": 0, "idx": 105119, "project": "Xen"}
{"func": "static uint32_t kdd_write_physical(kdd_state *s, uint64_t addr,   uint32_t len, void *buf) { return kdd_access_physical(s->guest, addr, len, buf, 1); }", "target": 0, "idx": 102953, "project": "Xen"}
{"func": "static int NeXTDecode(TIFF* tif, uint8* buf, tmsize_t occ, uint16 s) { static const char module[] = \"NeXTDecode\"; unsigned char *bp, *op; tmsize_t cc; uint8* row; tmsize_t scanline, n; (void) s; /*  * Each scanline is assumed to start off as all  * white (we assume a PhotometricInterpretation  * of ``min-is-black'').  */ for (op = (unsigned char*) buf, cc = occ; cc-- > 0;) *op++ = 0xff; bp = (unsigned char *)tif->tif_rawcp; cc = tif->tif_rawcc; scanline = tif->tif_scanlinesize; if (occ % scanline) { TIFFErrorExt(tif->tif_clientdata, module, \"Fractional scanlines cannot be read\"); return (0); } for (row = buf; cc > 0 && occ > 0; occ -= scanline, row += scanline) { n = *bp++; cc--; switch (n) { case LITERALROW: /*  * The entire scanline is given as literal values.  */ if (cc < scanline) goto bad; _TIFFmemcpy(row, bp, scanline); bp += scanline; cc -= scanline; break; case LITERALSPAN: { tmsize_t off; /*  * The scanline has a literal span that begins at some  * offset.  */ if( cc < 4 ) goto bad; off = (bp[0] * 256) + bp[1]; n = (bp[2] * 256) + bp[3]; if (cc < 4+n || off+n > scanline) goto bad; _TIFFmemcpy(row+off, bp+4, n); bp += 4+n; cc -= 4+n; break; } default: { uint32 npixels = 0, grey; tmsize_t op_offset = 0; uint32 imagewidth = tif->tif_dir.td_imagewidth; if( isTiled(tif) ) imagewidth = tif->tif_dir.td_tilewidth; /*  * The scanline is composed of a sequence of constant  * color ``runs''.We shift into ``run mode'' and  * interpret bytes as codes of the form  * <color><npixels> until we've filled the scanline.  */ op = row; for (;;) { grey = (uint32)((n>>6) & 0x3); n &= 0x3f; /*  * Ensure the run does not exceed the scanline  * bounds, potentially resulting in a security  * issue.  */ while (n-- > 0 && npixels < imagewidth && op_offset < scanline) SETPIXEL(op, grey); if (npixels >= imagewidth) break; if (op_offset >= scanline ) { TIFFErrorExt(tif->tif_clientdata, module, \"Invalid data for scanline %ld\", (long) tif->tif_row); return (0); } if (cc == 0) goto bad; n = *bp++; cc--; } break; } } } tif->tif_rawcp = (uint8*) bp; tif->tif_rawcc = cc; return (1); bad: TIFFErrorExt(tif->tif_clientdata, module, \"Not enough data for scanline %ld\", (long) tif->tif_row); return (0); }", "target": 1, "idx": 100770, "project": "LibTIFF"}
{"func": "void viridian_time_ref_count_freeze(struct domain *d) { struct viridian_time_ref_count *trc; trc = &d->arch.hvm_domain.viridian.time_ref_count; if ( test_and_clear_bit(_TRC_running, &trc->flags) ) trc->val = raw_trc_val(d) + trc->off; }", "target": 0, "idx": 106904, "project": "Xen"}
{"func": "EXPORT_SYMBOL(__ubsan_handle_add_overflow); void __ubsan_handle_sub_overflow(struct overflow_data *data, unsigned long lhs, unsigned long rhs) { handle_overflow(data, lhs, rhs, '-'); }", "target": 0, "idx": 106542, "project": "Xen"}
{"func": "static int generic_have_wrcomb(void) { unsigned long config; rdmsrl(MSR_MTRRcap, config); return (config & (1ULL << 10)); }", "target": 0, "idx": 102359, "project": "Xen"}
{"func": "long compat_set_callbacks(unsigned long event_selector, unsigned long event_address, unsigned long failsafe_selector, unsigned long failsafe_address) { struct compat_callback_register event = { .type = CALLBACKTYPE_event, .address = { .cs = event_selector, .eip = event_address } }; struct compat_callback_register failsafe = { .type = CALLBACKTYPE_failsafe, .address = { .cs = failsafe_selector, .eip = failsafe_address } }; compat_register_guest_callback(&event); compat_register_guest_callback(&failsafe); return 0; }", "target": 0, "idx": 101314, "project": "Xen"}
{"func": "static struct psr_socket_info *get_socket_info(unsigned int socket) { if ( !socket_info ) return ERR_PTR(-ENODEV); if ( socket >= nr_sockets ) return ERR_PTR(-ERANGE); if ( !socket_info[socket].feat_init ) return ERR_PTR(-ENOENT); return socket_info + socket; }", "target": 0, "idx": 105192, "project": "Xen"}
{"func": "void rb_erase(struct rb_node *node, struct rb_root *root) { struct rb_node *child = node->rb_right, *tmp = node->rb_left; struct rb_node *parent, *rebalance; unsigned long pc; if (!tmp) {  pc = node->__rb_parent_color; parent = __rb_parent(pc); __rb_change_child(node, child, parent, root); if (child) { child->__rb_parent_color = pc; rebalance = NULL; } else rebalance = __rb_is_black(pc) ? parent : NULL; } else if (!child) {  tmp->__rb_parent_color = pc = node->__rb_parent_color; parent = __rb_parent(pc); __rb_change_child(node, tmp, parent, root); rebalance = NULL; } else { struct rb_node *successor = child, *child2; tmp = child->rb_left; if (!tmp) {  parent = child; child2 = child->rb_right; } else {  do { parent = successor; successor = tmp; tmp = tmp->rb_left; } while (tmp); parent->rb_left = child2 = successor->rb_right; successor->rb_right = child; rb_set_parent(child, successor); } successor->rb_left = tmp = node->rb_left; rb_set_parent(tmp, successor); pc = node->__rb_parent_color; tmp = __rb_parent(pc); __rb_change_child(node, successor, tmp, root); if (child2) { successor->__rb_parent_color = pc; rb_set_parent_color(child2, parent, RB_BLACK); rebalance = NULL; } else { unsigned long pc2 = successor->__rb_parent_color; successor->__rb_parent_color = pc; rebalance = __rb_is_black(pc2) ? parent : NULL; } } if (rebalance) __rb_erase_color(rebalance, root); }", "target": 0, "idx": 105327, "project": "Xen"}
{"func": "int libxl_cpupool_cpuremove_cpumap(libxl_ctx *ctx, uint32_t poolid,  const libxl_bitmap *cpumap) { int c, ncpus = 0, rc = 0; libxl_for_each_set_bit(c, *cpumap) { if (!libxl_cpupool_cpuremove(ctx, poolid, c)) ncpus++; } if (ncpus != libxl_bitmap_count_set(cpumap)) rc = ERROR_FAIL; return rc; }", "target": 0, "idx": 103493, "project": "Xen"}
{"func": " */ static int suspend_domain(struct xc_sr_context *ctx) { xc_interface *xch = ctx->xch;  int cb_rc = ctx->save.callbacks->suspend(ctx->save.callbacks->data); if ( cb_rc == 0 ) { ERROR(\"save callback suspend() failed: %d\", cb_rc); return -1; }  if ( (xc_domain_getinfo(xch, ctx->domid, 1, &ctx->dominfo) != 1) ||  (ctx->dominfo.domid != ctx->domid) ) { PERROR(\"Unable to refresh domain information\"); return -1; }  if ( !ctx->dominfo.shutdown ||  (ctx->dominfo.shutdown_reason != SHUTDOWN_suspend) ) { ERROR(\"Domain has not been suspended: shutdown %d, reason %d\", ctx->dominfo.shutdown, ctx->dominfo.shutdown_reason); return -1; } xc_report_progress_single(xch, \"Domain now suspended\"); return 0; }", "target": 0, "idx": 107763, "project": "Xen"}
{"func": "int xenstat_collect_networks(xenstat_node * node) {  return 1; }", "target": 0, "idx": 108409, "project": "Xen"}
{"func": "static void ctlmsg_init(struct log_ctlmsg* msg, const char* cmd) { memset(msg, 0, sizeof(*msg)); memcpy(msg->msg, cmd, 4); }", "target": 0, "idx": 106074, "project": "Xen"}
{"func": "int main(int argc, char* argv[]) { uint16 defconfig = (uint16) -1; uint16 deffillorder = 0; uint32 deftilewidth = (uint32) -1; uint32 deftilelength = (uint32) -1; uint32 defrowsperstrip = (uint32) 0; uint64 diroff = 0; TIFF* in; TIFF* out; char mode[10]; char* mp = mode; int c; #if !HAVE_DECL_OPTARG extern int optind; extern char* optarg; #endif *mp++ = 'w'; *mp = '\\0'; while ((c = getopt(argc, argv, \",:b:c:f:l:o:p:r:w:aistBLMC8x\")) != -1) switch (c) { case ',': if (optarg[0] != '=') usage(); comma = optarg[1]; break; case 'b':  if (bias) { fputs (\"Only 1 bias image may be specified\\n\", stderr); exit (-2); } { uint16 samples = (uint16) -1; char **biasFn = &optarg; bias = openSrcImage (biasFn); if (!bias) exit (-5); if (TIFFIsTiled (bias)) { fputs (\"Bias image must be organized in strips\\n\", stderr); exit (-7); } TIFFGetField(bias, TIFFTAG_SAMPLESPERPIXEL, &samples); if (samples != 1) { fputs (\"Bias image must be monochrome\\n\", stderr); exit (-7); } } break; case 'a':  mode[0] = 'a'; break; case 'c':  if (!processCompressOptions(optarg)) usage(); break; case 'f':  if (streq(optarg, \"lsb2msb\")) deffillorder = FILLORDER_LSB2MSB; else if (streq(optarg, \"msb2lsb\")) deffillorder = FILLORDER_MSB2LSB; else usage(); break; case 'i':  ignore = TRUE; break; case 'l':  outtiled = TRUE; deftilelength = atoi(optarg); break; case 'o':  diroff = strtoul(optarg, NULL, 0); break; case 'p':  if (streq(optarg, \"separate\")) defconfig = PLANARCONFIG_SEPARATE; else if (streq(optarg, \"contig\")) defconfig = PLANARCONFIG_CONTIG; else usage(); break; case 'r':  defrowsperstrip = atol(optarg); break; case 's':  outtiled = FALSE; break; case 't':  outtiled = TRUE; break; case 'w':  outtiled = TRUE; deftilewidth = atoi(optarg); break; case 'B': *mp++ = 'b'; *mp = '\\0'; break; case 'L': *mp++ = 'l'; *mp = '\\0'; break; case 'M': *mp++ = 'm'; *mp = '\\0'; break; case 'C': *mp++ = 'c'; *mp = '\\0'; break; case '8': *mp++ = '8'; *mp = '\\0'; break; case 'x': pageInSeq = 1; break; case '?': usage();  } if (argc - optind < 2) usage(); out = TIFFOpen(argv[argc-1], mode); if (out == NULL) return (-2); if ((argc - optind) == 2) pageNum = -1; for (; optind < argc-1 ; optind++) { char *imageCursor = argv[optind]; in = openSrcImage (&imageCursor); if (in == NULL) { (void) TIFFClose(out); return (-3); } if (diroff != 0 && !TIFFSetSubDirectory(in, diroff)) { TIFFError(TIFFFileName(in), \"Error, setting subdirectory at \" TIFF_UINT64_FORMAT, diroff); (void) TIFFClose(in); (void) TIFFClose(out); return (1); } for (;;) { config = defconfig; compression = defcompression; predictor = defpredictor; preset = defpreset; fillorder = deffillorder; rowsperstrip = defrowsperstrip; tilewidth = deftilewidth; tilelength = deftilelength; g3opts = defg3opts; if (!tiffcp(in, out) || !TIFFWriteDirectory(out)) { (void) TIFFClose(in); (void) TIFFClose(out); return (1); } if (imageCursor) {  if (!nextSrcImage(in, &imageCursor)) break; }else if (!TIFFReadDirectory(in)) break; } (void) TIFFClose(in); } (void) TIFFClose(out); return (0); }", "target": 0, "idx": 100422, "project": "LibTIFF"}
{"func": "static void colo_stream_read_done(libxl__egc *egc, libxl__colo_restore_checkpoint_state *crcs, int id) { libxl__domain_create_state *dcs = CONTAINER_OF(crcs->crs, *dcs, crs); int ok = 0; EGC_GC; if (id != CHECKPOINT_NEW) { LOGD(ERROR, crcs->crs->domid, \"invalid section: %d\", id); goto out; } ok = 1; out: libxl__xc_domain_saverestore_async_callback_done(egc, &dcs->srs.shs, ok); }", "target": 0, "idx": 103426, "project": "Xen"}
{"func": "struct segment_register *hvmemul_get_seg_reg( enum x86_segment seg, struct hvm_emulate_ctxt *hvmemul_ctxt) { if ( !__test_and_set_bit(seg, &hvmemul_ctxt->seg_reg_accessed) ) hvm_get_segment_register(current, seg, &hvmemul_ctxt->seg_reg[seg]); return &hvmemul_ctxt->seg_reg[seg]; }", "target": 1, "idx": 109402, "project": "Xen"}
{"func": "static int vlapic_mmio_read(struct vcpu *v, unsigned long address, unsigned int len, unsigned long *pval) { struct vlapic *vlapic = vcpu_vlapic(v); unsigned int offset = address - vlapic_base_address(vlapic); unsigned int alignment = offset & 0xf, result = 0;  if ( (alignment + len) <= 4 && offset <= (APIC_TDCR + 3) ) { uint32_t reg = vlapic_read_aligned(vlapic, offset & ~0xf); switch ( len ) { case 1: result = (uint8_t) (reg >> (alignment * 8)); break; case 2: result = (uint16_t)(reg >> (alignment * 8)); break; case 4: result = reg;break; } HVM_DBG_LOG(DBG_LEVEL_VLAPIC, \"offset %#x with length %#x, \" \"and the result is %#x\", offset, len, result); } *pval = result; return X86EMUL_OKAY; }", "target": 0, "idx": 106948, "project": "Xen"}
{"func": "static int update_tailer(TDB_CONTEXT *tdb, tdb_off offset,  const struct list_struct *rec) { tdb_off totalsize;  totalsize = sizeof(*rec) + rec->rec_len; return ofs_write(tdb, offset + totalsize - sizeof(tdb_off),  &totalsize); }", "target": 0, "idx": 106405, "project": "Xen"}
{"func": "static void vram_put(struct hvm_hw_stdvga *s, void *p) { unmap_domain_page(p); }", "target": 0, "idx": 105849, "project": "Xen"}
{"func": "static int _fdt_find_add_string(void *fdt, const char *s) { char *strtab = (char *)fdt + fdt_totalsize(fdt); const char *p; int strtabsize = fdt_size_dt_strings(fdt); int len = strlen(s) + 1; int struct_top, offset; p = _fdt_find_string(strtab - strtabsize, strtabsize, s); if (p) return p - strtab;  offset = -strtabsize - len; struct_top = fdt_off_dt_struct(fdt) + fdt_size_dt_struct(fdt); if (fdt_totalsize(fdt) + offset < struct_top) return 0;  memcpy(strtab + offset, s, len); fdt_set_size_dt_strings(fdt, strtabsize + len); return offset; }", "target": 0, "idx": 102053, "project": "Xen"}
{"func": "static int __must_check arm_smmu_unmap_page(struct domain *d, unsigned long gfn) {  if ( !is_domain_direct_mapped(d) ) return -EINVAL; guest_physmap_remove_page(d, _gfn(gfn), _mfn(gfn), 0); return 0; }", "target": 1, "idx": 109462, "project": "Xen"}
{"func": "static int setup_hypercall_page(struct xc_dom_image *dom) { DECLARE_DOMCTL; xen_pfn_t pfn; int rc; if ( dom->parms.virt_hypercall == -1 ) return 0; pfn = (dom->parms.virt_hypercall - dom->parms.virt_base) >> XC_DOM_PAGE_SHIFT(dom); DOMPRINTF(\"%s: vaddr=0x%\" PRIx64 \" pfn=0x%\" PRIpfn \"\", __FUNCTION__, dom->parms.virt_hypercall, pfn); domctl.cmd = XEN_DOMCTL_hypercall_init; domctl.domain = dom->guest_domid; domctl.u.hypercall_init.gmfn = xc_dom_p2m(dom, pfn); rc = do_domctl(dom->xch, &domctl); if ( rc != 0 ) xc_dom_panic(dom->xch, XC_INTERNAL_ERROR,  \"%s: HYPERCALL_INIT failed: %d - %s)\",  __FUNCTION__, errno, strerror(errno)); return rc; }", "target": 0, "idx": 107396, "project": "Xen"}
{"func": "static unsigned int output_size; static void unsafe_error(const char *msg) { xc_dom_panic(unsafe_dom->xch, XC_INVALID_KERNEL, \"%s\", msg); }", "target": 0, "idx": 107406, "project": "Xen"}
{"func": "static void vhd_util_scan_pretty_free_list(void) { int i; if (scan.lists) { for (i = 0; i < scan.lists_cur; i++) free(scan.lists[i]); free(scan.lists); } free(scan.images); memset(&scan, 0, sizeof(scan)); }", "target": 0, "idx": 106842, "project": "Xen"}
{"func": "unsigned int arch_hwdom_irqs(domid_t domid) { unsigned int n = fls(num_present_cpus()); if ( !domid ) n = min(n, dom0_max_vcpus()); n = min(nr_irqs_gsi + n * NR_DYNAMIC_VECTORS, nr_irqs);  n = min_t(unsigned int, n, PAGE_SIZE * BITS_PER_BYTE); printk(\"Dom%d has maximum %u PIRQs\\n\", domid, n); return n; }", "target": 0, "idx": 102838, "project": "Xen"}
{"func": "int tap_ctl_write_message(int fd, tapdisk_message_t *message, int timeout) { fd_set writefds; int ret, len, offset; struct timeval tv, *t; t= NULL; offset = 0; len= sizeof(tapdisk_message_t); if (timeout) { tv.tv_sec= timeout; tv.tv_usec = 0; t = &tv; } DBG(\"sending '%s' message (uuid = %u)\\n\", tapdisk_message_name(message->type), message->cookie); while (offset < len) { FD_ZERO(&writefds); FD_SET(fd, &writefds);  ret = select(fd + 1, NULL, &writefds, NULL, t); if (ret == -1) { if (errno == EINTR) continue; break; } else if (FD_ISSET(fd, &writefds)) { ret = write(fd, message + offset, len - offset); if (ret <= 0) { if (errno == EINTR) continue; break; } offset += ret; } else break; } if (offset != len) { EPRINTF(\"failure writing message\\n\"); return -EIO; } return 0; }", "target": 0, "idx": 106019, "project": "Xen"}
{"func": "int tdaio_validate_parent(td_driver_t *driver, td_driver_t *pdriver, td_flag_t flags) { return -EINVAL; }", "target": 0, "idx": 101029, "project": "Xen"}
{"func": "static void drbd_teardown(libxl__egc *egc, libxl__checkpoint_device *dev) { libxl__remus_drbd_disk *drbd_disk = dev->concrete_data; STATE_AO_GC(dev->cds->ao); close(drbd_disk->ctl_fd); dev->aodev.rc = 0; dev->aodev.callback(egc, &dev->aodev); }", "target": 0, "idx": 103936, "project": "Xen"}
{"func": "static void vhd_journal_entry_in(vhd_journal_entry_t *entry) { BE32_IN(&entry->type); BE32_IN(&entry->size); BE64_IN(&entry->offset); BE64_IN(&entry->cookie); BE32_IN(&entry->checksum); }", "target": 0, "idx": 103073, "project": "Xen"}
{"func": "bool vpci_process_pending(struct vcpu *v) { if ( v->vpci.mem ) { struct map_data data = { .d = v->domain, .map = v->vpci.map, }; int rc = rangeset_consume_ranges(v->vpci.mem, map_range, &data); if ( rc == -ERESTART ) return true; spin_lock(&v->vpci.pdev->vpci->lock);  modify_decoding(v->vpci.pdev, !rc && v->vpci.map, !rc && v->vpci.rom_only); spin_unlock(&v->vpci.pdev->vpci->lock); rangeset_destroy(v->vpci.mem); v->vpci.mem = NULL; if ( rc )  vpci_remove_device(v->vpci.pdev); } return false; }", "target": 0, "idx": 102657, "project": "Xen"}
{"func": "static int Fax3PreEncode(TIFF* tif, tsample_t s) { Fax3CodecState* sp = EncoderState(tif); (void) s; assert(sp != NULL); sp->bit = 8; sp->data = 0; sp->tag = G3_1D;  if (sp->refline) _TIFFmemset(sp->refline, 0x00, sp->b.rowbytes); if (is2DEncoding(sp)) { float res = tif->tif_dir.td_yresolution;  if (tif->tif_dir.td_resolutionunit == RESUNIT_CENTIMETER) res *= 2.54f; sp->maxk = (res > 150 ? 4 : 2); sp->k = sp->maxk-1; } else sp->k = sp->maxk = 0; return (1); }", "target": 0, "idx": 100177, "project": "LibTIFF"}
{"func": "static int _tiffMapProc(thandle_t fd, tdata_t* pbase, toff_t* psize) { return (0); }", "target": 0, "idx": 100100, "project": "LibTIFF"}
{"func": " int rc); static void tfe_init(libxl__test_fdevent *tfe, libxl__ao *ao) { tfe->ao = ao; libxl__ev_fd_init(&tfe->fd); libxl__ao_abortable_init(&tfe->abrt); }", "target": 0, "idx": 104048, "project": "Xen"}
{"func": "size_t pv_console_rx(struct cpu_user_regs *regs) { char c; XENCONS_RING_IDX cons, prod; size_t recv = 0; if ( !cons_ring ) return 0; prod = ACCESS_ONCE(cons_ring->in_prod); cons = cons_ring->in_cons;  smp_rmb(); ASSERT((prod - cons) <= sizeof(cons_ring->in)); while ( cons != prod ) { c = cons_ring->in[MASK_XENCONS_IDX(cons++, cons_ring->in)]; if ( cons_rx_handler ) cons_rx_handler(c, regs); recv++; }  barrier(); ACCESS_ONCE(cons_ring->in_cons) = cons; notify_daemon(); return recv; }", "target": 0, "idx": 108590, "project": "Xen"}
{"func": "static tsize_t _tiffReadProc(thandle_t fd, tdata_t buf, tsize_t size) { return ((tsize_t) read((int) fd, buf, (size_t) size)); }", "target": 0, "idx": 100085, "project": "LibTIFF"}
{"func": "int vgic_connect_hw_irq(struct domain *d, struct vcpu *v, unsigned int virq, struct irq_desc *desc, bool connect) { unsigned long flags;  struct vcpu *v_target = vgic_get_target_vcpu(d->vcpu[0], virq); struct vgic_irq_rank *rank = vgic_rank_irq(v_target, virq); struct pending_irq *p = irq_to_pending(v_target, virq); int ret = 0;  ASSERT(connect && desc);  vgic_lock_rank(v_target, rank, flags); if ( connect ) {  if ( !p->desc &&  !test_bit(GIC_IRQ_GUEST_ENABLED, &p->status) ) p->desc = desc; else ret = -EBUSY; } else { if ( desc && p->desc != desc ) ret = -EINVAL; else p->desc = NULL; } vgic_unlock_rank(v_target, rank, flags); return ret; }", "target": 0, "idx": 102558, "project": "Xen"}
{"func": "static int vhd_util_scan_find_targets(int cnt, char **names,  const char *volume, const char *filter,  struct target **targets, int *total) { if (flags & VHD_SCAN_VOLUME) return vhd_util_scan_find_volume_targets(cnt, names,  volume, filter,  targets, total); return vhd_util_scan_find_file_targets(cnt, names,  filter, targets, total); }", "target": 0, "idx": 106830, "project": "Xen"}
{"func": "int xc_tmem_save(xc_interface *xch,  uint32_t domid, int io_fd, int live, int field_marker) { int marker = field_marker; int i, j, rc; uint32_t minusone = -1; struct tmem_handle *h; xen_tmem_client_t info; xen_tmem_pool_info_t *pools; char *buf = NULL; rc = xc_tmem_control(xch, 0, XEN_SYSCTL_TMEM_OP_SAVE_BEGIN,  domid, 0, live, NULL); if ( rc ) {  if ( errno == ENOENT ) return 0; return rc; } if ( xc_tmem_control(xch, 0 ,  XEN_SYSCTL_TMEM_OP_GET_CLIENT_INFO,  domid , sizeof(info), 0 ,  &info) < 0 ) return -1;  if ( !info.nr_pools ) return 0; pools = calloc(info.nr_pools, sizeof(*pools)); if ( !pools ) return -1; rc = xc_tmem_control(xch, 0 ,  XEN_SYSCTL_TMEM_OP_GET_POOLS,  domid , sizeof(*pools) * info.nr_pools,  0 , pools); if ( rc < 0 || (uint32_t)rc > info.nr_pools ) goto out_memory;  info.nr_pools = (uint32_t)rc; if ( write_exact(io_fd, &marker, sizeof(marker)) ) goto out_memory; if ( write_exact(io_fd, &info, sizeof(info)) ) goto out_memory; if ( write_exact(io_fd, &minusone, sizeof(minusone)) ) goto out_memory; for ( i = 0; i < info.nr_pools; i++ ) { uint32_t pagesize; int bufsize = 0; int checksum = 0; xen_tmem_pool_info_t *pool = &pools[i]; if ( pool->flags.raw != -1 ) { if ( !pool->flags.u.persist ) pool->n_pages = 0; if ( write_exact(io_fd, pool, sizeof(*pool)) ) goto out_memory; if ( !pool->flags.u.persist ) continue; pagesize = 1 << (pool->flags.u.pagebits + 12); if ( pagesize > bufsize ) { bufsize = pagesize + sizeof(struct tmem_handle); if ( (buf = realloc(buf,bufsize)) == NULL ) goto out_memory; } for ( j = pool->n_pages; j > 0; j-- ) { int ret; if ( (ret = xc_tmem_control( xch, pool->id, XEN_SYSCTL_TMEM_OP_SAVE_GET_NEXT_PAGE, domid, bufsize, 0, buf)) > 0 ) { h = (struct tmem_handle *)buf; if ( write_exact(io_fd, &h->oid, sizeof(h->oid)) ) goto out_memory; if ( write_exact(io_fd, &h->index, sizeof(h->index)) ) goto out_memory; h++; checksum += *(char *)h; if ( write_exact(io_fd, h, pagesize) ) goto out_memory; } else if ( ret == 0 ) { continue; } else {  h = (struct tmem_handle *)buf; h->oid.oid[0] = h->oid.oid[1] = h->oid.oid[2] = -1L; if ( write_exact(io_fd, &h->oid, sizeof(h->oid)) ) {  out_memory: free(pools); free(buf); return -1; } break; } } DPRINTF(\"saved %\"PRId64\" tmem pages for dom=%d pool=%d, checksum=%x\\n\", pool->n_pages - j, domid, pool->id, checksum); } } free(pools); free(buf);  minusone = -1; if ( write_exact(io_fd, &minusone, sizeof(minusone)) ) return -1; return 1; }", "target": 0, "idx": 107823, "project": "Xen"}
{"func": "static int tdb_next_lock(TDB_CONTEXT *tdb, struct tdb_traverse_lock *tlock,  struct list_struct *rec) { int want_next = (tlock->off != 0);  for (; tlock->hash < tdb->header.hash_size; tlock->hash++) {  if (!tlock->off && tlock->hash != 0) { uint32_t off; if (tdb->map_ptr) { for (;tlock->hash < tdb->header.hash_size;tlock->hash++) { if (0 != *(uint32_t *)(TDB_HASH_TOP(tlock->hash) + (unsigned char *)tdb->map_ptr)) { break; } } if (tlock->hash == tdb->header.hash_size) { continue; } } else { if (ofs_read(tdb, TDB_HASH_TOP(tlock->hash), &off) == 0 && off == 0) { continue; } } } if (tdb_lock(tdb, tlock->hash, F_WRLCK) == -1) return -1;  if (!tlock->off) { if (ofs_read(tdb, TDB_HASH_TOP(tlock->hash),  &tlock->off) == -1) goto fail; } else {  if (unlock_record(tdb, tlock->off) != 0) goto fail; } if (want_next) {  if (rec_read(tdb, tlock->off, rec) == -1) goto fail; tlock->off = rec->next; }  while( tlock->off) { tdb_off current; if (rec_read(tdb, tlock->off, rec) == -1) goto fail;  if (tlock->off == rec->next) { TDB_LOG((tdb, 0, \"tdb_next_lock: loop detected.\\n\")); goto fail; } if (!TDB_DEAD(rec)) {  if (lock_record(tdb, tlock->off) != 0) goto fail; return tlock->off; }  current = tlock->off; tlock->off = rec->next; if (!tdb->read_only &&  do_delete(tdb, current, rec) != 0) goto fail; } tdb_unlock(tdb, tlock->hash, F_WRLCK); want_next = 0; }  return TDB_ERRCODE(TDB_SUCCESS, 0);  fail: tlock->off = 0; if (tdb_unlock(tdb, tlock->hash, F_WRLCK) != 0) TDB_LOG((tdb, 0, \"tdb_next_lock: On error unlock failed!\\n\")); return -1; }", "target": 0, "idx": 106396, "project": "Xen"}
{"func": "int tapdisk_server_run() { int err; err = tapdisk_set_resource_limits(); if (err) return err; signal(SIGBUS, tapdisk_server_signal_handler); signal(SIGINT, tapdisk_server_signal_handler); signal(SIGUSR1, tapdisk_server_signal_handler); signal(SIGXFSZ, tapdisk_server_signal_handler); __tapdisk_server_run(); tapdisk_server_close(); return 0; }", "target": 0, "idx": 106237, "project": "Xen"}
{"func": "static void __init gicv3_init_v2(void) { if ( cbase == INVALID_PADDR || vbase == INVALID_PADDR ) return;  if ( vsize < GUEST_GICC_SIZE ) { printk(XENLOG_WARNING  \"GICv3: WARNING: Not enabling support for GICv2 compat mode.\\n\"  \"Size of GICV (%#\"PRIpaddr\") must at least be %#llx.\\n\",  vsize, GUEST_GICC_SIZE); return; } printk(\"GICv3 compatible with GICv2 cbase %#\"PRIpaddr\" vbase %#\"PRIpaddr\"\\n\",  cbase, vbase); vgic_v2_setup_hw(dbase, cbase, csize, vbase, 0); }", "target": 0, "idx": 102510, "project": "Xen"}
{"func": "void on_save_as1_activate(GtkMenuItem * menuitem, gpointer user_data) { GtkWidget *fs; fs = gtk_file_selection_new(_(\"Save file as...\")); g_signal_connect(GTK_OBJECT(GTK_FILE_SELECTION(fs)->ok_button),  \"clicked\",  G_CALLBACK(store_filename), (gpointer) fs); g_signal_connect_swapped(GTK_OBJECT  (GTK_FILE_SELECTION(fs)->ok_button),  \"clicked\", G_CALLBACK(gtk_widget_destroy),  (gpointer) fs); g_signal_connect_swapped(GTK_OBJECT  (GTK_FILE_SELECTION(fs)->cancel_button),  \"clicked\", G_CALLBACK(gtk_widget_destroy),  (gpointer) fs); gtk_widget_show(fs); }", "target": 0, "idx": 102295, "project": "Xen"}
{"func": "uint32_t xc_get_cpu_featureset_size(void) { return FEATURESET_NR_ENTRIES; }", "target": 0, "idx": 107346, "project": "Xen"}
{"func": "static int gicv3_secondary_cpu_init(void) { int res; spin_lock(&gicv3.lock); res = gicv3_cpu_init(); if ( res ) goto out; gicv3_hyp_init(); out: spin_unlock(&gicv3.lock); return res; }", "target": 0, "idx": 102533, "project": "Xen"}
{"func": "static void gicv2_disable_interface(void) { spin_lock(&gicv2.lock); gicv2_cpu_disable(); gicv2_hyp_disable(); spin_unlock(&gicv2.lock); }", "target": 0, "idx": 102391, "project": "Xen"}
{"func": "static int tapdisk_stream_initialize_requests(struct tapdisk_stream *s) { size_t size; td_ring_t *ring; int err, i, psize; ring= &s->vbd->ring; psize = getpagesize(); size= psize * BLKTAP_MMAP_REGION_SIZE;  err = posix_memalign((void **)&ring->vstart, psize, size); if (err) { fprintf(stderr, \"failed to allocate buffers: %d\\n\", err); ring->vstart = 0; return err; } for (i = 0; i < MAX_REQUESTS; i++) { struct tapdisk_stream_request *req = s->requests + i; tapdisk_stream_initialize_request(req); list_add_tail(&req->next, &s->free_list); } return 0; }", "target": 0, "idx": 106122, "project": "Xen"}
{"func": "int osdep_gnttab_unmap(xengnttab_handle *xgt,  void *start_address,  uint32_t count) { int fd = xgt->fd; int ret; ret = gntmap_munmap(&files[fd].gntmap, (unsigned long) start_address, count); if (ret < 0) { errno = -ret; return -1; } return ret; }", "target": 0, "idx": 104589, "project": "Xen"}
{"func": "static int vmce_save_vcpu_ctxt(struct domain *d, hvm_domain_context_t *h) { struct vcpu *v; int err = 0; for_each_vcpu ( d, v ) { struct hvm_vmce_vcpu ctxt = { .caps = v->arch.vmce.mcg_cap, .mci_ctl2_bank0 = v->arch.vmce.bank[0].mci_ctl2, .mci_ctl2_bank1 = v->arch.vmce.bank[1].mci_ctl2, .mcg_ext_ctl = v->arch.vmce.mcg_ext_ctl, }; err = hvm_save_entry(VMCE_VCPU, v->vcpu_id, h, &ctxt); if ( err ) break; } return err; }", "target": 0, "idx": 106999, "project": "Xen"}
{"func": "void svm_vmexit_handler(struct cpu_user_regs *regs) { uint64_t exit_reason; struct vcpu *v = current; struct vmcb_struct *vmcb = v->arch.hvm_svm.vmcb; eventinj_t eventinj; int inst_len, rc; vintr_t intr; bool_t vcpu_guestmode = 0; hvm_invalidate_regs_fields(regs); if ( paging_mode_hap(v->domain) ) v->arch.hvm_vcpu.guest_cr[3] = v->arch.hvm_vcpu.hw_cr[3] = vmcb_get_cr3(vmcb); if ( nestedhvm_enabled(v->domain) && nestedhvm_vcpu_in_guestmode(v) ) vcpu_guestmode = 1;  if ( !vcpu_guestmode ) { intr = vmcb_get_vintr(vmcb); vlapic_set_reg(vcpu_vlapic(v), APIC_TASKPRI,  ((intr.fields.tpr & 0x0F) << 4) |  (vlapic_get_reg(vcpu_vlapic(v), APIC_TASKPRI) & 0x0F)); } exit_reason = vmcb->exitcode; if ( hvm_long_mode_enabled(v) ) HVMTRACE_ND(VMEXIT64, vcpu_guestmode ? TRC_HVM_NESTEDFLAG : 0, 1, 3, exit_reason, (uint32_t)regs->eip, (uint32_t)((uint64_t)regs->eip >> 32), 0, 0, 0); else HVMTRACE_ND(VMEXIT, vcpu_guestmode ? TRC_HVM_NESTEDFLAG : 0, 1, 2, exit_reason, (uint32_t)regs->eip, 0, 0, 0, 0); if ( vcpu_guestmode ) { enum nestedhvm_vmexits nsret; struct nestedvcpu *nv = &vcpu_nestedhvm(v); struct vmcb_struct *ns_vmcb = nv->nv_vvmcx; uint64_t exitinfo1, exitinfo2; paging_update_nestedmode(v);  exitinfo1 = ns_vmcb->exitinfo1; ns_vmcb->exitinfo1 = vmcb->exitinfo1; nsret = nestedsvm_check_intercepts(v, regs, exit_reason); switch (nsret) { case NESTEDHVM_VMEXIT_CONTINUE: BUG(); break; case NESTEDHVM_VMEXIT_HOST: break; case NESTEDHVM_VMEXIT_INJECT:  exitinfo1 = vmcb->exitinfo1; exitinfo2 = vmcb->exitinfo2; nv->nv_vmswitch_in_progress = 1; nsret = nestedsvm_vmexit_n2n1(v, regs); nv->nv_vmswitch_in_progress = 0; switch (nsret) { case NESTEDHVM_VMEXIT_DONE:  nestedsvm_vmexit_defer(v, exit_reason, exitinfo1, exitinfo2); goto out; case NESTEDHVM_VMEXIT_FATALERROR: gdprintk(XENLOG_ERR, \"unexpected nestedsvm_vmexit() error\\n\"); domain_crash(v->domain); goto out; default: BUG(); case NESTEDHVM_VMEXIT_ERROR: break; } case NESTEDHVM_VMEXIT_ERROR: gdprintk(XENLOG_ERR, \"nestedsvm_check_intercepts() returned NESTEDHVM_VMEXIT_ERROR\\n\"); goto out; case NESTEDHVM_VMEXIT_FATALERROR: gdprintk(XENLOG_ERR, \"unexpected nestedsvm_check_intercepts() error\\n\"); domain_crash(v->domain); goto out; default: gdprintk(XENLOG_INFO, \"nestedsvm_check_intercepts() returned %i\\n\", nsret); domain_crash(v->domain); goto out; } } if ( unlikely(exit_reason == VMEXIT_INVALID) ) { gdprintk(XENLOG_ERR, \"invalid VMCB state:\\n\"); svm_vmcb_dump(__func__, vmcb); domain_crash(v->domain); goto out; } perfc_incra(svmexits, exit_reason); hvm_maybe_deassert_evtchn_irq(); vmcb->cleanbits.bytes = cpu_has_svm_cleanbits ? ~0u : 0u;  eventinj = vmcb->exitintinfo; if ( unlikely(eventinj.fields.v) &&  hvm_event_needs_reinjection(eventinj.fields.type,  eventinj.fields.vector) ) vmcb->eventinj = eventinj; switch ( exit_reason ) { case VMEXIT_INTR:  HVMTRACE_0D(INTR); break; case VMEXIT_NMI:  HVMTRACE_0D(NMI); break; case VMEXIT_SMI:  HVMTRACE_0D(SMI); break; case VMEXIT_EXCEPTION_DB: if ( !v->domain->debugger_attached ) goto unexpected_exit_type; domain_pause_for_debugger(); break; case VMEXIT_EXCEPTION_BP: if ( !v->domain->debugger_attached ) goto unexpected_exit_type;  if ( (inst_len = __get_instruction_length(v, INSTR_INT3)) == 0 ) break; __update_guest_eip(regs, inst_len); current->arch.gdbsx_vcpu_event = TRAP_int3; domain_pause_for_debugger(); break; case VMEXIT_EXCEPTION_NM: svm_fpu_dirty_intercept(); break; case VMEXIT_EXCEPTION_PF: { unsigned long va; va = vmcb->exitinfo2; regs->error_code = vmcb->exitinfo1; HVM_DBG_LOG(DBG_LEVEL_VMMU, \"eax=%lx, ebx=%lx, ecx=%lx, edx=%lx, esi=%lx, edi=%lx\", (unsigned long)regs->eax, (unsigned long)regs->ebx, (unsigned long)regs->ecx, (unsigned long)regs->edx, (unsigned long)regs->esi, (unsigned long)regs->edi); if ( cpu_has_svm_decode ) v->arch.hvm_svm.cached_insn_len = vmcb->guest_ins_len & 0xf; rc = paging_fault(va, regs); v->arch.hvm_svm.cached_insn_len = 0; if ( rc ) { if ( trace_will_trace_event(TRC_SHADOW) ) break; if ( hvm_long_mode_enabled(v) ) HVMTRACE_LONG_2D(PF_XEN, regs->error_code, TRC_PAR_LONG(va)); else HVMTRACE_2D(PF_XEN, regs->error_code, va); break; } hvm_inject_page_fault(regs->error_code, va); break; } case VMEXIT_EXCEPTION_UD: svm_vmexit_ud_intercept(regs); break;  case VMEXIT_EXCEPTION_MC: HVMTRACE_0D(MCE); svm_vmexit_mce_intercept(v, regs); break; case VMEXIT_VINTR: { u32 general1_intercepts = vmcb_get_general1_intercepts(vmcb); intr = vmcb_get_vintr(vmcb); intr.fields.irq = 0; general1_intercepts &= ~GENERAL1_INTERCEPT_VINTR; vmcb_set_vintr(vmcb, intr); vmcb_set_general1_intercepts(vmcb, general1_intercepts); break; } case VMEXIT_INVD: case VMEXIT_WBINVD: svm_vmexit_do_invalidate_cache(regs); break; case VMEXIT_TASK_SWITCH: { enum hvm_task_switch_reason reason; int32_t errcode = -1; if ( (vmcb->exitinfo2 >> 36) & 1 ) reason = TSW_iret; else if ( (vmcb->exitinfo2 >> 38) & 1 ) reason = TSW_jmp; else reason = TSW_call_or_int; if ( (vmcb->exitinfo2 >> 44) & 1 ) errcode = (uint32_t)vmcb->exitinfo2;  vmcb->eventinj.bytes = 0; hvm_task_switch((uint16_t)vmcb->exitinfo1, reason, errcode); break; } case VMEXIT_CPUID: svm_vmexit_do_cpuid(regs); break; case VMEXIT_HLT: svm_vmexit_do_hlt(vmcb, regs); break; case VMEXIT_IOIO: if ( (vmcb->exitinfo1 & (1u<<2)) == 0 ) { uint16_t port = (vmcb->exitinfo1 >> 16) & 0xFFFF; int bytes = ((vmcb->exitinfo1 >> 4) & 0x07); int dir = (vmcb->exitinfo1 & 1) ? IOREQ_READ : IOREQ_WRITE; if ( handle_pio(port, bytes, dir) ) __update_guest_eip(regs, vmcb->exitinfo2 - vmcb->rip); } else if ( !handle_mmio() ) hvm_inject_hw_exception(TRAP_gp_fault, 0); break; case VMEXIT_CR0_READ ... VMEXIT_CR15_READ: case VMEXIT_CR0_WRITE ... VMEXIT_CR15_WRITE: if ( cpu_has_svm_decode && (vmcb->exitinfo1 & (1ULL << 63)) ) svm_vmexit_do_cr_access(vmcb, regs); else if ( !handle_mmio() )  hvm_inject_hw_exception(TRAP_gp_fault, 0); break; case VMEXIT_INVLPG: if ( cpu_has_svm_decode ) { svm_invlpg_intercept(vmcb->exitinfo1); __update_guest_eip(regs, vmcb->nextrip - vmcb->rip); } else if ( !handle_mmio() ) hvm_inject_hw_exception(TRAP_gp_fault, 0); break; case VMEXIT_INVLPGA: if ( (inst_len = __get_instruction_length(v, INSTR_INVLPGA)) == 0 ) break; svm_invlpga_intercept(v, regs->eax, regs->ecx); __update_guest_eip(regs, inst_len); break; case VMEXIT_VMMCALL: if ( (inst_len = __get_instruction_length(v, INSTR_VMCALL)) == 0 ) break; BUG_ON(vcpu_guestmode); HVMTRACE_1D(VMMCALL, regs->eax); rc = hvm_do_hypercall(regs); if ( rc != HVM_HCALL_preempted ) { __update_guest_eip(regs, inst_len); if ( rc == HVM_HCALL_invalidate ) send_invalidate_req(); } break; case VMEXIT_DR0_READ ... VMEXIT_DR7_READ: case VMEXIT_DR0_WRITE ... VMEXIT_DR7_WRITE: svm_dr_access(v, regs); break; case VMEXIT_MSR: svm_do_msr_access(regs); break; case VMEXIT_SHUTDOWN: hvm_triple_fault(); break; case VMEXIT_RDTSCP: regs->ecx = hvm_msr_tsc_aux(v);  case VMEXIT_RDTSC: svm_vmexit_do_rdtsc(regs); break; case VMEXIT_MONITOR: case VMEXIT_MWAIT: hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE); break; case VMEXIT_VMRUN: svm_vmexit_do_vmrun(regs, v, regs->eax); break; case VMEXIT_VMLOAD: svm_vmexit_do_vmload(vmcb, regs, v, regs->eax); break; case VMEXIT_VMSAVE: svm_vmexit_do_vmsave(vmcb, regs, v, regs->eax); break; case VMEXIT_STGI: svm_vmexit_do_stgi(regs, v); break; case VMEXIT_CLGI: svm_vmexit_do_clgi(regs, v); break; case VMEXIT_SKINIT: hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE); break; case VMEXIT_XSETBV: if ( (inst_len = __get_instruction_length(current, INSTR_XSETBV))==0 ) break; if ( hvm_handle_xsetbv(regs->ecx,  (regs->rdx << 32) | regs->_eax) == 0 ) __update_guest_eip(regs, inst_len); break; case VMEXIT_NPF: perfc_incra(svmexits, VMEXIT_NPF_PERFC); if ( cpu_has_svm_decode ) v->arch.hvm_svm.cached_insn_len = vmcb->guest_ins_len & 0xf; rc = vmcb->exitinfo1 & PFEC_page_present  ? p2m_pt_handle_deferred_changes(vmcb->exitinfo2) : 0; if ( rc >= 0 ) svm_do_nested_pgfault(v, regs, vmcb->exitinfo1, vmcb->exitinfo2); else { printk(XENLOG_G_ERR  \"%pv: Error %d handling NPF (gpa=%08lx ec=%04lx)\\n\",  v, rc, vmcb->exitinfo2, vmcb->exitinfo1); domain_crash(v->domain); } v->arch.hvm_svm.cached_insn_len = 0; break; case VMEXIT_IRET: { u32 general1_intercepts = vmcb_get_general1_intercepts(vmcb);  general1_intercepts &= ~GENERAL1_INTERCEPT_IRET; vmcb->interrupt_shadow = 1; vmcb_set_general1_intercepts(vmcb, general1_intercepts); break; } case VMEXIT_PAUSE: svm_vmexit_do_pause(regs); break; default: unexpected_exit_type: gdprintk(XENLOG_ERR, \"unexpected VMEXIT: exit reason = %#\"PRIx64\", \"  \"exitinfo1 = %#\"PRIx64\", exitinfo2 = %#\"PRIx64\"\\n\",  exit_reason,   (u64)vmcb->exitinfo1, (u64)vmcb->exitinfo2); svm_crash_or_fault(v); break; } out: if ( vcpu_guestmode )  return;  intr = vmcb_get_vintr(vmcb); intr.fields.tpr = (vlapic_get_reg(vcpu_vlapic(v), APIC_TASKPRI) & 0xFF) >> 4; vmcb_set_vintr(vmcb, intr); }", "target": 1, "idx": 109295, "project": "Xen"}
{"func": "static void gicv2_dir_irq(struct irq_desc *irqd) {  writel_gicc(irqd->irq, GICC_DIR); }", "target": 0, "idx": 102390, "project": "Xen"}
{"func": "value stub_libxl_domain_reboot(value ctx, value domid) { CAMLparam2(ctx, domid); int ret; uint32_t c_domid = Int_val(domid); caml_enter_blocking_section(); ret = libxl_domain_reboot(CTX, c_domid); caml_leave_blocking_section(); if (ret != 0) failwith_xl(ret, \"domain_reboot\"); CAMLreturn(Val_unit); }", "target": 0, "idx": 108235, "project": "Xen"}
{"func": " */ static int process_start_info(struct xc_sr_context *ctx, vcpu_guest_context_any_t *vcpu) { xc_interface *xch = ctx->xch; xen_pfn_t pfn, mfn; start_info_any_t *guest_start_info = NULL; int rc = -1; pfn = GET_FIELD(vcpu, user_regs.edx, ctx->x86_pv.width); if ( pfn > ctx->x86_pv.max_pfn ) { ERROR(\"Start Info pfn %#lx out of range\", pfn); goto err; } else if ( ctx->x86_pv.restore.pfn_types[pfn] != XEN_DOMCTL_PFINFO_NOTAB ) { ERROR(\"Start Info pfn %#lx has bad type %u\", pfn, (ctx->x86_pv.restore.pfn_types[pfn] >>  XEN_DOMCTL_PFINFO_LTAB_SHIFT)); goto err; } mfn = pfn_to_mfn(ctx, pfn); if ( !mfn_in_pseudophysmap(ctx, mfn) ) { ERROR(\"Start Info has bad mfn\"); dump_bad_pseudophysmap_entry(ctx, mfn); goto err; } SET_FIELD(vcpu, user_regs.edx, mfn, ctx->x86_pv.width); guest_start_info = xc_map_foreign_range( xch, ctx->domid, PAGE_SIZE, PROT_READ | PROT_WRITE, mfn); if ( !guest_start_info ) { PERROR(\"Failed to map Start Info at mfn %#lx\", mfn); goto err; }  pfn = GET_FIELD(guest_start_info, store_mfn, ctx->x86_pv.width); if ( pfn > ctx->x86_pv.max_pfn ) { ERROR(\"XenStore pfn %#lx out of range\", pfn); goto err; } mfn = pfn_to_mfn(ctx, pfn); if ( !mfn_in_pseudophysmap(ctx, mfn) ) { ERROR(\"XenStore pfn has bad mfn\"); dump_bad_pseudophysmap_entry(ctx, mfn); goto err; } ctx->restore.xenstore_gfn = mfn; SET_FIELD(guest_start_info, store_mfn, mfn, ctx->x86_pv.width); SET_FIELD(guest_start_info, store_evtchn, ctx->restore.xenstore_evtchn, ctx->x86_pv.width);  pfn = GET_FIELD(guest_start_info, console.domU.mfn, ctx->x86_pv.width); if ( pfn > ctx->x86_pv.max_pfn ) { ERROR(\"Console pfn %#lx out of range\", pfn); goto err; } mfn = pfn_to_mfn(ctx, pfn); if ( !mfn_in_pseudophysmap(ctx, mfn) ) { ERROR(\"Console pfn has bad mfn\"); dump_bad_pseudophysmap_entry(ctx, mfn); goto err; } ctx->restore.console_gfn = mfn; SET_FIELD(guest_start_info, console.domU.mfn, mfn, ctx->x86_pv.width); SET_FIELD(guest_start_info, console.domU.evtchn, ctx->restore.console_evtchn, ctx->x86_pv.width);  SET_FIELD(guest_start_info, nr_pages, ctx->x86_pv.max_pfn + 1, ctx->x86_pv.width); SET_FIELD(guest_start_info, shared_info, ctx->dominfo.shared_info_frame << PAGE_SHIFT, ctx->x86_pv.width); SET_FIELD(guest_start_info, flags, 0, ctx->x86_pv.width); rc = 0; err: if ( guest_start_info ) munmap(guest_start_info, PAGE_SIZE); return rc; }", "target": 0, "idx": 107738, "project": "Xen"}
{"func": "static void tapdisk_rwio_destroy(struct tqueue *queue) { struct rwio *rwio = queue->tio_data; if (rwio->aio_events) { free(rwio->aio_events); rwio->aio_events = NULL; } }", "target": 0, "idx": 106199, "project": "Xen"}
{"func": " */ static void tcpa_add_measurement(uint32_t pcrIndex, uint16_t event_type, uint32_t data) { const char *string; switch (event_type) { case EV_SEPARATOR: tcpa_add_measurement_to_log_simple(pcrIndex, event_type, (uint8_t *)evt_separator, 4); break; case EV_ACTION: string = ev_action[data ]; tcpa_add_measurement_to_log(pcrIndex, event_type, data, string, strlen(string)); break; } }", "target": 0, "idx": 106339, "project": "Xen"}
{"func": "void xtl_logger_destroy(struct xentoollog_logger *logger) { if (!logger) return; logger->destroy(logger); }", "target": 0, "idx": 108972, "project": "Xen"}
{"func": "static void _xc_init_errbuf(void) { pthread_key_create(&errbuf_pkey, _xc_clean_errbuf); }", "target": 0, "idx": 107672, "project": "Xen"}
{"func": "static void vpl011_update_tx_fifo_status(struct vpl011 *vpl011,  unsigned int fifo_level) { struct xencons_interface *intf = vpl011->ring_buf; unsigned int fifo_threshold = sizeof(intf->out) - SBSA_UART_FIFO_LEVEL; BUILD_BUG_ON(sizeof(intf->out) < SBSA_UART_FIFO_SIZE);  if ( fifo_level <= fifo_threshold ) vpl011->uartris |= TXI; else vpl011->uartris &= ~TXI; }", "target": 0, "idx": 107102, "project": "Xen"}
{"func": "static inline void old_clear_bit(volatile char *addr, int nr) { ((uint32_t *)addr)[nr >> 5] &= ~(1 << (nr & 31)); }", "target": 0, "idx": 103111, "project": "Xen"}
{"func": "void tdram_queue_read(td_driver_t *driver, td_request_t treq) { struct tdram_state *prv = (struct tdram_state *)driver->data; intsize= treq.secs * driver->info.sector_size; uint64_t offset= treq.sec * (uint64_t)driver->info.sector_size; memcpy(treq.buf, img + offset, size); td_complete_request(treq, 0); }", "target": 0, "idx": 101094, "project": "Xen"}
{"func": "static void colo_enable_logdirty(libxl__colo_restore_state *crs, libxl__egc *egc) { libxl__domain_create_state *dcs = CONTAINER_OF(crs, *dcs, crs); libxl__colo_restore_checkpoint_state *crcs = crs->crcs;  const uint32_t domid = crs->domid; libxl__logdirty_switch *const lds = &crcs->lds; EGC_GC;  if (xc_shadow_control(CTX->xch, domid, XEN_DOMCTL_SHADOW_OP_ENABLE_LOGDIRTY, NULL, 0, NULL, 0, NULL) < 0) { LOGD(ERROR, domid, \"cannot enable secondary vm's logdirty\"); lds->callback(egc, lds, ERROR_FAIL); return; } if (crs->hvm) { libxl__domain_common_switch_qemu_logdirty(egc, domid, 1, lds); return; } lds->callback(egc, lds, 0); }", "target": 0, "idx": 103411, "project": "Xen"}
{"func": "void print_in_middle(WINDOW *win, int starty, int startx, int width, const char *string, chtype color) {int length, x, y; float temp; if (win == NULL) win = stdscr; getyx(win, y, x); if (startx != 0) x = startx; if (starty != 0) y = starty; if (width == 0) width = 80; length = strlen(string); temp = (width - length) / 2; x = startx + (int)temp; (void) wattrset(win, color); mvwprintw(win, y, x, \"%s\", string); refresh(); }", "target": 0, "idx": 104759, "project": "Xen"}
{"func": "int __init apei_post_unmap_gar(struct acpi_generic_address *reg) { u64 paddr; int rc; if (reg->space_id != ACPI_ADR_SPACE_SYSTEM_MEMORY) return 0; rc = apei_check_gar(reg, &paddr, 0); if (rc) return rc; apei_post_unmap(paddr, reg->bit_width / 8); return 0; }", "target": 0, "idx": 100892, "project": "Xen"}
{"func": "vcpuid_t xg_resume_n_wait(int guest_bitness) { vcpuid_t vcpu; XGTRC(\"E:\\n\"); assert(_domain_is_paused()); if ((vcpu=_vcpu_in_bp()) != -1) {  return vcpu; } XGTRC(\"unpausing domain\\n\"); if (_unpause_domain()) return -1;  _wait_domain_pause();  vcpu = _vcpu_in_bp();  XGTRC(\"X:vcpu:%d\\n\", vcpu); return vcpu; }", "target": 0, "idx": 108619, "project": "Xen"}
{"func": "static int cvtRaster(TIFF* tif, uint32* raster, uint32 width, uint32 height) { uint32 y; tstrip_t strip = 0; tsize_t cc, acc; unsigned char* buf; uint32 rwidth = roundup(width, horizSubSampling); uint32 rheight = roundup(height, vertSubSampling); uint32 nrows = (rowsperstrip > rheight ? rheight : rowsperstrip); uint32 rnrows = roundup(nrows,vertSubSampling); cc = rnrows*rwidth + 2*((rnrows*rwidth) / (horizSubSampling*vertSubSampling)); buf = (unsigned char*)_TIFFmalloc(cc);  for (y = height; (int32) y > 0; y -= nrows) { uint32 nr = (y > nrows ? nrows : y); cvtStrip(buf, raster + (y-1)*width, nr, width); nr = roundup(nr, vertSubSampling); acc = nr*rwidth + 2*((nr*rwidth)/(horizSubSampling*vertSubSampling)); if (!TIFFWriteEncodedStrip(tif, strip++, buf, acc)) { _TIFFfree(buf); return (0); } } _TIFFfree(buf); return (1); }", "target": 1, "idx": 100788, "project": "LibTIFF"}
{"func": "static int x86_compat(xc_interface *xch, uint32_t domid, char *guest_type) { static const struct { char *guest; uint32_tsize; } types[] = { { \"xen-3.0-x86_32p\", 32 }, { \"xen-3.0-x86_64\",64 }, }; DECLARE_DOMCTL; int i,rc; memset(&domctl, 0, sizeof(domctl)); domctl.domain = domid; domctl.cmd= XEN_DOMCTL_set_address_size; for ( i = 0; i < ARRAY_SIZE(types); i++ ) if ( !strcmp(types[i].guest, guest_type) ) domctl.u.address_size.size = types[i].size; if ( domctl.u.address_size.size == 0 )  return 0; xc_dom_printf(xch, \"%s: guest %s, address size %\" PRId32 \"\", __FUNCTION__, guest_type, domctl.u.address_size.size); rc = do_domctl(xch, &domctl); if ( rc != 0 ) xc_dom_printf(xch, \"%s: warning: failed (rc=%d)\", __FUNCTION__, rc); return rc; }", "target": 0, "idx": 107459, "project": "Xen"}
{"func": "static enum intel_mce_type intel_check_mce_type(uint64_t status) { if ( !(status & MCi_STATUS_VAL) ) return intel_mce_invalid; if ( status & MCi_STATUS_PCC ) return intel_mce_fatal;  if ( !(status & MCi_STATUS_UC) ) return intel_mce_corrected; if ( !ser_support ) return intel_mce_fatal; if ( status & MCi_STATUS_S ) { if ( status & MCi_STATUS_AR ) { if ( status & MCi_STATUS_OVER ) return intel_mce_fatal; else return intel_mce_ucr_srar; } else return intel_mce_ucr_srao; } else return intel_mce_ucr_ucna;  return intel_mce_fatal; }", "target": 0, "idx": 104392, "project": "Xen"}
{"func": "static void __init update_fixed_last(unsigned int base, unsigned int end,  mtrr_type type) { last_fixed_start = base; last_fixed_end = end; last_fixed_type = type; }", "target": 0, "idx": 102376, "project": "Xen"}
{"func": "char * libxl__domain_pvcontrol_read(libxl__gc *gc, xs_transaction_t t, uint32_t domid) { const char *shutdown_path; shutdown_path = libxl__domain_pvcontrol_xspath(gc, domid); if (!shutdown_path) return NULL; return libxl__xs_read(gc, t, shutdown_path); }", "target": 0, "idx": 103548, "project": "Xen"}
{"func": "static int libxl__device_disk_from_xs_be(libxl__gc *gc,  const char *be_path,  libxl_device_disk *disk) { libxl_ctx *ctx = libxl__gc_owner(gc); unsigned int len; char *tmp; int rc; libxl_device_disk_init(disk); rc = sscanf(be_path, \"/local/domain/%d/\", &disk->backend_domid); if (rc != 1) { LOG(ERROR, \"Unable to fetch device backend domid from %s\", be_path); goto cleanup; }  tmp = xs_read(ctx->xsh, XBT_NULL, libxl__sprintf(gc, \"%s/params\", be_path), &len); if (tmp && strchr(tmp, ':')) { disk->pdev_path = strdup(strchr(tmp, ':') + 1); free(tmp); } else { disk->pdev_path = tmp; } tmp = libxl__xs_read(gc, XBT_NULL,  libxl__sprintf(gc, \"%s/type\", be_path)); if (!tmp) { LOG(ERROR, \"Missing xenstore node %s/type\", be_path); goto cleanup; } libxl_string_to_backend(ctx, tmp, &(disk->backend)); disk->vdev = xs_read(ctx->xsh, XBT_NULL,  libxl__sprintf(gc, \"%s/dev\", be_path), &len); if (!disk->vdev) { LOG(ERROR, \"Missing xenstore node %s/dev\", be_path); goto cleanup; } tmp = libxl__xs_read(gc, XBT_NULL, libxl__sprintf  (gc, \"%s/removable\", be_path)); if (!tmp) { LOG(ERROR, \"Missing xenstore node %s/removable\", be_path); goto cleanup; } disk->removable = atoi(tmp); tmp = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/mode\", be_path)); if (!tmp) { LOG(ERROR, \"Missing xenstore node %s/mode\", be_path); goto cleanup; } if (!strcmp(tmp, \"w\")) disk->readwrite = 1; else disk->readwrite = 0; tmp = libxl__xs_read(gc, XBT_NULL,  libxl__sprintf(gc, \"%s/device-type\", be_path)); if (!tmp) { LOG(ERROR, \"Missing xenstore node %s/device-type\", be_path); goto cleanup; } disk->is_cdrom = !strcmp(tmp, \"cdrom\"); disk->format = LIBXL_DISK_FORMAT_UNKNOWN; return 0; cleanup: libxl_device_disk_dispose(disk); return ERROR_FAIL; }", "target": 1, "idx": 109387, "project": "Xen"}
{"func": "static inline char * __xconv(uint64_t num) { snprintf(nbuf, nsize, \"%#\" PRIx64 , num); return nbuf; }", "target": 0, "idx": 106791, "project": "Xen"}
{"func": "static void vlapic_reg_write(struct vcpu *v,  unsigned int offset, uint32_t val) { struct vlapic *vlapic = vcpu_vlapic(v); memset(&vlapic->loaded, 0, sizeof(vlapic->loaded)); switch ( offset ) { case APIC_ID: vlapic_set_reg(vlapic, APIC_ID, val); break; case APIC_TASKPRI: vlapic_set_reg(vlapic, APIC_TASKPRI, val & 0xff); break; case APIC_EOI: vlapic_EOI_set(vlapic); break; case APIC_LDR: vlapic_set_reg(vlapic, APIC_LDR, val & APIC_LDR_MASK); break; case APIC_DFR: vlapic_set_reg(vlapic, APIC_DFR, val | 0x0FFFFFFF); break; case APIC_SPIV: vlapic_set_reg(vlapic, APIC_SPIV, val & 0x3ff); if ( !(val & APIC_SPIV_APIC_ENABLED) ) { int i; uint32_t lvt_val; vlapic->hw.disabled |= VLAPIC_SW_DISABLED; for ( i = 0; i < VLAPIC_LVT_NUM; i++ ) { lvt_val = vlapic_get_reg(vlapic, APIC_LVTT + 0x10 * i); vlapic_set_reg(vlapic, APIC_LVTT + 0x10 * i,  lvt_val | APIC_LVT_MASKED); } } else { vlapic->hw.disabled &= ~VLAPIC_SW_DISABLED; pt_may_unmask_irq(vlapic_domain(vlapic), &vlapic->pt); } break; case APIC_ICR: val &= ~(1 << 12);  vlapic_ipi(vlapic, val, vlapic_get_reg(vlapic, APIC_ICR2)); vlapic_set_reg(vlapic, APIC_ICR, val); break; case APIC_ICR2: vlapic_set_reg(vlapic, APIC_ICR2, val & 0xff000000); break; case APIC_LVTT:  if ( vlapic_lvtt_tdt(vlapic) !=  ((val & APIC_TIMER_MODE_MASK) == APIC_TIMER_MODE_TSC_DEADLINE)) { vlapic_set_reg(vlapic, APIC_TMICT, 0); vlapic->hw.tdt_msr = 0; } vlapic->pt.irq = val & APIC_VECTOR_MASK; vlapic_update_timer(vlapic, val, false, vlapic->hw.timer_divisor);  case APIC_LVTTHMR: case APIC_LVTPC: case APIC_LVT0:  case APIC_LVT1:  case APIC_LVTERR:  if ( vlapic_sw_disabled(vlapic) ) val |= APIC_LVT_MASKED; val &= vlapic_lvt_mask[(offset - APIC_LVTT) >> 4]; vlapic_set_reg(vlapic, offset, val); if ( offset == APIC_LVT0 ) { vlapic_adjust_i8259_target(v->domain); pt_may_unmask_irq(v->domain, NULL); } if ( (offset == APIC_LVTT) && !(val & APIC_LVT_MASKED) ) pt_may_unmask_irq(NULL, &vlapic->pt); if ( offset == APIC_LVTPC ) vpmu_lvtpc_update(val); break; case APIC_TMICT: if ( !vlapic_lvtt_oneshot(vlapic) && !vlapic_lvtt_period(vlapic) ) break; vlapic_set_reg(vlapic, APIC_TMICT, val); vlapic_update_timer(vlapic, vlapic_get_reg(vlapic, APIC_LVTT), true, vlapic->hw.timer_divisor); break; case APIC_TDCR: { uint32_t current_divisor = vlapic->hw.timer_divisor; vlapic_set_tdcr(vlapic, val & 0xb); vlapic_update_timer(vlapic, vlapic_get_reg(vlapic, APIC_LVTT), false, current_divisor); HVM_DBG_LOG(DBG_LEVEL_VLAPIC_TIMER, \"timer divisor is %#x\", vlapic->hw.timer_divisor); break; } } }", "target": 0, "idx": 106954, "project": "Xen"}
{"func": "static int copy_node_by_path(libxl__gc *gc, const char *path,  void *fdt, void *pfdt) { int nodeoff, r; const char *name = strrchr(path, '/'); if (!name) return -FDT_ERR_INTERNAL; name++;  nodeoff = fdt_path_offset(pfdt, path); if (nodeoff < 0) return nodeoff; if (strcmp(fdt_get_name(pfdt, nodeoff, NULL), name)) return -FDT_ERR_NOTFOUND; r = copy_node(gc, fdt, pfdt, nodeoff, 0); if (r) return r; return 0; }", "target": 0, "idx": 103308, "project": "Xen"}
{"func": "int kdd_get_regs(kdd_guest *g, int cpuid, kdd_regs *r, int w64) { struct hvm_hw_cpu *cpu;  cpu = get_cpu(g, cpuid); if (!cpu)  return -1; memset(r, 0, sizeof(*r)); if (w64) kdd_get_regs_x86_64(cpu, &r->r64); else kdd_get_regs_x86_32(cpu, &r->r32); return 0; }", "target": 0, "idx": 102919, "project": "Xen"}
{"func": "static int __init early_scan_node(const void *fdt, int node, const char *name, int depth, u32 address_cells, u32 size_cells, void *data) { if ( device_tree_node_matches(fdt, node, \"memory\") ) process_memory_node(fdt, node, name, address_cells, size_cells); else if ( device_tree_node_compatible(fdt, node, \"xen,multiboot-module\" ) || device_tree_node_compatible(fdt, node, \"multiboot,module\" )) process_multiboot_node(fdt, node, name, address_cells, size_cells); else if ( depth == 1 && device_tree_node_matches(fdt, node, \"chosen\") ) process_chosen_node(fdt, node, name, address_cells, size_cells); return 0; }", "target": 0, "idx": 101264, "project": "Xen"}
{"func": "int xc_sched_arinc653_schedule_set( xc_interface *xch, uint32_t cpupool_id, struct xen_sysctl_arinc653_schedule *schedule) { int rc; DECLARE_SYSCTL; DECLARE_HYPERCALL_BOUNCE( schedule, sizeof(*schedule), XC_HYPERCALL_BUFFER_BOUNCE_IN); if ( xc_hypercall_bounce_pre(xch, schedule) ) return -1; sysctl.cmd = XEN_SYSCTL_scheduler_op; sysctl.u.scheduler_op.cpupool_id = cpupool_id; sysctl.u.scheduler_op.sched_id = XEN_SCHEDULER_ARINC653; sysctl.u.scheduler_op.cmd = XEN_SYSCTL_SCHEDOP_putinfo; set_xen_guest_handle(sysctl.u.scheduler_op.u.sched_arinc653.schedule, schedule); rc = do_sysctl(xch, &sysctl); xc_hypercall_bounce_post(xch, schedule); return rc; }", "target": 0, "idx": 107293, "project": "Xen"}
{"func": "void ACPI_INTERNAL_VAR_XFACE __init acpi_ut_info(const char *module_name, u32 line_number, char *format, ...) { va_list args;  acpi_os_printf(\"ACPI: \"); va_start(args, format); acpi_os_vprintf(format, args); acpi_os_printf(\"\\n\"); va_end(args); }", "target": 0, "idx": 106627, "project": "Xen"}
{"func": "void hvm_vmcall_summary(struct hvm_data *h, void *d) { int i; for ( i=0; i<HYPERCALL_MAX ; i++) { PRINT_SUMMARY(h->summary.vmcall[i], \"[%10s] \", hypercall_name[i]); } PRINT_SUMMARY(h->summary.vmcall[HYPERCALL_MAX], \"[%10s] \", \"max\"); }", "target": 0, "idx": 108013, "project": "Xen"}
{"func": " */ static int libxl__device_usbctrl_add_xenstore(libxl__gc *gc, uint32_t domid, libxl_device_usbctrl *usbctrl, bool update_json) { libxl__device *device; flexarray_t *front = NULL; flexarray_t *back; xs_transaction_t t = XBT_NULL; int i, rc; libxl_domain_config d_config; libxl_device_usbctrl usbctrl_saved; libxl__domain_userdata_lock *lock = NULL; libxl_domain_config_init(&d_config); libxl_device_usbctrl_init(&usbctrl_saved); libxl_device_usbctrl_copy(CTX, &usbctrl_saved, usbctrl); GCNEW(device); rc = libxl__device_from_usbctrl(gc, domid, usbctrl, device); if (rc) goto out; back = flexarray_make(gc, 12, 1); if (device->backend_kind != LIBXL__DEVICE_KIND_NONE) { front = flexarray_make(gc, 4, 1); flexarray_append_pair(back, \"frontend-id\", GCSPRINTF(\"%d\", domid)); flexarray_append_pair(back, \"online\", \"1\"); flexarray_append_pair(back, \"state\", GCSPRINTF(\"%d\", XenbusStateInitialising)); flexarray_append_pair(front, \"backend-id\", GCSPRINTF(\"%d\", usbctrl->backend_domid)); flexarray_append_pair(front, \"state\", GCSPRINTF(\"%d\", XenbusStateInitialising)); } flexarray_append_pair(back, \"type\", (char *)libxl_usbctrl_type_to_string(usbctrl->type)); flexarray_append_pair(back, \"usb-ver\", GCSPRINTF(\"%d\", usbctrl->version)); flexarray_append_pair(back, \"num-ports\", GCSPRINTF(\"%d\", usbctrl->ports)); flexarray_append_pair(back, \"port\", \"\"); for (i = 0; i < usbctrl->ports; i++) flexarray_append_pair(back, GCSPRINTF(\"port/%d\", i + 1), \"\"); if (update_json) { lock = libxl__lock_domain_userdata(gc, domid); if (!lock) { rc = ERROR_LOCK_FAIL; goto out; } rc = libxl__get_domain_configuration(gc, domid, &d_config); if (rc) goto out; device_add_domain_config(gc, &d_config, &libxl__usbctrl_devtype,  &usbctrl_saved); rc = libxl__dm_check_start(gc, &d_config, domid); if (rc) goto out; if (usbctrl->type == LIBXL_USBCTRL_TYPE_QUSB) { if (!libxl__query_qemu_backend(gc, domid, usbctrl->backend_domid,  \"qusb\", false)) { LOGD(ERROR, domid, \"backend type not supported by device model\"); rc = ERROR_FAIL; goto out; } } } for (;;) { rc = libxl__xs_transaction_start(gc, &t); if (rc) goto out; rc = libxl__device_exists(gc, t, device); if (rc < 0) goto out; if (rc == 1) {  LOGD(ERROR, domid, \"device already exists in xenstore\"); rc = ERROR_DEVICE_EXISTS; goto out; } if (update_json) { rc = libxl__set_domain_configuration(gc, domid, &d_config); if (rc) goto out; } libxl__device_generic_add(gc, t, device, libxl__xs_kvs_of_flexarray(gc, back), libxl__xs_kvs_of_flexarray(gc, front), NULL); rc = libxl__xs_transaction_commit(gc, &t); if (!rc) break; if (rc < 0) goto out; } out: libxl__xs_transaction_abort(gc, &t); if (lock) libxl__unlock_domain_userdata(lock); libxl_device_usbctrl_dispose(&usbctrl_saved); libxl_domain_config_dispose(&d_config); return rc; }", "target": 0, "idx": 104075, "project": "Xen"}
{"func": "static void check_conf(struct menu *menu) { struct symbol *sym; struct menu *child; if (!menu_is_visible(menu)) return; sym = menu->sym; if (sym && !sym_has_value(sym)) { if (sym_is_changable(sym) || (sym_is_choice(sym) && sym_get_tristate_value(sym) == yes)) { if (input_mode == listnewconfig) { if (sym->name && !sym_is_choice_value(sym)) { printf(\"%s%s\\n\", CONFIG_, sym->name); } } else if (input_mode != olddefconfig) { if (!conf_cnt++) printf(_(\"*\\n* Restart config...\\n*\\n\")); rootEntry = menu_get_parent_menu(menu); conf(rootEntry); } } } for (child = menu->list; child; child = child->next) check_conf(child); }", "target": 0, "idx": 101360, "project": "Xen"}
{"func": "void disable_pmr(struct iommu *iommu) { u32 val; unsigned long flags; val = dmar_readl(iommu->reg, DMAR_PMEN_REG); if ( !(val & DMA_PMEN_PRS) ) return; spin_lock_irqsave(&iommu->register_lock, flags); dmar_writel(iommu->reg, DMAR_PMEN_REG, val & ~DMA_PMEN_EPM); IOMMU_WAIT_OP(iommu, DMAR_PMEN_REG, dmar_readl, !(val & DMA_PMEN_PRS), val); spin_unlock_irqrestore(&iommu->register_lock, flags); dprintk(XENLOG_INFO VTDPREFIX, \"Disabled protected memory registers\\n\"); }", "target": 0, "idx": 106621, "project": "Xen"}
{"func": "static bool location_is_valid(struct source_location *loc) { return loc->file_name != NULL; }", "target": 0, "idx": 106520, "project": "Xen"}
{"func": " ignored, and data is read from file handle into temporary buffer. */ static int INIT start_bunzip(struct bunzip_data **bdp, void *inbuf, int len,  int (*fill)(void*, unsigned int)) { struct bunzip_data *bd; unsigned int i, j, c; const unsigned int BZh0 = (((unsigned int)'B') << 24)+(((unsigned int)'Z') << 16) +(((unsigned int)'h') << 8)+(unsigned int)'0';  i = sizeof(struct bunzip_data);  bd = *bdp = malloc(i); if (!bd) return RETVAL_OUT_OF_MEMORY; memset(bd, 0, sizeof(struct bunzip_data));  bd->inbuf = inbuf; bd->inbufCount = len; if (fill != NULL) bd->fill = fill; else bd->fill = nofill;  for (i = 0; i < 256; i++) { c = i << 24; for (j = 8; j; j--) c = c&0x80000000 ? (c << 1)^0x04c11db7 : (c << 1); bd->crc32Table[i] = c; }  i = get_bits(bd, 32); if (((unsigned int)(i-BZh0-1)) >= 9) return RETVAL_NOT_BZIP_DATA;  bd->dbufSize = 100000*(i-BZh0); bd->dbuf = large_malloc(bd->dbufSize * sizeof(int)); if (!bd->dbuf) return RETVAL_OUT_OF_MEMORY; return RETVAL_OK; }", "target": 0, "idx": 101297, "project": "Xen"}
{"func": "static inline void unlock_bat(struct vhd_state *s) { clear_vhd_flag(s->bat.status, VHD_FLAG_BAT_LOCKED); }", "target": 0, "idx": 101193, "project": "Xen"}
{"func": "struct symbol *sym_lookup(const char *name, int flags) { struct symbol *symbol; char *new_name; int hash; if (name) { if (name[0] && !name[1]) { switch (name[0]) { case 'y': return &symbol_yes; case 'm': return &symbol_mod; case 'n': return &symbol_no; } } hash = strhash(name) % SYMBOL_HASHSIZE; for (symbol = symbol_hash[hash]; symbol; symbol = symbol->next) { if (symbol->name && !strcmp(symbol->name, name) && (flags ? symbol->flags & flags  : !(symbol->flags & (SYMBOL_CONST|SYMBOL_CHOICE)))) return symbol; } new_name = strdup(name); } else { new_name = NULL; hash = 0; } symbol = xmalloc(sizeof(*symbol)); memset(symbol, 0, sizeof(*symbol)); symbol->name = new_name; symbol->type = S_UNKNOWN; symbol->flags |= flags; symbol->next = symbol_hash[hash]; symbol_hash[hash] = symbol; return symbol; }", "target": 0, "idx": 105916, "project": "Xen"}
{"func": "int shadow_enable(struct domain *d, u32 mode) { unsigned int old_pages; struct page_info *pg = NULL; uint32_t *e; int i, rv = 0; struct p2m_domain *p2m = p2m_get_hostp2m(d); mode |= PG_SH_enable; domain_pause(d);  if ( (d == current->domain) ||  shadow_mode_enabled(d) ||  ((mode & PG_translate) && !(mode & PG_refcounts)) ||  ((mode & PG_external) && !(mode & PG_translate)) ) { rv = -EINVAL; goto out_unlocked; }  old_pages = d->arch.paging.shadow.total_pages; if ( old_pages == 0 ) { unsigned int r; paging_lock(d); r = sh_set_allocation(d, 1024, NULL);  if ( r != 0 ) { sh_set_allocation(d, 0, NULL); rv = -ENOMEM; goto out_locked; } paging_unlock(d); }  d->arch.paging.alloc_page = shadow_alloc_p2m_page; d->arch.paging.free_page = shadow_free_p2m_page;  if ( mode & PG_translate ) { rv = p2m_alloc_table(p2m); if (rv != 0) goto out_unlocked; }  if ( is_hvm_domain(d) ) {  pg = shadow_alloc_p2m_page(d); if ( pg == NULL ) { rv = -ENOMEM; goto out_unlocked; }    e = __map_domain_page(pg); for ( i = 0; i < PAGE_SIZE / sizeof(*e); i++ ) e[i] = ((0x400000U * i) | _PAGE_PRESENT | _PAGE_RW | _PAGE_USER  | _PAGE_ACCESSED | _PAGE_DIRTY | _PAGE_PSE); sh_unmap_domain_page(e); pg->u.inuse.type_info = PGT_l2_page_table | 1 | PGT_validated; } paging_lock(d);  if ( shadow_mode_enabled(d) ) { rv = -EINVAL; goto out_locked; }  if ( shadow_hash_alloc(d) != 0 ) { rv = -ENOMEM; goto out_locked; } #if (SHADOW_OPTIMIZATIONS & SHOPT_LINUX_L3_TOPLEVEL)   d->arch.paging.shadow.opt_flags = SHOPT_LINUX_L3_TOPLEVEL; #endif  if ( is_hvm_domain(d) ) d->arch.paging.shadow.unpaged_pagetable = pagetable_from_page(pg);  sh_new_mode(d, mode);  out_locked: paging_unlock(d);  out_unlocked: if ( rv != 0 && !pagetable_is_null(p2m_get_pagetable(p2m)) ) p2m_teardown(p2m); if ( rv != 0 && pg != NULL ) shadow_free_p2m_page(d, pg); domain_unpause(d); return rv; }", "target": 1, "idx": 109564, "project": "Xen"}
{"func": "static void swapBytesInScanline(void *buf, uint32 width, TIFFDataType dtype) { switch (dtype) { case TIFF_SHORT: case TIFF_SSHORT: TIFFSwabArrayOfShort((uint16*)buf,  (unsigned long)width); break; case TIFF_LONG: case TIFF_SLONG: TIFFSwabArrayOfLong((uint32*)buf, (unsigned long)width); break;  case TIFF_DOUBLE: TIFFSwabArrayOfDouble((double*)buf, (unsigned long)width); break; default: break; } }", "target": 0, "idx": 100052, "project": "LibTIFF"}
{"func": "LPSTR FAR FindDIBBits(LPSTR lpDIB) {  return (lpDIB + *(LPDWORD)lpDIB + PaletteSize(lpDIB)); }", "target": 0, "idx": 100379, "project": "LibTIFF"}
{"func": "void talloc_show_parents(const void *context, FILE *file) { struct talloc_chunk *tc; if (context == NULL) { fprintf(file, \"talloc no parents for NULL\\n\"); return; } tc = talloc_chunk_from_ptr(context); fprintf(file, \"talloc parents of '%s'\\n\", talloc_get_name(context)); while (tc) { fprintf(file, \"\\t'%s'\\n\", talloc_get_name(TC_PTR_FROM_CHUNK(tc))); while (tc && tc->prev) tc = tc->prev; tc = tc->parent; } }", "target": 0, "idx": 105985, "project": "Xen"}
{"func": "static tmsize_t  t2pReadFile(TIFF *tif, tdata_t data, tmsize_t size) { thandle_t client = TIFFClientdata(tif); TIFFReadWriteProc proc = TIFFGetReadProc(tif); if (proc) return proc(client, data, size); return -1; }", "target": 0, "idx": 100666, "project": "LibTIFF"}
{"func": "static void tapdisk_vbd_pull_ring_requests(td_vbd_t *vbd) { int idx; RING_IDX rp, rc; td_ring_t *ring; blkif_request_t *req; td_vbd_request_t *vreq; ring = &vbd->ring; if (!ring->sring) return; rp = ring->fe_ring.sring->req_prod; xen_rmb(); for (rc = ring->fe_ring.req_cons; rc != rp; rc++) { req = RING_GET_REQUEST(&ring->fe_ring, rc); ++ring->fe_ring.req_cons; idx= req->id; vreq = &vbd->request_list[idx]; ASSERT(list_empty(&vreq->next)); ASSERT(vreq->secs_pending == 0); memcpy(&vreq->req, req, sizeof(blkif_request_t)); vbd->received++; vreq->vbd = vbd; tapdisk_vbd_move_request(vreq, &vbd->new_requests); DBG(TLOG_DBG, \"%s: request %d \\n\", vbd->name, idx); } }", "target": 1, "idx": 109323, "project": "Xen"}
{"func": "struct hashtab *hashtab_create(u32 (*hash_value)(struct hashtab *h,  const void *key), int (*keycmp)(struct hashtab *h, const void *key1, const void *key2), u32 size) { struct hashtab *p = xzalloc(struct hashtab); if ( p == NULL ) return p; p->size = size; p->hash_value = hash_value; p->keycmp = keycmp; p->htable = xzalloc_array(struct hashtab_node *, size); if ( p->htable == NULL ) { xfree(p); return NULL; } return p; }", "target": 0, "idx": 102631, "project": "Xen"}
{"func": "static void send_IPI_self_x2apic(uint8_t vector) { apic_wrmsr(APIC_SELF_IPI, vector); }", "target": 0, "idx": 107271, "project": "Xen"}
{"func": "int main_cpupoolcpuadd(int argc, char **argv) { int opt; const char *pool; uint32_t poolid; libxl_bitmap cpumap; int rc = EXIT_FAILURE; SWITCH_FOREACH_OPT(opt, \"\", NULL, \"cpupool-cpu-add\", 2) {  } libxl_bitmap_init(&cpumap); if (libxl_cpu_bitmap_alloc(ctx, &cpumap, 0)) { fprintf(stderr, \"Unable to allocate cpumap\"); return EXIT_FAILURE; } pool = argv[optind++]; if (parse_cpurange(argv[optind], &cpumap)) goto out; if (libxl_cpupool_qualifier_to_cpupoolid(ctx, pool, &poolid, NULL) || !libxl_cpupoolid_is_valid(ctx, poolid)) { fprintf(stderr, \"unknown cpupool \\'%s\\'\\n\", pool); goto out; } if (libxl_cpupool_cpuadd_cpumap(ctx, poolid, &cpumap)) fprintf(stderr, \"some cpus may not have been added to %s\\n\", pool); rc = EXIT_SUCCESS; out: libxl_bitmap_dispose(&cpumap); return rc; }", "target": 0, "idx": 108664, "project": "Xen"}
{"func": "static inline uint32_t readl_gich(int unsigned offset) { return readl_relaxed(gicv2.map_hbase + offset); }", "target": 0, "idx": 102437, "project": "Xen"}
{"func": "static void colo_preresume_cb(libxl__egc *egc, libxl__checkpoint_devices_state *cds, int rc) { libxl__colo_save_state *css = cds->concrete_data; libxl__domain_save_state *dss = CONTAINER_OF(css, *dss, css); EGC_GC; if (rc) { LOGD(ERROR, dss->domid, \"preresume fails\"); goto out; } if (css->qdisk_used && !css->qdisk_setuped) { if (libxl__qmp_start_replication(gc, dss->domid, true)) { LOGD(ERROR, dss->domid, \"starting replication fails\"); goto out; } css->qdisk_setuped = true; } if (!css->paused) { if (libxl__qmp_colo_do_checkpoint(gc, dss->domid)) { LOGD(ERROR, dss->domid, \"doing checkpoint fails\"); goto out; } }  if (libxl__domain_resume(gc, dss->domid, 1)) { LOGD(ERROR, dss->domid, \"cannot resume primary vm\"); goto out; }  if (css->paused) { rc = libxl_domain_unpause(CTX, dss->domid); if (rc) { LOGD(ERROR, dss->domid, \"cannot unpause primary vm\"); goto out; } css->paused = false; }  css->callback = colo_read_svm_resumed_done; css->srs.checkpoint_callback = colo_common_read_stream_done; libxl__stream_read_checkpoint_state(egc, &css->srs); return; out: libxl__xc_domain_saverestore_async_callback_done(egc, &dss->sws.shs, 0); }", "target": 0, "idx": 103446, "project": "Xen"}
{"func": "void grant_table_init_vcpu(struct vcpu *v) { v->maptrack_head = MAPTRACK_TAIL; v->maptrack_tail = MAPTRACK_TAIL; }", "target": 1, "idx": 109491, "project": "Xen"}
{"func": "void interval_callback(void) {  switch(opt.interval.mode) { case INTERVAL_MODE_LIST: case INTERVAL_MODE_ARRAY: interval_table_output(); return; default: break; } switch(opt.interval.output) { case INTERVAL_CR3_SCHEDULE_ORDERED: interval_cr3_schedule_ordered_output(); break; case INTERVAL_CR3_SHORT_SUMMARY: interval_cr3_short_summary_output(); break; case INTERVAL_DOMAIN_SHORT_SUMMARY: interval_domain_short_summary_output(); break; case INTERVAL_DOMAIN_GUEST_INTERRUPT: interval_domain_guest_interrupt_output(); break; case INTERVAL_DOMAIN_GRANT_MAPS: interval_domain_grant_maps_output(); break; default: break; } }", "target": 0, "idx": 108019, "project": "Xen"}
{"func": "void *talloc_reference(const void *context, const void *ptr) { struct talloc_chunk *tc; struct talloc_reference_handle *handle; if (ptr == NULL) return NULL; tc = talloc_chunk_from_ptr(ptr); handle = talloc_named_const(context, sizeof(*handle), TALLOC_MAGIC_REFERENCE); if (handle == NULL) return NULL;  talloc_set_destructor(handle, talloc_reference_destructor); handle->ptr = discard_const_p(void, ptr); _TLIST_ADD(tc->refs, handle); return handle->ptr; }", "target": 0, "idx": 105974, "project": "Xen"}
{"func": "TPM_RC TPM2_RSA_ENCRYPT(TPMI_DH_OBJECT keyHandle, TPM2B_PUBLIC_KEY_RSA *message, TPMT_RSA_DECRYPT *inScheme, TPM2B_DATA *label, TPM2B_PUBLIC_KEY_RSA *outData) { TPM_BEGIN(TPM_ST_NO_SESSIONS, TPM_CC_RSA_Encrypt); ptr = pack_UINT32(ptr, keyHandle); ptr = pack_TPM2B_PUBLIC_KEY_RSA(ptr, message); ptr = pack_TPMT_RSA_DECRYPT(ptr, inScheme); ptr = pack_TPM2B_DATA(ptr, label); TPM_TRANSMIT(); TPM_UNPACK_VERIFY(); if (outData != NULL) unpack_TPM2B_PUBLIC_KEY_RSA(ptr, outData); abort_egress: return status; }", "target": 0, "idx": 106484, "project": "Xen"}
{"func": "static int __put_final_page_type( struct page_info *page, unsigned long type, int preemptible) { int rc = free_page_type(page, type, preemptible);  if ( rc == 0 ) {  if ( !(shadow_mode_enabled(page_get_owner(page)) &&  (page->count_info & PGC_page_table)) ) page->tlbflush_timestamp = tlbflush_current_time(); wmb(); page->u.inuse.type_info--; } else if ( rc == -EINTR ) { ASSERT((page->u.inuse.type_info & (PGT_count_mask|PGT_validated|PGT_partial)) == 1); if ( !(shadow_mode_enabled(page_get_owner(page)) &&  (page->count_info & PGC_page_table)) ) page->tlbflush_timestamp = tlbflush_current_time(); wmb(); page->u.inuse.type_info |= PGT_validated; } else { BUG_ON(rc != -ERESTART); wmb(); get_page_light(page); page->u.inuse.type_info |= PGT_partial; } return rc; }", "target": 1, "idx": 109546, "project": "Xen"}
{"func": "void acpi_dmar_reinstate(void) { uint32_t sig = 0x52414d44;  if ( dmar_table ) write_atomic((uint32_t*)&dmar_table->signature[0], sig); }", "target": 0, "idx": 101730, "project": "Xen"}
{"func": "int __init apei_pre_map_gar(struct acpi_generic_address *reg) { u64 paddr; void __iomem *vaddr; int rc; if (reg->space_id != ACPI_ADR_SPACE_SYSTEM_MEMORY) return 0; rc = apei_check_gar(reg, &paddr, 0); if (rc) return rc; vaddr = apei_pre_map(paddr, reg->bit_width / 8); if (!vaddr) return -EIO; return 0; }", "target": 0, "idx": 100894, "project": "Xen"}
{"func": "static uint32 checkInkNamesString(TIFF* tif, uint32 slen, const char* s) { TIFFDirectory* td = &tif->tif_dir; uint16 i = td->td_samplesperpixel; if (slen > 0) { const char* ep = s+slen; const char* cp = s; for (; i > 0; i--) { for (; *cp != '\\0'; cp++) if (cp >= ep) goto bad; cp++; } return (cp-s); } bad: TIFFErrorExt(tif->tif_clientdata, \"TIFFSetField\", \"%s: Invalid InkNames value; expecting %d names, found %d\", tif->tif_name, td->td_samplesperpixel, td->td_samplesperpixel-i); return (0); }", "target": 0, "idx": 100570, "project": "LibTIFF"}
{"func": "int INIT lz4_decompress(const unsigned char *src, size_t *src_len, unsigned char *dest, size_t actual_dest_len) { int ret = -1; int input_len = 0; input_len = lz4_uncompress(src, dest, actual_dest_len); if (input_len < 0) goto exit_0; *src_len = input_len; return 0; exit_0: return ret; }", "target": 0, "idx": 101581, "project": "Xen"}
{"func": "void *talloc_check_name(const void *ptr, const char *name) { const char *pname; if (ptr == NULL) return NULL; pname = talloc_get_name(ptr); if (pname == name || strcmp(pname, name) == 0) { return discard_const_p(void, ptr); } return NULL; }", "target": 0, "idx": 105956, "project": "Xen"}
{"func": "static void spawn_fail(libxl__egc *egc, libxl__spawn_state *ss, int rc); void libxl__spawn_init(libxl__spawn_state *ss) { libxl__ev_child_init(&ss->mid); libxl__xswait_init(&ss->xswait); }", "target": 0, "idx": 103679, "project": "Xen"}
{"func": "static int _tiffCloseProc(thandle_t fd) { return (close((int) fd)); }", "target": 0, "idx": 100083, "project": "LibTIFF"}
{"func": " */ voidsetup_ioapic_dest(void) { int pin, ioapic, irq, irq_entry; if (skip_ioapic_setup) return; for (ioapic = 0; ioapic < nr_ioapics; ioapic++) { for (pin = 0; pin < nr_ioapic_entries[ioapic]; pin++) { struct irq_desc *desc; irq_entry = find_irq_entry(ioapic, pin, mp_INT); if (irq_entry == -1) continue; irq = pin_2_irq(irq_entry, ioapic, pin); desc = irq_to_desc(irq); BUG_ON(cpumask_empty(desc->arch.cpu_mask)); set_ioapic_affinity_irq(desc, desc->arch.cpu_mask); } } }", "target": 0, "idx": 102888, "project": "Xen"}
{"func": "int osdep_xenforeignmemory_unmap(xenforeignmemory_handle *fmem,  void *addr, size_t num) { return munmap(addr, num*XC_PAGE_SIZE); }", "target": 0, "idx": 105805, "project": "Xen"}
{"func": " */ int asprintf(char **bufp, const char *fmt, ...) { va_list args; int i; va_start(args, fmt); i=vasprintf(bufp,fmt,args); va_end(args); return i; }", "target": 0, "idx": 107141, "project": "Xen"}
{"func": "static const char *__read_mostly thresh_adj = \"standard\"; static void do_toggle_guest(unsigned char key, struct cpu_user_regs *regs) { if ( upper_thresh_adj == &xenlog_upper_thresh ) { upper_thresh_adj = &xenlog_guest_upper_thresh; lower_thresh_adj = &xenlog_guest_lower_thresh; thresh_adj = \"guest\"; } else { upper_thresh_adj = &xenlog_upper_thresh; lower_thresh_adj = &xenlog_lower_thresh; thresh_adj = \"standard\"; } printk(\"'%c' pressed -> %s log level adjustments enabled\\n\",  key, thresh_adj); }", "target": 0, "idx": 101426, "project": "Xen"}
{"func": "int mem_paging_memop(XEN_GUEST_HANDLE_PARAM(xen_mem_paging_op_t) arg) { int rc; xen_mem_paging_op_t mpo; struct domain *d; bool_t copyback = 0; if ( copy_from_guest(&mpo, arg, 1) ) return -EFAULT; rc = rcu_lock_live_remote_domain_by_id(mpo.domain, &d); if ( rc ) return rc; rc = xsm_mem_paging(XSM_DM_PRIV, d); if ( rc ) goto out; rc = -ENODEV; if ( unlikely(!vm_event_check_ring(d->vm_event_paging)) ) goto out; switch( mpo.op ) { case XENMEM_paging_op_nominate: rc = p2m_mem_paging_nominate(d, mpo.gfn); break; case XENMEM_paging_op_evict: rc = p2m_mem_paging_evict(d, mpo.gfn); break; case XENMEM_paging_op_prep: rc = p2m_mem_paging_prep(d, mpo.gfn, mpo.buffer); if ( !rc ) copyback = 1; break; default: rc = -ENOSYS; break; } if ( copyback && __copy_to_guest(arg, &mpo, 1) ) rc = -EFAULT; out: rcu_unlock_domain(d); return rc; }", "target": 0, "idx": 104454, "project": "Xen"}
{"func": " */ size_t (strlen)(const char * s) { const char *sc; for (sc = s; *sc != '\\0'; ++sc) ; return sc - s; }", "target": 0, "idx": 105867, "project": "Xen"}
{"func": "unsigned long strtoul(const char *nptr, char **endptr, int base) { const char *s; unsigned long acc, cutoff; int c; int neg, any, cutlim;  s = nptr; do { c = (unsigned char) *s++; } while (isspace(c)); if (c == '-') { neg = 1; c = *s++; } else { neg = 0; if (c == '+') c = *s++; } if ((base == 0 || base == 16) && c == '0' && (*s == 'x' || *s == 'X')) { c = s[1]; s += 2; base = 16; } if (base == 0) base = c == '0' ? 8 : 10; cutoff = ULONG_MAX / (unsigned long)base; cutlim = (int)(ULONG_MAX % (unsigned long)base); for (acc = 0, any = 0;; c = (unsigned char) *s++) { if (isdigit(c)) c -= '0'; else if (isalpha(c)) c -= isupper(c) ? 'A' - 10 : 'a' - 10; else break; if (c >= base) break; if (any < 0) continue; if (acc > cutoff || (acc == cutoff && c > cutlim)) { any = -1; acc = ULONG_MAX; errno = ERANGE; } else { any = 1; acc *= (unsigned long)base; acc += c; } } if (neg && any > 0) acc = -acc; if (endptr != 0)  *endptr = (char *)(any ? s - 1 : nptr); return (acc); }", "target": 0, "idx": 100295, "project": "LibTIFF"}
{"func": "static inline void tapdisk_stream_poll_clear(struct tapdisk_stream_poll *p) { int dummy; read_exact(p->pipe[POLL_READ], &dummy, sizeof(dummy)); p->set = 0; }", "target": 0, "idx": 106125, "project": "Xen"}
{"func": "static void pciassignable_list(void) { libxl_device_pci *pcidevs; int num, i; pcidevs = libxl_device_pci_assignable_list(ctx, &num); if ( pcidevs == NULL ) return; for (i = 0; i < num; i++) { printf(\"%04x:%02x:%02x.%01x\\n\",  pcidevs[i].domain, pcidevs[i].bus, pcidevs[i].dev, pcidevs[i].func); libxl_device_pci_dispose(&pcidevs[i]); } free(pcidevs); }", "target": 0, "idx": 108755, "project": "Xen"}
{"func": "static void execute_timer(struct timers *ts, struct timer *t) { void (*fn)(void *) = t->function; void *data = t->data; t->status = TIMER_STATUS_inactive; list_add(&t->inactive, &ts->inactive); ts->running = t; spin_unlock_irq(&ts->lock); (*fn)(data); spin_lock_irq(&ts->lock); ts->running = NULL; }", "target": 0, "idx": 106437, "project": "Xen"}
{"func": "static inline bool_t INIT dict_has_space(const struct dictionary *dict) { return dict->pos < dict->limit; }", "target": 0, "idx": 101598, "project": "Xen"}
{"func": "int xc_vm_event_control(xc_interface *xch, uint32_t domain_id, unsigned int op, unsigned int mode, uint32_t *port) { DECLARE_DOMCTL; int rc; domctl.cmd = XEN_DOMCTL_vm_event_op; domctl.domain = domain_id; domctl.u.vm_event_op.op = op; domctl.u.vm_event_op.mode = mode; rc = do_domctl(xch, &domctl); if ( !rc && port ) *port = domctl.u.vm_event_op.port; return rc; }", "target": 0, "idx": 107826, "project": "Xen"}
{"func": "void hvm_vmentry_process(struct record_info *ri, struct hvm_data *h) { if(!h->init) { if(opt.dump_all) printf(\"!%s vmentry\\n\",  ri->dump_header); return; }  hvm_vlapic_vmentry_cleanup(h->v, ri->tsc); if(h->w2h.waking && opt.dump_all) printf(\" [w2h] d%dv%d Finishing waking\\n\",  h->v->d->did, h->v->vid); h->w2h.waking = 0; if ( h->w2h.interrupts_wanting_tsc ) { int i; for(i=0; i<GUEST_INTERRUPT_MAX; i++) { if ( h->summary.guest_interrupt[i].start_tsc == 1 ) { if(opt.dump_all) printf(\" [w2h] d%dv%d Setting vec %d tsc to %lld\\n\",  h->v->d->did, h->v->vid, i, ri->tsc); h->summary.guest_interrupt[i].start_tsc = ri->tsc; h->w2h.interrupts_wanting_tsc--; if ( h->w2h.interrupts_wanting_tsc == 0 ) break; } } } if(!h->vmexit_valid) { if(opt.dump_all) printf(\"!%s vmentry\\n\",  ri->dump_header); return; } if(opt.dump_all) { unsigned long long arc_cycles = ri->tsc - h->exit_tsc; printf(\"]%s vmentry cycles %lld %s\\n\",  ri->dump_header, arc_cycles, (arc_cycles>10000)?\"!\":\"\"); } hvm_close_vmexit(h, ri->tsc); h->entry_tsc = ri->tsc; } } void hvm_vmentry_process(struct record_info *ri, struct hvm_data *h) { if(!h->init) { if(opt.dump_all) printf(\"!%s vmentry\\n\",  ri->dump_header); return; }  hvm_vlapic_vmentry_cleanup(h->v, ri->tsc); if(h->w2h.waking && opt.dump_all) printf(\" [w2h] d%dv%d Finishing waking\\n\",  h->v->d->did, h->v->vid); h->w2h.waking = 0; if ( h->w2h.interrupts_wanting_tsc ) { int i; for(i=0; i<GUEST_INTERRUPT_MAX; i++) { if ( h->summary.guest_interrupt[i].start_tsc == 1 ) { if(opt.dump_all) printf(\" [w2h] d%dv%d Setting vec %d tsc to %lld\\n\",  h->v->d->did, h->v->vid, i, ri->tsc); h->summary.guest_interrupt[i].start_tsc = ri->tsc; h->w2h.interrupts_wanting_tsc--; if ( h->w2h.interrupts_wanting_tsc == 0 ) break; } } } if(!h->vmexit_valid) { if(opt.dump_all) printf(\"!%s vmentry\\n\",  ri->dump_header); return; } if(opt.dump_all) { unsigned long long arc_cycles = ri->tsc - h->exit_tsc; printf(\"]%s vmentry cycles %lld %s\\n\",  ri->dump_header, arc_cycles, (arc_cycles>10000)?\"!\":\"\"); } hvm_close_vmexit(h, ri->tsc); h->entry_tsc = ri->tsc; }", "target": 0, "idx": 108014, "project": "Xen"}
{"func": "static inline void* dring_advance(struct writelog* wl, void* start, size_t len) { void* next; int dsz = sdataend(wl->shm) - sdatastart(wl->shm); next = start + (len % dsz); if (next > sdataend(wl->shm)) next -= dsz; return next; }", "target": 0, "idx": 106079, "project": "Xen"}
{"func": "int new_guest_cr3(unsigned long mfn) { struct vcpu *curr = current; struct domain *d = curr->domain; int okay; unsigned long old_base_mfn; #ifdef __x86_64__ if ( is_pv_32on64_domain(d) ) { okay = paging_mode_refcounts(d) ? 0  : mod_l4_entry( __va(pagetable_get_paddr(curr->arch.guest_table)), l4e_from_pfn( mfn, (_PAGE_PRESENT|_PAGE_RW|_PAGE_USER|_PAGE_ACCESSED)), pagetable_get_pfn(curr->arch.guest_table), 0, 0, curr) == 0; if ( unlikely(!okay) ) { MEM_LOG(\"Error while installing new compat baseptr %lx\", mfn); return 0; } invalidate_shadow_ldt(curr, 0); write_ptbase(curr); return 1; } #endif okay = paging_mode_refcounts(d) ? get_page_from_pagenr(mfn, d) : !get_page_and_type_from_pagenr(mfn, PGT_root_page_table, d, 0, 0); if ( unlikely(!okay) ) { MEM_LOG(\"Error while installing new baseptr %lx\", mfn); return 0; } invalidate_shadow_ldt(curr, 0); old_base_mfn = pagetable_get_pfn(curr->arch.guest_table); curr->arch.guest_table = pagetable_from_pfn(mfn); update_cr3(curr); write_ptbase(curr); if ( likely(old_base_mfn != 0) ) { if ( paging_mode_refcounts(d) ) put_page(mfn_to_page(old_base_mfn)); else put_page_and_type(mfn_to_page(old_base_mfn)); } return 1; }", "target": 1, "idx": 109095, "project": "Xen"}
{"func": "static struct task_slice a653sched_do_schedule( const struct scheduler *ops, s_time_t now, bool_t tasklet_work_scheduled) { struct task_slice ret; struct vcpu * new_task = NULL; static unsigned int sched_index = 0; static s_time_t next_switch_time; a653sched_priv_t *sched_priv = SCHED_PRIV(ops); const unsigned int cpu = smp_processor_id(); unsigned long flags; spin_lock_irqsave(&sched_priv->lock, flags); if ( sched_priv->num_schedule_entries < 1 ) sched_priv->next_major_frame = now + DEFAULT_TIMESLICE; else if ( now >= sched_priv->next_major_frame ) {   sched_index = 0; sched_priv->next_major_frame = now + sched_priv->major_frame; next_switch_time = now + sched_priv->schedule[0].runtime; } else { while ( (now >= next_switch_time) && (sched_index < sched_priv->num_schedule_entries) ) {  sched_index++; next_switch_time += sched_priv->schedule[sched_index].runtime; } }  if ( sched_index >= sched_priv->num_schedule_entries ) next_switch_time = sched_priv->next_major_frame;  new_task = (sched_index < sched_priv->num_schedule_entries) ? sched_priv->schedule[sched_index].vc : IDLETASK(cpu);  if ( !((new_task != NULL)  && (AVCPU(new_task) != NULL)  && AVCPU(new_task)->awake  && vcpu_runnable(new_task)) ) new_task = IDLETASK(cpu); BUG_ON(new_task == NULL);  BUG_ON(now >= sched_priv->next_major_frame); spin_unlock_irqrestore(&sched_priv->lock, flags);  if ( tasklet_work_scheduled ) new_task = IDLETASK(cpu);  if ( !is_idle_vcpu(new_task)  && (new_task->processor != cpu) ) new_task = IDLETASK(cpu);  ret.time = next_switch_time - now; ret.task = new_task; ret.migrated = 0; BUG_ON(ret.time <= 0); return ret; }", "target": 0, "idx": 105461, "project": "Xen"}
{"func": " */ unsigned long vmalloc_to_pfn(void * vmalloc_addr) { return page_to_pfn(vmalloc_to_page(vmalloc_addr)); }", "target": 0, "idx": 105065, "project": "Xen"}
{"func": "static int cvt_by_strip( TIFF *in, TIFF *out ) { uint32* raster; uint32width, height; uint32row; uint32*wrk_line; intok = 1; TIFFGetField(in, TIFFTAG_IMAGEWIDTH, &width); TIFFGetField(in, TIFFTAG_IMAGELENGTH, &height); if( !TIFFGetField(in, TIFFTAG_ROWSPERSTRIP, &rowsperstrip) ) { TIFFError(TIFFFileName(in), \"Source image not in strips\"); return (0); }  TIFFSetField(out, TIFFTAG_ROWSPERSTRIP, rowsperstrip);  raster = (uint32*)_TIFFmalloc(width * rowsperstrip * sizeof (uint32)); if (raster == 0) { TIFFError(TIFFFileName(in), \"No space for raster buffer\"); return (0); }  wrk_line = (uint32*)_TIFFmalloc(width * sizeof (uint32)); if (!wrk_line) { TIFFError(TIFFFileName(in), \"No space for raster scanline buffer\"); ok = 0; }   for( row = 0; ok && row < height; row += rowsperstrip ) { introws_to_write, i_row;  if (!TIFFReadRGBAStrip(in, row, raster)) { ok = 0; break; }  #if HOST_BIGENDIAN TIFFSwabArrayOfLong(raster, width * rowsperstrip); #endif  if( row + rowsperstrip > height ) rows_to_write = height - row; else rows_to_write = rowsperstrip;  for( i_row = 0; i_row < rows_to_write / 2; i_row++ ) { uint32*top_line, *bottom_line; top_line = raster + width * i_row; bottom_line = raster + width * (rows_to_write-i_row-1); _TIFFmemcpy(wrk_line, top_line, 4*width); _TIFFmemcpy(top_line, bottom_line, 4*width); _TIFFmemcpy(bottom_line, wrk_line, 4*width); }  if( TIFFWriteEncodedStrip( out, row / rowsperstrip, raster,  4 * rows_to_write * width ) == -1 ) { ok = 0; break; } } _TIFFfree( raster ); _TIFFfree( wrk_line ); return ok; }", "target": 1, "idx": 100796, "project": "LibTIFF"}
{"func": "static void finish_bitmap_transaction(struct vhd_state *s, struct vhd_bitmap *bm, int error) { int map_size; struct vhd_transaction *tx = &bm->tx; DBG(TLOG_DBG, \"blk: 0x%04x, err: %d\\n\", bm->blk, error); tx->error = (tx->error ? tx->error : error); map_size= vhd_sectors_to_bytes(s->bm_secs); if (!test_vhd_flag(s->flags, VHD_FLAG_OPEN_PREALLOCATE)) { if (test_vhd_flag(tx->status, VHD_FLAG_TX_UPDATE_BAT)) {  ASSERT(bm->blk == s->bat.pbw_blk); ASSERT(test_vhd_flag(s->bat.status,   VHD_FLAG_BAT_WRITE_STARTED)); s->bat.req.tx = tx; return; } } if (tx->error) {  memcpy(bm->shadow, bm->map, map_size); } else {  memcpy(bm->map, bm->shadow, map_size); if (!test_batmap(s, bm->blk) && bitmap_full(s, bm)) set_batmap(s, bm->blk); }  signal_completion(tx->requests.head, tx->error); init_tx(tx); start_new_bitmap_transaction(s, bm); if (!bitmap_in_use(bm)) unlock_bitmap(bm); finish_bat_transaction(s, bm); }", "target": 0, "idx": 101163, "project": "Xen"}
{"func": "void init_pipe(int reopen_log_pipe[2]) { reopen_log_pipe[0] = -1; reopen_log_pipe[1] = -1; }", "target": 0, "idx": 108439, "project": "Xen"}
{"func": "*/ static int xc_is_page_granted_v1(xc_interface *xch, xen_pfn_t gpfn,  grant_entry_v1_t *gnttab, int gnt_num) { int i = 0; if (!gnttab) return 0; for (i = 0; i < gnt_num; i++) if ( ((gnttab[i].flags & GTF_type_mask) !=GTF_invalid) &&  (gnttab[i].frame == gpfn) )  break;  return (i != gnt_num); }", "target": 0, "idx": 107614, "project": "Xen"}
{"func": "static int ret0(uintptr_t par) { return 0; }", "target": 0, "idx": 108886, "project": "Xen"}
{"func": "int acpi_build_tables(struct acpi_ctxt *ctxt, struct acpi_config *config) { struct acpi_info *acpi_info; struct acpi_20_rsdp *rsdp; struct acpi_20_rsdt *rsdt; struct acpi_20_xsdt *xsdt; struct acpi_fadt*fadt; struct acpi_10_fadt *fadt_10; struct acpi_20_facs *facs; unsigned char *dsdt; unsigned longsecondary_tables[ACPI_MAX_SECONDARY_TABLES]; intnr_secondaries, i; unsigned int fadt_size; acpi_info = (struct acpi_info *)config->infop; memset(acpi_info, 0, sizeof(*acpi_info)); acpi_info->com1_present = !!(config->table_flags & ACPI_HAS_COM1); acpi_info->com2_present = !!(config->table_flags & ACPI_HAS_COM2); acpi_info->lpt1_present = !!(config->table_flags & ACPI_HAS_LPT1); acpi_info->hpet_present = !!(config->table_flags & ACPI_HAS_HPET); acpi_info->pci_min = config->pci_start; acpi_info->pci_len = config->pci_len; if ( config->pci_hi_len ) { acpi_info->pci_hi_min = config->pci_hi_start; acpi_info->pci_hi_len = config->pci_hi_len; }  facs = ctxt->mem_ops.alloc(ctxt, sizeof(struct acpi_20_facs), 16); if (!facs) goto oom; memcpy(facs, &Facs, sizeof(struct acpi_20_facs));  if ( config->hvminfo->nr_vcpus <= 15 && config->dsdt_15cpu) { dsdt = ctxt->mem_ops.alloc(ctxt, config->dsdt_15cpu_len, 16); if (!dsdt) goto oom; memcpy(dsdt, config->dsdt_15cpu, config->dsdt_15cpu_len); } else { dsdt = ctxt->mem_ops.alloc(ctxt, config->dsdt_anycpu_len, 16); if (!dsdt) goto oom; memcpy(dsdt, config->dsdt_anycpu, config->dsdt_anycpu_len); }  fadt_10 = ctxt->mem_ops.alloc(ctxt, sizeof(struct acpi_10_fadt), 16); if (!fadt_10) goto oom; memcpy(fadt_10, &Fadt, sizeof(struct acpi_10_fadt)); fadt_10->header.length = sizeof(struct acpi_10_fadt); fadt_10->header.revision = ACPI_1_0_FADT_REVISION; fadt_10->dsdt= ctxt->mem_ops.v2p(ctxt, dsdt); fadt_10->firmware_ctrl = ctxt->mem_ops.v2p(ctxt, facs); set_checksum(fadt_10,  offsetof(struct acpi_header, checksum),  sizeof(struct acpi_10_fadt)); switch ( config->acpi_revision ) { case 4:  fadt_size = offsetof(struct acpi_fadt, sleep_control); break; case 5: fadt_size = sizeof(*fadt); break; default: printf(\"ACPI revision %u not supported\\n\", config->acpi_revision); return -1; } fadt = ctxt->mem_ops.alloc(ctxt, fadt_size, 16); if (!fadt) goto oom; if ( !(config->table_flags & ACPI_HAS_PMTIMER) ) { Fadt.pm_tmr_blk = Fadt.pm_tmr_len = 0; memset(&Fadt.x_pm_tmr_blk, 0, sizeof(Fadt.x_pm_tmr_blk)); } if ( !(config->table_flags & ACPI_HAS_BUTTONS) ) Fadt.flags |= (ACPI_PWR_BUTTON | ACPI_SLP_BUTTON); memcpy(fadt, &Fadt, fadt_size);  fadt->header.revision = config->acpi_revision; fadt->header.length = fadt_size; fadt->dsdt = ctxt->mem_ops.v2p(ctxt, dsdt); fadt->x_dsdt = ctxt->mem_ops.v2p(ctxt, dsdt); fadt->firmware_ctrl = ctxt->mem_ops.v2p(ctxt, facs); fadt->x_firmware_ctrl = ctxt->mem_ops.v2p(ctxt, facs); if ( !(config->table_flags & ACPI_HAS_VGA) ) fadt->iapc_boot_arch |= ACPI_FADT_NO_VGA; if ( config->table_flags & ACPI_HAS_8042 ) fadt->iapc_boot_arch |= ACPI_FADT_8042; if ( !(config->table_flags & ACPI_HAS_CMOS_RTC) ) { if ( fadt->header.revision < 5 ) { printf(\"ACPI_FADT_NO_CMOS_RTC requires FADT revision 5\\n\"); return -1; } fadt->iapc_boot_arch |= ACPI_FADT_NO_CMOS_RTC; } set_checksum(fadt, offsetof(struct acpi_header, checksum), fadt_size); nr_secondaries = construct_secondary_tables(ctxt, secondary_tables,  config, acpi_info); if ( nr_secondaries < 0 ) goto oom; xsdt = ctxt->mem_ops.alloc(ctxt, sizeof(struct acpi_20_xsdt) +   sizeof(uint64_t) * nr_secondaries,  16); if (!xsdt) goto oom; memcpy(xsdt, &Xsdt, sizeof(struct acpi_header)); xsdt->entry[0] = ctxt->mem_ops.v2p(ctxt, fadt); for ( i = 0; secondary_tables[i]; i++ ) xsdt->entry[i+1] = secondary_tables[i]; xsdt->header.length = sizeof(struct acpi_header) + (i+1)*sizeof(uint64_t); set_checksum(xsdt,  offsetof(struct acpi_header, checksum),  xsdt->header.length); rsdt = ctxt->mem_ops.alloc(ctxt, sizeof(struct acpi_20_rsdt) +  sizeof(uint32_t) * nr_secondaries,  16); if (!rsdt) goto oom; memcpy(rsdt, &Rsdt, sizeof(struct acpi_header)); rsdt->entry[0] = ctxt->mem_ops.v2p(ctxt, fadt_10); for ( i = 0; secondary_tables[i]; i++ ) rsdt->entry[i+1] = secondary_tables[i]; rsdt->header.length = sizeof(struct acpi_header) + (i+1)*sizeof(uint32_t); set_checksum(rsdt,  offsetof(struct acpi_header, checksum),  rsdt->header.length);  rsdp = (struct acpi_20_rsdp *)config->rsdp; memcpy(rsdp, &Rsdp, sizeof(struct acpi_20_rsdp)); rsdp->rsdt_address = ctxt->mem_ops.v2p(ctxt, rsdt); rsdp->xsdt_address = ctxt->mem_ops.v2p(ctxt, xsdt); set_checksum(rsdp,  offsetof(struct acpi_10_rsdp, checksum),  sizeof(struct acpi_10_rsdp)); set_checksum(rsdp,  offsetof(struct acpi_20_rsdp, extended_checksum),  sizeof(struct acpi_20_rsdp)); if ( !new_vm_gid(ctxt, config, acpi_info) ) goto oom; return 0; oom: printf(\"unable to build ACPI tables: out of memory\\n\"); return -1; }", "target": 0, "idx": 101283, "project": "Xen"}
{"func": "static void tiffinfo(TIFF* tif, uint16 order, long flags, int is_image) { TIFFPrintDirectory(tif, stdout, flags); if (!readdata || !is_image) return; if (rawdata) { if (order) { uint16 o; TIFFGetFieldDefaulted(tif, TIFFTAG_FILLORDER, &o); TIFFReadRawData(tif, o != order); } else TIFFReadRawData(tif, 0); } else { if (order) TIFFSetField(tif, TIFFTAG_FILLORDER, order); TIFFReadData(tif); } }", "target": 0, "idx": 100513, "project": "LibTIFF"}
{"func": "static struct symbol *sym_check_expr_deps(struct expr *e) { struct symbol *sym; if (!e) return NULL; switch (e->type) { case E_OR: case E_AND: sym = sym_check_expr_deps(e->left.expr); if (sym) return sym; return sym_check_expr_deps(e->right.expr); case E_NOT: return sym_check_expr_deps(e->left.expr); case E_EQUAL: case E_GEQ: case E_GTH: case E_LEQ: case E_LTH: case E_UNEQUAL: sym = sym_check_deps(e->left.sym); if (sym) return sym; return sym_check_deps(e->right.sym); case E_SYMBOL: return sym_check_deps(e->left.sym); default: break; } printf(\"Oops! How to check %d?\\n\", e->type); return NULL; }", "target": 0, "idx": 105902, "project": "Xen"}
{"func": "static void  TIFF_SetSample( unsigned char * pabyData, int nPixelBytes, int nSampleFormat,  double dfValue ) { if( nSampleFormat == SAMPLEFORMAT_UINT && nPixelBytes == 1 ) { *pabyData = (unsigned char) MAX(0,MIN(255,dfValue)); } else if( nSampleFormat == SAMPLEFORMAT_UINT && nPixelBytes == 2 ) { *((uint16 *)pabyData) = (uint16) MAX(0,MIN(65535,dfValue)); } else if( nSampleFormat == SAMPLEFORMAT_UINT && nPixelBytes == 4 ) { *((uint32 *)pabyData) = (uint32) dfValue; } else if( nSampleFormat == SAMPLEFORMAT_INT && nPixelBytes == 2 ) { *((int16 *)pabyData) = (int16) MAX(-32768,MIN(32767,dfValue)); } else if( nSampleFormat == SAMPLEFORMAT_INT && nPixelBytes == 32 ) { *((int32 *)pabyData) = (int32) dfValue; } else if( nSampleFormat == SAMPLEFORMAT_IEEEFP && nPixelBytes == 4 ) { *((float *)pabyData) = (float) dfValue; } else if( nSampleFormat == SAMPLEFORMAT_IEEEFP && nPixelBytes == 8 ) { *((double *)pabyData) = dfValue; } }", "target": 0, "idx": 100233, "project": "LibTIFF"}
{"func": "static uint8_t sector_inuse_map[DISK_MAX_SECTOR]; static int active_slot(const struct mem_tpm_mgr *mgr) { return 1 + mgr->active_root; }", "target": 0, "idx": 101674, "project": "Xen"}
{"func": "static int  writeSelections(TIFF *in, TIFF **out, struct crop_mask *crop,  struct image_data *image, struct dump_opts *dump, struct buffinfo seg_buffs[], char *mp, char *filename,  unsigned int *page, unsigned int total_pages) { int i, page_count; int autoindex = 0; unsigned char *crop_buff = NULL;  switch (crop->exp_mode) { case ONE_FILE_COMPOSITE:   autoindex = 0;  crop_buff = seg_buffs[0].buffer;  if (update_output_file (out, mp, autoindex, filename, page))  return (1);  page_count = total_pages;  if (writeCroppedImage(in, *out, image, dump,  crop->combined_width,   crop->combined_length,  crop_buff, *page, total_pages)) {  TIFFError(\"writeRegions\", \"Unable to write new image\");  return (-1);  }  break; case ONE_FILE_SEPARATED:   autoindex = 0;  if (update_output_file (out, mp, autoindex, filename, page))  return (1);  page_count = crop->selections * total_pages;  for (i = 0; i < crop->selections; i++)  {  crop_buff = seg_buffs[i].buffer;  if (writeCroppedImage(in, *out, image, dump,  crop->regionlist[i].width,   crop->regionlist[i].length,   crop_buff, *page, page_count))  {  TIFFError(\"writeRegions\", \"Unable to write new image\");  return (-1);  }  }  break; case FILE_PER_IMAGE_COMPOSITE:   autoindex = 1;  if (update_output_file (out, mp, autoindex, filename, page))  return (1);  crop_buff = seg_buffs[0].buffer;  if (writeCroppedImage(in, *out, image, dump,  crop->combined_width,   crop->combined_length,   crop_buff, *page, total_pages))  {  TIFFError(\"writeRegions\", \"Unable to write new image\");  return (-1);  }  break; case FILE_PER_IMAGE_SEPARATED:   autoindex = 1;  page_count = crop->selections;  if (update_output_file (out, mp, autoindex, filename, page))  return (1);  for (i = 0; i < crop->selections; i++)  {  crop_buff = seg_buffs[i].buffer;    if (writeCroppedImage(in, *out, image, dump,  crop->regionlist[i].width,   crop->regionlist[i].length,   crop_buff, *page, page_count))  {  TIFFError(\"writeRegions\", \"Unable to write new image\");  return (-1);  }  }  break; case FILE_PER_SELECTION:  autoindex = 1;  page_count = 1;  for (i = 0; i < crop->selections; i++)  {  if (update_output_file (out, mp, autoindex, filename, page))  return (1);  crop_buff = seg_buffs[i].buffer;    if (writeCroppedImage(in, *out, image, dump,  crop->regionlist[i].width,   crop->regionlist[i].length,   crop_buff, *page, page_count))  {  TIFFError(\"writeRegions\", \"Unable to write new image\");  return (-1);  }  }  break; default: return (1); } return (0); } ", "target": 0, "idx": 100700, "project": "LibTIFF"}
{"func": "TIFF* TIFFFdOpen(int fd, const char* name, const char* mode) { TIFF* tif; tif = TIFFClientOpen(name, mode, (void*) fd, _tiffReadProc, _tiffWriteProc, _tiffSeekProc, _tiffCloseProc, _tiffSizeProc, _tiffMapProc, _tiffUnmapProc); if (tif) tif->tif_fd = fd; return (tif); }", "target": 0, "idx": 100590, "project": "LibTIFF"}
{"func": " */ int security_compute_av(u32 ssid, u32 tsid, u16 tclass, u32 requested, struct av_decision *avd) { struct context *scontext = NULL, *tcontext = NULL; int rc = 0; if ( !ss_initialized ) { avd->allowed = 0xffffffff; avd->auditallow = 0; avd->auditdeny = 0xffffffff; avd->seqno = latest_granting; return 0; } POLICY_RDLOCK; scontext = sidtab_search(&sidtab, ssid); if ( !scontext ) { printk(\"security_compute_av:unrecognized SID %d\\n\", ssid); rc = -EINVAL; goto out; } tcontext = sidtab_search(&sidtab, tsid); if ( !tcontext ) { printk(\"security_compute_av:unrecognized SID %d\\n\", tsid); rc = -EINVAL; goto out; } rc = context_struct_compute_av(scontext, tcontext, tclass, requested, avd);  if ( ebitmap_get_bit(&policydb.permissive_map, scontext->type) ) avd->flags |= AVD_FLAGS_PERMISSIVE; out: POLICY_RDUNLOCK; return rc; }", "target": 0, "idx": 105701, "project": "Xen"}
{"func": "static int show_textbox_ext(const char *title, char *text, int r, int c, int *keys, int *vscroll, int *hscroll, update_text_fn update_text, void *data) { dialog_clear(); return dialog_textbox(title, text, r, c, keys, vscroll, hscroll, update_text, data); }", "target": 0, "idx": 104428, "project": "Xen"}
{"func": "void *_talloc_realloc(const void *context, void *ptr, size_t size, const char *name) { struct talloc_chunk *tc; void *new_ptr;  if (size == 0) { talloc_free(ptr); return NULL; } if (size >= MAX_TALLOC_SIZE) { return NULL; }  if (ptr == NULL) { return talloc_named_const(context, size, name); } tc = talloc_chunk_from_ptr(ptr);  if (tc->refs) { return NULL; }  tc->flags |= TALLOC_FLAG_FREE; #if ALWAYS_REALLOC new_ptr = malloc(size + TC_HDR_SIZE); if (new_ptr) { memcpy(new_ptr, tc, tc->size + TC_HDR_SIZE); free(tc); } #else new_ptr = realloc(tc, size + TC_HDR_SIZE); #endif if (!new_ptr) { tc->flags &= ~TALLOC_FLAG_FREE;  return NULL;  } tc = new_ptr; tc->flags &= ~TALLOC_FLAG_FREE;  if (tc->parent) { tc->parent->child = new_ptr; } if (tc->child) { tc->child->parent = new_ptr; } if (tc->prev) { tc->prev->next = tc; } if (tc->next) { tc->next->prev = tc; } tc->size = size; talloc_set_name_const(TC_PTR_FROM_CHUNK(tc), name); return TC_PTR_FROM_CHUNK(tc); }", "target": 0, "idx": 105996, "project": "Xen"}
{"func": " */ int vmce_rdmsr(uint32_t msr, uint64_t *val) { struct vcpu *cur = current; int ret = 1; *val = 0; spin_lock(&cur->arch.vmce.lock); switch ( msr ) { case MSR_IA32_MCG_STATUS: *val = cur->arch.vmce.mcg_status; if ( *val ) mce_printk(MCE_VERBOSE,  \"MCE: %pv: rd MCG_STATUS %#\"PRIx64\"\\n\", cur, *val); break; case MSR_IA32_MCG_CAP: *val = cur->arch.vmce.mcg_cap; mce_printk(MCE_VERBOSE, \"MCE: %pv: rd MCG_CAP %#\"PRIx64\"\\n\", cur, *val); break; case MSR_IA32_MCG_CTL: if ( cur->arch.vmce.mcg_cap & MCG_CTL_P ) *val = ~0ULL; mce_printk(MCE_VERBOSE, \"MCE: %pv: rd MCG_CTL %#\"PRIx64\"\\n\", cur, *val); break; case MSR_IA32_MCG_EXT_CTL:  if ( cur->arch.vmce.mcg_cap & MCG_LMCE_P ) { *val = cur->arch.vmce.mcg_ext_ctl; mce_printk(MCE_VERBOSE, \"MCE: %pv: rd MCG_EXT_CTL %#\"PRIx64\"\\n\",  cur, *val); } else { ret = -1; mce_printk(MCE_VERBOSE, \"MCE: %pv: rd MCG_EXT_CTL, not supported\\n\",  cur); } break; default: ret = mce_bank_msr(cur, msr) ? bank_mce_rdmsr(cur, msr, val) : 0; break; } spin_unlock(&cur->arch.vmce.lock); return ret; }", "target": 0, "idx": 106997, "project": "Xen"}
{"func": "static void usage(void) { printf(\"usage:\\n\\n\"); printf(\"xenpaging [options] -f <pagefile> -d <domain_id>\\n\\n\"); printf(\"options:\\n\"); printf(\" -d <domid> --domain=<domid> numerical domain_id of guest. This option is required.\\n\"); printf(\" -f <file>--pagefile=<file>pagefile to use. This option is required.\\n\"); printf(\" -m <max_memkb> --max_memkb=<max_memkb>maximum amount of memory to handle.\\n\"); printf(\" -r <num> --mru_size=<num> number of paged-in pages to keep in memory.\\n\"); printf(\" -v --verboseenable debug output.\\n\"); printf(\" -h --help this output.\\n\"); }", "target": 0, "idx": 108288, "project": "Xen"}
{"func": "static void qos_update_thread(int cpu, int domid, uint64_t now) { int n, id; uint64_t last_update_time, start; int64_t time_since_update, run_time = 0; id = indexof(domid); n = new_qos->next_datapoint; last_update_time = new_qos->domain_info[id].last_update_time; time_since_update = now - last_update_time; if (time_since_update < 0) {   if (-time_since_update < billion) {   time_since_update = -time_since_update; } else if ( ((~0ULL - last_update_time) < billion) && (now < billion) ) {    time_since_update = now + (~0ULL - last_update_time); printf(\"time wraparound\\n\"); } else {   return; } } new_qos->domain_info[id].last_update_time = now; if (new_qos->domain_info[id].runnable_at_last_update && is_current(domid, cpu)) { start = new_qos->domain_info[id].start_time; if (start > now) { run_time = now + (~0ULL - start);    } else run_time = now - start;   new_qos->domain_info[id].ns_oncpu_since_boot += run_time; new_qos->domain_info[id].start_time = now; new_qos->domain_info[id].ns_since_boot += time_since_update; new_qos->qdata[n].ns_gotten[id] += run_time;   } new_qos->domain_info[id].runnable_at_last_update = domain_runnable(domid); update_blocked_time(domid, now);  if (now >= new_qos->qdata[n].timestamp) {  new_qos->qdata[n].ns_passed += (now - new_qos->qdata[n].timestamp); } else {    } new_qos->qdata[n].timestamp = now; }", "target": 0, "idx": 108166, "project": "Xen"}
{"func": "static void stream_done(libxl__egc *egc, libxl__stream_write_state *stream, int rc) { assert(stream->running); assert(!stream->in_checkpoint_state); stream->running = false; if (stream->emu_carefd) libxl__carefd_close(stream->emu_carefd); free(stream->emu_body); if (!stream->back_channel) {   check_all_finished(egc, stream, rc); } }", "target": 0, "idx": 104034, "project": "Xen"}
{"func": "int xc_numainfo(xc_interface *xch, unsigned *max_nodes, xc_meminfo_t *meminfo, uint32_t *distance) { int ret; DECLARE_SYSCTL; DECLARE_HYPERCALL_BOUNCE(meminfo, *max_nodes * sizeof(*meminfo),  XC_HYPERCALL_BUFFER_BOUNCE_OUT); DECLARE_HYPERCALL_BOUNCE(distance,  *max_nodes * *max_nodes * sizeof(*distance),  XC_HYPERCALL_BUFFER_BOUNCE_OUT); if ( (ret = xc_hypercall_bounce_pre(xch, meminfo)) ) goto out; if ((ret = xc_hypercall_bounce_pre(xch, distance)) ) goto out; sysctl.u.numainfo.num_nodes = *max_nodes; set_xen_guest_handle(sysctl.u.numainfo.meminfo, meminfo); set_xen_guest_handle(sysctl.u.numainfo.distance, distance); sysctl.cmd = XEN_SYSCTL_numainfo; if ( (ret = do_sysctl(xch, &sysctl)) != 0 ) goto out; *max_nodes = sysctl.u.numainfo.num_nodes; out: xc_hypercall_bounce_post(xch, meminfo); xc_hypercall_bounce_post(xch, distance); return ret; }", "target": 0, "idx": 107585, "project": "Xen"}
{"func": "static void avc_node_delete(struct avc_node *node) { hlist_del_rcu(&node->list); call_rcu(&node->rhead, avc_node_free); atomic_dec(&avc_cache.active_nodes); }", "target": 0, "idx": 100921, "project": "Xen"}
{"func": "static int reiserfs_mount (fsi_file_t *ffi, const char *options) { struct reiserfs_super_block super; int superblock = REISERFS_DISK_OFFSET_IN_BYTES >> SECTOR_BITS; if (  !devread (ffi, superblock, 0, sizeof (struct reiserfs_super_block),  (char *) &super) || (substring (REISER3FS_SUPER_MAGIC_STRING, super.s_magic) > 0 && substring (REISER2FS_SUPER_MAGIC_STRING, super.s_magic) > 0 && substring (REISERFS_SUPER_MAGIC_STRING, super.s_magic) > 0) || ( super.s_journal_block * super.s_blocksize <= REISERFS_DISK_OFFSET_IN_BYTES)) {  superblock = REISERFS_OLD_DISK_OFFSET_IN_BYTES >> SECTOR_BITS; if (  ! devread (ffi, superblock, 0, sizeof (struct reiserfs_super_block),  (char *) &super)) return 0; if (substring (REISER3FS_SUPER_MAGIC_STRING, super.s_magic) > 0 && substring (REISER2FS_SUPER_MAGIC_STRING, super.s_magic) > 0 && substring (REISERFS_SUPER_MAGIC_STRING, super.s_magic) > 0) {  if (substring (REISERFS_SUPER_MAGIC_STRING,   (char*) ((char *) &super + 20)) > 0) return 0; super.s_blocksize = REISERFS_OLD_BLOCKSIZE; super.s_journal_block = 0; super.s_version = 0; } }  if (super.s_version > REISERFS_MAX_SUPPORTED_VERSION) return 0; INFO->version = super.s_version; INFO->blocksize = super.s_blocksize; INFO->fullblocksize_shift = log2 (super.s_blocksize); INFO->blocksize_shift = INFO->fullblocksize_shift - SECTOR_BITS; INFO->cached_slots =  (FSYSREISER_CACHE_SIZE >> INFO->fullblocksize_shift) - 1; #ifdef REISERDEBUG printf (\"reiserfs_mount: version=%d, blocksize=%d\\n\",  INFO->version, INFO->blocksize); #endif   memset (INFO->blocks, 0, sizeof (INFO->blocks)); if (super.s_blocksize < FSYSREISER_MIN_BLOCKSIZE || super.s_blocksize > FSYSREISER_MAX_BLOCKSIZE || (SECTOR_SIZE << INFO->blocksize_shift) != super.s_blocksize) return 0;  INFO->journal_transactions = 0; if (super.s_journal_block != 0 && super.s_journal_dev == 0) { INFO->journal_block = super.s_journal_block; INFO->journal_block_count = super.s_journal_size; if (is_power_of_two (INFO->journal_block_count)) journal_init (ffi);  block_read (ffi, superblock >> INFO->blocksize_shift,  0, sizeof (struct reiserfs_super_block), (char *) &super); } if (! block_read (ffi, super.s_root_block, 0, INFO->blocksize, (char*) ROOT)) return 0; INFO->tree_depth = BLOCKHEAD (ROOT)->blk_level; #ifdef REISERDEBUG printf (\"root read_in: block=%d, depth=%d\\n\",  super.s_root_block, INFO->tree_depth); #endif  if (INFO->tree_depth >= MAX_HEIGHT) return 0; if (INFO->tree_depth == DISK_LEAF_NODE_LEVEL) {  memcpy (LEAF, ROOT, INFO->blocksize); } return 1; }", "target": 0, "idx": 102156, "project": "Xen"}
{"func": "static xc_interface *xch; void show_help(void) { fprintf(stderr, \"xen-hptool: Xen CPU/memory hotplug tool\\n\" \"Usage: xen-hptool <command> [args]\\n\" \"Commands:\\n\" \"help display this help\\n\" \"cpu-online<cpuid>online CPU <cpuid>\\n\" \"cpu-offline <cpuid>offline CPU <cpuid>\\n\" \"mem-online<mfn>online MEMORY <mfn>\\n\" \"mem-offline <mfn>offline MEMORY <mfn>\\n\" \"mem-status<mfn>query Memory status<mfn>\\n\"  ); }", "target": 0, "idx": 107861, "project": "Xen"}
{"func": "int libxl_domain_set_nodeaffinity(libxl_ctx *ctx, uint32_t domid, libxl_bitmap *nodemap) { GC_INIT(ctx); if (xc_domain_node_setaffinity(ctx->xch, domid, nodemap->map)) { LOGED(ERROR, domid, \"Setting node affinity\"); GC_FREE; return ERROR_FAIL; } GC_FREE; return 0; }", "target": 0, "idx": 103972, "project": "Xen"}
{"func": "static void * rt_alloc_domdata(const struct scheduler *ops, struct domain *dom) { unsigned long flags; struct rt_dom *sdom; struct rt_private * prv = rt_priv(ops); sdom = xzalloc(struct rt_dom); if ( sdom == NULL ) return ERR_PTR(-ENOMEM); INIT_LIST_HEAD(&sdom->sdom_elem); sdom->dom = dom;  spin_lock_irqsave(&prv->lock, flags); list_add_tail(&sdom->sdom_elem, &(prv->sdom)); spin_unlock_irqrestore(&prv->lock, flags); return sdom; }", "target": 0, "idx": 105621, "project": "Xen"}
{"func": "void tlog_flush(void) { int fd, flags; size_t size, wsize; if (!tapdisk_log.buf) return; flags = O_CREAT | O_WRONLY | O_DIRECT | O_NONBLOCK; if (!tapdisk_log.append) flags |= O_TRUNC; fd = open(tapdisk_log.file, flags, 0644); if (fd == -1) return; if (tapdisk_log.append) if (lseek(fd, 0, SEEK_END) == (off_t)-1) goto out; tlog_flush_errors(); size= tapdisk_log.p - tapdisk_log.buf; wsize = ((size + 511) & (~511)); memset(tapdisk_log.buf + size, '\\n', wsize - size); write_exact(fd, tapdisk_log.buf, wsize); tapdisk_log.p = tapdisk_log.buf; out: close(fd); }", "target": 0, "idx": 106173, "project": "Xen"}
{"func": "static elf_negerrnoval xc_dom_parse_elf_kernel(struct xc_dom_image *dom) { struct elf_binary *elf; elf_negerrnoval rc; rc = check_elf_kernel(dom, 1); if ( rc != 0 ) return rc; elf = xc_dom_malloc(dom, sizeof(*elf)); if ( elf == NULL ) return -ENOMEM; dom->private_loader = elf; rc = elf_init(elf, dom->kernel_blob, dom->kernel_size) != 0 ? -EINVAL : 0; xc_elf_set_logfile(dom->xch, elf, 1); if ( rc != 0 ) { xc_dom_panic(dom->xch, XC_INVALID_KERNEL, \"%s: corrupted ELF image\",  __FUNCTION__); return rc; }  if ( ELF_PTRVAL_INVALID(elf->sec_strtab) ) { xc_dom_panic(dom->xch, XC_INVALID_KERNEL, \"%s: ELF image\"  \" has no shstrtab\", __FUNCTION__); rc = -EINVAL; goto out; }  elf_parse_binary(elf); if ( elf_xen_parse(elf, &dom->parms) != 0 ) { rc = -EINVAL; goto out; } if ( elf_xen_feature_get(XENFEAT_dom0, dom->parms.f_required) ) { xc_dom_panic(dom->xch, XC_INVALID_KERNEL, \"%s: Kernel does not\"  \" support unprivileged (DomU) operation\", __FUNCTION__); rc = -EINVAL; goto out; }  dom->kernel_seg.vstart = dom->parms.virt_kstart; dom->kernel_seg.vend = dom->parms.virt_kend; dom->guest_type = xc_dom_guest_type(dom, elf); if ( dom->guest_type == NULL ) return -EINVAL; DOMPRINTF(\"%s: %s: 0x%\" PRIx64 \" -> 0x%\" PRIx64 \"\", __FUNCTION__, dom->guest_type, dom->kernel_seg.vstart, dom->kernel_seg.vend); rc = 0; out: if ( elf_check_broken(elf) ) DOMPRINTF(\"%s: ELF broken: %s\", __FUNCTION__, elf_check_broken(elf)); return rc; }", "target": 0, "idx": 107420, "project": "Xen"}
{"func": "int TPM_disk_nvread(void *buf, size_t bufsiz, be32_t nvram_slot, struct tpm_authdata auth) {  memset(buf, 0, bufsiz); return 0; }", "target": 0, "idx": 101703, "project": "Xen"}
{"func": "static DECLARE_MUTEX_LOCKED(kbd_sem); static void kbd_thread(void *p) { kbd_dev = init_kbdfront(NULL, 1); up(&kbd_sem); }", "target": 0, "idx": 104571, "project": "Xen"}
{"func": "void parse_disk_config(XLU_Config **config, const char *spec,  libxl_device_disk *disk) { parse_disk_config_multistring(config, 1, &spec, disk); }", "target": 0, "idx": 108730, "project": "Xen"}
{"func": "int xc_monitor_emulate_each_rep(xc_interface *xch, uint32_t domain_id, bool enable) { DECLARE_DOMCTL; domctl.cmd = XEN_DOMCTL_monitor_op; domctl.domain = domain_id; domctl.u.monitor_op.op = XEN_DOMCTL_MONITOR_OP_EMULATE_EACH_REP; domctl.u.monitor_op.event = enable; return do_domctl(xch, &domctl); }", "target": 0, "idx": 107598, "project": "Xen"}
{"func": "static int _vhd_open(td_driver_t *driver, const char *name, td_flag_t flags) { vhd_flag_t vhd_flags = 0; if (flags & TD_OPEN_RDONLY) vhd_flags |= VHD_FLAG_OPEN_RDONLY; if (flags & TD_OPEN_QUIET) vhd_flags |= VHD_FLAG_OPEN_QUIET; if (flags & TD_OPEN_STRICT) vhd_flags |= VHD_FLAG_OPEN_STRICT; if (flags & TD_OPEN_QUERY) vhd_flags |= (VHD_FLAG_OPEN_QUERY| VHD_FLAG_OPEN_QUIET| VHD_FLAG_OPEN_RDONLY | VHD_FLAG_OPEN_NO_CACHE);  if (driver->storage != TAPDISK_STORAGE_TYPE_NFS && driver->storage != TAPDISK_STORAGE_TYPE_LVM) vhd_flags |= VHD_FLAG_OPEN_PREALLOCATE; return __vhd_open(driver, name, vhd_flags); }", "target": 0, "idx": 101213, "project": "Xen"}
{"func": "char *xs_control_command(struct xs_handle *h, const char *cmd,  void *data, unsigned int len) { struct iovec iov[2]; iov[0].iov_base = (void *)cmd; iov[0].iov_len = strlen(cmd) + 1; iov[1].iov_base = data; iov[1].iov_len = len; return xs_talkv(h, XBT_NULL, XS_CONTROL, iov, ARRAY_SIZE(iov), NULL); }", "target": 0, "idx": 108922, "project": "Xen"}
{"func": "long do_mmuext_op( XEN_GUEST_HANDLE_PARAM(mmuext_op_t) uops, unsigned int count, XEN_GUEST_HANDLE_PARAM(uint) pdone, unsigned int foreigndom) { struct mmuext_op op; unsigned long type; unsigned int i, done = 0; struct vcpu *curr = current; struct domain *d = curr->domain; struct domain *pg_owner; int okay, rc = put_old_guest_table(curr); if ( unlikely(rc) ) { if ( likely(rc == -ERESTART) ) rc = hypercall_create_continuation(  __HYPERVISOR_mmuext_op, \"hihi\", uops, count, pdone,  foreigndom); return rc; } if ( unlikely(count == MMU_UPDATE_PREEMPTED) &&  likely(guest_handle_is_null(uops)) ) {  return (int)foreigndom; } if ( unlikely(count & MMU_UPDATE_PREEMPTED) ) { count &= ~MMU_UPDATE_PREEMPTED; if ( unlikely(!guest_handle_is_null(pdone)) ) (void)copy_from_guest(&done, pdone, 1); } else perfc_incr(calls_to_mmuext_op); if ( unlikely(!guest_handle_okay(uops, count)) ) return -EFAULT; if ( (pg_owner = get_pg_owner(foreigndom)) == NULL ) return -ESRCH; rc = xsm_mmuext_op(XSM_TARGET, d, pg_owner); if ( rc ) { put_pg_owner(pg_owner); return rc; } for ( i = 0; i < count; i++ ) { if ( curr->arch.old_guest_table || (i && hypercall_preempt_check()) ) { rc = -ERESTART; break; } if ( unlikely(__copy_from_guest(&op, uops, 1) != 0) ) { MEM_LOG(\"Bad __copy_from_guest\"); rc = -EFAULT; break; } okay = 1; switch ( op.cmd ) { case MMUEXT_PIN_L1_TABLE: type = PGT_l1_page_table; goto pin_page; case MMUEXT_PIN_L2_TABLE: type = PGT_l2_page_table; goto pin_page; case MMUEXT_PIN_L3_TABLE: type = PGT_l3_page_table; goto pin_page; case MMUEXT_PIN_L4_TABLE: if ( is_pv_32bit_domain(pg_owner) ) break; type = PGT_l4_page_table; pin_page: { struct page_info *page;  if ( (op.cmd - MMUEXT_PIN_L1_TABLE) > (CONFIG_PAGING_LEVELS - 1) ) break; if ( paging_mode_refcounts(pg_owner) ) break; page = get_page_from_gfn(pg_owner, op.arg1.mfn, NULL, P2M_ALLOC); if ( unlikely(!page) ) { okay = 0; break; } rc = get_page_type_preemptible(page, type); okay = !rc; if ( unlikely(!okay) ) { if ( rc == -EINTR ) rc = -ERESTART; else if ( rc != -ERESTART ) MEM_LOG(\"Error while pinning mfn %lx\", page_to_mfn(page)); if ( page != curr->arch.old_guest_table ) put_page(page); break; } if ( (rc = xsm_memory_pin_page(XSM_HOOK, d, pg_owner, page)) != 0 ) okay = 0; else if ( unlikely(test_and_set_bit(_PGT_pinned, &page->u.inuse.type_info)) ) { MEM_LOG(\"Mfn %lx already pinned\", page_to_mfn(page)); okay = 0; } if ( unlikely(!okay) ) goto pin_drop;  paging_mark_dirty(pg_owner, page_to_mfn(page));  if ( unlikely(pg_owner != d) ) { int drop_ref; spin_lock(&pg_owner->page_alloc_lock); drop_ref = (pg_owner->is_dying && test_and_clear_bit(_PGT_pinned,  &page->u.inuse.type_info)); spin_unlock(&pg_owner->page_alloc_lock); if ( drop_ref ) { pin_drop: if ( type == PGT_l1_page_table ) put_page_and_type(page); else curr->arch.old_guest_table = page; } } break; } case MMUEXT_UNPIN_TABLE: { struct page_info *page; if ( paging_mode_refcounts(pg_owner) ) break; page = get_page_from_gfn(pg_owner, op.arg1.mfn, NULL, P2M_ALLOC); if ( unlikely(!page) ) { okay = 0; MEM_LOG(\"Mfn %lx bad domain\", op.arg1.mfn); break; } if ( !test_and_clear_bit(_PGT_pinned, &page->u.inuse.type_info) ) { okay = 0; put_page(page); MEM_LOG(\"Mfn %lx not pinned\", op.arg1.mfn); break; } switch ( rc = put_page_and_type_preemptible(page) ) { case -EINTR: case -ERESTART: curr->arch.old_guest_table = page; rc = 0; break; default: BUG_ON(rc); break; } put_page(page);  paging_mark_dirty(pg_owner, page_to_mfn(page)); break; } case MMUEXT_NEW_BASEPTR: if ( unlikely(d != pg_owner) ) rc = -EPERM; else if ( unlikely(paging_mode_translate(d)) ) rc = -EINVAL; else rc = new_guest_cr3(op.arg1.mfn); break; case MMUEXT_NEW_USER_BASEPTR: { unsigned long old_mfn; if ( unlikely(d != pg_owner) ) rc = -EPERM; else if ( unlikely(paging_mode_translate(d)) ) rc = -EINVAL; if ( unlikely(rc) ) break; old_mfn = pagetable_get_pfn(curr->arch.guest_table_user);  if ( old_mfn == op.arg1.mfn ) break; if ( op.arg1.mfn != 0 ) { if ( paging_mode_refcounts(d) ) okay = get_page_from_pagenr(op.arg1.mfn, d); else { rc = get_page_and_type_from_pagenr( op.arg1.mfn, PGT_root_page_table, d, 0, 1); okay = !rc; } if ( unlikely(!okay) ) { if ( rc == -EINTR ) rc = -ERESTART; else if ( rc != -ERESTART ) MEM_LOG(\"Error while installing new mfn %lx\", op.arg1.mfn); break; } } curr->arch.guest_table_user = pagetable_from_pfn(op.arg1.mfn); if ( old_mfn != 0 ) { struct page_info *page = mfn_to_page(old_mfn); if ( paging_mode_refcounts(d) ) put_page(page); else switch ( rc = put_page_and_type_preemptible(page) ) { case -EINTR: rc = -ERESTART; case -ERESTART: curr->arch.old_guest_table = page; okay = 0; break; default: BUG_ON(rc); break; } } break; }  case MMUEXT_TLB_FLUSH_LOCAL: if ( likely(d == pg_owner) ) flush_tlb_local(); else rc = -EPERM; break;  case MMUEXT_INVLPG_LOCAL: if ( unlikely(d != pg_owner) ) rc = -EPERM; else if ( !paging_mode_enabled(d) || paging_invlpg(curr, op.arg1.linear_addr) != 0 ) flush_tlb_one_local(op.arg1.linear_addr); break; case MMUEXT_TLB_FLUSH_MULTI: case MMUEXT_INVLPG_MULTI: { cpumask_t pmask; if ( unlikely(d != pg_owner) ) rc = -EPERM; else if ( unlikely(vcpumask_to_pcpumask(d,  guest_handle_to_param(op.arg2.vcpumask,  const_void),  &pmask)) ) rc = -EINVAL; if ( unlikely(rc) ) break; if ( op.cmd == MMUEXT_TLB_FLUSH_MULTI ) flush_tlb_mask(&pmask); else flush_tlb_one_mask(&pmask, op.arg1.linear_addr); break; } case MMUEXT_TLB_FLUSH_ALL: if ( likely(d == pg_owner) ) flush_tlb_mask(d->domain_dirty_cpumask); else rc = -EPERM; break;  case MMUEXT_INVLPG_ALL: if ( likely(d == pg_owner) ) flush_tlb_one_mask(d->domain_dirty_cpumask, op.arg1.linear_addr); else rc = -EPERM; break; case MMUEXT_FLUSH_CACHE: if ( unlikely(d != pg_owner) ) rc = -EPERM; else if ( unlikely(!cache_flush_permitted(d)) ) { MEM_LOG(\"Non-physdev domain tried to FLUSH_CACHE.\"); rc = -EACCES; } else { wbinvd(); } break; case MMUEXT_FLUSH_CACHE_GLOBAL: if ( unlikely(d != pg_owner) ) rc = -EPERM; else if ( likely(cache_flush_permitted(d)) ) { unsigned int cpu; cpumask_t mask; cpumask_clear(&mask); for_each_online_cpu(cpu) if ( !cpumask_intersects(&mask,  per_cpu(cpu_sibling_mask, cpu)) ) cpumask_set_cpu(cpu, &mask); flush_mask(&mask, FLUSH_CACHE); } else { MEM_LOG(\"Non-physdev domain tried to FLUSH_CACHE_GLOBAL\"); okay = 0; } break; case MMUEXT_SET_LDT: { unsigned long ptr= op.arg1.linear_addr; unsigned long ents = op.arg2.nr_ents; if ( unlikely(d != pg_owner) ) rc = -EPERM; else if ( paging_mode_external(d) ) { MEM_LOG(\"ignoring SET_LDT hypercall from external domain\"); okay = 0; } else if ( ((ptr & (PAGE_SIZE - 1)) != 0) || !__addr_ok(ptr) || (ents > 8192) ) { okay = 0; MEM_LOG(\"Bad args to SET_LDT: ptr=%lx, ents=%lx\", ptr, ents); } else if ( (curr->arch.pv_vcpu.ldt_ents != ents) || (curr->arch.pv_vcpu.ldt_base != ptr) ) { invalidate_shadow_ldt(curr, 0); flush_tlb_local(); curr->arch.pv_vcpu.ldt_base = ptr; curr->arch.pv_vcpu.ldt_ents = ents; load_LDT(curr); } break; } case MMUEXT_CLEAR_PAGE: { struct page_info *page; page = get_page_from_gfn(pg_owner, op.arg1.mfn, NULL, P2M_ALLOC); if ( !page || !get_page_type(page, PGT_writable_page) ) { if ( page ) put_page(page); MEM_LOG(\"Error while clearing mfn %lx\", op.arg1.mfn); okay = 0; break; }  paging_mark_dirty(pg_owner, page_to_mfn(page)); clear_domain_page(page_to_mfn(page)); put_page_and_type(page); break; } case MMUEXT_COPY_PAGE: { struct page_info *src_page, *dst_page; src_page = get_page_from_gfn(pg_owner, op.arg2.src_mfn, NULL,  P2M_ALLOC); if ( unlikely(!src_page) ) { okay = 0; MEM_LOG(\"Error while copying from mfn %lx\", op.arg2.src_mfn); break; } dst_page = get_page_from_gfn(pg_owner, op.arg1.mfn, NULL,  P2M_ALLOC); okay = (dst_page && get_page_type(dst_page, PGT_writable_page)); if ( unlikely(!okay) ) { put_page(src_page); if ( dst_page ) put_page(dst_page); MEM_LOG(\"Error while copying to mfn %lx\", op.arg1.mfn); break; }  paging_mark_dirty(pg_owner, page_to_mfn(dst_page)); copy_domain_page(page_to_mfn(dst_page), page_to_mfn(src_page)); put_page_and_type(dst_page); put_page(src_page); break; } case MMUEXT_MARK_SUPER: { unsigned long mfn = op.arg1.mfn; if ( unlikely(d != pg_owner) ) rc = -EPERM; else if ( mfn & (L1_PAGETABLE_ENTRIES-1) ) { MEM_LOG(\"Unaligned superpage reference mfn %lx\", mfn); okay = 0; } else if ( !opt_allow_superpage ) { MEM_LOG(\"Superpages disallowed\"); rc = -ENOSYS; } else rc = mark_superpage(mfn_to_spage(mfn), d); break; } case MMUEXT_UNMARK_SUPER: { unsigned long mfn = op.arg1.mfn; if ( unlikely(d != pg_owner) ) rc = -EPERM; else if ( mfn & (L1_PAGETABLE_ENTRIES-1) ) { MEM_LOG(\"Unaligned superpage reference mfn %lx\", mfn); okay = 0; } else if ( !opt_allow_superpage ) { MEM_LOG(\"Superpages disallowed\"); rc = -ENOSYS; } else rc = unmark_superpage(mfn_to_spage(mfn)); break; } default: MEM_LOG(\"Invalid extended pt command %#x\", op.cmd); rc = -ENOSYS; break; } if ( unlikely(!okay) && !rc ) rc = -EINVAL; if ( unlikely(rc) ) break; guest_handle_add_offset(uops, 1); } if ( rc == -ERESTART ) { ASSERT(i < count); rc = hypercall_create_continuation( __HYPERVISOR_mmuext_op, \"hihi\", uops, (count - i) | MMU_UPDATE_PREEMPTED, pdone, foreigndom); } else if ( curr->arch.old_guest_table ) { XEN_GUEST_HANDLE_PARAM(void) null; ASSERT(rc || i == count); set_xen_guest_handle(null, NULL);  rc = hypercall_create_continuation( __HYPERVISOR_mmuext_op, \"hihi\", null, MMU_UPDATE_PREEMPTED, null, rc); } put_pg_owner(pg_owner); perfc_add(num_mmuext_ops, i);  if ( unlikely(!guest_handle_is_null(pdone)) ) { done += i; copy_to_guest(pdone, &done, 1); } return rc; }", "target": 1, "idx": 109537, "project": "Xen"}
{"func": "boolean_param(\"noreboot\", opt_noreboot); static void noreturn maybe_reboot(void) { if ( opt_noreboot ) { printk(\"'noreboot' set - not rebooting.\\n\"); machine_halt(); } else { printk(\"rebooting machine in 5 seconds.\\n\"); watchdog_disable(); machine_restart(5000); } }", "target": 0, "idx": 105757, "project": "Xen"}
{"func": " */ int gicv3_allocate_host_lpi_block(struct domain *d, uint32_t *first_lpi) { uint32_t lpi, lpi_idx; int chunk; int i; spin_lock(&lpi_data.host_lpis_lock); lpi_idx = lpi_data.next_free_lpi % HOST_LPIS_PER_PAGE; chunk = find_unused_host_lpi(lpi_data.next_free_lpi / HOST_LPIS_PER_PAGE,  &lpi_idx); if ( chunk == - 1 ) { lpi_idx = 0; chunk = find_unused_host_lpi(0, &lpi_idx); if ( chunk == -1 ) { spin_unlock(&lpi_data.host_lpis_lock); return -ENOSPC; } }  if ( !lpi_data.host_lpis[chunk] ) { union host_lpi *new_chunk;  new_chunk = alloc_xenheap_page(); if ( !new_chunk ) { spin_unlock(&lpi_data.host_lpis_lock); return -ENOMEM; } for ( i = 0; i < HOST_LPIS_PER_PAGE; i += LPI_BLOCK ) new_chunk[i].dom_id = DOMID_INVALID;  smp_wmb(); lpi_data.host_lpis[chunk] = new_chunk; lpi_idx = 0; } lpi = chunk * HOST_LPIS_PER_PAGE + lpi_idx; for ( i = 0; i < LPI_BLOCK; i++ ) { union host_lpi hlpi;  hlpi.virt_lpi = INVALID_LPI; hlpi.dom_id = d->domain_id; write_u64_atomic(&lpi_data.host_lpis[chunk][lpi_idx + i].data,  hlpi.data);  lpi_data.lpi_property[lpi + i] |= LPI_PROP_ENABLED; } lpi_data.next_free_lpi = lpi + LPI_BLOCK;  spin_unlock(&lpi_data.host_lpis_lock); if ( lpi_data.flags & LPI_PROPTABLE_NEEDS_FLUSHING ) clean_and_invalidate_dcache_va_range(&lpi_data.lpi_property[lpi],  LPI_BLOCK); *first_lpi = lpi + LPI_OFFSET; return 0; }", "target": 0, "idx": 102474, "project": "Xen"}
{"func": "static int TIFFNoDecode(TIFF* tif, const char* method) { const TIFFCodec* c = TIFFFindCODEC(tif->tif_dir.td_compression); if (c) TIFFErrorExt(tif->tif_clientdata, tif->tif_name,  \"%s %s decoding is not implemented\",  c->name, method); else TIFFErrorExt(tif->tif_clientdata, tif->tif_name,  \"Compression scheme %u %s decoding is not implemented\",  tif->tif_dir.td_compression, method); return (-1); }", "target": 0, "idx": 100557, "project": "LibTIFF"}
{"func": "int main(int argc, char* argv[]) { FILE *in; TIFF *out = NULL; TIFFErrorHandler whandler = NULL; int compression_in = COMPRESSION_CCITTFAX3; int compression_out = COMPRESSION_CCITTFAX3; int fillorder_in = FILLORDER_LSB2MSB; int fillorder_out = FILLORDER_LSB2MSB; uint32 group3options_in = 0; uint32 group3options_out = 0; uint32 group4options_in = 0; uint32 group4options_out = 0; uint32 defrowsperstrip = (uint32) 0; uint32 rowsperstrip; int photometric_in = PHOTOMETRIC_MINISWHITE; int photometric_out = PHOTOMETRIC_MINISWHITE; int mode = FAXMODE_CLASSF; int rows; int c; int pn, npages; float resY = 196.0; extern int optind; extern char* optarg; while ((c = getopt(argc, argv, \"R:X:o:1234ABLMPUW5678abcflmprsuvwz?\")) != -1) switch (c) {  case '3': compression_in = COMPRESSION_CCITTFAX3; break; case '4': compression_in = COMPRESSION_CCITTFAX4; break; case 'U': group3options_in |= GROUP3OPT_UNCOMPRESSED; group4options_in |= GROUP4OPT_UNCOMPRESSED; break; case '1': group3options_in &= ~GROUP3OPT_2DENCODING; break; case '2': group3options_in |= GROUP3OPT_2DENCODING; break; case 'P': group3options_in &= ~GROUP3OPT_FILLBITS; break; case 'A': group3options_in |= GROUP3OPT_FILLBITS; break; case 'W': photometric_in = PHOTOMETRIC_MINISWHITE; break; case 'B': photometric_in = PHOTOMETRIC_MINISBLACK; break; case 'L': fillorder_in = FILLORDER_LSB2MSB; break; case 'M': fillorder_in = FILLORDER_MSB2LSB; break; case 'R': resY = (float) atof(optarg); break; case 'X': xsize = (uint32) atoi(optarg); break;  case '7': compression_out = COMPRESSION_CCITTFAX3; break; case '8': compression_out = COMPRESSION_CCITTFAX4; break; case 'u': group3options_out |= GROUP3OPT_UNCOMPRESSED; group4options_out |= GROUP4OPT_UNCOMPRESSED; break; case '5': group3options_out &= ~GROUP3OPT_2DENCODING; break; case '6': group3options_out |= GROUP3OPT_2DENCODING; break; case 'c': mode = FAXMODE_CLASSIC; break; case 'f': mode = FAXMODE_CLASSF; break; case 'm': fillorder_out = FILLORDER_MSB2LSB; break; case 'l': fillorder_out = FILLORDER_LSB2MSB; break; case 'o': out = TIFFOpen(optarg, \"w\"); if (out == NULL) { fprintf(stderr, \"%s: Can not create or open %s\\n\", argv[0], optarg); return EXIT_FAILURE; } break; case 'a': group3options_out |= GROUP3OPT_FILLBITS; break; case 'p': group3options_out &= ~GROUP3OPT_FILLBITS; break; case 'r': defrowsperstrip = atol(optarg); break; case 's': stretch = 1; break; case 'w': photometric_out = PHOTOMETRIC_MINISWHITE; break; case 'b': photometric_out = PHOTOMETRIC_MINISBLACK; break; case 'z': compression_out = COMPRESSION_LZW; break; case 'v': verbose++; break; case '?': usage();  } npages = argc - optind; if (npages < 1) usage(); rowbuf = _TIFFmalloc(TIFFhowmany8(xsize)); refbuf = _TIFFmalloc(TIFFhowmany8(xsize)); if (rowbuf == NULL || refbuf == NULL) { fprintf(stderr, \"%s: Not enough memory\\n\", argv[0]); return (EXIT_FAILURE); } if (out == NULL) { out = TIFFOpen(\"fax.tif\", \"w\"); if (out == NULL) { fprintf(stderr, \"%s: Can not create fax.tif\\n\", argv[0]); return (EXIT_FAILURE); } } faxTIFF = TIFFClientOpen(\"(FakeInput)\", \"w\",   TIFFClientdata(out),  TIFFGetReadProc(out), TIFFGetWriteProc(out),  TIFFGetSeekProc(out), TIFFGetCloseProc(out),  TIFFGetSizeProc(out), TIFFGetMapFileProc(out),  TIFFGetUnmapFileProc(out)); if (faxTIFF == NULL) { fprintf(stderr, \"%s: Can not create fake input file\\n\", argv[0]); return (EXIT_FAILURE); } TIFFSetMode(faxTIFF, O_RDONLY); TIFFSetField(faxTIFF, TIFFTAG_IMAGEWIDTH,xsize); TIFFSetField(faxTIFF, TIFFTAG_SAMPLESPERPIXEL,1); TIFFSetField(faxTIFF, TIFFTAG_BITSPERSAMPLE,1); TIFFSetField(faxTIFF, TIFFTAG_FILLORDER,fillorder_in); TIFFSetField(faxTIFF, TIFFTAG_PLANARCONFIG,PLANARCONFIG_CONTIG); TIFFSetField(faxTIFF, TIFFTAG_PHOTOMETRIC,photometric_in); TIFFSetField(faxTIFF, TIFFTAG_YRESOLUTION,resY); TIFFSetField(faxTIFF, TIFFTAG_RESOLUTIONUNIT,RESUNIT_INCH);  TIFFSetField(faxTIFF, TIFFTAG_COMPRESSION, compression_in); if (compression_in == COMPRESSION_CCITTFAX3) TIFFSetField(faxTIFF, TIFFTAG_GROUP3OPTIONS, group3options_in); else if (compression_in == COMPRESSION_CCITTFAX4) TIFFSetField(faxTIFF, TIFFTAG_GROUP4OPTIONS, group4options_in); for (pn = 0; optind < argc; pn++, optind++) { in = fopen(argv[optind], \"rb\"); if (in == NULL) { fprintf(stderr, \"%s: %s: Can not open\\n\", argv[0], argv[optind]); continue; } #if defined(_WIN32) && defined(USE_WIN32_FILEIO) TIFFSetClientdata(faxTIFF, (thandle_t)_get_osfhandle(fileno(in))); #else TIFFSetClientdata(faxTIFF, (thandle_t)fileno(in)); #endif TIFFSetFileName(faxTIFF, (const char*)argv[optind]); TIFFSetField(out, TIFFTAG_IMAGEWIDTH, xsize); TIFFSetField(out, TIFFTAG_BITSPERSAMPLE, 1); TIFFSetField(out, TIFFTAG_COMPRESSION, compression_out); TIFFSetField(out, TIFFTAG_PHOTOMETRIC, photometric_out); TIFFSetField(out, TIFFTAG_ORIENTATION, ORIENTATION_TOPLEFT); TIFFSetField(out, TIFFTAG_SAMPLESPERPIXEL, 1); switch (compression_out) {  case COMPRESSION_CCITTFAX3: TIFFSetField(out, TIFFTAG_GROUP3OPTIONS,  group3options_out); TIFFSetField(out, TIFFTAG_FAXMODE, mode); rowsperstrip = (defrowsperstrip)?defrowsperstrip:(uint32)-1L; break;  case COMPRESSION_CCITTFAX4: TIFFSetField(out, TIFFTAG_GROUP4OPTIONS,  group4options_out); TIFFSetField(out, TIFFTAG_FAXMODE, mode); rowsperstrip = (defrowsperstrip)?defrowsperstrip:(uint32)-1L; break; default: rowsperstrip = (defrowsperstrip) ? defrowsperstrip : TIFFDefaultStripSize(out, 0); } TIFFSetField(out, TIFFTAG_ROWSPERSTRIP, rowsperstrip); TIFFSetField(out, TIFFTAG_PLANARCONFIG, PLANARCONFIG_CONTIG); TIFFSetField(out, TIFFTAG_FILLORDER, fillorder_out); TIFFSetField(out, TIFFTAG_SOFTWARE, \"fax2tiff\"); TIFFSetField(out, TIFFTAG_XRESOLUTION, 204.0); if (!stretch) { TIFFGetField(faxTIFF, TIFFTAG_YRESOLUTION, &resY); TIFFSetField(out, TIFFTAG_YRESOLUTION, resY); } else TIFFSetField(out, TIFFTAG_YRESOLUTION, 196.); TIFFSetField(out, TIFFTAG_RESOLUTIONUNIT, RESUNIT_INCH); TIFFSetField(out, TIFFTAG_PAGENUMBER, pn, npages); if (!verbose) whandler = TIFFSetWarningHandler(NULL); rows = copyFaxFile(faxTIFF, out); fclose(in); if (!verbose) (void) TIFFSetWarningHandler(whandler); TIFFSetField(out, TIFFTAG_IMAGELENGTH, rows); if (verbose) { fprintf(stderr, \"%s:\\n\", argv[optind]); fprintf(stderr, \"%d rows in input\\n\", rows); fprintf(stderr, \"%ld total bad rows\\n\", (long) badfaxlines); fprintf(stderr, \"%d max consecutive bad rows\\n\", badfaxrun); } if (compression_out == COMPRESSION_CCITTFAX3 && mode == FAXMODE_CLASSF) { TIFFSetField(out, TIFFTAG_BADFAXLINES, badfaxlines); TIFFSetField(out, TIFFTAG_CLEANFAXDATA, badfaxlines ? CLEANFAXDATA_REGENERATED : CLEANFAXDATA_CLEAN); TIFFSetField(out, TIFFTAG_CONSECUTIVEBADFAXLINES, badfaxrun); } TIFFWriteDirectory(out); } TIFFClose(out); _TIFFfree(rowbuf); _TIFFfree(refbuf); return (EXIT_SUCCESS); }", "target": 0, "idx": 100014, "project": "LibTIFF"}
{"func": "unsigned int xenstat_node_num_cpus(xenstat_node * node) { return node->num_cpus; }", "target": 0, "idx": 108377, "project": "Xen"}
{"func": "static void domain_destroy_callback(libxl__egc *egc, libxl__destroy_domid_state *dis, int rc) { STATE_AO_GC(dis->ao); libxl__domain_destroy_state *dds = CONTAINER_OF(dis, *dds, domain); if (rc) { LOGD(ERROR, dis->domid, \"Unable to destroy guest\"); dds->rc = rc; } dds->domain_finished = 1; destroy_finish_check(egc, dds); }", "target": 0, "idx": 103522, "project": "Xen"}
{"func": "static int xen_oldmem_pfn_is_ram(unsigned long pfn) { struct xen_hvm_get_mem_type a; int ret; a.domid = DOMID_SELF; a.pfn = pfn; if (HYPERVISOR_hvm_op(HVMOP_get_mem_type, &a)) return -ENXIO; switch (a.mem_type) { case HVMMEM_mmio_dm: ret = 0; break; case HVMMEM_ram_rw: case HVMMEM_ram_ro: default: ret = 1; break; } return ret; }", "target": 0, "idx": 105077, "project": "Xen"}
{"func": " */ static int enable_qmp_capabilities(libxl__qmp_handler *qmp) { return qmp_send(qmp, \"qmp_capabilities\", NULL, qmp_capabilities_callback, NULL, NULL); }", "target": 0, "idx": 103860, "project": "Xen"}
{"func": "void *talloc_init(const char *fmt, ...) { va_list ap; void *ptr; talloc_enable_null_tracking(); ptr = _talloc(NULL, 0); if (ptr == NULL) return NULL; va_start(ap, fmt); talloc_set_name_v(ptr, fmt, ap); va_end(ap); return ptr; }", "target": 0, "idx": 105968, "project": "Xen"}
{"func": "static int vhd_write_parent_locators(vhd_context_t *ctx, const char *parent) { int i, err; off_t off; uint32_t code; code = PLAT_CODE_NONE; if (ctx->footer.type != HD_TYPE_DIFF) return -EINVAL; off = ctx->batmap.header.batmap_offset +  vhd_sectors_to_bytes(ctx->batmap.header.batmap_size); if (off & (VHD_SECTOR_SIZE - 1)) off = vhd_bytes_padded(off); for (i = 0; i < 3; i++) { switch (i) { case 0: code = PLAT_CODE_MACX; break; case 1: code = PLAT_CODE_W2KU; break; case 2: code = PLAT_CODE_W2RU; break; } err = vhd_parent_locator_write_at(ctx, parent, off, code, 0, ctx->header.loc + i); if (err) return err; off += vhd_parent_locator_size(ctx->header.loc + i); } return 0; }", "target": 0, "idx": 103198, "project": "Xen"}
{"func": "int nvmx_vmresume(struct vcpu *v, struct cpu_user_regs *regs) { struct nestedvmx *nvmx = &vcpu_2_nvmx(v); struct nestedvcpu *nvcpu = &vcpu_nestedhvm(v); int rc; rc = vmx_inst_check_privilege(regs, 0); if ( rc != X86EMUL_OKAY ) return rc;  if ( (nvcpu->nv_vvmcxaddr != VMCX_EADDR) && ((nvmx->iobitmap[0] && nvmx->iobitmap[1]) || !(__n2_exec_control(v) & CPU_BASED_ACTIVATE_IO_BITMAP) ) ) nvcpu->nv_vmentry_pending = 1; else vmreturn(regs, VMFAIL_INVALID); return X86EMUL_OKAY; }", "target": 1, "idx": 109141, "project": "Xen"}
{"func": "static elf_negerrnoval check_elf_kernel(struct xc_dom_image *dom, bool verbose) { if ( dom->kernel_blob == NULL ) { if ( verbose ) xc_dom_panic(dom->xch, XC_INTERNAL_ERROR,  \"%s: no kernel image loaded\", __func__); return -EINVAL; } if ( !elf_is_elfbinary(dom->kernel_blob, dom->kernel_size) ) { if ( verbose ) xc_dom_panic(dom->xch, XC_INVALID_KERNEL,  \"%s: kernel is not an ELF image\", __func__); return -EINVAL; } return 0; }", "target": 0, "idx": 107423, "project": "Xen"}
{"func": "static char *uptime_to_string(unsigned long uptime, int short_mode) { int sec, min, hour, day; char *time_string; day = (int)(uptime / 86400); uptime -= (day * 86400); hour = (int)(uptime / 3600); uptime -= (hour * 3600); min = (int)(uptime / 60); uptime -= (min * 60); sec = uptime; if (short_mode) if (day > 1) xasprintf(&time_string, \"%d days, %2d:%02d\", day, hour, min); else if (day == 1) xasprintf(&time_string, \"%d day, %2d:%02d\", day, hour, min); else xasprintf(&time_string, \"%2d:%02d\", hour, min); else if (day > 1) xasprintf(&time_string, \"%d days, %2d:%02d:%02d\", day, hour, min, sec); else if (day == 1) xasprintf(&time_string, \"%d day, %2d:%02d:%02d\", day, hour, min, sec); else xasprintf(&time_string, \"%2d:%02d:%02d\", hour, min, sec); return time_string; }", "target": 0, "idx": 108694, "project": "Xen"}
{"func": "static int tmemc_list_global_perf(tmem_cli_va_param_t buf, int off, uint32_t len, bool use_long) { char info[BSIZE]; int n = 0, sum = 0; n = scnprintf(info+n,BSIZE-n,\"T=\"); n--;  n += scnprintf(info+n,BSIZE-n,\"\\n\"); if ( sum + n >= len ) return sum; if ( !copy_to_guest_offset(buf, off + sum, info, n + 1) ) sum += n; return sum; }", "target": 0, "idx": 106458, "project": "Xen"}
{"func": "int hvm_msr_write_intercept(unsigned int msr, uint64_t msr_content, bool_t may_defer) { struct vcpu *v = current; bool_t mtrr; unsigned int edx, index; int ret = X86EMUL_OKAY; struct arch_domain *currad = &current->domain->arch; HVMTRACE_3D(MSR_WRITE, msr,  (uint32_t)msr_content, (uint32_t)(msr_content >> 32)); hvm_cpuid(1, NULL, NULL, NULL, &edx); mtrr = !!(edx & cpufeat_mask(X86_FEATURE_MTRR)); if ( may_defer && unlikely(currad->monitor.mov_to_msr_enabled) ) { ASSERT(currad->event_write_data != NULL);  currad->event_write_data[v->vcpu_id].do_write.msr = 1; currad->event_write_data[v->vcpu_id].msr = msr; currad->event_write_data[v->vcpu_id].value = msr_content; hvm_event_msr(msr, msr_content); return X86EMUL_OKAY; } switch ( msr ) { case MSR_EFER: if ( hvm_set_efer(msr_content) )  return X86EMUL_EXCEPTION; break; case MSR_IA32_TSC: hvm_set_guest_tsc(v, msr_content); break; case MSR_IA32_TSC_ADJUST: hvm_set_guest_tsc_adjust(v, msr_content); break; case MSR_TSC_AUX: v->arch.hvm_vcpu.msr_tsc_aux = (uint32_t)msr_content; if ( cpu_has_rdtscp  && (v->domain->arch.tsc_mode != TSC_MODE_PVRDTSCP) ) wrmsrl(MSR_TSC_AUX, (uint32_t)msr_content); break; case MSR_IA32_APICBASE: if ( unlikely(is_pvh_vcpu(v)) ||  !vlapic_msr_set(vcpu_vlapic(v), msr_content) ) goto gp_fault; break; case MSR_IA32_TSC_DEADLINE: vlapic_tdt_msr_set(vcpu_vlapic(v), msr_content); break; case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0x3ff: if ( hvm_x2apic_msr_write(v, msr, msr_content) ) goto gp_fault; break; case MSR_IA32_CR_PAT: if ( !hvm_set_guest_pat(v, msr_content) )  goto gp_fault; break; case MSR_MTRRcap: if ( !mtrr ) goto gp_fault; goto gp_fault; case MSR_MTRRdefType: if ( !mtrr ) goto gp_fault; if ( !mtrr_def_type_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr, msr_content) )  goto gp_fault; break; case MSR_MTRRfix64K_00000: if ( !mtrr ) goto gp_fault; if ( !mtrr_fix_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr, 0,  msr_content) ) goto gp_fault; break; case MSR_MTRRfix16K_80000: case MSR_MTRRfix16K_A0000: if ( !mtrr ) goto gp_fault; index = msr - MSR_MTRRfix16K_80000 + 1; if ( !mtrr_fix_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,  index, msr_content) ) goto gp_fault; break; case MSR_MTRRfix4K_C0000...MSR_MTRRfix4K_F8000: if ( !mtrr ) goto gp_fault; index = msr - MSR_MTRRfix4K_C0000 + 3; if ( !mtrr_fix_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,  index, msr_content) ) goto gp_fault; break; case MSR_IA32_MTRR_PHYSBASE(0)...MSR_IA32_MTRR_PHYSMASK(MTRR_VCNT-1): if ( !mtrr ) goto gp_fault; if ( !mtrr_var_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,  msr, msr_content) ) goto gp_fault; break; case MSR_AMD64_NB_CFG:  break; default: if ( (ret = vmce_wrmsr(msr, msr_content)) < 0 ) goto gp_fault;  ret = ((ret == 0)  ? hvm_funcs.msr_write_intercept(msr, msr_content)  : X86EMUL_OKAY); break; } return ret; gp_fault: hvm_inject_hw_exception(TRAP_gp_fault, 0); return X86EMUL_EXCEPTION; }", "target": 1, "idx": 109630, "project": "Xen"}
{"func": "static void text_insert_msg(const char *title, const char *message) { GtkTextBuffer *buffer; GtkTextIter start, end; const char *msg = message; buffer = gtk_text_view_get_buffer(GTK_TEXT_VIEW(text_w)); gtk_text_buffer_get_bounds(buffer, &start, &end); gtk_text_buffer_delete(buffer, &start, &end); gtk_text_view_set_left_margin(GTK_TEXT_VIEW(text_w), 15); gtk_text_buffer_get_end_iter(buffer, &end); gtk_text_buffer_insert_with_tags(buffer, &end, title, -1, tag1,  NULL); gtk_text_buffer_insert_at_cursor(buffer, \"\\n\\n\", 2); gtk_text_buffer_get_end_iter(buffer, &end); gtk_text_buffer_insert_with_tags(buffer, &end, msg, -1, tag2,  NULL); }", "target": 0, "idx": 102315, "project": "Xen"}
{"func": "static bool_t __initdata cmdline_apic; void __init generic_bigsmp_probe(void) {  if (!cmdline_apic && genapic == &apic_default) if (apic_bigsmp.probe()) { genapic = &apic_bigsmp; printk(KERN_INFO \"Overriding APIC driver with %s\\n\",  genapic->name); } }", "target": 0, "idx": 105165, "project": "Xen"}
{"func": "void interval_table_tail(void) { struct interval_list *p; printf(\"time\"); for(p=P.interval.list.head; p; p = p->next) printf(\" %s\", p->desc); printf(\"\\n\"); }", "target": 0, "idx": 108034, "project": "Xen"}
{"func": "static uint64_t slot_size = 0; int init_vtpmblk(struct tpmfront_dev* tpmfront_dev) {  struct blkfront_info blkinfo;  info(\"Initializing persistent NVM storage\\n\");  if((blkdev = init_blkfront(NULL, &blkinfo)) == NULL) { error(\"BLKIO: ERROR Unable to initialize blkfront\"); return -1;  }  if (blkinfo.info & VDISK_READONLY || blkinfo.mode != O_RDWR) { error(\"BLKIO: ERROR block device is read only!\"); goto error;  }  if((blkfront_fd = blkfront_open(blkdev)) == -1) { error(\"Unable to open blkfront file descriptor!\"); goto error;  }  slot_size = blkinfo.sectors * blkinfo.sector_size / 2;  return 0; error:  shutdown_blkfront(blkdev);  blkdev = NULL;  return -1; }", "target": 0, "idx": 107194, "project": "Xen"}
{"func": "static int _domain_is_paused(void) { memset(&domctl.u, 0, sizeof(domctl.u)); if (_domctl_hcall(XEN_DOMCTL_getdomaininfo, NULL, 0)) { XGERR(\"ERROR: Unable to get domain paused info:%d\\n\", _dom_id); return 0; }  return (domctl.u.getdomaininfo.flags & XEN_DOMINF_paused); }", "target": 0, "idx": 108631, "project": "Xen"}
{"func": " */ static int common_index(void *key, void *datum, void *datap) { return 0; }", "target": 0, "idx": 105112, "project": "Xen"}
{"func": "static int role_index(void *key, void *datum, void *datap) { struct policydb *p; struct role_datum *role; role = datum; p = datap; if ( !role->value  || role->value > p->p_roles.nprim  || role->bounds > p->p_roles.nprim ) return -EINVAL; p->p_role_val_to_name[role->value - 1] = key; p->role_val_to_struct[role->value - 1] = role; return 0; }", "target": 0, "idx": 105134, "project": "Xen"}
{"func": "void TIFFWarning(const char* module, const char* fmt, ...) { va_list ap; va_start(ap, fmt); if (_TIFFwarningHandler) (*_TIFFwarningHandler)(module, fmt, ap); if (_TIFFwarningHandlerExt) (*_TIFFwarningHandlerExt)(0, module, fmt, ap); va_end(ap); }", "target": 0, "idx": 100334, "project": "LibTIFF"}
{"func": "static bool vtimer_emulate_cp32(struct cpu_user_regs *regs, union hsr hsr) { struct hsr_cp32 cp32 = hsr.cp32; if ( cp32.read ) perfc_incr(vtimer_cp32_reads); else perfc_incr(vtimer_cp32_writes); switch ( hsr.bits & HSR_CP32_REGS_MASK ) { case HSR_CPREG32(CNTP_CTL): return vreg_emulate_cp32(regs, hsr, vtimer_cntp_ctl); case HSR_CPREG32(CNTP_TVAL): return vreg_emulate_cp32(regs, hsr, vtimer_cntp_tval); default: return false; } }", "target": 0, "idx": 107173, "project": "Xen"}
{"func": "static void amd_xc_cpuid_policy(xc_interface *xch, const struct cpuid_domain_info *info, const unsigned int *input, unsigned int *regs) { switch ( input[0] ) { case 0x00000002: case 0x00000004: regs[0] = regs[1] = regs[2] = 0; break; case 0x80000000: if ( regs[0] > DEF_MAX_AMDEXT ) regs[0] = DEF_MAX_AMDEXT; break; case 0x80000008:  regs[2] = ((regs[2] + (1u << 12)) & 0xf000u) | ((regs[2] & 0xffu) << 1) | 1u; break; case 0x8000000a: { if ( !info->nestedhvm ) { regs[0] = regs[1] = regs[2] = regs[3] = 0; break; } #define SVM_FEATURE_NPT0x00000001  #define SVM_FEATURE_LBRV 0x00000002  #define SVM_FEATURE_SVML 0x00000004  #define SVM_FEATURE_NRIPS0x00000008  #define SVM_FEATURE_TSCRATEMSR 0x00000010  #define SVM_FEATURE_VMCBCLEAN0x00000020  #define SVM_FEATURE_FLUSHBYASID0x00000040  #define SVM_FEATURE_DECODEASSISTS0x00000080  #define SVM_FEATURE_PAUSEFILTER0x00000400   regs[3] &= (SVM_FEATURE_NPT | SVM_FEATURE_LBRV | \\ SVM_FEATURE_NRIPS | SVM_FEATURE_PAUSEFILTER | \\ SVM_FEATURE_DECODEASSISTS);  regs[3] |= SVM_FEATURE_VMCBCLEAN | SVM_FEATURE_TSCRATEMSR; break; } } } } static void amd_xc_cpuid_policy(xc_interface *xch, const struct cpuid_domain_info *info, const unsigned int *input, unsigned int *regs) { switch ( input[0] ) { case 0x00000002: case 0x00000004: regs[0] = regs[1] = regs[2] = 0; break; case 0x80000000: if ( regs[0] > DEF_MAX_AMDEXT ) regs[0] = DEF_MAX_AMDEXT; break; case 0x80000008:  regs[2] = ((regs[2] + (1u << 12)) & 0xf000u) | ((regs[2] & 0xffu) << 1) | 1u; break; case 0x8000000a: { if ( !info->nestedhvm ) { regs[0] = regs[1] = regs[2] = regs[3] = 0; break; } #define SVM_FEATURE_NPT0x00000001  #define SVM_FEATURE_LBRV 0x00000002  #define SVM_FEATURE_SVML 0x00000004  #define SVM_FEATURE_NRIPS0x00000008  #define SVM_FEATURE_TSCRATEMSR 0x00000010  #define SVM_FEATURE_VMCBCLEAN0x00000020  #define SVM_FEATURE_FLUSHBYASID0x00000040  #define SVM_FEATURE_DECODEASSISTS0x00000080  #define SVM_FEATURE_PAUSEFILTER0x00000400   regs[3] &= (SVM_FEATURE_NPT | SVM_FEATURE_LBRV | \\ SVM_FEATURE_NRIPS | SVM_FEATURE_PAUSEFILTER | \\ SVM_FEATURE_DECODEASSISTS);  regs[3] |= SVM_FEATURE_VMCBCLEAN | SVM_FEATURE_TSCRATEMSR; break; } }", "target": 0, "idx": 107332, "project": "Xen"}
{"func": "static struct symbol *sym_calc_choice(struct symbol *sym) { struct symbol *def_sym; struct property *prop; struct expr *e; int flags;  flags = sym->flags; prop = sym_get_choice_prop(sym); expr_list_for_each_sym(prop->expr, e, def_sym) { sym_calc_visibility(def_sym); if (def_sym->visible != no) flags &= def_sym->flags; } sym->flags &= flags | ~SYMBOL_DEF_USER;  def_sym = sym->def[S_DEF_USER].val; if (def_sym && def_sym->visible != no) return def_sym; def_sym = sym_choice_default(sym); if (def_sym == NULL)  sym->curr.tri = no; return def_sym; }", "target": 0, "idx": 105897, "project": "Xen"}
{"func": "void tdqcow_queue_write(td_driver_t *driver, td_request_t treq) { struct tdqcow_state *s= (struct tdqcow_state *)driver->data; int ret = 0, index_in_cluster, n, i; uint64_t cluster_offset, sector, nb_sectors; td_callback_t cb; struct qcow_prv* prv; char* buf = treq.buf; td_request_t clone=treq; sector = treq.sec; nb_sectors = treq.secs;  while (nb_sectors > 0) { index_in_cluster = sector & (s->cluster_sectors - 1); n = s->cluster_sectors - index_in_cluster; if (n > nb_sectors) n = nb_sectors; if (s->aio_free_count == 0) { td_complete_request(treq, -EBUSY); return; } cluster_offset = get_cluster_offset(s, sector << 9, 1, 0, index_in_cluster,  index_in_cluster+n); if (!cluster_offset) { DPRINTF(\"Ooops, no write cluster offset!\\n\"); td_complete_request(treq, -EIO); return; } if (s->crypt_method) { encrypt_sectors(s, sector, s->cluster_data,  (unsigned char *)buf, n, 1, &s->aes_encrypt_key); clone.buf= buf; clone.sec= (cluster_offset>>9) + index_in_cluster; clone.secs = n; async_write(driver, clone); } else { clone.buf= buf; clone.sec= (cluster_offset>>9) + index_in_cluster; clone.secs = n; async_write(driver, clone); } nb_sectors -= n; sector += n; buf += n * 512; } s->cluster_cache_offset = -1;  return; }", "target": 0, "idx": 101087, "project": "Xen"}
{"func": "int sha256_verify(const struct hash256 *targ, const void *data, size_t size) { struct hash256 hash; sha256(&hash, data, size); return verify_256(&hash, targ); }", "target": 0, "idx": 101669, "project": "Xen"}
{"func": "int x86_emulate( struct x86_emulate_ctxt *ctxt, const struct x86_emulate_ops*ops) {  struct cpu_user_regs _regs = *ctxt->regs; uint8_t b, d, sib, sib_index, sib_base, twobyte = 0, rex_prefix = 0; uint8_t modrm = 0, modrm_mod = 0, modrm_reg = 0, modrm_rm = 0; union vex vex = {}; unsigned int op_bytes, def_op_bytes, ad_bytes, def_ad_bytes; bool_t lock_prefix = 0; int override_seg = -1, rc = X86EMUL_OKAY; struct operand src, dst; enum x86_swint_type swint_type; DECLARE_ALIGNED(mmval_t, mmval);  struct operand ea = { .type = OP_MEM }; ea.mem.seg = x86_seg_ds;  ctxt->retire.byte = 0; op_bytes = def_op_bytes = ad_bytes = def_ad_bytes = ctxt->addr_size/8; if ( op_bytes == 8 ) { op_bytes = def_op_bytes = 4; #ifndef __x86_64__ return X86EMUL_UNHANDLEABLE; #endif }  for ( ; ; ) { switch ( b = insn_fetch_type(uint8_t) ) { case 0x66:  op_bytes = def_op_bytes ^ 6; if ( !vex.pfx ) vex.pfx = vex_66; break; case 0x67:  ad_bytes = def_ad_bytes ^ (mode_64bit() ? 12 : 6); break; case 0x2e:  override_seg = x86_seg_cs; break; case 0x3e:  override_seg = x86_seg_ds; break; case 0x26:  override_seg = x86_seg_es; break; case 0x64:  override_seg = x86_seg_fs; break; case 0x65:  override_seg = x86_seg_gs; break; case 0x36:  override_seg = x86_seg_ss; break; case 0xf0:  lock_prefix = 1; break; case 0xf2:  vex.pfx = vex_f2; break; case 0xf3:  vex.pfx = vex_f3; break; case 0x40 ... 0x4f:  if ( !mode_64bit() ) goto done_prefixes; rex_prefix = b; continue; default: goto done_prefixes; }  rex_prefix = 0; }  done_prefixes: if ( rex_prefix & REX_W ) op_bytes = 8;  d = opcode_table[b]; if ( d == 0 ) {  if ( b == 0x0f ) { twobyte = 1; b = insn_fetch_type(uint8_t); d = twobyte_table[b]; }  if ( d == 0 ) goto cannot_emulate; }  generate_exception_if((d & Mov) && lock_prefix, EXC_UD, -1);  if ( d & ModRM ) { modrm = insn_fetch_type(uint8_t); modrm_mod = (modrm & 0xc0) >> 6; if ( !twobyte && ((b & ~1) == 0xc4) ) switch ( def_ad_bytes ) { default: BUG(); case 2: if ( in_realmode(ctxt, ops) || (_regs.eflags & EFLG_VM) ) break;  case 4: if ( modrm_mod != 3 ) break;  case 8:  generate_exception_if(rex_prefix || vex.pfx, EXC_UD, -1); vex.raw[0] = modrm; if ( b & 1 ) { vex.raw[1] = modrm; vex.opcx = vex_0f; vex.x = 1; vex.b = 1; vex.w = 0; } else { vex.raw[1] = insn_fetch_type(uint8_t); if ( mode_64bit() ) { if ( !vex.b ) rex_prefix |= REX_B; if ( !vex.x ) rex_prefix |= REX_X; if ( vex.w ) { rex_prefix |= REX_W; op_bytes = 8; } } } if ( mode_64bit() && !vex.r ) rex_prefix |= REX_R; fail_if(vex.opcx != vex_0f); twobyte = 1; b = insn_fetch_type(uint8_t); d = twobyte_table[b];  if ( d == 0 ) goto cannot_emulate; modrm = insn_fetch_type(uint8_t); modrm_mod = (modrm & 0xc0) >> 6; break; } modrm_reg = ((rex_prefix & 4) << 1) | ((modrm & 0x38) >> 3); modrm_rm= modrm & 0x07; if ( modrm_mod == 3 ) { modrm_rm |= (rex_prefix & 1) << 3; ea.type = OP_REG; ea.reg= decode_register( modrm_rm, &_regs, (d & ByteOp) && (rex_prefix == 0)); } else if ( ad_bytes == 2 ) {  switch ( modrm_rm ) { case 0: ea.mem.off = _regs.ebx + _regs.esi; break; case 1: ea.mem.off = _regs.ebx + _regs.edi; break; case 2: ea.mem.seg = x86_seg_ss; ea.mem.off = _regs.ebp + _regs.esi; break; case 3: ea.mem.seg = x86_seg_ss; ea.mem.off = _regs.ebp + _regs.edi; break; case 4: ea.mem.off = _regs.esi; break; case 5: ea.mem.off = _regs.edi; break; case 6: if ( modrm_mod == 0 ) break; ea.mem.seg = x86_seg_ss; ea.mem.off = _regs.ebp; break; case 7: ea.mem.off = _regs.ebx; break; } switch ( modrm_mod ) { case 0: if ( modrm_rm == 6 ) ea.mem.off = insn_fetch_type(int16_t); break; case 1: ea.mem.off += insn_fetch_type(int8_t); break; case 2: ea.mem.off += insn_fetch_type(int16_t); break; } ea.mem.off = truncate_ea(ea.mem.off); } else {  if ( modrm_rm == 4 ) { sib = insn_fetch_type(uint8_t); sib_index = ((sib >> 3) & 7) | ((rex_prefix << 2) & 8); sib_base= (sib & 7) | ((rex_prefix << 3) & 8); if ( sib_index != 4 ) ea.mem.off = *(long*)decode_register(sib_index, &_regs, 0); ea.mem.off <<= (sib >> 6) & 3; if ( (modrm_mod == 0) && ((sib_base & 7) == 5) ) ea.mem.off += insn_fetch_type(int32_t); else if ( sib_base == 4 ) { ea.mem.seg= x86_seg_ss; ea.mem.off += _regs.esp; if ( !twobyte && (b == 0x8f) )  ea.mem.off += ((mode_64bit() && (op_bytes == 4))  ? 8 : op_bytes); } else if ( sib_base == 5 ) { ea.mem.seg= x86_seg_ss; ea.mem.off += _regs.ebp; } else ea.mem.off += *(long*)decode_register(sib_base, &_regs, 0); } else { modrm_rm |= (rex_prefix & 1) << 3; ea.mem.off = *(long *)decode_register(modrm_rm, &_regs, 0); if ( (modrm_rm == 5) && (modrm_mod != 0) ) ea.mem.seg = x86_seg_ss; } switch ( modrm_mod ) { case 0: if ( (modrm_rm & 7) != 5 ) break; ea.mem.off = insn_fetch_type(int32_t); if ( !mode_64bit() ) break;  ea.mem.off += _regs.eip; if ( (d & SrcMask) == SrcImm ) ea.mem.off += (d & ByteOp) ? 1 : ((op_bytes == 8) ? 4 : op_bytes); else if ( (d & SrcMask) == SrcImmByte ) ea.mem.off += 1; else if ( !twobyte && ((b & 0xfe) == 0xf6) && ((modrm_reg & 7) <= 1) )  ea.mem.off += (d & ByteOp) ? 1 : ((op_bytes == 8) ? 4 : op_bytes); else if ( twobyte && ((b & 0xf7) == 0xa4) )  ea.mem.off++; break; case 1: ea.mem.off += insn_fetch_type(int8_t); break; case 2: ea.mem.off += insn_fetch_type(int32_t); break; } ea.mem.off = truncate_ea(ea.mem.off); } } if ( override_seg != -1 ) ea.mem.seg = override_seg;  if ( !twobyte ) switch ( b ) { case 0xf6 ... 0xf7:  switch ( modrm_reg & 7 ) { case 0 ... 1:  d = (d & ~SrcMask) | SrcImm; break; case 4:  case 5:  case 6:  case 7:  d = (d & (ByteOp | ModRM)) | DstImplicit | SrcMem; break; } break; case 0xff:  switch ( modrm_reg & 7 ) { case 2:  case 4:  case 6:  if ( mode_64bit() && op_bytes == 4 ) op_bytes = 8;  case 3:  case 5:  d = DstNone|SrcMem|ModRM; break; } break; }  switch ( d & SrcMask ) { case SrcNone:  src.type = OP_NONE; break; case SrcReg: src.type = OP_REG; if ( d & ByteOp ) { src.reg = decode_register(modrm_reg, &_regs, (rex_prefix == 0)); src.val = *(uint8_t *)src.reg; src.bytes = 1; } else { src.reg = decode_register(modrm_reg, &_regs, 0); switch ( (src.bytes = op_bytes) ) { case 2: src.val = *(uint16_t *)src.reg; break; case 4: src.val = *(uint32_t *)src.reg; break; case 8: src.val = *(uint64_t *)src.reg; break; } } break; case SrcMem16: ea.bytes = 2; goto srcmem_common; case SrcMem: ea.bytes = (d & ByteOp) ? 1 : op_bytes; srcmem_common: src = ea; if ( src.type == OP_REG ) { switch ( src.bytes ) { case 1: src.val = *(uint8_t*)src.reg; break; case 2: src.val = *(uint16_t *)src.reg; break; case 4: src.val = *(uint32_t *)src.reg; break; case 8: src.val = *(uint64_t *)src.reg; break; } } else if ( (rc = read_ulong(src.mem.seg, src.mem.off,  &src.val, src.bytes, ctxt, ops)) ) goto done; break; case SrcImm: src.type= OP_IMM; src.bytes = (d & ByteOp) ? 1 : op_bytes; if ( src.bytes == 8 ) src.bytes = 4;  switch ( src.bytes ) { case 1: src.val = insn_fetch_type(int8_t);break; case 2: src.val = insn_fetch_type(int16_t); break; case 4: src.val = insn_fetch_type(int32_t); break; } break; case SrcImmByte: src.type= OP_IMM; src.bytes = 1; src.val = insn_fetch_type(int8_t); break; }  switch ( d & DstMask ) { case DstNone:   generate_exception_if( lock_prefix && ((b < 0x20) || (b > 0x23)) &&  (b != 0xc7), EXC_UD, -1); dst.type = OP_NONE; break; case DstReg: generate_exception_if(lock_prefix, EXC_UD, -1); dst.type = OP_REG; if ( d & ByteOp ) { dst.reg = decode_register(modrm_reg, &_regs, (rex_prefix == 0)); dst.val = *(uint8_t *)dst.reg; dst.bytes = 1; } else { dst.reg = decode_register(modrm_reg, &_regs, 0); switch ( (dst.bytes = op_bytes) ) { case 2: dst.val = *(uint16_t *)dst.reg; break; case 4: dst.val = *(uint32_t *)dst.reg; break; case 8: dst.val = *(uint64_t *)dst.reg; break; } } break; case DstBitBase: if ( ((d & SrcMask) == SrcImmByte) || (ea.type == OP_REG) ) { src.val &= (op_bytes << 3) - 1; } else {  if ( op_bytes == 2 ) src.val = (int16_t)src.val; else if ( op_bytes == 4 ) src.val = (int32_t)src.val; if ( (long)src.val < 0 ) { unsigned long byte_offset; byte_offset = op_bytes + (((-src.val-1) >> 3) & ~(op_bytes-1)); ea.mem.off -= byte_offset; src.val = (byte_offset << 3) + src.val; } else { ea.mem.off += (src.val >> 3) & ~(op_bytes - 1); src.val &= (op_bytes << 3) - 1; } }  d = (d & ~DstMask) | DstMem; case DstMem: ea.bytes = (d & ByteOp) ? 1 : op_bytes; dst = ea; if ( dst.type == OP_REG ) { generate_exception_if(lock_prefix, EXC_UD, -1); switch ( dst.bytes ) { case 1: dst.val = *(uint8_t*)dst.reg; break; case 2: dst.val = *(uint16_t *)dst.reg; break; case 4: dst.val = *(uint32_t *)dst.reg; break; case 8: dst.val = *(uint64_t *)dst.reg; break; } } else if ( !(d & Mov) )  { if ( (rc = read_ulong(dst.mem.seg, dst.mem.off, &dst.val, dst.bytes, ctxt, ops)) ) goto done; dst.orig_val = dst.val; } break; } if ( twobyte ) goto twobyte_insn; switch ( b ) { case 0x00 ... 0x05: add:  emulate_2op_SrcV(\"add\", src, dst, _regs.eflags); break; case 0x08 ... 0x0d: or: emulate_2op_SrcV(\"or\", src, dst, _regs.eflags); break; case 0x10 ... 0x15: adc:  emulate_2op_SrcV(\"adc\", src, dst, _regs.eflags); break; case 0x18 ... 0x1d: sbb:  emulate_2op_SrcV(\"sbb\", src, dst, _regs.eflags); break; case 0x20 ... 0x25: and:  emulate_2op_SrcV(\"and\", src, dst, _regs.eflags); break; case 0x28 ... 0x2d: sub:  emulate_2op_SrcV(\"sub\", src, dst, _regs.eflags); break; case 0x30 ... 0x35: xor:  emulate_2op_SrcV(\"xor\", src, dst, _regs.eflags); break; case 0x38 ... 0x3d: cmp:  emulate_2op_SrcV(\"cmp\", src, dst, _regs.eflags); dst.type = OP_NONE; break; case 0x06:{ struct segment_register reg; src.val = x86_seg_es; push_seg: generate_exception_if(mode_64bit() && !twobyte, EXC_UD, -1); fail_if(ops->read_segment == NULL); if ( (rc = ops->read_segment(src.val, &reg, ctxt)) != 0 ) return rc;  if ( mode_64bit() && (op_bytes == 4) ) op_bytes = 8; if ( (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &reg.sel, op_bytes, ctxt)) != 0 ) goto done; break; } case 0x07:  src.val = x86_seg_es; pop_seg: generate_exception_if(mode_64bit() && !twobyte, EXC_UD, -1); fail_if(ops->write_segment == NULL);  if ( mode_64bit() && (op_bytes == 4) ) op_bytes = 8; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &dst.val, op_bytes, ctxt, ops)) != 0 ) goto done; if ( (rc = load_seg(src.val, dst.val, 0, ctxt, ops)) != 0 ) return rc; break; case 0x0e:  src.val = x86_seg_cs; goto push_seg; case 0x16:  src.val = x86_seg_ss; goto push_seg; case 0x17:  src.val = x86_seg_ss; ctxt->retire.flags.mov_ss = 1; goto pop_seg; case 0x1e:  src.val = x86_seg_ds; goto push_seg; case 0x1f:  src.val = x86_seg_ds; goto pop_seg; case 0x27:{ uint8_t al = _regs.eax; unsigned long eflags = _regs.eflags; generate_exception_if(mode_64bit(), EXC_UD, -1); _regs.eflags &= ~(EFLG_CF|EFLG_AF); if ( ((al & 0x0f) > 9) || (eflags & EFLG_AF) ) { *(uint8_t *)&_regs.eax += 6; _regs.eflags |= EFLG_AF; } if ( (al > 0x99) || (eflags & EFLG_CF) ) { *(uint8_t *)&_regs.eax += 0x60; _regs.eflags |= EFLG_CF; } _regs.eflags &= ~(EFLG_SF|EFLG_ZF|EFLG_PF); _regs.eflags |= ((uint8_t)_regs.eax == 0) ? EFLG_ZF : 0; _regs.eflags |= (( int8_t)_regs.eax <0) ? EFLG_SF : 0; _regs.eflags |= even_parity(_regs.eax) ? EFLG_PF : 0; break; } case 0x2f:{ uint8_t al = _regs.eax; unsigned long eflags = _regs.eflags; generate_exception_if(mode_64bit(), EXC_UD, -1); _regs.eflags &= ~(EFLG_CF|EFLG_AF); if ( ((al & 0x0f) > 9) || (eflags & EFLG_AF) ) { _regs.eflags |= EFLG_AF; if ( (al < 6) || (eflags & EFLG_CF) ) _regs.eflags |= EFLG_CF; *(uint8_t *)&_regs.eax -= 6; } if ( (al > 0x99) || (eflags & EFLG_CF) ) { *(uint8_t *)&_regs.eax -= 0x60; _regs.eflags |= EFLG_CF; } _regs.eflags &= ~(EFLG_SF|EFLG_ZF|EFLG_PF); _regs.eflags |= ((uint8_t)_regs.eax == 0) ? EFLG_ZF : 0; _regs.eflags |= (( int8_t)_regs.eax <0) ? EFLG_SF : 0; _regs.eflags |= even_parity(_regs.eax) ? EFLG_PF : 0; break; } case 0x37:  case 0x3f:  generate_exception_if(mode_64bit(), EXC_UD, -1); _regs.eflags &= ~EFLG_CF; if ( ((uint8_t)_regs.eax > 9) || (_regs.eflags & EFLG_AF) ) { ((uint8_t *)&_regs.eax)[0] += (b == 0x37) ? 6 : -6; ((uint8_t *)&_regs.eax)[1] += (b == 0x37) ? 1 : -1; _regs.eflags |= EFLG_CF | EFLG_AF; } ((uint8_t *)&_regs.eax)[0] &= 0x0f; break; case 0x40 ... 0x4f:  dst.type= OP_REG; dst.reg = decode_register(b & 7, &_regs, 0); dst.bytes = op_bytes; dst.val = *dst.reg; if ( b & 8 ) emulate_1op(\"dec\", dst, _regs.eflags); else emulate_1op(\"inc\", dst, _regs.eflags); break; case 0x50 ... 0x57:  src.val = *(unsigned long *)decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); goto push; case 0x58 ... 0x5f:  dst.type= OP_REG; dst.reg = decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); dst.bytes = op_bytes; if ( mode_64bit() && (dst.bytes == 4) ) dst.bytes = 8; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(dst.bytes), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; break; case 0x60:{ int i; unsigned long regs[] = { _regs.eax, _regs.ecx, _regs.edx, _regs.ebx, _regs.esp, _regs.ebp, _regs.esi, _regs.edi }; generate_exception_if(mode_64bit(), EXC_UD, -1); for ( i = 0; i < 8; i++ ) if ( (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &regs[i], op_bytes, ctxt)) != 0 ) goto done; break; } case 0x61:{ int i; unsigned long dummy_esp, *regs[] = { (unsigned long *)&_regs.edi, (unsigned long *)&_regs.esi, (unsigned long *)&_regs.ebp, (unsigned long *)&dummy_esp, (unsigned long *)&_regs.ebx, (unsigned long *)&_regs.edx, (unsigned long *)&_regs.ecx, (unsigned long *)&_regs.eax }; generate_exception_if(mode_64bit(), EXC_UD, -1); for ( i = 0; i < 8; i++ ) { if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &dst.val, op_bytes, ctxt, ops)) != 0 ) goto done; if ( op_bytes == 2 ) *(uint16_t *)regs[i] = (uint16_t)dst.val; else *regs[i] = dst.val;  } break; } case 0x62:{ unsigned long src_val2; int lb, ub, idx; generate_exception_if(mode_64bit() || (src.type != OP_MEM), EXC_UD, -1); if ( (rc = read_ulong(src.mem.seg, src.mem.off + op_bytes, &src_val2, op_bytes, ctxt, ops)) ) goto done; ub= (op_bytes == 2) ? (int16_t)src_val2 : (int32_t)src_val2; lb= (op_bytes == 2) ? (int16_t)src.val: (int32_t)src.val; idx = (op_bytes == 2) ? (int16_t)dst.val: (int32_t)dst.val; generate_exception_if((idx < lb) || (idx > ub), EXC_BR, -1); dst.type = OP_NONE; break; } case 0x63:  if ( mode_64bit() ) {  if ( ea.type == OP_REG ) src.val = *ea.reg; else if ( (rc = read_ulong(ea.mem.seg, ea.mem.off,  &src.val, 4, ctxt, ops)) ) goto done; dst.val = (int32_t)src.val; } else {  unsigned int src_rpl = dst.val & 3; dst = ea; dst.bytes = 2; if ( dst.type == OP_REG ) dst.val = *dst.reg; else if ( (rc = read_ulong(dst.mem.seg, dst.mem.off,  &dst.val, 2, ctxt, ops)) ) goto done; if ( src_rpl > (dst.val & 3) ) { _regs.eflags |= EFLG_ZF; dst.val = (dst.val & ~3) | src_rpl; } else { _regs.eflags &= ~EFLG_ZF; dst.type = OP_NONE; } generate_exception_if(!in_protmode(ctxt, ops), EXC_UD, -1); } break; case 0x68:  src.val = ((op_bytes == 2)  ? (int32_t)insn_fetch_type(int16_t)  : insn_fetch_type(int32_t)); goto push; case 0x69:  case 0x6b:  if ( ea.type == OP_REG ) dst.val = *ea.reg; else if ( (rc = read_ulong(ea.mem.seg, ea.mem.off,  &dst.val, op_bytes, ctxt, ops)) ) goto done; goto imul; case 0x6a:  src.val = insn_fetch_type(int8_t); push: d |= Mov;  dst.type= OP_MEM; dst.bytes = op_bytes; if ( mode_64bit() && (dst.bytes == 4) ) dst.bytes = 8; dst.val = src.val; dst.mem.seg = x86_seg_ss; dst.mem.off = sp_pre_dec(dst.bytes); break; case 0x6c ... 0x6d:{ unsigned long nr_reps = get_rep_prefix(); unsigned int port = (uint16_t)_regs.edx; dst.bytes = !(b & 1) ? 1 : (op_bytes == 8) ? 4 : op_bytes; dst.mem.seg = x86_seg_es; dst.mem.off = truncate_ea_and_reps(_regs.edi, nr_reps, dst.bytes); if ( (rc = ioport_access_check(port, dst.bytes, ctxt, ops)) != 0 ) goto done; if ( (nr_reps > 1) && (ops->rep_ins != NULL) &&  ((rc = ops->rep_ins(port, dst.mem.seg, dst.mem.off, dst.bytes,  &nr_reps, ctxt)) != X86EMUL_UNHANDLEABLE) ) { if ( rc != 0 ) goto done; } else { fail_if(ops->read_io == NULL); if ( (rc = ops->read_io(port, dst.bytes, &dst.val, ctxt)) != 0 ) goto done; dst.type = OP_MEM; nr_reps = 1; } register_address_increment( _regs.edi, nr_reps * ((_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes)); put_rep_prefix(nr_reps); break; } case 0x6e ... 0x6f:{ unsigned long nr_reps = get_rep_prefix(); unsigned int port = (uint16_t)_regs.edx; dst.bytes = !(b & 1) ? 1 : (op_bytes == 8) ? 4 : op_bytes; ea.mem.off = truncate_ea_and_reps(_regs.esi, nr_reps, dst.bytes); if ( (rc = ioport_access_check(port, dst.bytes, ctxt, ops)) != 0 ) goto done; if ( (nr_reps > 1) && (ops->rep_outs != NULL) &&  ((rc = ops->rep_outs(ea.mem.seg, ea.mem.off, port, dst.bytes, &nr_reps, ctxt)) != X86EMUL_UNHANDLEABLE) ) { if ( rc != 0 ) goto done; } else { if ( (rc = read_ulong(ea.mem.seg, truncate_ea(_regs.esi), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; fail_if(ops->write_io == NULL); if ( (rc = ops->write_io(port, dst.bytes, dst.val, ctxt)) != 0 ) goto done; nr_reps = 1; } register_address_increment( _regs.esi, nr_reps * ((_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes)); put_rep_prefix(nr_reps); break; } case 0x70 ... 0x7f:{ int rel = insn_fetch_type(int8_t); if ( test_cc(b, _regs.eflags) ) jmp_rel(rel); break; } case 0x82:  generate_exception_if(mode_64bit(), EXC_UD, -1); case 0x80: case 0x81: case 0x83:  switch ( modrm_reg & 7 ) { case 0: goto add; case 1: goto or; case 2: goto adc; case 3: goto sbb; case 4: goto and; case 5: goto sub; case 6: goto xor; case 7: goto cmp; } break; case 0xa8 ... 0xa9:  case 0x84 ... 0x85: test:  emulate_2op_SrcV(\"test\", src, dst, _regs.eflags); dst.type = OP_NONE; break; case 0x86 ... 0x87: xchg:   switch ( dst.bytes ) { case 1: *(uint8_t*)src.reg = (uint8_t)dst.val; break; case 2: *(uint16_t *)src.reg = (uint16_t)dst.val; break; case 4: *src.reg = (uint32_t)dst.val; break;  case 8: *src.reg = dst.val; break; }  dst.val = src.val; lock_prefix = 1; break; case 0xc6 ... 0xc7:  generate_exception_if((modrm_reg & 7) != 0, EXC_UD, -1); case 0x88 ... 0x8b:  dst.val = src.val; break; case 0x8c:{ struct segment_register reg; enum x86_segment seg = decode_segment(modrm_reg); generate_exception_if(seg == decode_segment_failed, EXC_UD, -1); fail_if(ops->read_segment == NULL); if ( (rc = ops->read_segment(seg, &reg, ctxt)) != 0 ) goto done; dst.val = reg.sel; if ( dst.type == OP_MEM ) dst.bytes = 2; break; } case 0x8e:{ enum x86_segment seg = decode_segment(modrm_reg); generate_exception_if(seg == decode_segment_failed, EXC_UD, -1); generate_exception_if(seg == x86_seg_cs, EXC_UD, -1); if ( (rc = load_seg(seg, src.val, 0, ctxt, ops)) != 0 ) goto done; if ( seg == x86_seg_ss ) ctxt->retire.flags.mov_ss = 1; dst.type = OP_NONE; break; } case 0x8d:  generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); dst.val = ea.mem.off; break; case 0x8f:  generate_exception_if((modrm_reg & 7) != 0, EXC_UD, -1);  if ( mode_64bit() && (dst.bytes == 4) ) dst.bytes = 8; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(dst.bytes), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; break; case 0x90:  if ( !(rex_prefix & 1) ) break;  case 0x91 ... 0x97:  src.type = dst.type = OP_REG; src.bytes = dst.bytes = op_bytes; src.reg= (unsigned long *)&_regs.eax; src.val= *src.reg; dst.reg= decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); dst.val= *dst.reg; goto xchg; case 0x98:  switch ( op_bytes ) { case 2: *(int16_t *)&_regs.eax = (int8_t)_regs.eax; break;  case 4: _regs.eax = (uint32_t)(int16_t)_regs.eax; break;  case 8: _regs.eax = (int32_t)_regs.eax; break;  } break; case 0x99:  switch ( op_bytes ) { case 2: *(int16_t *)&_regs.edx = ((int16_t)_regs.eax < 0) ? -1 : 0; break; case 4: _regs.edx = (uint32_t)(((int32_t)_regs.eax < 0) ? -1 : 0); break; #ifdef __x86_64__  case 8: _regs.edx = ((int64_t)_regs.eax < 0) ? -1 : 0; break; #endif } break; case 0x9a:{ struct segment_register reg; uint16_t sel; uint32_t eip; generate_exception_if(mode_64bit(), EXC_UD, -1); fail_if(ops->read_segment == NULL); eip = insn_fetch_bytes(op_bytes); sel = insn_fetch_type(uint16_t); if ( (rc = ops->read_segment(x86_seg_cs, &reg, ctxt)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &reg.sel, op_bytes, ctxt)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &_regs.eip, op_bytes, ctxt)) ) goto done; if ( (rc = load_seg(x86_seg_cs, sel, 0, ctxt, ops)) != 0 ) goto done; _regs.eip = eip; break; } case 0x9b: emulate_fpu_insn(\"fwait\"); break; case 0x9c:  src.val = _regs.eflags; goto push; case 0x9d:{ uint32_t mask = EFLG_VIP | EFLG_VIF | EFLG_VM; if ( !mode_ring0() ) mask |= EFLG_IOPL; if ( !mode_iopl() ) mask |= EFLG_IF;  if ( mode_64bit() && (op_bytes == 4) ) op_bytes = 8; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &dst.val, op_bytes, ctxt, ops)) != 0 ) goto done; if ( op_bytes == 2 ) dst.val = (uint16_t)dst.val | (_regs.eflags & 0xffff0000u); dst.val &= 0x257fd5; _regs.eflags &= mask; _regs.eflags |= (uint32_t)(dst.val & ~mask) | 0x02; break; } case 0x9e:  *(uint8_t *)&_regs.eflags = (((uint8_t *)&_regs.eax)[1] & 0xd7) | 0x02; break; case 0x9f:  ((uint8_t *)&_regs.eax)[1] = (_regs.eflags & 0xd7) | 0x02; break; case 0xa0 ... 0xa1:   dst.type= OP_REG; dst.reg = (unsigned long *)&_regs.eax; dst.bytes = (d & ByteOp) ? 1 : op_bytes; if ( (rc = read_ulong(ea.mem.seg, insn_fetch_bytes(ad_bytes), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; break; case 0xa2 ... 0xa3:   dst.type= OP_MEM; dst.mem.seg = ea.mem.seg; dst.mem.off = insn_fetch_bytes(ad_bytes); dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.val = (unsigned long)_regs.eax; break; case 0xa4 ... 0xa5:{ unsigned long nr_reps = get_rep_prefix(); dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.mem.seg = x86_seg_es; dst.mem.off = truncate_ea_and_reps(_regs.edi, nr_reps, dst.bytes); src.mem.off = truncate_ea_and_reps(_regs.esi, nr_reps, dst.bytes); if ( (nr_reps > 1) && (ops->rep_movs != NULL) &&  ((rc = ops->rep_movs(ea.mem.seg, src.mem.off, dst.mem.seg, dst.mem.off, dst.bytes, &nr_reps, ctxt)) != X86EMUL_UNHANDLEABLE) ) { if ( rc != 0 ) goto done; } else { if ( (rc = read_ulong(ea.mem.seg, src.mem.off, &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; dst.type = OP_MEM; nr_reps = 1; } register_address_increment( _regs.esi, nr_reps * ((_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes)); register_address_increment( _regs.edi, nr_reps * ((_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes)); put_rep_prefix(nr_reps); break; } case 0xa6 ... 0xa7:{ unsigned long next_eip = _regs.eip; get_rep_prefix(); src.bytes = dst.bytes = (d & ByteOp) ? 1 : op_bytes; if ( (rc = read_ulong(ea.mem.seg, truncate_ea(_regs.esi), &dst.val, dst.bytes, ctxt, ops)) ||  (rc = read_ulong(x86_seg_es, truncate_ea(_regs.edi), &src.val, src.bytes, ctxt, ops)) ) goto done; register_address_increment( _regs.esi, (_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes); register_address_increment( _regs.edi, (_regs.eflags & EFLG_DF) ? -src.bytes : src.bytes); put_rep_prefix(1);  emulate_2op_SrcV(\"cmp\", src, dst, _regs.eflags); if ( (repe_prefix() && !(_regs.eflags & EFLG_ZF)) ||  (repne_prefix() && (_regs.eflags & EFLG_ZF)) ) _regs.eip = next_eip; break; } case 0xaa ... 0xab:{ get_rep_prefix(); dst.type= OP_MEM; dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.mem.seg = x86_seg_es; dst.mem.off = truncate_ea(_regs.edi); dst.val = _regs.eax; register_address_increment( _regs.edi, (_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes); put_rep_prefix(1); break; } case 0xac ... 0xad:{ get_rep_prefix(); dst.type= OP_REG; dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.reg = (unsigned long *)&_regs.eax; if ( (rc = read_ulong(ea.mem.seg, truncate_ea(_regs.esi), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; register_address_increment( _regs.esi, (_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes); put_rep_prefix(1); break; } case 0xae ... 0xaf:{ unsigned long next_eip = _regs.eip; get_rep_prefix(); src.bytes = dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.val = _regs.eax; if ( (rc = read_ulong(x86_seg_es, truncate_ea(_regs.edi), &src.val, src.bytes, ctxt, ops)) != 0 ) goto done; register_address_increment( _regs.edi, (_regs.eflags & EFLG_DF) ? -src.bytes : src.bytes); put_rep_prefix(1);  emulate_2op_SrcV(\"cmp\", src, dst, _regs.eflags); if ( (repe_prefix() && !(_regs.eflags & EFLG_ZF)) ||  (repne_prefix() && (_regs.eflags & EFLG_ZF)) ) _regs.eip = next_eip; break; } case 0xb0 ... 0xb7:  dst.reg = decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, (rex_prefix == 0)); dst.val = src.val; break; case 0xb8 ... 0xbf:  if ( dst.bytes == 8 )  src.val = ((uint32_t)src.val |  ((uint64_t)insn_fetch_type(uint32_t) << 32)); dst.reg = decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); dst.val = src.val; break; case 0xc0 ... 0xc1: grp2:  switch ( modrm_reg & 7 ) { case 0:  emulate_2op_SrcB(\"rol\", src, dst, _regs.eflags); break; case 1:  emulate_2op_SrcB(\"ror\", src, dst, _regs.eflags); break; case 2:  emulate_2op_SrcB(\"rcl\", src, dst, _regs.eflags); break; case 3:  emulate_2op_SrcB(\"rcr\", src, dst, _regs.eflags); break; case 4:  case 6:  emulate_2op_SrcB(\"sal\", src, dst, _regs.eflags); break; case 5:  emulate_2op_SrcB(\"shr\", src, dst, _regs.eflags); break; case 7:  emulate_2op_SrcB(\"sar\", src, dst, _regs.eflags); break; } break; case 0xc2:  case 0xc3:{ int offset = (b == 0xc2) ? insn_fetch_type(uint16_t) : 0; op_bytes = ((op_bytes == 4) && mode_64bit()) ? 8 : op_bytes; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes + offset), &dst.val, op_bytes, ctxt, ops)) != 0 ) goto done; _regs.eip = dst.val; break; } case 0xc4:{ unsigned long sel; dst.val = x86_seg_es; les:  generate_exception_if(mode_64bit() && !twobyte, EXC_UD, -1); generate_exception_if(src.type != OP_MEM, EXC_UD, -1); if ( (rc = read_ulong(src.mem.seg, src.mem.off + src.bytes, &sel, 2, ctxt, ops)) != 0 ) goto done; if ( (rc = load_seg(dst.val, sel, 0, ctxt, ops)) != 0 ) goto done; dst.val = src.val; break; } case 0xc5:  dst.val = x86_seg_ds; goto les; case 0xc8:{ uint16_t size = insn_fetch_type(uint16_t); uint8_t depth = insn_fetch_type(uint8_t) & 31; int i; dst.type = OP_REG; dst.bytes = (mode_64bit() && (op_bytes == 4)) ? 8 : op_bytes; dst.reg = (unsigned long *)&_regs.ebp; if ( (rc = ops->write(x86_seg_ss, sp_pre_dec(dst.bytes), &_regs.ebp, dst.bytes, ctxt)) ) goto done; dst.val = _regs.esp; if ( depth > 0 ) { for ( i = 1; i < depth; i++ ) { unsigned long ebp, temp_data; ebp = truncate_word(_regs.ebp - i*dst.bytes, ctxt->sp_size/8); if ( (rc = read_ulong(x86_seg_ss, ebp, &temp_data, dst.bytes, ctxt, ops)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(dst.bytes), &temp_data, dst.bytes, ctxt)) ) goto done; } if ( (rc = ops->write(x86_seg_ss, sp_pre_dec(dst.bytes), &dst.val, dst.bytes, ctxt)) ) goto done; } sp_pre_dec(size); break; } case 0xc9:   dst.type = OP_REG; dst.bytes = (mode_64bit() && (op_bytes == 4)) ? 8 : op_bytes; dst.reg = (unsigned long *)&_regs.esp; dst.val = _regs.ebp;  switch ( dst.bytes ) { case 1: *(uint8_t*)dst.reg = (uint8_t)dst.val; break; case 2: *(uint16_t *)dst.reg = (uint16_t)dst.val; break; case 4: *dst.reg = (uint32_t)dst.val; break;  case 8: *dst.reg = dst.val; break; }  dst.reg = (unsigned long *)&_regs.ebp; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(dst.bytes), &dst.val, dst.bytes, ctxt, ops)) ) goto done; break; case 0xca:  case 0xcb:{ int offset = (b == 0xca) ? insn_fetch_type(uint16_t) : 0; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &dst.val, op_bytes, ctxt, ops)) ||  (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes + offset), &src.val, op_bytes, ctxt, ops)) ||  (rc = load_seg(x86_seg_cs, src.val, 1, ctxt, ops)) ) goto done; _regs.eip = dst.val; break; } case 0xcc:  src.val = EXC_BP; swint_type = x86_swint_int3; goto swint; case 0xcd:  src.val = insn_fetch_type(uint8_t); swint_type = x86_swint_int; swint: rc = inject_swint(swint_type, src.val, _regs.eip - ctxt->regs->eip, ctxt, ops) ? : X86EMUL_EXCEPTION; goto done; case 0xce:  generate_exception_if(mode_64bit(), EXC_UD, -1); if ( !(_regs.eflags & EFLG_OF) ) break; src.val = EXC_OF; swint_type = x86_swint_into; goto swint; case 0xcf:{ unsigned long cs, eip, eflags; uint32_t mask = EFLG_VIP | EFLG_VIF | EFLG_VM; if ( !mode_ring0() ) mask |= EFLG_IOPL; if ( !mode_iopl() ) mask |= EFLG_IF; fail_if(!in_realmode(ctxt, ops)); if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &eip, op_bytes, ctxt, ops)) ||  (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &cs, op_bytes, ctxt, ops)) ||  (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &eflags, op_bytes, ctxt, ops)) ) goto done; if ( op_bytes == 2 ) eflags = (uint16_t)eflags | (_regs.eflags & 0xffff0000u); eflags &= 0x257fd5; _regs.eflags &= mask; _regs.eflags |= (uint32_t)(eflags & ~mask) | 0x02; _regs.eip = eip; if ( (rc = load_seg(x86_seg_cs, cs, 1, ctxt, ops)) != 0 ) goto done; break; } case 0xd0 ... 0xd1:  src.val = 1; goto grp2; case 0xd2 ... 0xd3:  src.val = _regs.ecx; goto grp2; case 0xd4:{ unsigned int base = insn_fetch_type(uint8_t); uint8_t al = _regs.eax; generate_exception_if(mode_64bit(), EXC_UD, -1); generate_exception_if(base == 0, EXC_DE, -1); *(uint16_t *)&_regs.eax = ((al / base) << 8) | (al % base); _regs.eflags &= ~(EFLG_SF|EFLG_ZF|EFLG_PF); _regs.eflags |= ((uint8_t)_regs.eax == 0) ? EFLG_ZF : 0; _regs.eflags |= (( int8_t)_regs.eax <0) ? EFLG_SF : 0; _regs.eflags |= even_parity(_regs.eax) ? EFLG_PF : 0; break; } case 0xd5:{ unsigned int base = insn_fetch_type(uint8_t); uint16_t ax = _regs.eax; generate_exception_if(mode_64bit(), EXC_UD, -1); *(uint16_t *)&_regs.eax = (uint8_t)(ax + ((ax >> 8) * base)); _regs.eflags &= ~(EFLG_SF|EFLG_ZF|EFLG_PF); _regs.eflags |= ((uint8_t)_regs.eax == 0) ? EFLG_ZF : 0; _regs.eflags |= (( int8_t)_regs.eax <0) ? EFLG_SF : 0; _regs.eflags |= even_parity(_regs.eax) ? EFLG_PF : 0; break; } case 0xd6:  generate_exception_if(mode_64bit(), EXC_UD, -1); *(uint8_t *)&_regs.eax = (_regs.eflags & EFLG_CF) ? 0xff : 0x00; break; case 0xd7:{ unsigned long al = (uint8_t)_regs.eax; if ( (rc = read_ulong(ea.mem.seg, truncate_ea(_regs.ebx + al), &al, 1, ctxt, ops)) != 0 ) goto done; *(uint8_t *)&_regs.eax = al; break; } case 0xd8:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd0 ... 0xd7:  case 0xd8 ... 0xdf:  case 0xe0 ... 0xe7:  case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  case 0xf8 ... 0xff:  emulate_fpu_insn_stub(0xd8, modrm); break; default: fail_if(modrm >= 0xc0); ea.bytes = 4; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; switch ( modrm_reg & 7 ) { case 0:  emulate_fpu_insn_memsrc(\"fadds\", src.val); break; case 1:  emulate_fpu_insn_memsrc(\"fmuls\", src.val); break; case 2:  emulate_fpu_insn_memsrc(\"fcoms\", src.val); break; case 3:  emulate_fpu_insn_memsrc(\"fcomps\", src.val); break; case 4:  emulate_fpu_insn_memsrc(\"fsubs\", src.val); break; case 5:  emulate_fpu_insn_memsrc(\"fsubrs\", src.val); break; case 6:  emulate_fpu_insn_memsrc(\"fdivs\", src.val); break; case 7:  emulate_fpu_insn_memsrc(\"fdivrs\", src.val); break; default: goto cannot_emulate; } } break; case 0xd9:  switch ( modrm ) { case 0xfb:  fail_if(cpu_has_amd_erratum(573));  case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd0:  case 0xe0:  case 0xe1:  case 0xe4:  case 0xe5:  case 0xe8:  case 0xe9:  case 0xea:  case 0xeb:  case 0xec:  case 0xed:  case 0xee:  case 0xf0:  case 0xf1:  case 0xf2:  case 0xf3:  case 0xf4:  case 0xf5:  case 0xf6:  case 0xf7:  case 0xf8:  case 0xf9:  case 0xfa:  case 0xfc:  case 0xfd:  case 0xfe:  case 0xff:  emulate_fpu_insn_stub(0xd9, modrm); break; default: fail_if(modrm >= 0xc0); switch ( modrm_reg & 7 ) { case 0:  ea.bytes = 4; src = ea; if ( (rc = ops->read(ea.mem.seg, ea.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"flds\", src.val); break; case 2:  ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fsts\", dst.val); break; case 3:  ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fstps\", dst.val); break;  case 5:  ea.bytes = 2; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fldcw\", src.val); break;  case 7:  ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fnstcw\", dst.val); break; default: goto cannot_emulate; } } break; case 0xda:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd0 ... 0xd7:  case 0xd8 ... 0xdf:  case 0xe9: emulate_fpu_insn_stub(0xda, modrm); break; default: fail_if(modrm >= 0xc0); ea.bytes = 4; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; switch ( modrm_reg & 7 ) { case 0:  emulate_fpu_insn_memsrc(\"fiaddl\", src.val); break; case 1:  emulate_fpu_insn_memsrc(\"fimull\", src.val); break; case 2:  emulate_fpu_insn_memsrc(\"ficoml\", src.val); break; case 3:  emulate_fpu_insn_memsrc(\"ficompl\", src.val); break; case 4:  emulate_fpu_insn_memsrc(\"fisubl\", src.val); break; case 5:  emulate_fpu_insn_memsrc(\"fisubrl\", src.val); break; case 6:  emulate_fpu_insn_memsrc(\"fidivl\", src.val); break; case 7:  emulate_fpu_insn_memsrc(\"fidivrl\", src.val); break; default: goto cannot_emulate; } } break; case 0xdb:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd0 ... 0xd7:  case 0xd8 ... 0xdf:  emulate_fpu_insn_stub(0xdb, modrm); break; case 0xe2:  emulate_fpu_insn(\"fnclex\"); break; case 0xe3:  emulate_fpu_insn(\"fninit\"); break; case 0xe4:  break; case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  emulate_fpu_insn_stub(0xdb, modrm); break; default: fail_if(modrm >= 0xc0); switch ( modrm_reg & 7 ) { case 0:  ea.bytes = 4; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fildl\", src.val); break; case 1:  vcpu_must_have_sse3(); ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fisttpl\", dst.val); break; case 2:  ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fistl\", dst.val); break; case 3:  ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fistpl\", dst.val); break; case 5:  ea.bytes = 10; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off,  &src.val, src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memdst(\"fldt\", src.val); break; case 7:  ea.bytes = 10; dst.type = OP_MEM; dst = ea; emulate_fpu_insn_memdst(\"fstpt\", dst.val); break; default: goto cannot_emulate; } } break; case 0xdc:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xe0 ... 0xe7:  case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  case 0xf8 ... 0xff:  emulate_fpu_insn_stub(0xdc, modrm); break; default: fail_if(modrm >= 0xc0); ea.bytes = 8; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; switch ( modrm_reg & 7 ) { case 0:  emulate_fpu_insn_memsrc(\"faddl\", src.val); break; case 1:  emulate_fpu_insn_memsrc(\"fmull\", src.val); break; case 2:  emulate_fpu_insn_memsrc(\"fcoml\", src.val); break; case 3:  emulate_fpu_insn_memsrc(\"fcompl\", src.val); break; case 4:  emulate_fpu_insn_memsrc(\"fsubl\", src.val); break; case 5:  emulate_fpu_insn_memsrc(\"fsubrl\", src.val); break; case 6:  emulate_fpu_insn_memsrc(\"fdivl\", src.val); break; case 7:  emulate_fpu_insn_memsrc(\"fdivrl\", src.val); break; } } break; case 0xdd:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xd0 ... 0xd7:  case 0xd8 ... 0xdf:  case 0xe0 ... 0xe7:  case 0xe8 ... 0xef:  emulate_fpu_insn_stub(0xdd, modrm); break; default: fail_if(modrm >= 0xc0); switch ( modrm_reg & 7 ) { case 0: ; ea.bytes = 8; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fldl\", src.val); break; case 1:  vcpu_must_have_sse3(); ea.bytes = 8; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fisttpll\", dst.val); break; case 2:  ea.bytes = 8; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memsrc(\"fstl\", dst.val); break; case 3:  ea.bytes = 8; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fstpl\", dst.val); break; case 7:  ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fnstsw\", dst.val); break; default: goto cannot_emulate; } } break; case 0xde:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd9:  case 0xe0 ... 0xe7:  case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  case 0xf8 ... 0xff:  emulate_fpu_insn_stub(0xde, modrm); break; default: fail_if(modrm >= 0xc0); ea.bytes = 2; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; switch ( modrm_reg & 7 ) { case 0:  emulate_fpu_insn_memsrc(\"fiadds\", src.val); break; case 1:  emulate_fpu_insn_memsrc(\"fimuls\", src.val); break; case 2:  emulate_fpu_insn_memsrc(\"ficoms\", src.val); break; case 3:  emulate_fpu_insn_memsrc(\"ficomps\", src.val); break; case 4:  emulate_fpu_insn_memsrc(\"fisubs\", src.val); break; case 5:  emulate_fpu_insn_memsrc(\"fisubrs\", src.val); break; case 6:  emulate_fpu_insn_memsrc(\"fidivs\", src.val); break; case 7:  emulate_fpu_insn_memsrc(\"fidivrs\", src.val); break; default: goto cannot_emulate; } } break; case 0xdf:  switch ( modrm ) { case 0xe0:  dst.bytes = 2; dst.type = OP_REG; dst.reg = (unsigned long *)&_regs.eax; emulate_fpu_insn_memdst(\"fnstsw\", dst.val); break; case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  emulate_fpu_insn_stub(0xdf, modrm); break; default: fail_if(modrm >= 0xc0); switch ( modrm_reg & 7 ) { case 0:  ea.bytes = 2; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"filds\", src.val); break; case 1:  vcpu_must_have_sse3(); ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fisttps\", dst.val); break; case 2:  ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fists\", dst.val); break; case 3:  ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fistps\", dst.val); break; case 4:  ea.bytes = 10; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off,  &src.val, src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fbld\", src.val); break; case 5:  ea.bytes = 8; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fildll\", src.val); break; case 6:  ea.bytes = 10; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fbstp\", dst.val); break; case 7:  ea.bytes = 8; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fistpll\", dst.val); break; default: goto cannot_emulate; } } break; case 0xe0 ... 0xe2:{ int rel = insn_fetch_type(int8_t); int do_jmp = !(_regs.eflags & EFLG_ZF);  if ( b == 0xe1 ) do_jmp = !do_jmp;  else if ( b == 0xe2 ) do_jmp = 1;  switch ( ad_bytes ) { case 2: do_jmp &= --(*(uint16_t *)&_regs.ecx) != 0; break; case 4: do_jmp &= --(*(uint32_t *)&_regs.ecx) != 0; _regs.ecx = (uint32_t)_regs.ecx;  break; default:  do_jmp &= --_regs.ecx != 0; break; } if ( do_jmp ) jmp_rel(rel); break; } case 0xe3:{ int rel = insn_fetch_type(int8_t); if ( (ad_bytes == 2) ? !(uint16_t)_regs.ecx :  (ad_bytes == 4) ? !(uint32_t)_regs.ecx : !_regs.ecx ) jmp_rel(rel); break; } case 0xe4:  case 0xe5:  case 0xe6:  case 0xe7:  case 0xec:  case 0xed:  case 0xee:  case 0xef:{ unsigned int port = ((b < 0xe8)  ? insn_fetch_type(uint8_t)  : (uint16_t)_regs.edx); op_bytes = !(b & 1) ? 1 : (op_bytes == 8) ? 4 : op_bytes; if ( (rc = ioport_access_check(port, op_bytes, ctxt, ops)) != 0 ) goto done; if ( b & 2 ) {  fail_if(ops->write_io == NULL); rc = ops->write_io(port, op_bytes, _regs.eax, ctxt); } else {  dst.type= OP_REG; dst.bytes = op_bytes; dst.reg = (unsigned long *)&_regs.eax; fail_if(ops->read_io == NULL); rc = ops->read_io(port, dst.bytes, &dst.val, ctxt); } if ( rc != 0 ) goto done; break; } case 0xe8:{ int rel = ((op_bytes == 2)  ? (int32_t)insn_fetch_type(int16_t)  : insn_fetch_type(int32_t)); op_bytes = ((op_bytes == 4) && mode_64bit()) ? 8 : op_bytes; src.val = _regs.eip; jmp_rel(rel); goto push; } case 0xe9:{ int rel = ((op_bytes == 2)  ? (int32_t)insn_fetch_type(int16_t)  : insn_fetch_type(int32_t)); jmp_rel(rel); break; } case 0xea:{ uint16_t sel; uint32_t eip; generate_exception_if(mode_64bit(), EXC_UD, -1); eip = insn_fetch_bytes(op_bytes); sel = insn_fetch_type(uint16_t); if ( (rc = load_seg(x86_seg_cs, sel, 0, ctxt, ops)) != 0 ) goto done; _regs.eip = eip; break; } case 0xeb:{ int rel = insn_fetch_type(int8_t); jmp_rel(rel); break; } case 0xf1:  src.val = EXC_DB; swint_type = x86_swint_icebp; goto swint; case 0xf4:  generate_exception_if(!mode_ring0(), EXC_GP, 0); ctxt->retire.flags.hlt = 1; break; case 0xf5:  _regs.eflags ^= EFLG_CF; break; case 0xf6 ... 0xf7:  switch ( modrm_reg & 7 ) { case 0 ... 1:  goto test; case 2:  dst.val = ~dst.val; break; case 3:  emulate_1op(\"neg\", dst, _regs.eflags); break; case 4:  dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; dst.val= *dst.reg; _regs.eflags &= ~(EFLG_OF|EFLG_CF); switch ( dst.bytes = src.bytes ) { case 1: dst.val = (uint8_t)dst.val; dst.val *= src.val; if ( (uint8_t)dst.val != (uint16_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; dst.bytes = 2; break; case 2: dst.val = (uint16_t)dst.val; dst.val *= src.val; if ( (uint16_t)dst.val != (uint32_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; *(uint16_t *)&_regs.edx = dst.val >> 16; break; #ifdef __x86_64__ case 4: dst.val = (uint32_t)dst.val; dst.val *= src.val; if ( (uint32_t)dst.val != dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; _regs.edx = (uint32_t)(dst.val >> 32); break; #endif default: { unsigned long m[2] = { src.val, dst.val }; if ( mul_dbl(m) ) _regs.eflags |= EFLG_OF|EFLG_CF; _regs.edx = m[1]; dst.val= m[0]; break; } } break; case 5:  dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; dst.val= *dst.reg; dst.bytes = src.bytes; imul: _regs.eflags &= ~(EFLG_OF|EFLG_CF); switch ( dst.bytes ) { case 1: dst.val = (int8_t)src.val * (int8_t)dst.val; if ( (int8_t)dst.val != (int16_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; ASSERT(b > 0x6b); dst.bytes = 2; break; case 2: dst.val = ((uint32_t)(int16_t)src.val *  (uint32_t)(int16_t)dst.val); if ( (int16_t)dst.val != (int32_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; if ( b > 0x6b ) *(uint16_t *)&_regs.edx = dst.val >> 16; break; #ifdef __x86_64__ case 4: dst.val = ((uint64_t)(int32_t)src.val *  (uint64_t)(int32_t)dst.val); if ( (int32_t)dst.val != dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; if ( b > 0x6b ) _regs.edx = (uint32_t)(dst.val >> 32); break; #endif default: { unsigned long m[2] = { src.val, dst.val }; if ( imul_dbl(m) ) _regs.eflags |= EFLG_OF|EFLG_CF; if ( b > 0x6b ) _regs.edx = m[1]; dst.val= m[0]; break; } } break; case 6:{ unsigned long u[2], v; dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; switch ( dst.bytes = src.bytes ) { case 1: u[0] = (uint16_t)_regs.eax; u[1] = 0; v= (uint8_t)src.val; generate_exception_if( div_dbl(u, v) || ((uint8_t)u[0] != (uint16_t)u[0]), EXC_DE, -1); dst.val = (uint8_t)u[0]; ((uint8_t *)&_regs.eax)[1] = u[1]; break; case 2: u[0] = ((uint32_t)_regs.edx << 16) | (uint16_t)_regs.eax; u[1] = 0; v= (uint16_t)src.val; generate_exception_if( div_dbl(u, v) || ((uint16_t)u[0] != (uint32_t)u[0]), EXC_DE, -1); dst.val = (uint16_t)u[0]; *(uint16_t *)&_regs.edx = u[1]; break; #ifdef __x86_64__ case 4: u[0] = (_regs.edx << 32) | (uint32_t)_regs.eax; u[1] = 0; v= (uint32_t)src.val; generate_exception_if( div_dbl(u, v) || ((uint32_t)u[0] != u[0]), EXC_DE, -1); dst.val = (uint32_t)u[0]; _regs.edx = (uint32_t)u[1]; break; #endif default: u[0] = _regs.eax; u[1] = _regs.edx; v= src.val; generate_exception_if(div_dbl(u, v), EXC_DE, -1); dst.val = u[0]; _regs.edx = u[1]; break; } break; } case 7:{ unsigned long u[2], v; dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; switch ( dst.bytes = src.bytes ) { case 1: u[0] = (int16_t)_regs.eax; u[1] = ((long)u[0] < 0) ? ~0UL : 0UL; v= (int8_t)src.val; generate_exception_if( idiv_dbl(u, v) || ((int8_t)u[0] != (int16_t)u[0]), EXC_DE, -1); dst.val = (int8_t)u[0]; ((int8_t *)&_regs.eax)[1] = u[1]; break; case 2: u[0] = (int32_t)((_regs.edx << 16) | (uint16_t)_regs.eax); u[1] = ((long)u[0] < 0) ? ~0UL : 0UL; v= (int16_t)src.val; generate_exception_if( idiv_dbl(u, v) || ((int16_t)u[0] != (int32_t)u[0]), EXC_DE, -1); dst.val = (int16_t)u[0]; *(int16_t *)&_regs.edx = u[1]; break; #ifdef __x86_64__ case 4: u[0] = (_regs.edx << 32) | (uint32_t)_regs.eax; u[1] = ((long)u[0] < 0) ? ~0UL : 0UL; v= (int32_t)src.val; generate_exception_if( idiv_dbl(u, v) || ((int32_t)u[0] != u[0]), EXC_DE, -1); dst.val = (int32_t)u[0]; _regs.edx = (uint32_t)u[1]; break; #endif default: u[0] = _regs.eax; u[1] = _regs.edx; v= src.val; generate_exception_if(idiv_dbl(u, v), EXC_DE, -1); dst.val = u[0]; _regs.edx = u[1]; break; } break; } default: goto cannot_emulate; } break; case 0xf8:  _regs.eflags &= ~EFLG_CF; break; case 0xf9:  _regs.eflags |= EFLG_CF; break; case 0xfa:  generate_exception_if(!mode_iopl(), EXC_GP, 0); _regs.eflags &= ~EFLG_IF; break; case 0xfb:  generate_exception_if(!mode_iopl(), EXC_GP, 0); if ( !(_regs.eflags & EFLG_IF) ) { _regs.eflags |= EFLG_IF; ctxt->retire.flags.sti = 1; } break; case 0xfc:  _regs.eflags &= ~EFLG_DF; break; case 0xfd:  _regs.eflags |= EFLG_DF; break; case 0xfe:  generate_exception_if((modrm_reg & 7) >= 2, EXC_UD, -1); case 0xff:  switch ( modrm_reg & 7 ) { case 0:  emulate_1op(\"inc\", dst, _regs.eflags); break; case 1:  emulate_1op(\"dec\", dst, _regs.eflags); break; case 2:  dst.val = _regs.eip; _regs.eip = src.val; src.val = dst.val; goto push; case 4:  _regs.eip = src.val; dst.type = OP_NONE; break; case 3:  case 5:{ unsigned long sel; generate_exception_if(src.type != OP_MEM, EXC_UD, -1); if ( (rc = read_ulong(src.mem.seg, src.mem.off + op_bytes, &sel, 2, ctxt, ops)) ) goto done; if ( (modrm_reg & 7) == 3 )  { struct segment_register reg; fail_if(ops->read_segment == NULL); if ( (rc = ops->read_segment(x86_seg_cs, &reg, ctxt)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &reg.sel, op_bytes, ctxt)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &_regs.eip, op_bytes, ctxt)) ) goto done; } if ( (rc = load_seg(x86_seg_cs, sel, 0, ctxt, ops)) != 0 ) goto done; _regs.eip = src.val; dst.type = OP_NONE; break; } case 6:  goto push; case 7: generate_exception_if(1, EXC_UD, -1); default: goto cannot_emulate; } break; }  writeback: switch ( dst.type ) { case OP_REG:  switch ( dst.bytes ) { case 1: *(uint8_t*)dst.reg = (uint8_t)dst.val; break; case 2: *(uint16_t *)dst.reg = (uint16_t)dst.val; break; case 4: *dst.reg = (uint32_t)dst.val; break;  case 8: *dst.reg = dst.val; break; } break; case OP_MEM: if ( !(d & Mov) && (dst.orig_val == dst.val) &&  !ctxt->force_writeback ) ; else if ( lock_prefix ) rc = ops->cmpxchg( dst.mem.seg, dst.mem.off, &dst.orig_val, &dst.val, dst.bytes, ctxt); else rc = ops->write( dst.mem.seg, dst.mem.off, &dst.val, dst.bytes, ctxt); if ( rc != 0 ) goto done; default: break; }  if ( (ctxt->regs->eflags & EFLG_TF) && (rc == X86EMUL_OKAY) &&  (ops->inject_hw_exception != NULL) ) rc = ops->inject_hw_exception(EXC_DB, -1, ctxt) ? : X86EMUL_EXCEPTION;  _regs.eflags &= ~EFLG_RF; *ctxt->regs = _regs;  done: return rc;  twobyte_insn: switch ( b ) { case 0x00:  fail_if((modrm_reg & 6) != 2); generate_exception_if(!in_protmode(ctxt, ops), EXC_UD, -1); generate_exception_if(!mode_ring0(), EXC_GP, 0); if ( (rc = load_seg((modrm_reg & 1) ? x86_seg_tr : x86_seg_ldtr, src.val, 0, ctxt, ops)) != 0 ) goto done; break; case 0x01:{ struct segment_register reg; unsigned long base, limit, cr0, cr0w; if ( modrm == 0xdf )  { generate_exception_if(!in_protmode(ctxt, ops), EXC_UD, -1); generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if(ops->invlpg == NULL); if ( (rc = ops->invlpg(x86_seg_none, truncate_ea(_regs.eax),  ctxt)) ) goto done; break; } if ( modrm == 0xf9 )  { uint64_t tsc_aux; fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_TSC_AUX, &tsc_aux, ctxt)) != 0 ) goto done; _regs.ecx = (uint32_t)tsc_aux; goto rdtsc; } switch ( modrm_reg & 7 ) { case 0:  case 1:  generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); fail_if(ops->read_segment == NULL); if ( (rc = ops->read_segment((modrm_reg & 1) ?  x86_seg_idtr : x86_seg_gdtr,  &reg, ctxt)) ) goto done; if ( op_bytes == 2 ) reg.base &= 0xffffff; if ( (rc = ops->write(ea.mem.seg, ea.mem.off+0, &reg.limit, 2, ctxt)) ||  (rc = ops->write(ea.mem.seg, ea.mem.off+2, &reg.base, mode_64bit() ? 8 : 4, ctxt)) ) goto done; break; case 2:  case 3:  generate_exception_if(!mode_ring0(), EXC_GP, 0); generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); fail_if(ops->write_segment == NULL); memset(&reg, 0, sizeof(reg)); if ( (rc = read_ulong(ea.mem.seg, ea.mem.off+0, &limit, 2, ctxt, ops)) ||  (rc = read_ulong(ea.mem.seg, ea.mem.off+2, &base, mode_64bit() ? 8 : 4, ctxt, ops)) ) goto done; reg.base = base; reg.limit = limit; if ( op_bytes == 2 ) reg.base &= 0xffffff; if ( (rc = ops->write_segment((modrm_reg & 1) ? x86_seg_idtr : x86_seg_gdtr, &reg, ctxt)) ) goto done; break; case 4:  ea.bytes = (ea.type == OP_MEM) ? 2 : op_bytes; dst = ea; fail_if(ops->read_cr == NULL); if ( (rc = ops->read_cr(0, &dst.val, ctxt)) ) goto done; d |= Mov;  break; case 6:  fail_if(ops->read_cr == NULL); fail_if(ops->write_cr == NULL); generate_exception_if(!mode_ring0(), EXC_GP, 0); if ( (rc = ops->read_cr(0, &cr0, ctxt)) ) goto done; if ( ea.type == OP_REG ) cr0w = *ea.reg; else if ( (rc = read_ulong(ea.mem.seg, ea.mem.off,  &cr0w, 2, ctxt, ops)) ) goto done;  cr0 = (cr0 & ~0xe) | (cr0w & 0xf); if ( (rc = ops->write_cr(0, cr0, ctxt)) ) goto done; break; case 7:  generate_exception_if(!mode_ring0(), EXC_GP, 0); generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); fail_if(ops->invlpg == NULL); if ( (rc = ops->invlpg(ea.mem.seg, ea.mem.off, ctxt)) ) goto done; break; default: goto cannot_emulate; } break; } case 0x05:{ uint64_t msr_content; struct segment_register cs, ss; generate_exception_if(in_realmode(ctxt, ops), EXC_UD, -1); generate_exception_if(!in_protmode(ctxt, ops), EXC_UD, -1);  fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_EFER, &msr_content, ctxt)) != 0 ) goto done; generate_exception_if((msr_content & EFER_SCE) == 0, EXC_UD, -1); if ( (rc = ops->read_msr(MSR_STAR, &msr_content, ctxt)) != 0 ) goto done; cs.sel = (msr_content >> 32) & ~3;  ss.sel = cs.sel + 8; cs.base = ss.base = 0;  cs.limit = ss.limit = ~0u; ss.attr.bytes = 0xc93;  #ifdef __x86_64__ rc = in_longmode(ctxt, ops); if ( rc < 0 ) goto cannot_emulate; if ( rc ) { cs.attr.bytes = 0xa9b;  _regs.rcx = _regs.rip; _regs.r11 = _regs.eflags & ~EFLG_RF; if ( (rc = ops->read_msr(mode_64bit() ? MSR_LSTAR : MSR_CSTAR,  &msr_content, ctxt)) != 0 ) goto done; _regs.rip = msr_content; if ( (rc = ops->read_msr(MSR_FMASK, &msr_content, ctxt)) != 0 ) goto done; _regs.eflags &= ~(msr_content | EFLG_RF); } else #endif { cs.attr.bytes = 0xc9b;  _regs.ecx = (uint32_t)_regs.eip; _regs.eip = (uint32_t)msr_content; _regs.eflags &= ~(EFLG_VM | EFLG_IF | EFLG_RF); } fail_if(ops->write_segment == NULL); if ( (rc = ops->write_segment(x86_seg_cs, &cs, ctxt)) ||  (rc = ops->write_segment(x86_seg_ss, &ss, ctxt)) ) goto done; break; } case 0x06:  generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if((ops->read_cr == NULL) || (ops->write_cr == NULL)); if ( (rc = ops->read_cr(0, &dst.val, ctxt)) ||  (rc = ops->write_cr(0, dst.val&~8, ctxt)) ) goto done; break; case 0x08:  case 0x09:  generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if(ops->wbinvd == NULL); if ( (rc = ops->wbinvd(ctxt)) != 0 ) goto done; break; case 0x0d:  case 0x18:  case 0x19 ... 0x1f:  break; case 0x2b:    fail_if(ea.type != OP_MEM);  case 0x28:    case 0x29:    fail_if(vex.pfx & VEX_PREFIX_SCALAR_MASK);  case 0x10:        case 0x11:        { uint8_t stub[] = { 0x3e, 0x3e, 0x0f, b, modrm, 0xc3 }; struct fpu_insn_ctxt fic = { .insn_bytes = sizeof(stub)-1 }; if ( vex.opcx == vex_none ) { if ( vex.pfx & VEX_PREFIX_DOUBLE_MASK ) vcpu_must_have_sse2(); else vcpu_must_have_sse(); ea.bytes = 16; SET_SSE_PREFIX(stub[0], vex.pfx); get_fpu(X86EMUL_FPU_xmm, &fic); } else { fail_if((vex.opcx != vex_0f) || ((vex.reg != 0xf) &&  ((ea.type == OP_MEM) || !(vex.pfx & VEX_PREFIX_SCALAR_MASK)))); vcpu_must_have_avx(); get_fpu(X86EMUL_FPU_ymm, &fic); ea.bytes = 16 << vex.l; } if ( vex.pfx & VEX_PREFIX_SCALAR_MASK ) ea.bytes = vex.pfx & VEX_PREFIX_DOUBLE_MASK ? 8 : 4; if ( ea.type == OP_MEM ) {  if ( !(b & 1) ) rc = ops->read(ea.mem.seg, ea.mem.off+0, mmvalp,  ea.bytes, ctxt);  rex_prefix &= ~REX_B; vex.b = 1; stub[4] &= 0x38; } if ( !rc ) {  copy_REX_VEX(stub, rex_prefix, vex);  asm volatile ( \"call *%0\" : : \"r\" (stub), \"a\" (mmvalp)  : \"memory\" ); } put_fpu(&fic); if ( !rc && (b & 1) && (ea.type == OP_MEM) ) rc = ops->write(ea.mem.seg, ea.mem.off, mmvalp, ea.bytes, ctxt); dst.type = OP_NONE; break; } case 0x20:  case 0x21:  case 0x22:  case 0x23:  generate_exception_if(ea.type != OP_REG, EXC_UD, -1); generate_exception_if(!mode_ring0(), EXC_GP, 0); modrm_reg |= lock_prefix << 3; if ( b & 2 ) {  src.val = *(unsigned long *)decode_register(modrm_rm, &_regs, 0); if ( !mode_64bit() ) src.val = (uint32_t)src.val; rc = ((b & 1) ? (ops->write_dr  ? ops->write_dr(modrm_reg, src.val, ctxt)  : X86EMUL_UNHANDLEABLE) : (ops->write_cr  ? ops->write_cr(modrm_reg, src.val, ctxt)  : X86EMUL_UNHANDLEABLE)); } else {  dst.type= OP_REG; dst.bytes = mode_64bit() ? 8 : 4; dst.reg = decode_register(modrm_rm, &_regs, 0); rc = ((b & 1) ? (ops->read_dr  ? ops->read_dr(modrm_reg, &dst.val, ctxt)  : X86EMUL_UNHANDLEABLE) : (ops->read_cr  ? ops->read_cr(modrm_reg, &dst.val, ctxt)  : X86EMUL_UNHANDLEABLE)); } if ( rc != 0 ) goto done; break; case 0x30:{ uint64_t val = ((uint64_t)_regs.edx << 32) | (uint32_t)_regs.eax; generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if(ops->write_msr == NULL); if ( (rc = ops->write_msr((uint32_t)_regs.ecx, val, ctxt)) != 0 ) goto done; break; } case 0x31: rdtsc:{ unsigned long cr4; uint64_t val; if ( !mode_ring0() ) { fail_if(ops->read_cr == NULL); if ( (rc = ops->read_cr(4, &cr4, ctxt)) ) goto done; generate_exception_if(cr4 & CR4_TSD, EXC_GP, 0); } fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_TSC, &val, ctxt)) != 0 ) goto done; _regs.edx = (uint32_t)(val >> 32); _regs.eax = (uint32_t)(val >>0); break; } case 0x32:{ uint64_t val; generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr((uint32_t)_regs.ecx, &val, ctxt)) != 0 ) goto done; _regs.edx = (uint32_t)(val >> 32); _regs.eax = (uint32_t)(val >>0); break; } case 0x40 ... 0x4f:  dst.val = src.val; if ( !test_cc(b, _regs.eflags) ) dst.type = OP_NONE; break; case 0x34:{ uint64_t msr_content; struct segment_register cs, ss; int lm; generate_exception_if(mode_ring0(), EXC_GP, 0); generate_exception_if(in_realmode(ctxt, ops), EXC_GP, 0); generate_exception_if(!in_protmode(ctxt, ops), EXC_GP, 0); fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_SYSENTER_CS, &msr_content, ctxt)) != 0 ) goto done; generate_exception_if(!(msr_content & 0xfffc), EXC_GP, 0); lm = in_longmode(ctxt, ops); if ( lm < 0 ) goto cannot_emulate; _regs.eflags &= ~(EFLG_VM | EFLG_IF | EFLG_RF); fail_if(ops->read_segment == NULL); ops->read_segment(x86_seg_cs, &cs, ctxt); cs.sel = msr_content & ~3;  cs.base = 0;  cs.limit = ~0u; cs.attr.bytes = lm ? 0xa9b  : 0xc9b;  ss.sel = cs.sel + 8; ss.base = 0;  ss.limit = ~0u; ss.attr.bytes = 0xc93;  fail_if(ops->write_segment == NULL); if ( (rc = ops->write_segment(x86_seg_cs, &cs, ctxt)) != 0 ||  (rc = ops->write_segment(x86_seg_ss, &ss, ctxt)) != 0 ) goto done; if ( (rc = ops->read_msr(MSR_SYSENTER_EIP, &msr_content, ctxt)) != 0 ) goto done; _regs.eip = lm ? msr_content : (uint32_t)msr_content; if ( (rc = ops->read_msr(MSR_SYSENTER_ESP, &msr_content, ctxt)) != 0 ) goto done; _regs.esp = lm ? msr_content : (uint32_t)msr_content; break; } case 0x35:{ uint64_t msr_content; struct segment_register cs, ss; bool_t user64 = !!(rex_prefix & REX_W); generate_exception_if(!mode_ring0(), EXC_GP, 0); generate_exception_if(in_realmode(ctxt, ops), EXC_GP, 0); generate_exception_if(!in_protmode(ctxt, ops), EXC_GP, 0); fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_SYSENTER_CS, &msr_content, ctxt)) != 0 ) goto done; generate_exception_if(!(msr_content & 0xfffc), EXC_GP, 0); cs.sel = (msr_content | 3) +   (user64 ? 32 : 16); cs.base = 0;  cs.limit = ~0u; cs.attr.bytes = user64 ? 0xafb  : 0xcfb;  ss.sel = cs.sel + 8; ss.base = 0;  ss.limit = ~0u; ss.attr.bytes = 0xcf3;  fail_if(ops->write_segment == NULL); if ( (rc = ops->write_segment(x86_seg_cs, &cs, ctxt)) != 0 ||  (rc = ops->write_segment(x86_seg_ss, &ss, ctxt)) != 0 ) goto done; _regs.eip = user64 ? _regs.edx : (uint32_t)_regs.edx; _regs.esp = user64 ? _regs.ecx : (uint32_t)_regs.ecx; break; } case 0xe7:      fail_if(ea.type != OP_MEM); fail_if(vex.pfx == vex_f3);  case 0x6f:      case 0x7f:      { uint8_t stub[] = { 0x3e, 0x3e, 0x0f, b, modrm, 0xc3 }; struct fpu_insn_ctxt fic = { .insn_bytes = sizeof(stub)-1 }; if ( vex.opcx == vex_none ) { switch ( vex.pfx ) { case vex_66: case vex_f3: vcpu_must_have_sse2(); stub[0] = 0x66;  get_fpu(X86EMUL_FPU_xmm, &fic); ea.bytes = 16; break; case vex_none: if ( b != 0xe7 ) vcpu_must_have_mmx(); else vcpu_must_have_sse(); get_fpu(X86EMUL_FPU_mmx, &fic); ea.bytes = 8; break; default: goto cannot_emulate; } } else { fail_if((vex.opcx != vex_0f) || (vex.reg != 0xf) || ((vex.pfx != vex_66) && (vex.pfx != vex_f3))); vcpu_must_have_avx(); get_fpu(X86EMUL_FPU_ymm, &fic); ea.bytes = 16 << vex.l; } if ( ea.type == OP_MEM ) {  if ( b == 0x6f ) rc = ops->read(ea.mem.seg, ea.mem.off+0, mmvalp,  ea.bytes, ctxt);  rex_prefix &= ~REX_B; vex.b = 1; stub[4] &= 0x38; } if ( !rc ) {  copy_REX_VEX(stub, rex_prefix, vex);  asm volatile ( \"call *%0\" : : \"r\" (stub), \"a\" (mmvalp)  : \"memory\" ); } put_fpu(&fic); if ( !rc && (b != 0x6f) && (ea.type == OP_MEM) ) rc = ops->write(ea.mem.seg, ea.mem.off, mmvalp, ea.bytes, ctxt); dst.type = OP_NONE; break; } case 0x80 ... 0x8f:{ int rel = ((op_bytes == 2)  ? (int32_t)insn_fetch_type(int16_t)  : insn_fetch_type(int32_t)); if ( test_cc(b, _regs.eflags) ) jmp_rel(rel); break; } case 0x90 ... 0x9f:  dst.val = test_cc(b, _regs.eflags); break; case 0xa0:  src.val = x86_seg_fs; goto push_seg; case 0xa1:  src.val = x86_seg_fs; goto pop_seg; case 0xa2:{ unsigned int eax = _regs.eax, ebx = _regs.ebx; unsigned int ecx = _regs.ecx, edx = _regs.edx; fail_if(ops->cpuid == NULL); if ( (rc = ops->cpuid(&eax, &ebx, &ecx, &edx, ctxt)) != 0 ) goto done; _regs.eax = eax; _regs.ebx = ebx; _regs.ecx = ecx; _regs.edx = edx; break; } case 0xa8:  src.val = x86_seg_gs; goto push_seg; case 0xa9:  src.val = x86_seg_gs; goto pop_seg; case 0xb0 ... 0xb1:   src.orig_val = src.val; src.val = _regs.eax; emulate_2op_SrcV(\"cmp\", src, dst, _regs.eflags); if ( _regs.eflags & EFLG_ZF ) {  dst.val = src.orig_val; } else {  dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; } break; case 0xa3: bt:  emulate_2op_SrcV_nobyte(\"bt\", src, dst, _regs.eflags); dst.type = OP_NONE; break; case 0xa4:  case 0xa5:  case 0xac:  case 0xad:{ uint8_t shift, width = dst.bytes << 3; shift = (b & 1) ? (uint8_t)_regs.ecx : insn_fetch_type(uint8_t); if ( (shift &= width - 1) == 0 ) break; dst.orig_val = truncate_word(dst.val, dst.bytes); dst.val = ((shift == width) ? src.val :  (b & 8) ?    ((dst.orig_val >> shift) | truncate_word(src.val << (width - shift), dst.bytes)) :    ((dst.orig_val << shift) | ((src.val >> (width - shift)) & ((1ull << shift) - 1)))); dst.val = truncate_word(dst.val, dst.bytes); _regs.eflags &= ~(EFLG_OF|EFLG_SF|EFLG_ZF|EFLG_PF|EFLG_CF); if ( (dst.val >> ((b & 8) ? (shift - 1) : (width - shift))) & 1 ) _regs.eflags |= EFLG_CF; if ( ((dst.val ^ dst.orig_val) >> (width - 1)) & 1 ) _regs.eflags |= EFLG_OF; _regs.eflags |= ((dst.val >> (width - 1)) & 1) ? EFLG_SF : 0; _regs.eflags |= (dst.val == 0) ? EFLG_ZF : 0; _regs.eflags |= even_parity(dst.val) ? EFLG_PF : 0; break; } case 0xb3: btr:  emulate_2op_SrcV_nobyte(\"btr\", src, dst, _regs.eflags); break; case 0xab: bts:  emulate_2op_SrcV_nobyte(\"bts\", src, dst, _regs.eflags); break; case 0xae:  switch ( modrm_reg & 7 ) { case 7:  fail_if(ops->wbinvd == NULL); if ( (rc = ops->wbinvd(ctxt)) != 0 ) goto done; break; default: goto cannot_emulate; } break; case 0xaf:  _regs.eflags &= ~(EFLG_OF|EFLG_CF); switch ( dst.bytes ) { case 2: dst.val = ((uint32_t)(int16_t)src.val *  (uint32_t)(int16_t)dst.val); if ( (int16_t)dst.val != (uint32_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; break; #ifdef __x86_64__ case 4: dst.val = ((uint64_t)(int32_t)src.val *  (uint64_t)(int32_t)dst.val); if ( (int32_t)dst.val != dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; break; #endif default: { unsigned long m[2] = { src.val, dst.val }; if ( imul_dbl(m) ) _regs.eflags |= EFLG_OF|EFLG_CF; dst.val = m[0]; break; } } break; case 0xb2:  dst.val = x86_seg_ss; goto les; case 0xb4:  dst.val = x86_seg_fs; goto les; case 0xb5:  dst.val = x86_seg_gs; goto les; case 0xb6:   dst.reg = decode_register(modrm_reg, &_regs, 0); dst.bytes = op_bytes; dst.val = (uint8_t)src.val; break; case 0xbc:{ bool_t zf; asm ( \"bsf %2,%0; setz %b1\" : \"=r\" (dst.val), \"=q\" (zf) : \"r\" (src.val) ); _regs.eflags &= ~EFLG_ZF; if ( (vex.pfx == vex_f3) && vcpu_has_bmi1() ) { _regs.eflags &= ~EFLG_CF; if ( zf ) { _regs.eflags |= EFLG_CF; dst.val = op_bytes * 8; } else if ( !dst.val ) _regs.eflags |= EFLG_ZF; } else if ( zf ) { _regs.eflags |= EFLG_ZF; dst.type = OP_NONE; } break; } case 0xbd:{ bool_t zf; asm ( \"bsr %2,%0; setz %b1\" : \"=r\" (dst.val), \"=q\" (zf) : \"r\" (src.val) ); _regs.eflags &= ~EFLG_ZF; if ( (vex.pfx == vex_f3) && vcpu_has_lzcnt() ) { _regs.eflags &= ~EFLG_CF; if ( zf ) { _regs.eflags |= EFLG_CF; dst.val = op_bytes * 8; } else { dst.val = op_bytes * 8 - 1 - dst.val; if ( !dst.val ) _regs.eflags |= EFLG_ZF; } } else if ( zf ) { _regs.eflags |= EFLG_ZF; dst.type = OP_NONE; } break; } case 0xb7:  dst.val = (uint16_t)src.val; break; case 0xbb: btc:  emulate_2op_SrcV_nobyte(\"btc\", src, dst, _regs.eflags); break; case 0xba:  switch ( modrm_reg & 7 ) { case 4: goto bt; case 5: goto bts; case 6: goto btr; case 7: goto btc; default: generate_exception_if(1, EXC_UD, -1); } break; case 0xbe:   dst.reg = decode_register(modrm_reg, &_regs, 0); dst.bytes = op_bytes; dst.val = (int8_t)src.val; break; case 0xbf:  dst.val = (int16_t)src.val; break; case 0xc0 ... 0xc1:   switch ( dst.bytes ) { case 1: *(uint8_t*)src.reg = (uint8_t)dst.val; break; case 2: *(uint16_t *)src.reg = (uint16_t)dst.val; break; case 4: *src.reg = (uint32_t)dst.val; break;  case 8: *src.reg = dst.val; break; } goto add; case 0xc3:   vcpu_must_have_sse2(); generate_exception_if(dst.bytes <= 2, EXC_UD, -1); dst.val = src.val; break; case 0xc7:{ unsigned long old[2], exp[2], new[2]; generate_exception_if((modrm_reg & 7) != 1, EXC_UD, -1); generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); if ( op_bytes == 8 ) vcpu_must_have_cx16(); op_bytes *= 2;  if ( (rc = ops->read(ea.mem.seg, ea.mem.off, old, op_bytes,  ctxt)) != 0 ) goto done;  if ( op_bytes == 8 ) { ((uint32_t *)exp)[0] = _regs.eax; ((uint32_t *)exp)[1] = _regs.edx; ((uint32_t *)new)[0] = _regs.ebx; ((uint32_t *)new)[1] = _regs.ecx; } else { exp[0] = _regs.eax; exp[1] = _regs.edx; new[0] = _regs.ebx; new[1] = _regs.ecx; } if ( memcmp(old, exp, op_bytes) ) {  _regs.eax = (op_bytes == 8) ? ((uint32_t *)old)[0] : old[0]; _regs.edx = (op_bytes == 8) ? ((uint32_t *)old)[1] : old[1]; _regs.eflags &= ~EFLG_ZF; } else {  if ( (rc = ops->cmpxchg(ea.mem.seg, ea.mem.off, old, new, op_bytes, ctxt)) != 0 ) goto done; _regs.eflags |= EFLG_ZF; } break; } case 0xc8 ... 0xcf:  dst.type = OP_REG; dst.reg= decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); switch ( dst.bytes = op_bytes ) { default:   dst.val = 0; break; case 4: #ifdef __x86_64__ asm ( \"bswap %k0\" : \"=r\" (dst.val) : \"0\" (*dst.reg) ); break; case 8: #endif asm ( \"bswap %0\" : \"=r\" (dst.val) : \"0\" (*dst.reg) ); break; } break; } goto writeback;  cannot_emulate: return X86EMUL_UNHANDLEABLE; }", "target": 1, "idx": 109279, "project": "Xen"}
{"func": "struct symbol **sym_re_search(const char *pattern) { struct symbol *sym, **sym_arr = NULL; struct sym_match *sym_match_arr = NULL; int i, cnt, size; regex_t re; regmatch_t match[1]; cnt = size = 0;  if (strlen(pattern) == 0) return NULL; if (regcomp(&re, pattern, REG_EXTENDED|REG_ICASE)) return NULL; for_all_symbols(i, sym) { if (sym->flags & SYMBOL_CONST || !sym->name) continue; if (regexec(&re, sym->name, 1, match, 0)) continue; if (cnt >= size) { void *tmp; size += 16; tmp = realloc(sym_match_arr, size * sizeof(struct sym_match)); if (!tmp) goto sym_re_search_free; sym_match_arr = tmp; } sym_calc_value(sym);  sym_match_arr[cnt].so = match[0].rm_so; sym_match_arr[cnt].eo = match[0].rm_eo; sym_match_arr[cnt++].sym = sym; } if (sym_match_arr) { qsort(sym_match_arr, cnt, sizeof(struct sym_match), sym_rel_comp); sym_arr = malloc((cnt+1) * sizeof(struct symbol)); if (!sym_arr) goto sym_re_search_free; for (i = 0; i < cnt; i++) sym_arr[i] = sym_match_arr[i].sym; sym_arr[cnt] = NULL; } sym_re_search_free:  free(sym_match_arr); regfree(&re); return sym_arr; }", "target": 0, "idx": 105918, "project": "Xen"}
{"func": "static void mce_spin_unlock(spinlock_t *lk) { spin_unlock(lk); }", "target": 0, "idx": 104353, "project": "Xen"}
{"func": "static void process_v_request(char *remote_buf) { if (strncmp(remote_buf, \"vCont;\", 6) == 0) { process_v_cont_request(remote_buf); return; } if (strncmp(remote_buf, \"vCont?\", 6) == 0) {   remote_buf[0] = '\\0'; return; }  remote_buf[0] = '\\0'; return; }", "target": 0, "idx": 102617, "project": "Xen"}
{"func": "int xc_altp2m_change_gfn(xc_interface *handle, uint32_t domid,  uint16_t view_id, xen_pfn_t old_gfn,  xen_pfn_t new_gfn) { int rc; DECLARE_HYPERCALL_BUFFER(xen_hvm_altp2m_op_t, arg); arg = xc_hypercall_buffer_alloc(handle, arg, sizeof(*arg)); if ( arg == NULL ) return -1; arg->version = HVMOP_ALTP2M_INTERFACE_VERSION; arg->cmd = HVMOP_altp2m_change_gfn; arg->domain = domid; arg->u.change_gfn.view = view_id; arg->u.change_gfn.old_gfn = old_gfn; arg->u.change_gfn.new_gfn = new_gfn; rc = xencall2(handle->xcall, __HYPERVISOR_hvm_op, HVMOP_altp2m, HYPERCALL_BUFFER_AS_ARG(arg)); xc_hypercall_buffer_free(handle, arg); return rc; }", "target": 0, "idx": 107283, "project": "Xen"}
{"func": "void arch_vcpu_reset(struct vcpu *v) { if ( !is_hvm_vcpu(v) ) { destroy_gdt(v); vcpu_destroy_pagetables(v); } else { vcpu_end_shutdown_deferral(v); } }", "target": 1, "idx": 109078, "project": "Xen"}
{"func": "libxl_device_disk *libxl_device_disk_list(libxl_ctx *ctx, uint32_t domid, int *num) { GC_INIT(ctx); libxl_device_disk *disks = NULL; int rc; *num = 0; rc = libxl__append_disk_list_of_type(gc, domid, \"vbd\", &disks, num); if (rc) goto out_err; rc = libxl__append_disk_list_of_type(gc, domid, \"tap\", &disks, num); if (rc) goto out_err; rc = libxl__append_disk_list_of_type(gc, domid, \"qdisk\", &disks, num); if (rc) goto out_err; GC_FREE; return disks; out_err: LIBXL__LOG(ctx, LIBXL__LOG_ERROR, \"Unable to list disks\"); while (disks && *num) { (*num)--; libxl_device_disk_dispose(&disks[*num]); } free(disks); return NULL; }", "target": 1, "idx": 109371, "project": "Xen"}
{"func": "static void tapdisk_control_get_pid(struct tapdisk_control_connection *connection, tapdisk_message_t *request) { tapdisk_message_t response; memset(&response, 0, sizeof(response)); response.type = TAPDISK_MESSAGE_PID_RSP; response.cookie = request->cookie; response.u.tapdisk_pid = getpid(); tapdisk_control_write_message(connection->socket, &response, 2); tapdisk_control_close_connection(connection); }", "target": 0, "idx": 106099, "project": "Xen"}
{"func": "void  help(void) { fprintf(stderr, \"Tapdisk Utilities: v1.0.0\\n\"); fprintf(stderr, \"usage: td-util COMMAND [TYPE] [OPTIONS]\\n\"); print_commands(); print_disk_types(); exit(-1); }", "target": 0, "idx": 106360, "project": "Xen"}
{"func": "static inline void __runq_remove(struct csched_vcpu *svc) { BUG_ON( !__vcpu_on_runq(svc) ); list_del_init(&svc->runq_elem); }", "target": 0, "idx": 105514, "project": "Xen"}
{"func": "static void colo_postsuspend_cb(libxl__egc *egc, libxl__checkpoint_devices_state *cds, int rc) { libxl__colo_save_state *css = cds->concrete_data; libxl__domain_save_state *dss = CONTAINER_OF(css, *dss, css); EGC_GC; if (rc) { LOGD(ERROR, dss->domid, \"postsuspend fails\"); goto out; } if (!css->svm_running) { rc = 0; goto out; }  css->callback = colo_read_svm_suspended_done; css->srs.checkpoint_callback = colo_common_read_stream_done; libxl__stream_read_checkpoint_state(egc, &css->srs); return; out: libxl__xc_domain_saverestore_async_callback_done(egc, &dss->sws.shs, !rc); }", "target": 0, "idx": 103445, "project": "Xen"}
{"func": "void psr_domain_free(struct domain *d) { psr_free_rmid(d); psr_free_cos(d); }", "target": 0, "idx": 105214, "project": "Xen"}
{"func": "unsigned long long xenstat_network_tbytes(xenstat_network * network) { return network->tbytes; }", "target": 0, "idx": 108371, "project": "Xen"}
{"func": "static void x86_pv_set_page_type(struct xc_sr_context *ctx, xen_pfn_t pfn,  unsigned long type) { assert(pfn <= ctx->x86_pv.max_pfn); ctx->x86_pv.restore.pfn_types[pfn] = type; }", "target": 0, "idx": 107750, "project": "Xen"}
{"func": "int xc_hvm_inject_trap( xc_interface *xch, uint32_t domid, int vcpu, uint8_t vector, uint8_t type, uint32_t error_code, uint8_t insn_len, uint64_t cr2) { return xendevicemodel_inject_event(xch->dmod, domid, vcpu, vector,  type, error_code, insn_len, cr2); }", "target": 0, "idx": 107364, "project": "Xen"}
{"func": "static void cuart_interrupt(int irq, void *data, struct cpu_user_regs *regs) { struct serial_port *port = data; struct cuart *uart = port->uart; unsigned int status; do { status = cuart_read(uart, R_UART_SR);  if ( status & UART_SR_INTR_RTRIG ) { serial_rx_interrupt(port, regs); cuart_write(uart, R_UART_CISR, UART_SR_INTR_RTRIG); } } while ( status & UART_SR_INTR_RTRIG ); }", "target": 0, "idx": 101307, "project": "Xen"}
{"func": " */ void init_apic_ldr_phys(void) { unsigned long val; apic_write(APIC_DFR, APIC_DFR_FLAT);  val = apic_read(APIC_LDR) & ~APIC_LDR_MASK; apic_write(APIC_LDR, val); }", "target": 0, "idx": 101641, "project": "Xen"}
{"func": "int libxl__prepare_acpi(libxl__gc *gc, libxl_domain_build_info *info, struct xc_dom_image *dom) { const libxl_version_info *vers; int rc = 0; struct acpitable acpitables[MAX_TABLE_NUMS]; vers = libxl_get_version_info(CTX); if (vers == NULL) { rc = ERROR_FAIL; goto out; } LOG(DEBUG, \"constructing ACPI tables for Xen version %d.%d guest\", vers->xen_version_major, vers->xen_version_minor); dom->acpi_modules[0].data = NULL; dom->acpi_modules[0].length = 0; dom->acpi_modules[0].guest_addr_out = GUEST_ACPI_BASE; rc = libxl__allocate_acpi_tables(gc, info, dom, acpitables); if (rc) goto out; make_acpi_rsdp(gc, dom, acpitables); make_acpi_xsdt(gc, dom, acpitables); make_acpi_gtdt(gc, dom, acpitables); rc = make_acpi_madt(gc, dom, info, acpitables); if (rc) goto out; make_acpi_fadt(gc, dom, acpitables); make_acpi_dsdt(gc, dom, acpitables); out: return rc; }", "target": 0, "idx": 103342, "project": "Xen"}
{"func": "static bool_t verify_patch_size(uint32_t patch_size) { uint32_t max_size; #define F1XH_MPB_MAX_SIZE 2048 #define F14H_MPB_MAX_SIZE 1824 #define F15H_MPB_MAX_SIZE 4096 #define F16H_MPB_MAX_SIZE 3458 #define F17H_MPB_MAX_SIZE 3200 switch (boot_cpu_data.x86) { case 0x14: max_size = F14H_MPB_MAX_SIZE; break; case 0x15: max_size = F15H_MPB_MAX_SIZE; break; case 0x16: max_size = F16H_MPB_MAX_SIZE; break; case 0x17: max_size = F17H_MPB_MAX_SIZE; break; default: max_size = F1XH_MPB_MAX_SIZE; break; } return (patch_size <= max_size); }", "target": 0, "idx": 104552, "project": "Xen"}
{"func": "int libxl__pci_numdevs(libxl__gc *gc) { DIR *dir; struct dirent *entry; int num_devs = 0; dir = opendir(\"/sys/bus/pci/devices\"); if (!dir) { LOGE(ERROR, \"Cannot open /sys/bus/pci/devices\"); return ERROR_FAIL; } while ((entry = readdir(dir))) { if (entry->d_name[0] == '.') continue; num_devs++; } closedir(dir); return num_devs; }", "target": 0, "idx": 103759, "project": "Xen"}
{"func": "void vm_event_vcpu_unpause(struct vcpu *v) { int old, new, prev = v->vm_event_pause_count.counter;  do { old = prev; new = old - 1; if ( new < 0 ) { printk(XENLOG_G_WARNING  \"%pv vm_event: Too many unpause attempts\\n\", v); return; } prev = cmpxchg(&v->vm_event_pause_count.counter, old, new); } while ( prev != old ); vcpu_unpause(v); }", "target": 0, "idx": 107072, "project": "Xen"}
{"func": "static inline bool has_cap(const struct csched2_vcpu *svc) { return svc->budget != STIME_MAX; }", "target": 0, "idx": 105557, "project": "Xen"}
{"func": "static void rt_deinit_pdata(const struct scheduler *ops, void *pcpu, int cpu) { unsigned long flags; struct rt_private *prv = rt_priv(ops); spin_lock_irqsave(&prv->lock, flags); if ( prv->repl_timer.cpu == cpu ) { struct cpupool *c = per_cpu(cpupool, cpu); unsigned int new_cpu = cpumask_cycle(cpu, cpupool_online_cpumask(c));  if ( new_cpu >= nr_cpu_ids ) { kill_timer(&prv->repl_timer); dprintk(XENLOG_DEBUG, \"RTDS: timer killed on cpu %d\\n\", cpu); } else { migrate_timer(&prv->repl_timer, new_cpu); } } spin_unlock_irqrestore(&prv->lock, flags); }", "target": 0, "idx": 105626, "project": "Xen"}
{"func": "static void print_stack_word(guest_word_t word, int width) { if (width == 2) printf(FMT_16B_WORD, word); else if (width == 4) printf(FMT_32B_WORD, word); else printf(FMT_64B_WORD, word); }", "target": 0, "idx": 108196, "project": "Xen"}
{"func": "int vcpu_set_data_type(struct vcpu_data *v, int type) { if (v->data_type == VCPU_DATA_NONE ) { v->data_type = type; switch(type) { case VCPU_DATA_HVM: init_hvm_data(&v->hvm, v); break; default: break; } } else assert(v->data_type == type); return 0; }", "target": 0, "idx": 108121, "project": "Xen"}
{"func": " */ YY_BUFFER_STATE xlu__disk_yy_scan_string (yyconst char * yystr , yyscan_t yyscanner) { return xlu__disk_yy_scan_bytes(yystr,strlen(yystr) ,yyscanner); }", "target": 0, "idx": 103269, "project": "Xen"}
{"func": "static inline uint32_t readl_gicc(unsigned int offset) { return readl_relaxed(gicv2.map_cbase + offset); }", "target": 0, "idx": 102435, "project": "Xen"}
{"func": "static int csched_init(struct scheduler *ops) { struct csched_private *prv; prv = xzalloc(struct csched_private); if ( prv == NULL ) return -ENOMEM; prv->balance_bias = xzalloc_array(uint32_t, MAX_NUMNODES); if ( prv->balance_bias == NULL ) { xfree(prv); return -ENOMEM; } if ( !zalloc_cpumask_var(&prv->cpus) ||  !zalloc_cpumask_var(&prv->idlers) ) { free_cpumask_var(prv->cpus); xfree(prv->balance_bias); xfree(prv); return -ENOMEM; } ops->sched_data = prv; spin_lock_init(&prv->lock); INIT_LIST_HEAD(&prv->active_sdom); prv->master = UINT_MAX; if ( sched_credit_tslice_ms > XEN_SYSCTL_CSCHED_TSLICE_MAX  || sched_credit_tslice_ms < XEN_SYSCTL_CSCHED_TSLICE_MIN ) { printk(\"WARNING: sched_credit_tslice_ms outside of valid range [%d,%d].\\n\"  \" Resetting to default %u\\n\",  XEN_SYSCTL_CSCHED_TSLICE_MIN,  XEN_SYSCTL_CSCHED_TSLICE_MAX,  CSCHED_DEFAULT_TSLICE_MS); sched_credit_tslice_ms = CSCHED_DEFAULT_TSLICE_MS; } __csched_set_tslice(prv, sched_credit_tslice_ms); if ( MICROSECS(sched_ratelimit_us) > MILLISECS(sched_credit_tslice_ms) ) { printk(\"WARNING: sched_ratelimit_us >\"   \"sched_credit_tslice_ms is undefined\\n\"  \"Setting ratelimit to tslice\\n\"); prv->ratelimit = prv->tslice; } else prv->ratelimit = MICROSECS(sched_ratelimit_us); if ( vcpu_migration_delay_us > XEN_SYSCTL_CSCHED_MGR_DLY_MAX_US ) { vcpu_migration_delay_us = 0; printk(\"WARNING: vcpu_migration_delay outside of valid range [0,%d]us.\\n\"  \"Resetting to default: %u\\n\",  XEN_SYSCTL_CSCHED_MGR_DLY_MAX_US, vcpu_migration_delay_us); } prv->vcpu_migr_delay = MICROSECS(vcpu_migration_delay_us); return 0; }", "target": 0, "idx": 105484, "project": "Xen"}
{"func": "static void dump_pic(void)  { HVM_SAVE_TYPE(PIC) p; READ(p); printf(\"PIC: IRQ base %#x, irr %#x, imr %#x, isr %#x\\n\",  p.irq_base, p.irr, p.imr, p.isr); printf(\" init_state %u, priority_add %u, readsel_isr %u, poll %u\\n\",  p.init_state, p.priority_add, p.readsel_isr, p.poll); printf(\" auto_eoi %u, rotate_on_auto_eoi %u\\n\",  p.auto_eoi, p.rotate_on_auto_eoi); printf(\" special_fully_nested_mode %u, special_mask_mode %u\\n\",  p.special_fully_nested_mode, p.special_mask_mode); printf(\" is_master %u, elcr %#x, int_output %#x\\n\",  p.is_master, p.elcr, p.int_output); }", "target": 0, "idx": 107875, "project": "Xen"}
{"func": "static inline void tapdisk_stream_initialize_request(struct tapdisk_stream_request *req) { memset(req, 0, sizeof(*req)); INIT_LIST_HEAD(&req->next); }", "target": 0, "idx": 106250, "project": "Xen"}
{"func": "int xc_machphys_mfn_list(xc_interface *xch,  unsigned long max_extents,  xen_pfn_t *extent_start) { int rc; DECLARE_HYPERCALL_BOUNCE(extent_start, max_extents * sizeof(xen_pfn_t), XC_HYPERCALL_BUFFER_BOUNCE_OUT); struct xen_machphys_mfn_list xmml = { .max_extents = max_extents, }; if ( xc_hypercall_bounce_pre(xch, extent_start) ) { PERROR(\"Could not bounce memory for XENMEM_machphys_mfn_list hypercall\"); return -1; } set_xen_guest_handle(xmml.extent_start, extent_start); rc = do_memory_op(xch, XENMEM_machphys_mfn_list, &xmml, sizeof(xmml)); if (rc || xmml.nr_extents != max_extents) rc = -1; else rc = 0; xc_hypercall_bounce_post(xch, extent_start); return rc; }", "target": 0, "idx": 107659, "project": "Xen"}
{"func": "static void pl011_tx_stop(struct serial_port *port) { struct pl011 *uart = port->uart; pl011_write(uart, IMSC, pl011_read(uart, IMSC) & ~(TXI)); }", "target": 0, "idx": 105059, "project": "Xen"}
{"func": "int mcequirk_amd_apply(enum mcequirk_amd_flags flags) { uint64_t val; switch ( flags ) { case MCEQUIRK_K8_GART:  wrmsrl(MSR_IA32_MCx_CTL(4), ~(1ULL << 10)); wrmsrl(MSR_IA32_MCx_STATUS(4), 0ULL); break; case MCEQUIRK_F10_GART: if ( rdmsr_safe(MSR_AMD64_MCx_MASK(4), val) == 0 ) wrmsr_safe(MSR_AMD64_MCx_MASK(4), val | (1 << 10)); break; } return 0; }", "target": 0, "idx": 104377, "project": "Xen"}
{"func": "int pv_ro_page_fault(unsigned long addr, struct cpu_user_regs *regs) { l1_pgentry_t pte; const struct domain *currd = current->domain; unsigned int addr_size = is_pv_32bit_domain(currd) ? 32 : BITS_PER_LONG; struct x86_emulate_ctxt ctxt = { .regs= regs, .vendor= currd->arch.cpuid->x86_vendor, .addr_size = addr_size, .sp_size = addr_size, .lma = addr_size > 32, }; int rc; bool mmio_ro;  pte = guest_get_eff_l1e(addr);  if ( ((l1e_get_flags(pte) & (_PAGE_PRESENT | _PAGE_RW)) != _PAGE_PRESENT) ) return 0; mmio_ro = is_hardware_domain(currd) && rangeset_contains_singleton(mmio_ro_ranges, l1e_get_pfn(pte)); if ( mmio_ro ) rc = mmio_ro_do_page_fault(&ctxt, addr, pte); else rc = ptwr_do_page_fault(&ctxt, addr, pte); switch ( rc ) { case X86EMUL_EXCEPTION:  if ( ctxt.event.type == X86_EVENTTYPE_HW_EXCEPTION &&  ctxt.event.vector == TRAP_page_fault ) pv_inject_event(&ctxt.event); else gdprintk(XENLOG_WARNING,  \"Unexpected event (type %u, vector %#x) from emulation\\n\",  ctxt.event.type, ctxt.event.vector);  case X86EMUL_OKAY: if ( ctxt.retire.singlestep ) pv_inject_hw_exception(TRAP_debug, X86_EVENT_NO_EC);  case X86EMUL_RETRY: if ( mmio_ro ) perfc_incr(mmio_ro_emulations); else perfc_incr(ptwr_emulations); return EXCRET_fault_fixed; } return 0; }", "target": 0, "idx": 105395, "project": "Xen"}
{"func": " *********************************************************************/ int __cpufreq_driver_target(struct cpufreq_policy *policy, unsigned int target_freq, unsigned int relation) { int retval = -EINVAL; if (cpu_online(policy->cpu) && cpufreq_driver->target) { unsigned int prev_freq = policy->cur; retval = cpufreq_driver->target(policy, target_freq, relation); if ( retval == 0 ) TRACE_2D(TRC_PM_FREQ_CHANGE, prev_freq/1000, policy->cur/1000); } return retval; }", "target": 0, "idx": 106619, "project": "Xen"}
{"func": "static void setup_signals(void (*handler)(int)) { struct sigaction sa; sigset_t spmask; int r; unwriteable_fd = open(\"/dev/null\",O_RDONLY); if (unwriteable_fd < 0) fail(errno,\"open /dev/null for reading\"); LIBXL_FILLZERO(sa); sa.sa_handler = handler; sigemptyset(&sa.sa_mask); r = sigaction(SIGTERM, &sa, 0); if (r) fail(errno,\"sigaction SIGTERM failed\"); sigemptyset(&spmask); sigaddset(&spmask,SIGTERM); r = sigprocmask(SIG_UNBLOCK,&spmask,0); if (r) fail(errno,\"sigprocmask unblock SIGTERM failed\"); }", "target": 0, "idx": 103963, "project": "Xen"}
{"func": "static int elfnote_dump_xen_version(xc_interface *xch, void *args,  dumpcore_rtn_t dump_rtn, unsigned int guest_width) { int sts; struct elfnote elfnote; struct xen_dumpcore_elfnote_xen_version_desc xen_version; elfnote_init(&elfnote); memset(&xen_version, 0, sizeof(xen_version)); elfnote.descsz = sizeof(xen_version); elfnote.type = XEN_ELFNOTE_DUMPCORE_XEN_VERSION; elfnote_fill_xen_version(xch, &xen_version); if (guest_width < sizeof(unsigned long)) {  char *p = (char *)&xen_version.pagesize; memmove(p - 4, p, sizeof(xen_version.pagesize)); } sts = dump_rtn(xch, args, (char*)&elfnote, sizeof(elfnote)); if ( sts != 0 ) return sts; return dump_rtn(xch, args, (char*)&xen_version, sizeof(xen_version)); }", "target": 0, "idx": 107306, "project": "Xen"}
{"func": " */ static int apply_payload(struct payload *data) { unsigned int i; int rc; printk(XENLOG_INFO LIVEPATCH \"%s: Applying %u functions\\n\", data->name, data->nfuncs); rc = arch_livepatch_quiesce(); if ( rc ) { printk(XENLOG_ERR LIVEPATCH \"%s: unable to quiesce!\\n\", data->name); return rc; }  spin_debug_disable(); for ( i = 0; i < data->n_load_funcs; i++ ) data->load_funcs[i](); spin_debug_enable(); ASSERT(!local_irq_is_enabled()); for ( i = 0; i < data->nfuncs; i++ ) arch_livepatch_apply(&data->funcs[i]); arch_livepatch_revive();  list_add_tail_rcu(&data->applied_list, &applied_list); register_virtual_region(&data->region); return 0; }", "target": 0, "idx": 104233, "project": "Xen"}
{"func": "int paging_log_dirty_disable(struct domain *d) { int ret; domain_pause(d);  ret = d->arch.paging.log_dirty.disable_log_dirty(d); if ( !paging_mode_log_dirty(d) ) paging_free_log_dirty_bitmap(d); domain_unpause(d); return ret; }", "target": 1, "idx": 109215, "project": "Xen"}
{"func": "static void init_amd(struct cpuinfo_x86 *c) { u32 l, h; unsigned long long value;  if (c->x86 == 15) { rdmsrl(MSR_K7_HWCR, value); value |= 1 << 6; wrmsrl(MSR_K7_HWCR, value); }  __clear_bit(X86_FEATURE_PBE, c->x86_capability);  if (c->x86 == 0xf && c->x86_model < 0x14 && cpu_has(c, X86_FEATURE_LAHF_LM)) {  __clear_bit(X86_FEATURE_LAHF_LM, c->x86_capability); if (!rdmsr_amd_safe(0xc001100d, &l, &h)) wrmsr_amd_safe(0xc001100d, l, h & ~1); }  __set_bit(X86_FEATURE_MFENCE_RDTSC, c->x86_capability); switch(c->x86) { case 0xf ... 0x17: disable_c1e(NULL); if (acpi_smi_cmd && (acpi_enable_value | acpi_disable_value)) pv_post_outb_hook = check_disable_c1e; break; } display_cacheinfo(c); if (c->extended_cpuid_level >= 0x80000008) { c->x86_max_cores = (cpuid_ecx(0x80000008) & 0xff) + 1; } if (c->extended_cpuid_level >= 0x80000007) { if (cpu_has(c, X86_FEATURE_ITSC)) { __set_bit(X86_FEATURE_CONSTANT_TSC, c->x86_capability); __set_bit(X86_FEATURE_NONSTOP_TSC, c->x86_capability); if (c->x86 != 0x11) __set_bit(X86_FEATURE_TSC_RELIABLE, c->x86_capability); } }  if ((c->x86 == 0x15) && (c->x86_model >= 0x10) && (c->x86_model <= 0x1f) && !cpu_has(c, X86_FEATURE_TOPOEXT) && !rdmsr_safe(MSR_K8_EXT_FEATURE_MASK, value)) { value |= 1ULL << 54; wrmsr_safe(MSR_K8_EXT_FEATURE_MASK, value); rdmsrl(MSR_K8_EXT_FEATURE_MASK, value); if (value & (1ULL << 54)) { __set_bit(X86_FEATURE_TOPOEXT, c->x86_capability); printk(KERN_INFO \"CPU: Re-enabling disabled \"  \"Topology Extensions Support\\n\"); } }  if (c->x86 == 0x15 && c->x86_model >= 0x02 && c->x86_model < 0x20 && !rdmsr_safe(MSR_AMD64_IC_CFG, value) && (value & 0x1e) != 0x1e) wrmsr_safe(MSR_AMD64_IC_CFG, value | 0x1e); amd_get_topology(c);  if (c->x86 == 0x10) __clear_bit(X86_FEATURE_MONITOR, c->x86_capability); if (!cpu_has_amd_erratum(c, AMD_ERRATUM_121)) opt_allow_unsafe = 1; else if (opt_allow_unsafe < 0) panic(\"Xen will not boot on this CPU for security reasons\" \"Pass \\\"allow_unsafe\\\" if you're trusting all your\" \" (PV) guest kernels.\\n\"); else if (!opt_allow_unsafe && c == &boot_cpu_data) printk(KERN_WARNING  \"*** Xen will not allow creation of DomU-s on\"  \" this CPU for security reasons. ***\\n\"  KERN_WARNING  \"*** Pass \\\"allow_unsafe\\\" if you're trusting\"  \" all your (PV) guest kernels. ***\\n\"); if (c->x86 == 0x16 && c->x86_model <= 0xf) { if (c == &boot_cpu_data) { l = pci_conf_read32(0, 0, 0x18, 0x3, 0x58); h = pci_conf_read32(0, 0, 0x18, 0x3, 0x5c); if ((l & 0x1f) | (h & 0x1)) printk(KERN_WARNING  \"Applying workaround for erratum 792: %s%s%s\\n\",  (l & 0x1f) ? \"clearing D18F3x58[4:0]\" : \"\",  ((l & 0x1f) && (h & 0x1)) ? \" and \" : \"\",  (h & 0x1) ? \"clearing D18F3x5C[0]\" : \"\"); if (l & 0x1f) pci_conf_write32(0, 0, 0x18, 0x3, 0x58,  l & ~0x1f); if (h & 0x1) pci_conf_write32(0, 0, 0x18, 0x3, 0x5c,  h & ~0x1); } rdmsrl(MSR_AMD64_LS_CFG, value); if (!(value & (1 << 15))) { static bool_t warned; if (c == &boot_cpu_data || opt_cpu_info || !test_and_set_bool(warned)) printk(KERN_WARNING  \"CPU%u: Applying workaround for erratum 793\\n\",  smp_processor_id()); wrmsrl(MSR_AMD64_LS_CFG, value | (1 << 15)); } } else if (c->x86 == 0x12) { rdmsrl(MSR_AMD64_DE_CFG, value); if (!(value & (1U << 31))) { static bool warned; if (c == &boot_cpu_data || opt_cpu_info || !test_and_set_bool(warned)) printk(KERN_WARNING  \"CPU%u: Applying workaround for erratum 665\\n\",  smp_processor_id()); wrmsrl(MSR_AMD64_DE_CFG, value | (1U << 31)); } }  __clear_bit(X86_FEATURE_SEP, c->x86_capability); if (c->x86 == 0x10) {  if (c == &boot_cpu_data) check_enable_amd_mmconf_dmi(); fam10h_check_enable_mmcfg();  rdmsrl(MSR_F10_BU_CFG2, value); value &= ~(1ULL << 24); wrmsrl(MSR_F10_BU_CFG2, value); }  if ( opt_arat && c->x86 > 0x11 ) __set_bit(X86_FEATURE_ARAT, c->x86_capability);  if (nmi_watchdog != NMI_LOCAL_APIC && c->x86 < 0x14) { wrmsrl(MSR_K7_PERFCTR0, 0); wrmsrl(MSR_K7_PERFCTR1, 0); wrmsrl(MSR_K7_PERFCTR2, 0); wrmsrl(MSR_K7_PERFCTR3, 0); } if (cpu_has(c, X86_FEATURE_EFRO)) { rdmsr(MSR_K7_HWCR, l, h); l |= (1 << 27);  wrmsr(MSR_K7_HWCR, l, h); }  if ((smp_processor_id() == 1) && !cpu_has(c, X86_FEATURE_ITSC)) disable_c1_ramping(); check_syscfg_dram_mod_en(); }", "target": 1, "idx": 109619, "project": "Xen"}
{"func": "EXPORT_SYMBOL(__bitmap_andnot); int __bitmap_intersects(const unsigned long *bitmap1, const unsigned long *bitmap2, int bits) { int k, lim = bits/BITS_PER_LONG; for (k = 0; k < lim; ++k) if (bitmap1[k] & bitmap2[k]) return 1; if (bits % BITS_PER_LONG) if ((bitmap1[k] & bitmap2[k]) & BITMAP_LAST_WORD_MASK(bits)) return 1; return 0; }", "target": 0, "idx": 101009, "project": "Xen"}
{"func": "void writer(struct libxenvchan *ctrl) { int size; for (;;) { size = rand() % (BUFSIZE - 1) + 1; size = read(0, buf, size); if (size < 0) { perror(\"read stdin\"); libxenvchan_close(ctrl); exit(1); } if (size == 0) break; size = libxenvchan_write_all(ctrl, buf, size); fprintf(stderr, \"#\"); if (size < 0) { perror(\"vchan write\"); exit(1); } if (size == 0) { perror(\"write size=0?\\n\"); exit(1); } } }", "target": 0, "idx": 104871, "project": "Xen"}
{"func": "int xc_tbuf_disable(xc_interface *xch) { return tbuf_enable(xch, 0); }", "target": 0, "idx": 107813, "project": "Xen"}
{"func": "TIFFErrorHandlerExt TIFFSetErrorHandlerExt(TIFFErrorHandlerExt handler) { TIFFErrorHandlerExt prev = _TIFFerrorHandlerExt; _TIFFerrorHandlerExt = handler; return (prev); }", "target": 0, "idx": 100162, "project": "LibTIFF"}
{"func": "static int processCompressOptions(char* opt) { if (streq(opt, \"none\")) compression = COMPRESSION_NONE; else if (streq(opt, \"packbits\")) compression = COMPRESSION_PACKBITS; else if (strneq(opt, \"g3\", 2)) { processG3Options(opt); compression = COMPRESSION_CCITTFAX3; } else if (streq(opt, \"g4\")) compression = COMPRESSION_CCITTFAX4; else if (strneq(opt, \"lzw\", 3)) { char* cp = strchr(opt, ':'); if (cp) predictor = atoi(cp+1); compression = COMPRESSION_LZW; } else if (strneq(opt, \"zip\", 3)) { char* cp = strchr(opt, ':'); if (cp) predictor = atoi(cp+1); compression = COMPRESSION_DEFLATE; } else return (0); return (1); }", "target": 0, "idx": 100483, "project": "LibTIFF"}
{"func": "void sched_runstate_process(struct pcpu_info *p) { enum { CHANGE=0, CONTINUE } type; struct vcpu_data *v; struct record_info *ri = &p->ri; struct { unsigned vcpu:16, dom:16; unsigned long long p1, p2; } __attribute__((packed)) * r = (typeof(r))ri->d; union { unsigned int event; struct { unsigned lo:4, new_runstate:4, old_runstate:4, sub:4, main:12, unused:4; }; } _sevt = { .event = ri->event }; struct { int new_runstate, old_runstate; } sevt; int perfctrs; struct last_oldstate_struct last_oldstate; switch(_sevt.lo) { case 1: type = CHANGE; sevt.new_runstate = _sevt.new_runstate; sevt.old_runstate = _sevt.old_runstate; break; case 2: type = CONTINUE; sevt.new_runstate = sevt.old_runstate = RUNSTATE_RUNNING; break; default: fprintf(warn, \"FATAL: Unexpected runstate change type %d!\\n\", _sevt.lo); error(ERR_RECORD, NULL); return; } perfctrs = (ri->extra_words == 5); if(opt.dump_all) { if( perfctrs ) { printf(\" %s %s {%lld,%lld} d%uv%u %s->%s\\n\",  ri->dump_header,  type?\"runstate_continue\":\"runstate_change\",  r->p1, r->p2,  r->dom, r->vcpu,  runstate_name[sevt.old_runstate],  runstate_name[sevt.new_runstate]); } else { printf(\" %s %s d%uv%u %s->%s\\n\",  ri->dump_header,  type?\"runstate_continue\":\"runstate_change\",  r->dom, r->vcpu,  runstate_name[sevt.old_runstate],  runstate_name[sevt.new_runstate]); } }  if ( type == CHANGE ) { if( (sevt.new_runstate == RUNSTATE_RUNNING  && sevt.old_runstate != RUNSTATE_RUNNABLE) || (sevt.new_runstate == RUNSTATE_BLOCKED && sevt.old_runstate == RUNSTATE_RUNNABLE ) ) { fprintf(warn, \"Strange, d%dv%d unexpected runstate transition %s->%s\\n\", r->dom, r->vcpu, runstate_name[sevt.old_runstate], runstate_name[sevt.new_runstate]); } } if(r->vcpu > MAX_CPUS) { fprintf(warn, \"%s: vcpu %u > MAX_VCPUS %d!\\n\", __func__, r->vcpu, MAX_CPUS); return; } v = vcpu_find(r->dom, r->vcpu);  last_oldstate = v->runstate.last_oldstate; v->runstate.last_oldstate.wrong = RUNSTATE_INIT;  if(sevt.new_runstate == RUNSTATE_RUNNABLE  && v->data_type == VCPU_DATA_HVM  && v->hvm.vmexit_valid) { hvm_close_vmexit(&v->hvm, ri->tsc); }  if ( v->data_type == VCPU_DATA_HVM && v->runstate.state != RUNSTATE_LOST ) { if ( sevt.new_runstate == RUNSTATE_RUNNABLE  && sevt.old_runstate == RUNSTATE_BLOCKED ) {  if(opt.dump_all) printf(\" [w2h] d%dv%d Setting waking\\n\", v->d->did, v->vid); v->hvm.w2h.waking = 1; } else if ( sevt.new_runstate != RUNSTATE_RUNNING || sevt.old_runstate != RUNSTATE_RUNNABLE ) { if( v->hvm.w2h.waking && sevt.old_runstate == RUNSTATE_RUNNING && sevt.new_runstate != RUNSTATE_OFFLINE ) {  if ( sevt.old_runstate != v->runstate.state ) fprintf(warn, \"Strange, unexpected waking transition for d%dv%d: %s -> %s\\n\", v->d->did, v->vid, runstate_name[sevt.old_runstate], runstate_name[sevt.new_runstate]); v->hvm.w2h.waking = 0; }   if (sevt.new_runstate == RUNSTATE_BLOCKED && sevt.old_runstate == RUNSTATE_RUNNING && v->hvm.w2h.interrupts ) { int i; for(i=0; i<GUEST_INTERRUPT_MAX; i++) { struct hvm_gi_struct *g=v->hvm.summary.guest_interrupt + i; tsc_t start_tsc = g->start_tsc; if(start_tsc) { tsc_t t = (start_tsc == 1) ? 0 : ri->tsc - start_tsc; if(opt.dump_all) printf(\" [w2h] Halting vec %d is_wake %d time %lld\\n\",  i,  g->is_wake,  t); if(opt.scatterplot_wake_to_halt  && t  && g->is_wake) scatterplot_vs_time(ri->tsc, t); if(opt.summary && t) { if(g->is_wake) { if(v->hvm.w2h.interrupts==1) update_cycles(&g->runtime[GUEST_INTERRUPT_CASE_WAKE_TO_HALT_ALONE], t); update_cycles(&g->runtime[GUEST_INTERRUPT_CASE_WAKE_TO_HALT_ANY], t); } else { update_cycles(&g->runtime[GUEST_INTERRUPT_CASE_INTERRUPT_TO_HALT], t); } } g->start_tsc = 0; g->is_wake = 0; } } v->hvm.w2h.interrupts = 0; v->hvm.w2h.vector = 0; } } }  if( v->runstate.state != sevt.old_runstate && v->runstate.state != RUNSTATE_INIT ) { if(v->runstate.state == RUNSTATE_LOST) { if( sevt.new_runstate == RUNSTATE_RUNNING ) goto update; else if(opt.dump_all) fprintf(warn, \"%s: d%dv%d in runstate lost, not updating to %s\\n\", __func__, v->d->did, v->vid, runstate_name[sevt.new_runstate]); goto no_update; } else if (last_oldstate.wrong == sevt.new_runstate  && last_oldstate.actual == sevt.old_runstate) { tsc_t lag, old_offset; struct pcpu_info *p2; if(ri->tsc < last_oldstate.tsc) { fprintf(warn, \"WARNING: new tsc %lld < detected runstate tsc %lld! Not updating\\n\", ri->tsc, last_oldstate.tsc); goto no_update; } p2 = P.pcpu + last_oldstate.pid; lag = ri->tsc - last_oldstate.tsc; old_offset = p2->tsc_skew.offset; cpumask_union(&p2->tsc_skew.downstream, &p->tsc_skew.downstream); cpumask_set(&p2->tsc_skew.downstream, p->pid); if(cpumask_isset(&p2->tsc_skew.downstream, p2->pid)) { if ( opt.tsc_loop_fatal ) { fprintf(stderr, \"FATAL: tsc skew dependency loop detected!\\n\"); error(ERR_FILE, NULL); } else { int i; fprintf(warn, \"Tsc skew dependency loop detected!Resetting...\\n\"); for ( i=0; i<=P.max_active_pcpu; i++) { struct pcpu_info *p = P.pcpu + i; p->tsc_skew.offset = 0; cpumask_init(&p->tsc_skew.downstream); } goto no_update; } } p2->tsc_skew.offset += lag * 2; fprintf(warn, \"TSC skew detected p%d->p%d, %lld cycles. Changing p%d offset from %lld to %lld\\n\", p->pid, p2->pid, lag, p2->pid, old_offset, p2->tsc_skew.offset); goto no_update; } else { fprintf(warn, \"runstate_change old_runstate %s, d%dv%d runstate %s.Possible tsc skew.\\n\", runstate_name[sevt.old_runstate], v->d->did, v->vid, runstate_name[v->runstate.state]); v->runstate.last_oldstate.wrong = sevt.old_runstate; v->runstate.last_oldstate.actual = v->runstate.state; v->runstate.last_oldstate.tsc = ri->tsc; v->runstate.last_oldstate.pid = p->pid; if ( v->runstate.state == RUNSTATE_RUNNING ) { fprintf(warn, \" Not updating.\\n\"); goto no_update; } goto update; } fprintf(stderr, \"FATAL: Logic hole in %s\\n\", __func__); error(ERR_ASSERT, NULL); } update:  if ( type == CONTINUE ) { if( v->runstate.state == RUNSTATE_INIT ) {  vcpu_start(p, v); } else {  if ( v->runstate.state == RUNSTATE_LOST ) { fprintf(warn, \"WARNING: continue with d%dv%d in RUNSTATE_LOST.Resetting current.\\n\", v->d->did, v->vid); if ( p->current ) vcpu_prev_update(p, p->current, ri->tsc, RUNSTATE_LOST); vcpu_next_update(p, v, ri->tsc); } else if( v->runstate.state != RUNSTATE_RUNNING ) {  fprintf(warn, \"FATAL: sevt.old_runstate running, but d%dv%d runstate %s!\\n\", v->d->did, v->vid, runstate_name[v->runstate.state]); error(ERR_FILE, NULL); } else if ( v->p != p ) { fprintf(warn, \"FATAL: continue on p%d, but d%dv%d p%d!\\n\", p->pid, v->d->did, v->vid, v->p ? v->p->pid : -1); error(ERR_FILE, NULL); } runstate_update(v, RUNSTATE_RUNNING, ri->tsc); } } else if ( sevt.old_runstate == RUNSTATE_RUNNING || v->runstate.state == RUNSTATE_RUNNING ) {  if( sevt.old_runstate == RUNSTATE_RUNNING ) { if( v->runstate.state == RUNSTATE_INIT ) {  vcpu_start(p, v); } else if( v->runstate.state != RUNSTATE_RUNNING  && v->runstate.state != RUNSTATE_LOST ) {  fprintf(warn, \"FATAL: sevt.old_runstate running, but d%dv%d runstate %s!\\n\", v->d->did, v->vid, runstate_name[v->runstate.state]); error(ERR_FILE, NULL); } vcpu_prev_update(p, v, ri->tsc, sevt.new_runstate); } else { vcpu_prev_update(v->p, v, ri->tsc, sevt.new_runstate); } if(P.lost_cpus && v->d->did != IDLE_DOMAIN) { if(opt.dump_all) fprintf(warn, \"%s: %d lost cpus, setting d%dv%d runstate to RUNSTATE_LOST\\n\", __func__, P.lost_cpus, v->d->did, v->vid); lose_vcpu(v, ri->tsc); } } else if ( sevt.new_runstate == RUNSTATE_RUNNING ) { if(perfctrs) { v->runstate.p1_start = r->p1; v->runstate.p2_start = r->p2; } vcpu_next_update(p, v, ri->tsc); } else if ( v->runstate.state != RUNSTATE_INIT ) {  runstate_update(v, sevt.new_runstate, ri->tsc); } no_update: return; }", "target": 0, "idx": 108091, "project": "Xen"}
{"func": "static void kdd_xc_log(struct xentoollog_logger *logger,  xentoollog_level level,  int errnoval ,  const char *context ,  const char *format ,  va_list al) { kdd_guest *g = (kdd_guest *) logger;  if (g->verbosity < 1 || (level < XTL_WARN && g->verbosity < 3)) return; fprintf(g->log, \"libxc[%s:%i:%i]: \", context ? : \"?\", level, errnoval); vfprintf(g->log, format, al); fprintf(g->log, \"\\n\"); (void) fflush(g->log); }", "target": 0, "idx": 102930, "project": "Xen"}
{"func": "void xenstat_uninit_networks(xenstat_handle * handle) { struct priv_data *priv = get_priv_data(handle); if (priv != NULL && priv->procnetdev != NULL) fclose(priv->procnetdev); }", "target": 0, "idx": 108411, "project": "Xen"}
{"func": "int libxl__arch_vnuma_build_vmemrange(libxl__gc *gc, uint32_t domid, libxl_domain_build_info *b_info, libxl__domain_build_state *state) { int nid, nr_vmemrange, rc; uint32_t nr_e820, e820_count; struct e820entry map[E820MAX]; xen_vmemrange_t *vmemranges; unsigned int array_size;  if (!(b_info->type == LIBXL_DOMAIN_TYPE_PV && libxl_defbool_val(b_info->u.pv.e820_host))) return libxl__vnuma_build_vmemrange_pv_generic(gc, domid, b_info,  state); assert(state->vmemranges == NULL); nr_e820 = E820MAX; rc = e820_host_sanitize(gc, b_info, map, &nr_e820); if (rc) goto out; e820_count = 0; nr_vmemrange = 0; vmemranges = NULL; array_size = 0; for (nid = 0; nid < b_info->num_vnuma_nodes; nid++) { libxl_vnode_info *p = &b_info->vnuma_nodes[nid]; uint64_t remaining_bytes = (p->memkb << 10), bytes; while (remaining_bytes > 0) { if (e820_count >= nr_e820) { rc = ERROR_NOMEM; goto out; }  if (map[e820_count].type != E820_RAM) { e820_count++; continue; } if (nr_vmemrange >= array_size) { array_size += 32; GCREALLOC_ARRAY(vmemranges, array_size); } bytes = map[e820_count].size >= remaining_bytes ? remaining_bytes : map[e820_count].size; vmemranges[nr_vmemrange].start = map[e820_count].addr; vmemranges[nr_vmemrange].end = map[e820_count].addr + bytes; if (map[e820_count].size >= remaining_bytes) { map[e820_count].addr += bytes; map[e820_count].size -= bytes; } else { e820_count++; } remaining_bytes -= bytes; vmemranges[nr_vmemrange].flags = 0; vmemranges[nr_vmemrange].nid = nid; nr_vmemrange++; } } state->vmemranges = vmemranges; state->num_vmemranges = nr_vmemrange; rc = 0; out: return rc; }", "target": 0, "idx": 104196, "project": "Xen"}
{"func": "static uint32_t TSS32(struct ti *ti, struct to *to,  uint32_t ebx, uint32_t ecx, uint32_t edx) { uint32_t rc = 0; if (TCG_IsShutdownPreBootInterface() == 0) { rc = TCG_PC_UNSUPPORTED; } else { rc = (TCG_PC_TPMERROR | ((uint32_t)TCG_INTERFACE_SHUTDOWN << 16)); } if (rc != 0) { to->opblength = 4; to->reserved= 0; } return rc; }", "target": 0, "idx": 106355, "project": "Xen"}
{"func": "static int TIFFWriteRational(TIFF* tif, TIFFDataType type, ttag_t tag, TIFFDirEntry* dir, float v) { return (TIFFWriteRationalArray(tif, type, tag, dir, 1, &v)); }", "target": 0, "idx": 100264, "project": "LibTIFF"}
{"func": " */ void libxl__ctx_lock(libxl_ctx *ctx) { __coverity_recursive_lock_acquire__(&ctx->lock); }", "target": 0, "idx": 104642, "project": "Xen"}
{"func": "void GetTIFFHeader() { register int i; if (!TIFFSetDirectory(tfFile, tfDirectory)) { fprintf(stderr, \"xtiff: can't seek to directory %d in %s\\n\", tfDirectory, fileName); exit(0); } TIFFGetField(tfFile, TIFFTAG_IMAGEWIDTH, &tfImageWidth); TIFFGetField(tfFile, TIFFTAG_IMAGELENGTH, &tfImageHeight);  TIFFGetFieldDefaulted(tfFile, TIFFTAG_BITSPERSAMPLE, &tfBitsPerSample); TIFFGetFieldDefaulted(tfFile, TIFFTAG_SAMPLESPERPIXEL, &tfSamplesPerPixel); TIFFGetFieldDefaulted(tfFile, TIFFTAG_PLANARCONFIG, &tfPlanarConfiguration); TIFFGetFieldDefaulted(tfFile, TIFFTAG_GRAYRESPONSEUNIT, &tfGrayResponseUnit); tfUnitMap = tfGrayResponseUnitMap[tfGrayResponseUnit]; colormapSize = 1 << tfBitsPerSample; tfImageDepth = tfBitsPerSample * tfSamplesPerPixel; dRed = (double *) malloc(colormapSize * sizeof(double)); dGreen = (double *) malloc(colormapSize * sizeof(double)); dBlue = (double *) malloc(colormapSize * sizeof(double)); MCHECK(dRed); MCHECK(dGreen); MCHECK(dBlue);  if (!TIFFGetField(tfFile, TIFFTAG_PHOTOMETRIC, &tfPhotometricInterpretation)) { if (tfSamplesPerPixel != 1) tfPhotometricInterpretation = PHOTOMETRIC_RGB; else if (tfBitsPerSample == 1) tfPhotometricInterpretation = PHOTOMETRIC_MINISBLACK; else if (TIFFGetField(tfFile, TIFFTAG_COLORMAP, &redMap, &greenMap, &blueMap)) { tfPhotometricInterpretation = PHOTOMETRIC_PALETTE; redMap = greenMap = blueMap = NULL; } else tfPhotometricInterpretation = PHOTOMETRIC_MINISBLACK; }  switch (tfPhotometricInterpretation) { case PHOTOMETRIC_RGB: redMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); greenMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); blueMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); MCHECK(redMap); MCHECK(greenMap); MCHECK(blueMap); for (i = 0; i < colormapSize; i++) dRed[i] = dGreen[i] = dBlue[i] = (double) SCALE(i, colormapSize - 1); break; case PHOTOMETRIC_PALETTE: if (!TIFFGetField(tfFile, TIFFTAG_COLORMAP, &redMap, &greenMap, &blueMap)) { redMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); greenMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); blueMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); MCHECK(redMap); MCHECK(greenMap); MCHECK(blueMap); for (i = 0; i < colormapSize; i++) dRed[i] = dGreen[i] = dBlue[i] = (double) SCALE(i, colormapSize - 1); } else { CheckAndCorrectColormap(); for (i = 0; i < colormapSize; i++) { dRed[i] = (double) redMap[i]; dGreen[i] = (double) greenMap[i]; dBlue[i] = (double) blueMap[i]; } } break; case PHOTOMETRIC_MINISWHITE: redMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); greenMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); blueMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); MCHECK(redMap); MCHECK(greenMap); MCHECK(blueMap); for (i = 0; i < colormapSize; i++) dRed[i] = dGreen[i] = dBlue[i] = (double)  SCALE(colormapSize-1-i, colormapSize-1); break; case PHOTOMETRIC_MINISBLACK: redMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); greenMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); blueMap = (uint16 *) malloc(colormapSize * sizeof(uint16)); MCHECK(redMap); MCHECK(greenMap); MCHECK(blueMap); for (i = 0; i < colormapSize; i++) dRed[i] = dGreen[i] = dBlue[i] = (double) SCALE(i, colormapSize-1); break; default: fprintf(stderr, \"xtiff: can't display photometric interpretation type %d\\n\", tfPhotometricInterpretation); exit(0); } }", "target": 0, "idx": 100542, "project": "LibTIFF"}
{"func": "int hvm_param_set(uint32_t index, uint64_t value) { struct xen_hvm_param p; p.domid = DOMID_SELF; p.index = index; p.value = value; return hypercall_hvm_op(HVMOP_set_param, &p); }", "target": 0, "idx": 102671, "project": "Xen"}
{"func": "static struct brcm_plat_regs regs; static __init int brcm_get_dt_node(char *compat_str,  const struct dt_device_node **dn,  u32 *reg_base) { const struct dt_device_node *node; u64 reg_base_64; int rc; node = dt_find_compatible_node(NULL, NULL, compat_str); if ( !node ) { dprintk(XENLOG_ERR, \"%s: missing \\\"%s\\\" node\\n\", __func__, compat_str); return -ENOENT; } rc = dt_device_get_address(node, 0, &reg_base_64, NULL); if ( rc ) { dprintk(XENLOG_ERR, \"%s: missing \\\"reg\\\" prop\\n\", __func__); return rc; } if ( dn ) *dn = node; if ( reg_base ) *reg_base = reg_base_64; return 0; }", "target": 0, "idx": 101271, "project": "Xen"}
{"func": "static void domain_suspend_callback_common(libxl__egc *egc,  libxl__domain_suspend_state *dsps) { STATE_AO_GC(dsps->ao); uint64_t hvm_s_state = 0, hvm_pvdrv = 0; int ret, rc;  const uint32_t domid = dsps->domid; if (dsps->type != LIBXL_DOMAIN_TYPE_PV) { xc_hvm_param_get(CTX->xch, domid, HVM_PARAM_CALLBACK_IRQ, &hvm_pvdrv); xc_hvm_param_get(CTX->xch, domid, HVM_PARAM_ACPI_S_STATE, &hvm_s_state); } if ((hvm_s_state == 0) && (dsps->guest_evtchn.port >= 0)) { LOGD(DEBUG, domid, \"issuing %s suspend request via event channel\", dsps->type != LIBXL_DOMAIN_TYPE_PV ? \"PVH/HVM\" : \"PV\"); ret = xenevtchn_notify(CTX->xce, dsps->guest_evtchn.port); if (ret < 0) { LOGD(ERROR, domid, \"xenevtchn_notify failed ret=%d\", ret); rc = ERROR_FAIL; goto err; } dsps->guest_evtchn.callback = domain_suspend_common_wait_guest_evtchn; rc = libxl__ev_evtchn_wait(gc, &dsps->guest_evtchn); if (rc) goto err; rc = libxl__ev_time_register_rel(ao, &dsps->guest_timeout,  suspend_common_wait_guest_timeout,  60*1000); if (rc) goto err; return; } if (dsps->type == LIBXL_DOMAIN_TYPE_HVM && (!hvm_pvdrv || hvm_s_state)) { LOGD(DEBUG, domid, \"Calling xc_domain_shutdown on HVM domain\"); ret = xc_domain_shutdown(CTX->xch, domid, SHUTDOWN_suspend); if (ret < 0) { LOGED(ERROR, domid, \"xc_domain_shutdown failed\"); rc = ERROR_FAIL; goto err; }  dsps->guest_responded = 1; domain_suspend_common_wait_guest(egc, dsps); return; } LOGD(DEBUG, domid, \"issuing %s suspend request via XenBus control node\", dsps->type != LIBXL_DOMAIN_TYPE_PV ? \"PVH/HVM\" : \"PV\"); libxl__domain_pvcontrol_write(gc, XBT_NULL, domid, \"suspend\"); dsps->pvcontrol.path = libxl__domain_pvcontrol_xspath(gc, domid); if (!dsps->pvcontrol.path) { rc = ERROR_FAIL; goto err; } dsps->pvcontrol.ao = ao; dsps->pvcontrol.what = \"guest acknowledgement of suspend request\"; dsps->pvcontrol.timeout_ms = 60 * 1000; dsps->pvcontrol.callback = domain_suspend_common_pvcontrol_suspending; libxl__xswait_start(gc, &dsps->pvcontrol); return;  err: domain_suspend_common_done(egc, dsps, rc); }", "target": 0, "idx": 103577, "project": "Xen"}
{"func": "int main_setenforce(int argc, char **argv) { int ret, mode; const char *p = NULL; if (optind >= argc) { help(\"setenforce\"); return 2; } p = argv[optind]; if (!strcmp(p, \"0\")) mode = 0; else if (!strcmp(p, \"1\")) mode = 1; else if (!strcasecmp(p, \"permissive\")) mode = 0; else if (!strcasecmp(p, \"enforcing\")) mode = 1; else { help(\"setenforce\"); return 2; } ret = libxl_flask_setenforce(ctx, mode); if (ret) { if (errno == ENOSYS) { fprintf(stderr, \"Flask XSM disabled\\n\"); } else fprintf(stderr, \"error occured while setting enforcing mode (%i)\\n\", ret); } return ret; }", "target": 0, "idx": 108672, "project": "Xen"}
{"func": "static int NFSnormalizedStatTime(char *fn, struct stat *statnow, int *reterrno) { int result = LOCK_OK; int uniq; char *buf; int fd; int pid = (int)getpid(); int clstat; *reterrno = 0;  srandom((int)time(0) ^ pid); uniq = random() % 0xffffff; buf = malloc(strlen(fn) + 24); if (unlikely(!buf)) { result = LOCK_ENOMEM; goto finish; } strcpy(buf, fn); sprintf(buf + strlen(buf), \".xen%08d.tmp\", uniq); fd = open(buf, O_WRONLY | O_CREAT, 0644); if (fd == -1) { *reterrno = errno; result = LOCK_EOPEN; goto finish; } clstat = close(fd); if (unlikely(clstat == -1)) { LOG(\"fail on close\\n\"); } if (lstat(buf, statnow) == -1) { unlink(buf); *reterrno = errno; result = LOCK_ESTAT; goto finish; } unlink(buf); finish: return result; }", "target": 0, "idx": 104282, "project": "Xen"}
{"func": " */ static bool write_itte(struct virt_its *its, uint32_t devid,  uint32_t evid, uint32_t collid, uint32_t vlpi) { paddr_t addr; struct vits_itte itte; ASSERT(spin_is_locked(&its->its_lock)); addr = its_get_itte_address(its, devid, evid); if ( addr == INVALID_PADDR ) return false; itte.collection = collid; itte.vlpi = vlpi; if ( access_guest_memory_by_ipa(its->d, addr, &itte, sizeof(itte), true) ) return false; return true; }", "target": 0, "idx": 106738, "project": "Xen"}
{"func": "static void update_reference_tsc(struct domain *d, bool_t initialize) { unsigned long gmfn = d->arch.hvm_domain.viridian.reference_tsc.fields.pfn; struct page_info *page = get_page_from_gfn(d, gmfn, NULL, P2M_ALLOC); HV_REFERENCE_TSC_PAGE *p; if ( !page || !get_page_type(page, PGT_writable_page) ) { if ( page ) put_page(page); gdprintk(XENLOG_WARNING, \"Bad GMFN %#\"PRI_gfn\" (MFN %#\"PRI_mfn\")\\n\",  gmfn, mfn_x(page ? page_to_mfn(page) : INVALID_MFN)); return; } p = __map_domain_page(page); if ( initialize ) clear_page(p);  if ( !host_tsc_is_safe() || d->arch.vtsc ) {  p->TscSequence = 0; printk(XENLOG_G_INFO \"d%d: VIRIDIAN REFERENCE_TSC: invalidated\\n\",  d->domain_id); goto out; }  p->TscScale = ((10000ul << 32) / d->arch.tsc_khz) << 32; p->TscSequence++; if ( p->TscSequence == 0xFFFFFFFF ||  p->TscSequence == 0 )  p->TscSequence = 1;  out: unmap_domain_page(p); put_page_and_type(page); }", "target": 0, "idx": 106895, "project": "Xen"}
{"func": "static int viridian_load_domain_ctxt(struct domain *d, hvm_domain_context_t *h) { struct hvm_viridian_domain_context ctxt; if ( hvm_load_entry_zeroextend(VIRIDIAN_DOMAIN, h, &ctxt) != 0 ) return -EINVAL; d->arch.hvm_domain.viridian.time_ref_count.val = ctxt.time_ref_count; d->arch.hvm_domain.viridian.hypercall_gpa.raw= ctxt.hypercall_gpa; d->arch.hvm_domain.viridian.guest_os_id.raw= ctxt.guest_os_id; d->arch.hvm_domain.viridian.reference_tsc.raw= ctxt.reference_tsc; if ( d->arch.hvm_domain.viridian.reference_tsc.fields.enabled ) update_reference_tsc(d, 0); return 0; }", "target": 0, "idx": 106900, "project": "Xen"}
{"func": "TIFF* TIFFOpen(const char* name, const char* mode) { static const char module[] = \"TIFFOpen\"; int m, fd; m = _TIFFgetMode(mode, module); if (m == -1) return ((TIFF*)0); if (m&O_TRUNC){  fd = creat((char *)name, 0666, \"alq = 128\", \"deq = 64\", \"mbc = 32\", \"fop = tef\"); } else if (m&O_RDWR) { fd = open(name, m, 0666, \"deq = 64\", \"mbc = 32\", \"fop = tef\", \"ctx = stm\"); } else fd = open(name, m, 0666, \"mbc = 32\", \"ctx = stm\"); if (fd < 0) { TIFFErrorExt(0, module, \"%s: Cannot open\", name); return ((TIFF*)0); } return (TIFFFdOpen(fd, name, mode)); }", "target": 0, "idx": 100639, "project": "LibTIFF"}
{"func": "static void caxx_vcpu_initialise(struct vcpu *v) {  if ( v->domain->max_vcpus > 1 ) v->arch.actlr |= ACTLR_SMP; else v->arch.actlr &= ~ACTLR_SMP; }", "target": 0, "idx": 105167, "project": "Xen"}
{"func": "void dump_sched_vcpu_action(struct record_info *ri, const char *action) { struct { unsigned int domid, vcpuid; } *r = (typeof(r))ri->d; printf(\" %s %s d%uv%u\\n\", ri->dump_header, action, r->domid, r->vcpuid); }", "target": 0, "idx": 107959, "project": "Xen"}
{"func": "int xc_tmem_control(xc_interface *xch, int32_t pool_id, uint32_t cmd, uint32_t cli_id, uint32_t len, uint32_t arg, void *buf) { DECLARE_SYSCTL; DECLARE_HYPERCALL_BOUNCE(buf, len, XC_HYPERCALL_BUFFER_BOUNCE_OUT); int rc; sysctl.cmd = XEN_SYSCTL_tmem_op; sysctl.u.tmem_op.pool_id = pool_id; sysctl.u.tmem_op.cmd = cmd; sysctl.u.tmem_op.cli_id = cli_id; sysctl.u.tmem_op.len = len; sysctl.u.tmem_op.arg = arg; sysctl.u.tmem_op.pad = 0; sysctl.u.tmem_op.oid.oid[0] = 0; sysctl.u.tmem_op.oid.oid[1] = 0; sysctl.u.tmem_op.oid.oid[2] = 0; if ( cmd == XEN_SYSCTL_TMEM_OP_SET_CLIENT_INFO ||  cmd == XEN_SYSCTL_TMEM_OP_SET_AUTH ) HYPERCALL_BOUNCE_SET_DIR(buf, XC_HYPERCALL_BUFFER_BOUNCE_IN); if ( len ) { if ( buf == NULL ) { errno = EINVAL; return -1; } if ( xc_hypercall_bounce_pre(xch, buf) ) { PERROR(\"Could not bounce buffer for tmem control hypercall\"); return -1; } } set_xen_guest_handle(sysctl.u.tmem_op.u.buf, buf); rc = do_sysctl(xch, &sysctl); if ( len ) xc_hypercall_bounce_post(xch, buf); return rc; }", "target": 0, "idx": 107819, "project": "Xen"}
{"func": "void hvm_cr_write_process(struct record_info *ri, struct hvm_data *h) { union { struct { unsigned cr; unsigned int val; } x32; struct { unsigned cr; unsigned long long val; } __attribute__((packed)) x64; } *r = (typeof(r))h->d; unsigned cr; unsigned long long val; if(ri->event & TRC_64_FLAG) { h->inflight.cr_write.cr = cr = r->x64.cr; h->inflight.cr_write.val = val = r->x64.val; } else { h->inflight.cr_write.cr = cr = r->x32.cr; h->inflight.cr_write.val = val = r->x32.val; }  if ( hvm_set_postprocess(h, hvm_cr_write_postprocess) ) fprintf(warn, \"%s: Strange, h->postprocess already set!\\n\", __func__); if(opt.dump_all) { if(cr == 3 && h->v->cr3.val) { printf(\"]%s cr_write cr3 val %llx oval %llx %s\\n\",  ri->dump_header,  val,  h->v->cr3.val,  (h->v->cr3.val == val)?\"flush\":\"switch\"); } else { printf(\" %s cr_write cr%d val %llx\\n\",  ri->dump_header,  cr, val); } } }", "target": 0, "idx": 107971, "project": "Xen"}
{"func": "void libxl_dominfo_list_free(libxl_dominfo *list, int nr) { int i; for (i = 0; i < nr; i++) libxl_dominfo_dispose(&list[i]); free(list); }", "target": 0, "idx": 104123, "project": "Xen"}
{"func": "static int compare_maxmem(xenstat_domain *domain1, xenstat_domain *domain2) { return -compare(xenstat_domain_max_mem(domain1), xenstat_domain_max_mem(domain2)); }", "target": 0, "idx": 108503, "project": "Xen"}
{"func": "static int omap_uart_getc(struct serial_port *port, char *pc) { struct omap_uart *uart = port->uart; if ( !(omap_read(uart, UART_LSR) & UART_LSR_DR) ) return 0; *pc = omap_read(uart, UART_RBR) & 0xff; return 1; }", "target": 0, "idx": 104930, "project": "Xen"}
{"func": " */ static void clear_msr_range(unsigned int base, unsigned int n) { unsigned int i; for (i = 0; i < n; i++) wrmsr(base+i, 0, 0); }", "target": 0, "idx": 104817, "project": "Xen"}
{"func": "static void svm_vmexit_ud_intercept(struct cpu_user_regs *regs) { struct hvm_emulate_ctxt ctxt; int rc; if ( opt_hvm_fep ) { char sig[5];  if ( (hvm_fetch_from_guest_virt_nofault( sig, regs->eip, sizeof(sig), 0) == HVMCOPY_okay) &&  (memcmp(sig, \"\\xf\\xbxen\", sizeof(sig)) == 0) ) { regs->eip += sizeof(sig); regs->eflags &= ~X86_EFLAGS_RF; } } hvm_emulate_prepare(&ctxt, regs); rc = hvm_emulate_one(&ctxt); switch ( rc ) { case X86EMUL_UNHANDLEABLE: hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE); break; case X86EMUL_EXCEPTION: if ( ctxt.exn_pending ) hvm_inject_trap(&ctxt.trap);  default: hvm_emulate_writeback(&ctxt); break; } }", "target": 1, "idx": 109395, "project": "Xen"}
{"func": "int vhd_uuid_compare(vhd_uuid_t *uuid1, vhd_uuid_t *uuid2) { return uuid_compare(uuid1->uuid, uuid2->uuid); } } int vhd_uuid_compare(vhd_uuid_t *uuid1, vhd_uuid_t *uuid2) { uint32_t status; return uuid_compare((uuid_t *)uuid1, (uuid_t *)uuid2, &status); }", "target": 0, "idx": 106855, "project": "Xen"}
{"func": "const unsigned long *__init get_platform_badpages(unsigned int *array_size) { u32 igd_id; static unsigned long __initdata bad_pages[] = { 0x20050000, 0x20110000, 0x20130000, 0x20138000, 0x40004000, }; *array_size = ARRAY_SIZE(bad_pages); igd_id = pci_conf_read32(0, 0, 2, 0, 0); if ( !IS_SNB_GFX(igd_id) ) return NULL; return bad_pages; }", "target": 1, "idx": 109615, "project": "Xen"}
{"func": "void pv_shim_online_memory(unsigned int nr, unsigned int order) { struct page_info *page, *tmp; PAGE_LIST_HEAD(list); spin_lock(&balloon_lock); page_list_for_each_safe ( page, tmp, &balloon ) {  if ( page->v.free.order != order ) continue; page_list_del(page, &balloon); page_list_add_tail(page, &list); if ( !--nr ) break; } spin_unlock(&balloon_lock); if ( nr ) gprintk(XENLOG_WARNING, \"failed to allocate %u extents of order %u for onlining\\n\", nr, order); nr = batch_memory_op(XENMEM_populate_physmap, order, &list); while ( nr-- ) { BUG_ON((page = page_list_remove_head(&list)) == NULL); free_domheap_pages(page, order); } if ( !page_list_empty(&list) ) { gprintk(XENLOG_WARNING, \"failed to online some of the memory regions\\n\"); spin_lock(&balloon_lock); page_list_splice(&list, &balloon); spin_unlock(&balloon_lock); } }", "target": 0, "idx": 105746, "project": "Xen"}
{"func": "int xc_compression_uncompress_page(xc_interface *xch, char *compbuf,  unsigned long compbuf_size,  unsigned long *compbuf_pos, char *destpage) { unsigned long pos; unsigned int len = 0, pagepos = 0; char flag; pos = *compbuf_pos; if (pos >= compbuf_size) { ERROR(\"Out of bounds exception in compression buffer (a):\" \"read ptr:%lu, bufsize = %lu\\n\", *compbuf_pos, compbuf_size); return -1; } switch (compbuf[pos]) { case EMPTY_PAGE: pos++; break; case FULL_PAGE: {  if ((pos + FULL_PAGE_SIZE) > compbuf_size) { ERROR(\"Out of bounds exception in compression buffer (b):\" \"read ptr = %lu, bufsize = %lu\\n\", *compbuf_pos, compbuf_size); return -1; } memcpy(destpage, &compbuf[pos + 1], XC_PAGE_SIZE); pos += FULL_PAGE_SIZE; } break; default:  { do { flag = compbuf[pos] & FLAGMASK; len = (compbuf[pos] & LENMASK) * sizeof(uint32_t);  if (!len) { ERROR(\"Zero length run encountered for normal page: \" \"buffer (d):read ptr = %lu, flag = %u, \" \"bufsize = %lu, pagepos = %u\\n\", pos, (unsigned int)flag, compbuf_size, pagepos); return -1; } pos++; if (flag == RUNFLAG) {  if (((pos + len) > compbuf_size) || ((pagepos + len) > XC_PAGE_SIZE)) { ERROR(\"Out of bounds exception in compression \" \"buffer (c):read ptr = %lu, runlen = %u, \" \"bufsize = %lu, pagepos = %u\\n\", pos, len, compbuf_size, pagepos); return -1; } memcpy(&destpage[pagepos], &compbuf[pos], len); pos += len; } pagepos += len; } while ((pagepos < XC_PAGE_SIZE) && (pos < compbuf_size));  if (pagepos != XC_PAGE_SIZE) { ERROR(\"Invalid data in compression buffer:\" \"read ptr = %lu, bufsize = %lu, pagepos = %u\\n\", pos, compbuf_size, pagepos); return -1; } } } *compbuf_pos = pos; return 0; }", "target": 0, "idx": 107302, "project": "Xen"}
{"func": "void xfree(void *p) { struct bhdr *b; if ( p == NULL || p == ZERO_BLOCK_PTR ) return; ASSERT(!in_irq()); if ( !((unsigned long)p & (PAGE_SIZE - 1)) ) { unsigned long size = PFN_ORDER(virt_to_page(p)); unsigned int i, order = get_order_from_pages(size); BUG_ON((unsigned long)p & ((PAGE_SIZE << order) - 1)); PFN_ORDER(virt_to_page(p)) = 0; for ( i = 0; ; ++i ) { if ( !(size & (1 << i)) ) continue; size -= 1 << i; free_xenheap_pages(p + (size << PAGE_SHIFT), i); if ( i + 1 >= order ) return; } }  b = (struct bhdr *)((char *) p - BHDR_OVERHEAD); if ( b->size & 1 ) { p = (char *)p - (b->size & ~1u); b = (struct bhdr *)((char *)p - BHDR_OVERHEAD); ASSERT(!(b->size & 1)); } xmem_pool_free(p, xenpool); }", "target": 0, "idx": 108871, "project": "Xen"}
{"func": "static void show_guest_stack(struct vcpu *v, const struct cpu_user_regs *regs) { int i; unsigned long *stack, addr; unsigned long mask = STACK_SIZE;  if ( is_hvm_vcpu(v) ) return; if ( is_pv_32bit_vcpu(v) ) { compat_show_guest_stack(v, regs, debug_stack_lines); return; } if ( vm86_mode(regs) ) { stack = (unsigned long *)((regs->ss << 4) + (regs->esp & 0xffff)); printk(\"Guest stack trace from ss:sp = %04x:%04x (VM86)\\n\",  regs->ss, (uint16_t)(regs->esp & 0xffff)); } else { stack = (unsigned long *)regs->esp; printk(\"Guest stack trace from \"__OP\"sp=%p:\\n\", stack); } if ( !access_ok(stack, sizeof(*stack)) ) { printk(\"Guest-inaccessible memory.\\n\"); return; } if ( v != current ) { struct vcpu *vcpu; ASSERT(guest_kernel_mode(v, regs)); vcpu = maddr_get_owner(read_cr3()) == v->domain ? v : NULL; if ( !vcpu ) { stack = do_page_walk(v, (unsigned long)stack); if ( (unsigned long)stack < PAGE_SIZE ) { printk(\"Inaccessible guest memory.\\n\"); return; } mask = PAGE_SIZE; } } for ( i = 0; i < (debug_stack_lines*stack_words_per_line); i++ ) { if ( (((long)stack - 1) ^ ((long)(stack + 1) - 1)) & mask ) break; if ( __get_user(addr, stack) ) { if ( i != 0 ) printk(\"\\n\"); printk(\"Fault while accessing guest memory.\"); i = 1; break; } if ( (i != 0) && ((i % stack_words_per_line) == 0) ) printk(\"\\n\"); printk(\" %p\", _p(addr)); stack++; } if ( mask == PAGE_SIZE ) { BUILD_BUG_ON(PAGE_SIZE == STACK_SIZE); unmap_domain_page(stack); } if ( i == 0 ) printk(\"Stack empty.\"); printk(\"\\n\"); }", "target": 1, "idx": 109654, "project": "Xen"}
{"func": "int io_expand_iocbs(struct opioctx *ctx, struct iocb **queue, int idx, int num) { int i, on_queue; struct iocb *io, **q; if (!num) return 0; on_queue = 0; q = ctx->iocb_queue; memcpy(q, queue, num * sizeof(struct iocb *)); for (i = idx; i < num; i++) { io = q[i]; if (!iocb_optimized(ctx, io)) queue[on_queue++] = io; else on_queue += expand_iocb(ctx, queue + on_queue, io); } return on_queue; }", "target": 0, "idx": 102761, "project": "Xen"}
{"func": "int main_dmesg(int argc, char **argv) { unsigned int clear = 0; libxl_xen_console_reader *cr; char *line; int opt, ret = 1; static struct option opts[] = { {\"clear\", 0, 0, 'c'}, COMMON_LONG_OPTS }; SWITCH_FOREACH_OPT(opt, \"c\", opts, \"dmesg\", 0) { case 'c': clear = 1; break; } cr = libxl_xen_console_read_start(ctx, clear); if (!cr) goto finish; while ((ret = libxl_xen_console_read_line(ctx, cr, &line)) > 0) printf(\"%s\", line); finish: if (cr) libxl_xen_console_read_finish(ctx, cr); return ret ? EXIT_FAILURE : EXIT_SUCCESS; }", "target": 0, "idx": 108677, "project": "Xen"}
{"func": "int main(int argc, char **argv) {    sleep(2);    tpm_extern_init = vtpm_extern_init_fake;  tpm_extern_release = vtpm_extern_release_fake;  tpm_malloc = malloc;  tpm_free = free;  tpm_log = vtpm_log;  tpm_get_ticks = vtpm_get_ticks;  tpm_get_extern_random_bytes = vtpm_get_extern_random_bytes;  tpm_write_to_storage = vtpm_write_to_file;  tpm_read_from_storage = vtpm_read_from_file;  info(\"starting TPM Emulator (1.2.%d.%d-%d)\", VERSION_MAJOR, VERSION_MINOR, VERSION_BUILD);  if(parse_cmd_line(argc, argv)) { error(\"Error parsing commandline\\n\"); return -1;  }    init_tpmback(NULL, NULL);  if((tpmfront_dev = init_tpmfront(NULL)) == NULL) { error(\"Unable to initialize tpmfront device\"); goto abort_posttpmfront;  }    if(init_random()) { error(\"Unable to initialize RNG\"); goto abort_postrng;  }    if(init_vtpmblk(tpmfront_dev)) { error(\"Unable to initialize Blkfront persistent storage\"); goto abort_postvtpmblk;  }    main_loop();    shutdown_vtpmblk(); abort_postvtpmblk: abort_postrng:    shutdown_tpmfront(tpmfront_dev); abort_posttpmfront:  shutdown_tpmback();  cleanup_opt_args();  return 0; }", "target": 0, "idx": 107183, "project": "Xen"}
{"func": "int nvmx_handle_vmxoff(struct cpu_user_regs *regs) { struct vcpu *v=current; struct nestedvmx *nvmx = &vcpu_2_nvmx(v); int rc; rc = vmx_inst_check_privilege(regs, 0); if ( rc != X86EMUL_OKAY ) return rc; nvmx_purge_vvmcs(v); nvmx->vmxon_region_pa = INVALID_PADDR; vmsucceed(regs); return X86EMUL_OKAY; }", "target": 1, "idx": 109595, "project": "Xen"}
{"func": "void on_set_option_mode3_activate(GtkMenuItem *menuitem, gpointer user_data) { opt_mode = OPT_PROMPT; gtk_tree_store_clear(tree2); display_tree(&rootmenu); }", "target": 0, "idx": 102298, "project": "Xen"}
{"func": "static int __erst_get_next_record_id(u64 *record_id) { struct apei_exec_context ctx; int rc; erst_exec_ctx_init(&ctx); rc = apei_exec_run(&ctx, ACPI_ERST_GET_RECORD_ID); if (rc) return rc; *record_id = apei_exec_ctx_get_output(&ctx); return 0; }", "target": 0, "idx": 101906, "project": "Xen"}
{"func": " */ static void vmx_enable_intr_window(struct vcpu *v, struct hvm_intack intack) { u32 ctl = CPU_BASED_VIRTUAL_INTR_PENDING; ASSERT(intack.source != hvm_intsrc_none); if ( unlikely(tb_init_done) ) { unsigned long intr; __vmread(VM_ENTRY_INTR_INFO, &intr); HVMTRACE_3D(INTR_WINDOW, intack.vector, intack.source, (intr & INTR_INFO_VALID_MASK) ? intr & 0xff : -1); } if ( (intack.source == hvm_intsrc_nmi) && cpu_has_vmx_vnmi ) {  unsigned long intr_shadow; __vmread(GUEST_INTERRUPTIBILITY_INFO, &intr_shadow); if ( intr_shadow & VMX_INTR_SHADOW_STI ) {  intr_shadow &= ~VMX_INTR_SHADOW_STI; intr_shadow |= VMX_INTR_SHADOW_MOV_SS; __vmwrite(GUEST_INTERRUPTIBILITY_INFO, intr_shadow); } ctl = CPU_BASED_VIRTUAL_NMI_PENDING; } if ( !(v->arch.hvm_vmx.exec_control & ctl) ) { v->arch.hvm_vmx.exec_control |= ctl; vmx_update_cpu_exec_control(v); } }", "target": 0, "idx": 102750, "project": "Xen"}
{"func": "static void evtchn_fd_callback(libxl__egc *egc, libxl__ev_fd *ev,  int fd, short events, short revents) { EGC_GC; libxl__ev_evtchn *evev; int rc; xenevtchn_port_or_error_t port; rc = evtchn_revents_check(egc, revents); if (rc) return; for (;;) {  revents = libxl__fd_poll_recheck(egc,fd,POLLIN); if (!revents) break; rc = evtchn_revents_check(egc, revents); if (rc) return;  port = xenevtchn_pending(CTX->xce); if (port < 0) { if (errno == EAGAIN) break; LIBXL__EVENT_DISASTER(egc,  \"unexpected failure fetching occurring event port number from evtchn\", errno, 0); return; } LIBXL_LIST_FOREACH(evev, &CTX->evtchns_waiting, entry) if (port == evev->port) goto found;  DBG(\"ev_evtchn port=%d no-one cared\", port); continue; found: DBG(\"ev_evtchn=%p port=%d signaled\", evev, port); evev->waiting = 0; LIBXL_LIST_REMOVE(evev, entry); evev->callback(egc, evev); } }", "target": 0, "idx": 103608, "project": "Xen"}
{"func": "void libxl__ev_evtchn_cancel(libxl__gc *gc, libxl__ev_evtchn *evev) { DBG(\"ev_evtchn=%p port=%d cancel (was waiting=%d)\", evev, evev->port, evev->waiting); if (!evev->waiting) return; evev->waiting = 0; LIBXL_LIST_REMOVE(evev, entry); evtchn_check_fd_deregister(gc); }", "target": 0, "idx": 103640, "project": "Xen"}
{"func": "static void csched2_init_pdata(const struct scheduler *ops, void *pdata, int cpu) { struct csched2_private *prv = csched2_priv(ops); spinlock_t *old_lock; unsigned long flags; unsigned rqi; write_lock_irqsave(&prv->lock, flags); old_lock = pcpu_schedule_lock(cpu); rqi = init_pdata(prv, pdata, cpu);  per_cpu(schedule_data, cpu).schedule_lock = &prv->rqd[rqi].lock;  spin_unlock(old_lock); write_unlock_irqrestore(&prv->lock, flags); }", "target": 0, "idx": 105539, "project": "Xen"}
{"func": "static PyObject * fsimage_fs_open_file(fsimage_fs_t *fs, PyObject *args, PyObject *kwargs) { static char *kwlist[] = { \"name\", NULL }; fsimage_file_t *file; char *name; if (!PyArg_ParseTupleAndKeywords(args, kwargs, \"s\", kwlist, &name)) return (NULL); file = (fsimage_file_t *)PyObject_NEW(fsimage_file_t, &fsimage_file_type); if (file == NULL) return (NULL); file->fs = fs; Py_INCREF(file->fs); if ((file->file = fsi_open_file(fs->fs, name)) == NULL) { Py_DECREF(file->fs); file->fs = NULL; PyErr_SetFromErrno(PyExc_IOError); return (NULL); } return ((PyObject *)file); }", "target": 0, "idx": 102100, "project": "Xen"}
{"func": "static void __init gicv3_dist_init(void) { uint32_t type; uint32_t priority; uint64_t affinity; unsigned int nr_lines; int i;  writel_relaxed(0, GICD + GICD_CTLR); type = readl_relaxed(GICD + GICD_TYPER); nr_lines = 32 * ((type & GICD_TYPE_LINES) + 1); if ( type & GICD_TYPE_LPIS ) gicv3_lpi_init_host_lpis(GICD_TYPE_ID_BITS(type)); printk(\"GICv3: %d lines, (IID %8.8x).\\n\",  nr_lines, readl_relaxed(GICD + GICD_IIDR));  for ( i = NR_GIC_LOCAL_IRQS; i < nr_lines; i += 16 ) writel_relaxed(0, GICD + GICD_ICFGR + (i / 16) * 4);  for ( i = NR_GIC_LOCAL_IRQS; i < nr_lines; i += 4 ) { priority = (GIC_PRI_IRQ << 24 | GIC_PRI_IRQ << 16 | GIC_PRI_IRQ << 8 | GIC_PRI_IRQ); writel_relaxed(priority, GICD + GICD_IPRIORITYR + (i / 4) * 4); }  for ( i = NR_GIC_LOCAL_IRQS; i < nr_lines; i += 32 ) writel_relaxed(0xffffffff, GICD + GICD_ICENABLER + (i / 32) * 4);  for ( i = NR_GIC_LOCAL_IRQS; i < nr_lines; i += 32 ) writel_relaxed(GENMASK(31, 0), GICD + GICD_IGROUPR + (i / 32) * 4); gicv3_dist_wait_for_rwp();  writel_relaxed(GICD_CTL_ENABLE | GICD_CTLR_ARE_NS | GICD_CTLR_ENABLE_G1A | GICD_CTLR_ENABLE_G1, GICD + GICD_CTLR);  affinity = gicv3_mpidr_to_affinity(smp_processor_id());  affinity &= ~GICD_IROUTER_SPI_MODE_ANY; for ( i = NR_GIC_LOCAL_IRQS; i < nr_lines; i++ ) writeq_relaxed(affinity, GICD + GICD_IROUTER + i * 8);  gicv3_info.nr_lines = min(1020U, nr_lines); }", "target": 0, "idx": 102493, "project": "Xen"}
{"func": "void ioapic_suspend(void) { struct IO_APIC_route_entry *entry = ioapic_pm_state; unsigned long flags; int apic, i; spin_lock_irqsave(&ioapic_lock, flags); for (apic = 0; apic < nr_ioapics; apic++) { for (i = 0; i < nr_ioapic_entries[apic]; i ++, entry ++ ) { *(((int *)entry) + 1) = __io_apic_read(apic, 0x11 + 2 * i); *(((int *)entry) + 0) = __io_apic_read(apic, 0x10 + 2 * i); } } spin_unlock_irqrestore(&ioapic_lock, flags); }", "target": 0, "idx": 102866, "project": "Xen"}
{"func": "static int ptwr_emulated_read(enum x86_segment seg, unsigned long offset, void *p_data, unsigned int bytes, struct x86_emulate_ctxt *ctxt) { unsigned int rc = bytes; unsigned long addr = offset; if ( !__addr_ok(addr) ||  (rc = __copy_from_user(p_data, (void *)addr, bytes)) ) { x86_emul_pagefault(0, addr + bytes - rc, ctxt); return X86EMUL_EXCEPTION; } return X86EMUL_OKAY; }", "target": 0, "idx": 105392, "project": "Xen"}
{"func": "int libxl__domain_resume_device_model(libxl__gc *gc, uint32_t domid) { const char *path, *state; switch (libxl__device_model_version_running(gc, domid)) { case LIBXL_DEVICE_MODEL_VERSION_QEMU_XEN_TRADITIONAL: { uint32_t dm_domid = libxl_get_stubdom_id(CTX, domid); path = DEVICE_MODEL_XS_PATH(gc, dm_domid, domid, \"/state\"); state = libxl__xs_read(gc, XBT_NULL, path); if (state != NULL && !strcmp(state, \"paused\")) { libxl__qemu_traditional_cmd(gc, domid, \"continue\"); libxl__wait_for_device_model_deprecated(gc, domid, \"running\", NULL, NULL, NULL); } break; } case LIBXL_DEVICE_MODEL_VERSION_QEMU_XEN: if (libxl__qmp_resume(gc, domid)) return ERROR_FAIL; break; default: return ERROR_INVAL; } return 0; }", "target": 0, "idx": 103585, "project": "Xen"}
{"func": "static int apei_range_nr; static void __iomem *__init apei_range_map(paddr_t paddr, unsigned long size) { int i, pg; int start_nr, cur_nr; pg = ((((paddr + size -1) & PAGE_MASK)  - (paddr & PAGE_MASK)) >> PAGE_SHIFT) + 1; if (apei_range_nr + pg > FIX_APEI_RANGE_MAX) return NULL; start_nr = apei_range_nr + pg -1; for (i = 0; i < pg; i++) { cur_nr = start_nr - i; set_fixmap_nocache(FIX_APEI_RANGE_BASE + cur_nr, paddr + (i << PAGE_SHIFT)); apei_range_nr++; } return fix_to_virt(FIX_APEI_RANGE_BASE + start_nr); }", "target": 0, "idx": 100895, "project": "Xen"}
{"func": "static int iso9660_devread (fsi_file_t *ffi, int sector, int byte_offset, int byte_len, char *buf) { static int read_count = 0, threshold = 2; unsigned short sector_size_lg2 = log2(512 );  if (sector < 0) { errnum = ERR_OUTSIDE_PART; return 0; } if (byte_len <= 0) return 1; #if 0 sector += (byte_offset >> sector_size_lg2); byte_offset &= (buf_geom.sector_size - 1); asm volatile (\"shl%L0 %1,%0\" : \"=r\"(sector) : \"Ic\"((int8_t)(ISO_SECTOR_BITS - sector_size_lg2)), \"0\"(sector)); #else sector = (sector * 4) + (byte_offset >> sector_size_lg2); byte_offset &= 511; #endif #if !defined(STAGE1_5) if (disk_read_hook && debug) printf (\"<%d, %d, %d>\", sector, byte_offset, byte_len); #endif  read_count += (byte_len >> 9); if ((read_count >> 11) > threshold) { noisy_printf(\".\"); threshold += 2; } return devread(ffi, sector, byte_offset, byte_len, buf); }", "target": 0, "idx": 102145, "project": "Xen"}
{"func": "static int conf_sym(struct menu *menu) { struct symbol *sym = menu->sym; tristate oldval, newval; while (1) { printf(\"%*s%s \", indent - 1, \"\", _(menu->prompt->text)); if (sym->name) printf(\"(%s) \", sym->name); putchar('['); oldval = sym_get_tristate_value(sym); switch (oldval) { case no: putchar('N'); break; case mod: putchar('M'); break; case yes: putchar('Y'); break; } if (oldval != no && sym_tristate_within_range(sym, no)) printf(\"/n\"); if (oldval != mod && sym_tristate_within_range(sym, mod)) printf(\"/m\"); if (oldval != yes && sym_tristate_within_range(sym, yes)) printf(\"/y\"); if (menu_has_help(menu)) printf(\"/?\"); printf(\"] \"); if (!conf_askvalue(sym, sym_get_string_value(sym))) return 0; strip(line); switch (line[0]) { case 'n': case 'N': newval = no; if (!line[1] || !strcmp(&line[1], \"o\")) break; continue; case 'm': case 'M': newval = mod; if (!line[1]) break; continue; case 'y': case 'Y': newval = yes; if (!line[1] || !strcmp(&line[1], \"es\")) break; continue; case 0: newval = oldval; break; case '?': goto help; default: continue; } if (sym_set_tristate_value(sym, newval)) return 0; help: print_help(menu); } }", "target": 0, "idx": 101366, "project": "Xen"}
{"func": "static inline uint64_t __bitmap_lru_seqno(struct vhd_state *s) { int i; struct vhd_bitmap *bm; if (s->bm_lru == 0xffffffff) { s->bm_lru = 0; for (i = 0; i < VHD_CACHE_SIZE; i++) { bm = s->bitmap[i]; if (bm) { bm->seqno >>= 1; if (bm->seqno > s->bm_lru) s->bm_lru = bm->seqno; } } } return ++s->bm_lru; }", "target": 0, "idx": 101214, "project": "Xen"}
{"func": "int cpufreq_limit_change(unsigned int cpu) { struct processor_performance *perf; struct cpufreq_policy *data; struct cpufreq_policy policy; if (!cpu_online(cpu) || !(data = per_cpu(cpufreq_cpu_policy, cpu)) || !processor_pminfo[cpu]) return -ENODEV; perf = &processor_pminfo[cpu]->perf; if (perf->platform_limit >= perf->state_count) return -EINVAL; memcpy(&policy, data, sizeof(struct cpufreq_policy));  policy.max = perf->states[perf->platform_limit].core_frequency * 1000; return __cpufreq_set_policy(data, &policy); }", "target": 0, "idx": 101494, "project": "Xen"}
{"func": "int main(int argc, char **argv) { struct xs_handle *xsh; char *par = NULL; char *ret; unsigned int p, len = 0; int rc = 0; if (argc < 2) { fprintf(stderr, \"Usage:\\n\" \"%s <command> [<arg>...]\\n\", argv[0]); rc = 2; goto out; } for (p = 2; p < argc; p++) len += strlen(argv[p]) + 1; if (len) { par = malloc(len); if (!par) { fprintf(stderr, \"Allocation error.\\n\"); rc = 1; goto out; } len = 0; for (p = 2; p < argc; p++) { memcpy(par + len, argv[p], strlen(argv[p]) + 1); len += strlen(argv[p]) + 1; } } xsh = xs_open(0); if (xsh == NULL) { fprintf(stderr, \"Failed to contact Xenstored.\\n\"); rc = 1; goto out; } ret = xs_control_command(xsh, argv[1], par, len); if (!ret) { rc = 3; if (errno == EINVAL) { ret = xs_control_command(xsh, \"help\", NULL, 0); if (ret) fprintf(stderr, \"Command not supported. Valid commands are:\\n\" \"%s\\n\", ret); else fprintf(stderr, \"Error when executing command.\\n\"); } else fprintf(stderr, \"Error %d when trying to execute command.\\n\", errno); } else if (strlen(ret) > 0) printf(\"%s\\n\", ret); xs_close(xsh);  out: free(par); return rc; }", "target": 0, "idx": 108486, "project": "Xen"}
{"func": " */ int erst_get_next_record_id(u64 *record_id) { int rc; unsigned long flags; if (!erst_enabled) return -ENODEV; spin_lock_irqsave(&erst_lock, flags); rc = __erst_get_next_record_id(record_id); spin_unlock_irqrestore(&erst_lock, flags); return rc; }", "target": 0, "idx": 101898, "project": "Xen"}
{"func": " */ static int load_verify_group(struct mem_group_hdr *dst, const struct mem_tpm_mgr *mgr) { struct mem_group *group; struct disk_group_sector disk; int rc; aes_context key_e; aes_context *opened_key = NULL; disk_set_used(dst->disk_loc, mgr); rc = disk_read_crypt_sector(&disk, sizeof(disk), dst->disk_loc, mgr); if (rc) { printk(\"Malformed sector %d\\n\", be32_native(dst->disk_loc)); return rc; } rc = sha256_verify(&dst->disk_hash, &disk.v, sizeof(disk.v) + sizeof(disk.group_mac)); if (rc) { printk(\"Hash mismatch in sector %d\\n\", be32_native(dst->disk_loc)); return rc; } dst->v = group = calloc(1, sizeof(*group)); rc = find_group_key(group, &disk, mgr); if (rc == 0) { opened_key = &key_e;  aes_setup(opened_key, &group->group_key); if (aes_cmac_verify(&disk.group_mac, &disk.v, sizeof(disk.v), opened_key)) { printk(\"Group CMAC failed\\n\"); return 2; } memcpy(&group->id_data, &disk.v.id_data, sizeof(group->id_data)); memcpy(&group->details, &disk.v.details, sizeof(group->details)); } else if (rc == 1) {  rc = 0; } else { printk(\"Group key unsealing failed\\n\"); return rc; } group->nr_vtpms = be32_native(disk.v.nr_vtpms); group->nr_pages = (group->nr_vtpms + VTPMS_PER_SECTOR - 1) / VTPMS_PER_SECTOR; group->data = calloc(group->nr_pages, sizeof(group->data[0])); rc = load_verify_vtpm_itree(dst, 0, group->nr_pages, disk.v.vtpm_hash, disk.vtpm_location, NR_ENTRIES_PER_GROUP_BASE, mgr, opened_key); if (!opened_key) {  free(group->data); free(group->seals); free(group); dst->v = NULL; } return rc; }", "target": 0, "idx": 101688, "project": "Xen"}
{"func": "void *xengnttab_map_domain_grant_refs(xengnttab_handle *xgt, uint32_t count, uint32_t domid, uint32_t *refs, int prot) { return osdep_gnttab_grant_map(xgt, count, XENGNTTAB_GRANT_MAP_SINGLE_DOMAIN, prot, &domid, refs, -1, -1); }", "target": 0, "idx": 102574, "project": "Xen"}
{"func": "static unsigned int num_counter_active(const struct gcov_info *info) { unsigned int i; unsigned int result = 0; for ( i = 0; i < GCOV_COUNTERS; i++ ) if ( counter_active(info, i) ) result++; return result; }", "target": 0, "idx": 102262, "project": "Xen"}
{"func": "static int make_chosen_node(libxl__gc *gc, void *fdt, bool ramdisk, libxl__domain_build_state *state, const libxl_domain_build_info *info) { int res;  res = fdt_begin_node(fdt, \"chosen\"); if (res) return res; if (state->pv_cmdline) { LOG(DEBUG, \"/chosen/bootargs = %s\", state->pv_cmdline); res = fdt_property_string(fdt, \"bootargs\", state->pv_cmdline); if (res) return res; } if (ramdisk) { uint64_t dummy = 0; LOG(DEBUG, \"/chosen adding placeholder linux,initrd properties\"); res = fdt_property(fdt, PROP_INITRD_START, &dummy, sizeof(dummy)); if (res) return res; res = fdt_property(fdt, PROP_INITRD_END, &dummy, sizeof(dummy)); if (res) return res; } if (libxl_defbool_val(info->acpi)) { const uint64_t acpi_base = GUEST_ACPI_BASE; const char *name = GCSPRINTF(\"module@%\"PRIx64, acpi_base); res = fdt_begin_node(fdt, name); if (res) return res; res = fdt_property_compat(gc, fdt, 2, \"xen,guest-acpi\", \"multiboot,module\"); if (res) return res; res = fdt_property_regs(gc, fdt, ROOT_ADDRESS_CELLS, ROOT_SIZE_CELLS, 1, 0, 0); if (res) return res; res = fdt_end_node(fdt); if (res) return res; } res = fdt_end_node(fdt); if (res) return res; return 0; }", "target": 0, "idx": 103327, "project": "Xen"}
{"func": " */ int libxl__vnuma_config_check(libxl__gc *gc, const libxl_domain_build_info *b_info, const libxl__domain_build_state *state) { int nr_nodes = 0, rc = ERROR_VNUMA_CONFIG_INVALID; unsigned int i, j; libxl_numainfo *ninfo = NULL; uint64_t total_memkb = 0; libxl_bitmap cpumap; libxl_vnode_info *v; libxl_bitmap_init(&cpumap);  ninfo = libxl_get_numainfo(CTX, &nr_nodes); if (!ninfo) { LOG(ERROR, \"libxl_get_numainfo failed\"); goto out; } for (i = 0; i < b_info->num_vnuma_nodes; i++) { uint32_t pnode; v = &b_info->vnuma_nodes[i]; pnode = v->pnode;  if (pnode >= nr_nodes) { LOG(ERROR, \"Invalid pnode %\"PRIu32\" specified\", pnode); goto out; } total_memkb += v->memkb; } if (total_memkb != b_info->max_memkb) { LOG(ERROR, \"Amount of memory mismatch (0x%\"PRIx64\" != 0x%\"PRIx64\")\", total_memkb, b_info->max_memkb); goto out; }  libxl_cpu_bitmap_alloc(CTX, &cpumap, b_info->max_vcpus); for (i = 0; i < b_info->num_vnuma_nodes; i++) { v = &b_info->vnuma_nodes[i]; libxl_for_each_set_bit(j, v->vcpus) { if (!libxl_bitmap_test(&cpumap, j)) libxl_bitmap_set(&cpumap, j); else { LOG(ERROR, \"Vcpu %d assigned more than once\", j); goto out; } } } for (i = 0; i < b_info->max_vcpus; i++) { if (!libxl_bitmap_test(&cpumap, i)) { LOG(ERROR, \"Vcpu %d is not assigned to any vnode\", i); goto out; } }  for (i = 0; i < b_info->num_vnuma_nodes; i++) { v = &b_info->vnuma_nodes[i]; libxl_for_each_set_bit(j, v->vcpus) { if (b_info->num_vcpu_hard_affinity > j) check_vnuma_affinity(gc, j, v->pnode,  b_info->num_vcpu_hard_affinity,  &b_info->vcpu_hard_affinity[j],  \"hard\"); if (b_info->num_vcpu_soft_affinity > j) check_vnuma_affinity(gc, j, v->pnode,  b_info->num_vcpu_soft_affinity,  &b_info->vcpu_soft_affinity[j],  \"soft\"); } }  qsort(state->vmemranges, state->num_vmemranges, sizeof(xen_vmemrange_t), compare_vmemrange); for (i = 0; i < state->num_vmemranges; i++) { if (state->vmemranges[i].end < state->vmemranges[i].start) { LOG(ERROR, \"Vmemrange end < start\"); goto out; } } for (i = 0; i < state->num_vmemranges - 1; i++) { if (state->vmemranges[i].end > state->vmemranges[i+1].start) { LOG(ERROR, \"Vmemranges overlapped, 0x%\"PRIx64\"-0x%\"PRIx64\", 0x%\"PRIx64\"-0x%\"PRIx64, state->vmemranges[i].start, state->vmemranges[i].end, state->vmemranges[i+1].start, state->vmemranges[i+1].end); goto out; } }  for (i = 0; i < b_info->num_vnuma_nodes; i++) { uint32_t local_distance, remote_distance; v = &b_info->vnuma_nodes[i]; local_distance = v->distances[i]; for (j = 0; j < v->num_distances; j++) { if (i == j) continue; remote_distance = v->distances[j]; if (local_distance > remote_distance) { LOG(ERROR, \"Distance from %u to %u smaller than %u's local distance\", i, j, i); goto out; } } } rc = 0; out: libxl_numainfo_list_free(ninfo, nr_nodes); libxl_bitmap_dispose(&cpumap); return rc; }", "target": 0, "idx": 104174, "project": "Xen"}
{"func": "int cpumask_isset(const cpu_mask_t *c, int cpu) { if(*c & (1UL<<cpu)) return 1; else return 0; }", "target": 0, "idx": 107939, "project": "Xen"}
{"func": " * not on the last line. */ static void print(const char *fmt, ...) { va_list args; if (!batch) { if((current_row() < lines()-1)) { va_start(args, fmt); vwprintw(stdscr, (curses_str_t)fmt, args); va_end(args); } } else { va_start(args, fmt); vprintf(fmt, args); va_end(args); } }", "target": 0, "idx": 108525, "project": "Xen"}
{"func": "static void inject_abt64_exception(struct cpu_user_regs *regs,  int prefetch,  register_t addr,  int instr_len) { union hsr esr = { .iss = 0, .len = instr_len, };  if ( psr_mode_is_32bit(regs->cpsr) || psr_mode(regs->cpsr,PSR_MODE_EL0t) ) esr.ec = prefetch ? HSR_EC_INSTR_ABORT_LOWER_EL : HSR_EC_DATA_ABORT_LOWER_EL; else esr.ec = prefetch ? HSR_EC_INSTR_ABORT_CURR_EL : HSR_EC_DATA_ABORT_CURR_EL; BUG_ON( is_pv32_domain(current->domain) ); regs->spsr_el1 = regs->cpsr; regs->elr_el1 = regs->pc; regs->cpsr = PSR_MODE_EL1h | PSR_ABT_MASK | PSR_FIQ_MASK | \\ PSR_IRQ_MASK | PSR_DBG_MASK; regs->pc = READ_SYSREG(VBAR_EL1) + VECTOR64_CURRENT_SPx_SYNC; WRITE_SYSREG(addr, FAR_EL1); WRITE_SYSREG32(esr.bits, ESR_EL1); }", "target": 1, "idx": 109199, "project": "Xen"}
{"func": " */ int access_node(struct connection *conn, struct node *node, enum node_access_type type, TDB_DATA *key) { struct accessed_node *i = NULL; struct transaction *trans; TDB_DATA local_key; const char *trans_name = NULL; int ret; bool introduce = false; if (type != NODE_ACCESS_READ) { node->generation = generation++; if (conn && !conn->transaction) wrl_apply_debit_direct(conn); } if (!conn || !conn->transaction) {  if (key) set_tdb_key(node->name, key); return 0; } trans = conn->transaction; trans_name = transaction_get_node_name(node, trans, node->name); if (!trans_name) goto nomem; i = find_accessed_node(trans, node->name); if (!i) { i = talloc_zero(trans, struct accessed_node); if (!i) goto nomem; i->node = talloc_strdup(i, node->name); if (!i->node) goto nomem; introduce = true; i->ta_node = false;  if (type == NODE_ACCESS_READ) { i->generation = node->generation; i->check_gen = true; if (node->generation != NO_GENERATION) { set_tdb_key(trans_name, &local_key); ret = write_node_raw(conn, &local_key, node); if (ret) goto err; i->ta_node = true; } } list_add_tail(&i->list, &trans->accessed); } if (type != NODE_ACCESS_READ) i->modified = true; if (introduce && type == NODE_ACCESS_DELETE)  return -1; if (key) { set_tdb_key(trans_name, key); if (type == NODE_ACCESS_WRITE) i->ta_node = true; if (type == NODE_ACCESS_DELETE) i->ta_node = false; } return 0; nomem: ret = ENOMEM; err: talloc_free((void *)trans_name); talloc_free(i); trans->fail = true; errno = ret; return ret; }", "target": 0, "idx": 108457, "project": "Xen"}
{"func": "static void tapdisk_stream_release(struct tapdisk_stream *s) { tapdisk_stream_close_image(s); tapdisk_stream_unregister_enqueue_event(s); }", "target": 0, "idx": 106132, "project": "Xen"}
{"func": "static inline uint32_t bswap(uint32_t a) { return ( ( a >> 24 ) & 0x000000ff) |  ( ( a >> 8) & 0x0000ff00) |  ( ( a << 8) & 0x00ff0000) |  ( ( a << 24 ) & 0xff000000); }", "target": 0, "idx": 106321, "project": "Xen"}
{"func": "void activate_early_eof(void) { struct pcpu_info *p; int i; fprintf(warn, \"Short cpu_change window, activating early_eof\\n\"); P.early_eof = 1; for(i=0; i<=P.max_active_pcpu; i++) { p = P.pcpu + i; if(p->active && p->file_offset > P.last_epoch_offset) { fprintf(warn, \" deactivating pid %d\\n\", p->pid); p->active = 0; } } }", "target": 0, "idx": 107931, "project": "Xen"}
{"func": "static void Fax3BadLength(const char* module, TIFF* tif, uint32 line, uint32 a0, uint32 lastx) { TIFFWarningExt(tif->tif_clientdata, module, \"%s: %s at line %lu of %s %lu (got %lu, expected %lu)\", tif->tif_name, a0 < lastx ? \"Premature EOL\" : \"Line length mismatch\", (unsigned long) line, isTiled(tif) ? \"tile\" : \"strip\", (unsigned long) (isTiled(tif) ? tif->tif_curtile : tif->tif_curstrip), (unsigned long) a0, lastx); }", "target": 0, "idx": 100175, "project": "LibTIFF"}
{"func": "static int message__add_file_line(struct message *self, const char *file, int lineno) { int rc = -1; struct file_line *fl = file_line__new(file, lineno); if (fl == NULL) goto out; fl->next= self->files; self->files = fl; rc = 0; out: return rc; }", "target": 0, "idx": 103011, "project": "Xen"}
{"func": "static void remus_checkpoint_stream_done( libxl__egc *egc, libxl__stream_read_state *stream, int rc) { libxl__xc_domain_saverestore_async_callback_done(egc, &stream->shs, rc); }", "target": 0, "idx": 103921, "project": "Xen"}
{"func": " */ static bool process_record(libxl__egc *egc,  libxl__stream_read_state *stream) { STATE_AO_GC(stream->ao); libxl__domain_create_state *dcs = stream->dcs; libxl__sr_record_buf *rec; libxl_sr_checkpoint_state *srcs; bool further_action_needed = false; int rc = 0;  assert(!LIBXL_STAILQ_EMPTY(&stream->record_queue)); rec = LIBXL_STAILQ_FIRST(&stream->record_queue); LIBXL_STAILQ_REMOVE_HEAD(&stream->record_queue, entry); LOG(DEBUG, \"Record: %u, length %u\", rec->hdr.type, rec->hdr.length); switch (rec->hdr.type) { case REC_TYPE_END: stream_complete(egc, stream, 0); break; case REC_TYPE_LIBXC_CONTEXT: libxl__xc_domain_restore(egc, dcs, &stream->shs, 0, 0); break; case REC_TYPE_EMULATOR_XENSTORE_DATA: if (dcs->guest_config->b_info.type != LIBXL_DOMAIN_TYPE_HVM) { rc = ERROR_FAIL; LOG(ERROR, \"Received a xenstore emulator record when none was expected\"); goto err; } if (rec->hdr.length < sizeof(libxl__sr_emulator_hdr)) { rc = ERROR_FAIL; LOG(ERROR, \"Emulator xenstore data record too short to contain header\"); goto err; } rc = libxl__restore_emulator_xenstore_data(dcs, rec->body + sizeof(libxl__sr_emulator_hdr), rec->hdr.length - sizeof(libxl__sr_emulator_hdr)); if (rc) goto err;  further_action_needed = true; break; case REC_TYPE_EMULATOR_CONTEXT: if (dcs->guest_config->b_info.type != LIBXL_DOMAIN_TYPE_HVM) { rc = ERROR_FAIL; LOG(ERROR, \"Received an emulator context record when none was expected\"); goto err; } write_emulator_blob(egc, stream, rec); break; case REC_TYPE_CHECKPOINT_END: if (!stream->in_checkpoint) { LOG(ERROR, \"Unexpected CHECKPOINT_END record in stream\"); rc = ERROR_FAIL; goto err; } checkpoint_done(egc, stream, 0); break; case REC_TYPE_CHECKPOINT_STATE: if (!stream->in_checkpoint_state) { LOG(ERROR, \"Unexpected CHECKPOINT_STATE record in stream\"); rc = ERROR_FAIL; goto err; } srcs = rec->body; checkpoint_state_done(egc, stream, srcs->id); break; default: LOG(ERROR, \"Unrecognised record 0x%08x\", rec->hdr.type); rc = ERROR_FAIL; goto err; } assert(!rc); free_record(rec); return further_action_needed;  err: assert(rc); free_record(rec); stream_complete(egc, stream, rc); return false; }", "target": 0, "idx": 104007, "project": "Xen"}
{"func": "int TIFFPredictorInit(TIFF* tif) { TIFFPredictorState* sp = PredictorState(tif); assert(sp != 0);  if (!_TIFFMergeFields(tif, predictFields, TIFFArrayCount(predictFields))) { TIFFErrorExt(tif->tif_clientdata, \"TIFFPredictorInit\", \"Merging Predictor codec-specific tags failed\"); return 0; }  sp->vgetparent = tif->tif_tagmethods.vgetfield; tif->tif_tagmethods.vgetfield = PredictorVGetField; sp->vsetparent = tif->tif_tagmethods.vsetfield; tif->tif_tagmethods.vsetfield = PredictorVSetField; sp->printdir = tif->tif_tagmethods.printdir; tif->tif_tagmethods.printdir = PredictorPrintDir; sp->setupdecode = tif->tif_setupdecode; tif->tif_setupdecode = PredictorSetupDecode; sp->setupencode = tif->tif_setupencode; tif->tif_setupencode = PredictorSetupEncode; sp->predictor = 1; sp->encodepfunc = NULL; sp->decodepfunc = NULL; return 1; }", "target": 0, "idx": 100290, "project": "LibTIFF"}
{"func": " */ static inline void ADD_REGION(void *region, unsigned long region_size, struct xmem_pool *pool) { int fl, sl; struct bhdr *b, *lb; b = (struct bhdr *)(region); b->prev_hdr = NULL; b->size = ROUNDDOWN_SIZE(region_size - 2 * BHDR_OVERHEAD) | FREE_BLOCK | PREV_USED; MAPPING_INSERT(b->size & BLOCK_SIZE_MASK, &fl, &sl); INSERT_BLOCK(b, pool, fl, sl);  lb = GET_NEXT_BLOCK(b->ptr.buffer, b->size & BLOCK_SIZE_MASK); lb->prev_hdr = b; lb->size = 0 | USED_BLOCK | PREV_FREE; pool->used_size += BHDR_OVERHEAD;  pool->num_regions++; }", "target": 0, "idx": 108863, "project": "Xen"}
{"func": "void Usage() { fprintf(stderr, \"Usage: %s -depth (8 | 4 | 2 | 1) tiff-image\\n\", programName); exit(0); }", "target": 0, "idx": 100369, "project": "LibTIFF"}
{"func": "static int vgic_v2_to_sgi(struct vcpu *v, register_t sgir) { int virq; int irqmode; enum gic_sgi_mode sgi_mode; unsigned long vcpu_mask = 0; irqmode = (sgir & GICD_SGI_TARGET_LIST_MASK) >> GICD_SGI_TARGET_LIST_SHIFT; virq = (sgir & GICD_SGI_INTID_MASK); vcpu_mask = (sgir & GICD_SGI_TARGET_MASK) >> GICD_SGI_TARGET_SHIFT;  switch ( irqmode ) { case GICD_SGI_TARGET_LIST_VAL: sgi_mode = SGI_TARGET_LIST; break; case GICD_SGI_TARGET_OTHERS_VAL: sgi_mode = SGI_TARGET_OTHERS; break; case GICD_SGI_TARGET_SELF_VAL: sgi_mode = SGI_TARGET_SELF; break; default: BUG(); } return vgic_to_sgi(v, sgir, sgi_mode, virq, vcpu_mask); }", "target": 1, "idx": 109257, "project": "Xen"}
{"func": "static char **xs_directory_part(struct xs_handle *h, xs_transaction_t t, const char *path, unsigned int *num) { unsigned int off, result_len; char gen[24], offstr[8]; struct iovec iovec[2]; char *result = NULL, *strings = NULL; memset(gen, 0, sizeof(gen)); iovec[0].iov_base = (void *)path; iovec[0].iov_len = strlen(path) + 1; for (off = 0;;) { snprintf(offstr, sizeof(offstr), \"%u\", off); iovec[1].iov_base = (void *)offstr; iovec[1].iov_len = strlen(offstr) + 1; result = xs_talkv(h, t, XS_DIRECTORY_PART, iovec, 2, &result_len);  if (!result) { if (errno == ENOSYS) errno = E2BIG; return NULL; } if (off) { if (strcmp(gen, result)) { free(result); free(strings); strings = NULL; off = 0; continue; } } else strncpy(gen, result, sizeof(gen) - 1); result_len -= strlen(result) + 1; strings = realloc(strings, off + result_len); memcpy(strings + off, result + strlen(result) + 1, result_len); free(result); off += result_len; if (off <= 1 || strings[off - 2] == 0) break; } if (off > 1) off--; return xs_directory_common(strings, off, num); }", "target": 0, "idx": 108929, "project": "Xen"}
{"func": "int xc_flask_setavc_threshold(xc_interface *xch, int threshold) { DECLARE_FLASK_OP; op.cmd = FLASK_SETAVC_THRESHOLD; op.u.setavc_threshold.threshold = threshold; return xc_flask_op(xch, &op); }", "target": 0, "idx": 107498, "project": "Xen"}
{"func": "static int cpu_request_microcode(unsigned int cpu, const void *buf,  size_t size) { long offset = 0; int error = 0; void *mc; unsigned int matching_count = 0;  BUG_ON(cpu != raw_smp_processor_id()); while ( (offset = get_next_ucode_from_buffer(&mc, buf, size, offset)) > 0 ) { error = microcode_sanity_check(mc); if ( error ) break; error = get_matching_microcode(mc, cpu); if ( error < 0 ) break;  if ( error == 1 ) { matching_count++; error = 0; } xfree(mc); } if ( offset > 0 ) xfree(mc); if ( offset < 0 ) error = offset; if ( !error && matching_count ) error = apply_microcode(cpu); return error; }", "target": 0, "idx": 104554, "project": "Xen"}
{"func": " */ unsigned long create_pir_tables(void) { int length = sizeof(struct pir_table) + sizeof(struct pir_slot) * NR_PIR_SLOTS; struct pir_table *pir = scratch_alloc(length, 0); int i, checksum; memset(pir, 0, length); memcpy(pir->signature, \"$PIR\", 4); pir->version = 0x0100; pir->length = length; pir->router_bus = 0; pir->router_devfn = PCI_ISA_DEVFN; pir->router_vid = 0x8086; pir->router_did = 0x122e; pir->pci_irqs = 0x0000; for ( i = 0 ; i < NR_PIR_SLOTS; i++ ) { struct pir_slot *slot = &pir->slots[i]; slot->slot = i; slot->bus = 0; slot->dev = i<<3; slot->link_a = 0x60 + (i+1)%4; slot->bitmap_a = PCI_ISA_IRQ_MASK; slot->link_b = 0x60 + (i+2)%4; slot->bitmap_b = PCI_ISA_IRQ_MASK; slot->link_c = 0x60 + (i+3)%4; slot->bitmap_c = PCI_ISA_IRQ_MASK; slot->link_d = 0x60 + (i+4)%4; slot->bitmap_d = PCI_ISA_IRQ_MASK; } checksum = 0; for ( i = 0; i < length; i++ ) checksum += ((int8_t *)pir)[i]; pir->checksum = -checksum; return (unsigned long)pir; }", "target": 0, "idx": 105047, "project": "Xen"}
{"func": "static int min_order(size_t siz) { int rv = PAGE_SHIFT; while (siz > (1 << rv)) rv++; return rv; }", "target": 0, "idx": 102720, "project": "Xen"}
{"func": "bool mfn_in_pseudophysmap(struct xc_sr_context *ctx, xen_pfn_t mfn) { return ( (mfn <= ctx->x86_pv.max_mfn) &&  (mfn_to_pfn(ctx, mfn) <= ctx->x86_pv.max_pfn) &&  (xc_pfn_to_mfn(mfn_to_pfn(ctx, mfn), ctx->x86_pv.p2m, ctx->x86_pv.width) == mfn) ); }", "target": 0, "idx": 107705, "project": "Xen"}
{"func": "static int __tap_ctl_close(const int id, const int minor, const int force) { int err; tapdisk_message_t message; memset(&message, 0, sizeof(message)); message.type = TAPDISK_MESSAGE_CLOSE; if (force) message.type = TAPDISK_MESSAGE_FORCE_SHUTDOWN; message.cookie = minor; err = tap_ctl_connect_send_and_receive(id, &message, 5); if (err) return err; if (message.type == TAPDISK_MESSAGE_CLOSE_RSP) { err = message.u.response.error; if (err) EPRINTF(\"close failed: %d\\n\", err); } else { EPRINTF(\"got unexpected result '%s' from %d\\n\", tapdisk_message_name(message.type), id); err = EINVAL; } return err; } int tap_ctl_close(const int id, const int minor, const int force) { int i, err; for (i = 0; i < 20; i++) { err = __tap_ctl_close(id, minor, force); if (!err) return 0; err = (err < 0 ? -err : err); if (err != EAGAIN) { EPRINTF(\"close failed: %d\\n\", err); return err; } usleep(1000); } EPRINTF(\"close timed out\\n\"); return EIO; }", "target": 0, "idx": 106008, "project": "Xen"}
{"func": "long do_mmuext_op( XEN_GUEST_HANDLE(mmuext_op_t) uops, unsigned int count, XEN_GUEST_HANDLE(uint) pdone, unsigned int foreigndom) { struct mmuext_op op; int rc = 0, i = 0, okay; unsigned long type; unsigned int done = 0; struct vcpu *curr = current; struct domain *d = curr->domain; struct domain *pg_owner; if ( unlikely(count & MMU_UPDATE_PREEMPTED) ) { count &= ~MMU_UPDATE_PREEMPTED; if ( unlikely(!guest_handle_is_null(pdone)) ) (void)copy_from_guest(&done, pdone, 1); } else perfc_incr(calls_to_mmuext_op); if ( unlikely(!guest_handle_okay(uops, count)) ) { rc = -EFAULT; goto out; } if ( (pg_owner = get_pg_owner(foreigndom)) == NULL ) { rc = -ESRCH; goto out; } for ( i = 0; i < count; i++ ) { if ( hypercall_preempt_check() ) { rc = -EAGAIN; break; } if ( unlikely(__copy_from_guest(&op, uops, 1) != 0) ) { MEM_LOG(\"Bad __copy_from_guest\"); rc = -EFAULT; break; } okay = 1; switch ( op.cmd ) { case MMUEXT_PIN_L1_TABLE: type = PGT_l1_page_table; goto pin_page; case MMUEXT_PIN_L2_TABLE: type = PGT_l2_page_table; goto pin_page; case MMUEXT_PIN_L3_TABLE: type = PGT_l3_page_table; goto pin_page; case MMUEXT_PIN_L4_TABLE: if ( is_pv_32bit_domain(pg_owner) ) break; type = PGT_l4_page_table; pin_page: { struct page_info *page;  if ( (op.cmd - MMUEXT_PIN_L1_TABLE) > (CONFIG_PAGING_LEVELS - 1) ) break; if ( paging_mode_refcounts(pg_owner) ) break; page = get_page_from_gfn(pg_owner, op.arg1.mfn, NULL, P2M_ALLOC); if ( unlikely(!page) ) { rc = -EINVAL; break; } rc = get_page_type_preemptible(page, type); okay = !rc; if ( unlikely(!okay) ) { if ( rc == -EINTR ) rc = -EAGAIN; else if ( rc != -EAGAIN ) MEM_LOG(\"Error while pinning mfn %lx\", page_to_mfn(page)); put_page(page); break; } if ( (rc = xsm_memory_pin_page(d, pg_owner, page)) != 0 ) { put_page_and_type(page); okay = 0; break; } if ( unlikely(test_and_set_bit(_PGT_pinned,  &page->u.inuse.type_info)) ) { MEM_LOG(\"Mfn %lx already pinned\", page_to_mfn(page)); put_page_and_type(page); okay = 0; break; }  paging_mark_dirty(pg_owner, page_to_mfn(page));  if ( unlikely(pg_owner != d) ) { int drop_ref; spin_lock(&pg_owner->page_alloc_lock); drop_ref = (pg_owner->is_dying && test_and_clear_bit(_PGT_pinned,  &page->u.inuse.type_info)); spin_unlock(&pg_owner->page_alloc_lock); if ( drop_ref ) put_page_and_type(page); } break; } case MMUEXT_UNPIN_TABLE: { struct page_info *page; if ( paging_mode_refcounts(pg_owner) ) break; page = get_page_from_gfn(pg_owner, op.arg1.mfn, NULL, P2M_ALLOC); if ( unlikely(!page) ) { MEM_LOG(\"Mfn %lx bad domain\", op.arg1.mfn); break; } if ( !test_and_clear_bit(_PGT_pinned, &page->u.inuse.type_info) ) { okay = 0; put_page(page); MEM_LOG(\"Mfn %lx not pinned\", op.arg1.mfn); break; } put_page_and_type(page); put_page(page);  paging_mark_dirty(pg_owner, page_to_mfn(page)); break; } case MMUEXT_NEW_BASEPTR: okay = (!paging_mode_translate(d) && new_guest_cr3(op.arg1.mfn)); break;  #ifdef __x86_64__ case MMUEXT_NEW_USER_BASEPTR: { unsigned long old_mfn; if ( paging_mode_translate(current->domain) ) { okay = 0; break; } if ( op.arg1.mfn != 0 ) { if ( paging_mode_refcounts(d) ) okay = get_page_from_pagenr(op.arg1.mfn, d); else okay = !get_page_and_type_from_pagenr( op.arg1.mfn, PGT_root_page_table, d, 0, 0); if ( unlikely(!okay) ) { MEM_LOG(\"Error while installing new mfn %lx\", op.arg1.mfn); break; } } old_mfn = pagetable_get_pfn(curr->arch.guest_table_user); curr->arch.guest_table_user = pagetable_from_pfn(op.arg1.mfn); if ( old_mfn != 0 ) { if ( paging_mode_refcounts(d) ) put_page(mfn_to_page(old_mfn)); else put_page_and_type(mfn_to_page(old_mfn)); } break; } #endif  case MMUEXT_TLB_FLUSH_LOCAL: flush_tlb_local(); break;  case MMUEXT_INVLPG_LOCAL: if ( !paging_mode_enabled(d)   || paging_invlpg(curr, op.arg1.linear_addr) != 0 ) flush_tlb_one_local(op.arg1.linear_addr); break; case MMUEXT_TLB_FLUSH_MULTI: case MMUEXT_INVLPG_MULTI: { cpumask_t pmask; if ( unlikely(vcpumask_to_pcpumask(d, op.arg2.vcpumask, &pmask)) ) { okay = 0; break; } if ( op.cmd == MMUEXT_TLB_FLUSH_MULTI ) flush_tlb_mask(&pmask); else flush_tlb_one_mask(&pmask, op.arg1.linear_addr); break; } case MMUEXT_TLB_FLUSH_ALL: flush_tlb_mask(d->domain_dirty_cpumask); break;  case MMUEXT_INVLPG_ALL: flush_tlb_one_mask(d->domain_dirty_cpumask, op.arg1.linear_addr); break; case MMUEXT_FLUSH_CACHE: if ( unlikely(!cache_flush_permitted(d)) ) { MEM_LOG(\"Non-physdev domain tried to FLUSH_CACHE.\"); okay = 0; } else { wbinvd(); } break; case MMUEXT_FLUSH_CACHE_GLOBAL: if ( unlikely(foreigndom != DOMID_SELF) ) okay = 0; else if ( likely(cache_flush_permitted(d)) ) { unsigned int cpu; cpumask_t mask; cpumask_clear(&mask); for_each_online_cpu(cpu) if ( !cpumask_intersects(&mask,  per_cpu(cpu_sibling_mask, cpu)) ) cpumask_set_cpu(cpu, &mask); flush_mask(&mask, FLUSH_CACHE); } else { MEM_LOG(\"Non-physdev domain tried to FLUSH_CACHE_GLOBAL\"); okay = 0; } break; case MMUEXT_SET_LDT: { unsigned long ptr= op.arg1.linear_addr; unsigned long ents = op.arg2.nr_ents; if ( paging_mode_external(d) ) { MEM_LOG(\"ignoring SET_LDT hypercall from external domain\"); okay = 0; } else if ( ((ptr & (PAGE_SIZE-1)) != 0) ||  (ents > 8192) || !array_access_ok(ptr, ents, LDT_ENTRY_SIZE) ) { okay = 0; MEM_LOG(\"Bad args to SET_LDT: ptr=%lx, ents=%lx\", ptr, ents); } else if ( (curr->arch.pv_vcpu.ldt_ents != ents) || (curr->arch.pv_vcpu.ldt_base != ptr) ) { invalidate_shadow_ldt(curr, 0); flush_tlb_local(); curr->arch.pv_vcpu.ldt_base = ptr; curr->arch.pv_vcpu.ldt_ents = ents; load_LDT(curr); if ( ents != 0 ) (void)map_ldt_shadow_page(0); } break; } case MMUEXT_CLEAR_PAGE: { struct page_info *page; unsigned char *ptr; page = get_page_from_gfn(d, op.arg1.mfn, NULL, P2M_ALLOC); if ( !page || !get_page_type(page, PGT_writable_page) ) { if ( page ) put_page(page); MEM_LOG(\"Error while clearing mfn %lx\", op.arg1.mfn); okay = 0; break; }  paging_mark_dirty(d, page_to_mfn(page)); ptr = fixmap_domain_page(page_to_mfn(page)); clear_page(ptr); fixunmap_domain_page(ptr); put_page_and_type(page); break; } case MMUEXT_COPY_PAGE: { const unsigned char *src; unsigned char *dst; struct page_info *src_page, *dst_page; src_page = get_page_from_gfn(d, op.arg2.src_mfn, NULL, P2M_ALLOC); if ( unlikely(!src_page) ) { okay = 0; MEM_LOG(\"Error while copying from mfn %lx\", op.arg2.src_mfn); break; } dst_page = get_page_from_gfn(d, op.arg1.mfn, NULL, P2M_ALLOC); okay = (dst_page && get_page_type(dst_page, PGT_writable_page)); if ( unlikely(!okay) ) { put_page(src_page); if ( dst_page ) put_page(dst_page); MEM_LOG(\"Error while copying to mfn %lx\", op.arg1.mfn); break; }  paging_mark_dirty(d, page_to_mfn(dst_page)); src = __map_domain_page(src_page); dst = fixmap_domain_page(page_to_mfn(dst_page)); copy_page(dst, src); fixunmap_domain_page(dst); unmap_domain_page(src); put_page_and_type(dst_page); put_page(src_page); break; } #ifdef __x86_64__ case MMUEXT_MARK_SUPER: { unsigned long mfn; struct spage_info *spage; mfn = op.arg1.mfn; if ( mfn & (L1_PAGETABLE_ENTRIES-1) ) { MEM_LOG(\"Unaligned superpage reference mfn %lx\", mfn); okay = 0; break; } if ( !opt_allow_superpage ) { MEM_LOG(\"Superpages disallowed\"); okay = 0; rc = -ENOSYS; break; } spage = mfn_to_spage(mfn); okay = (mark_superpage(spage, d) >= 0); break; } case MMUEXT_UNMARK_SUPER: { unsigned long mfn; struct spage_info *spage; mfn = op.arg1.mfn; if ( mfn & (L1_PAGETABLE_ENTRIES-1) ) { MEM_LOG(\"Unaligned superpage reference mfn %lx\", mfn); okay = 0; break; } if ( !opt_allow_superpage ) { MEM_LOG(\"Superpages disallowed\"); okay = 0; rc = -ENOSYS; break; } spage = mfn_to_spage(mfn); okay = (unmark_superpage(spage) >= 0); break; } #endif default: MEM_LOG(\"Invalid extended pt command 0x%x\", op.cmd); rc = -ENOSYS; okay = 0; break; } if ( unlikely(!okay) ) { rc = rc ? rc : -EINVAL; break; } guest_handle_add_offset(uops, 1); } if ( rc == -EAGAIN ) rc = hypercall_create_continuation( __HYPERVISOR_mmuext_op, \"hihi\", uops, (count - i) | MMU_UPDATE_PREEMPTED, pdone, foreigndom); put_pg_owner(pg_owner); perfc_add(num_mmuext_ops, i);  out:  if ( unlikely(!guest_handle_is_null(pdone)) ) { done += i; copy_to_guest(pdone, &done, 1); } return rc; }", "target": 1, "idx": 109093, "project": "Xen"}
{"func": "static void _update_cr3(struct vcpu *v, int do_locking, bool noflush) { ASSERT_UNREACHABLE(); }", "target": 0, "idx": 104882, "project": "Xen"}
{"func": "static void bootloader_arg(libxl__bootloader_state *bl, const char *arg) { assert(bl->nargs < bl->argsspace); bl->args[bl->nargs++] = arg; }", "target": 0, "idx": 103356, "project": "Xen"}
{"func": " */ static int mfn_in_guarded_stack(unsigned long mfn) { void *p; int i; for ( i = 0; i < nr_cpu_ids; i++ ) { if ( !stack_base[i] ) continue; p = (void *)((unsigned long)stack_base[i] + STACK_SIZE -  PRIMARY_STACK_SIZE - PAGE_SIZE); if ( mfn == virt_to_mfn(p) ) return -1; } return 0; }", "target": 0, "idx": 106295, "project": "Xen"}
{"func": " */ static int INIT gunzip(void) { uch flags; unsigned char magic[2];  char method; ulg orig_crc = 0;  ulg orig_len = 0;  int res; magic[0] = NEXTBYTE(); magic[1] = NEXTBYTE(); method = NEXTBYTE(); if (magic[0] != 037 || ((magic[1] != 0213) && (magic[1] != 0236))) { error(\"bad gzip magic numbers\"); return -1; }  if (method != 8){ error(\"internal error, invalid method\"); return -1; } flags= (uch)get_byte(); if ((flags & ENCRYPTED) != 0) { error(\"Input is encrypted\"); return -1; } if ((flags & CONTINUATION) != 0) { error(\"Multi part input\"); return -1; } if ((flags & RESERVED) != 0) { error(\"Input has invalid flags\"); return -1; } NEXTBYTE();  NEXTBYTE(); NEXTBYTE(); NEXTBYTE(); (void)NEXTBYTE(); (void)NEXTBYTE(); if ((flags & EXTRA_FIELD) != 0) { unsigned len = (unsigned)NEXTBYTE(); len |= ((unsigned)NEXTBYTE())<<8; while (len--) (void)NEXTBYTE(); }  if ((flags & ORIG_NAME) != 0) {  while (NEXTBYTE() != 0); }   if ((flags & COMMENT) != 0) { while (NEXTBYTE() != 0); }  if ((res = inflate())) { switch (res) { case 0: break; case 1: error(\"invalid compressed format (err=1)\"); break; case 2: error(\"invalid compressed format (err=2)\"); break; case 3: error(\"out of memory\"); break; case 4: error(\"out of input data\"); break; default: error(\"invalid compressed format (other)\"); } return -1; }   orig_crc = (ulg) NEXTBYTE(); orig_crc |= (ulg) NEXTBYTE() << 8; orig_crc |= (ulg) NEXTBYTE() << 16; orig_crc |= (ulg) NEXTBYTE() << 24; orig_len = (ulg) NEXTBYTE(); orig_len |= (ulg) NEXTBYTE() << 8; orig_len |= (ulg) NEXTBYTE() << 16; orig_len |= (ulg) NEXTBYTE() << 24;  if (orig_crc != CRC_VALUE) { error(\"crc error\"); return -1; } if (orig_len != bytes_out) { error(\"length error\"); return -1; } return 0;  underrun:  error(\"out of input data\"); return -1; }", "target": 0, "idx": 102702, "project": "Xen"}
{"func": "static void print_PSS(struct xen_processor_px *ptr, int count) { int i; printk(\"\\t_PSS: state_count=%d\\n\", count); for (i=0; i<count; i++){ printk(\"\\tState%d: %\"PRId64\"MHz %\"PRId64\"mW %\"PRId64\"us \"  \"%\"PRId64\"us %#\"PRIx64\" %#\"PRIx64\"\\n\",  i,  ptr[i].core_frequency,  ptr[i].power,  ptr[i].transition_latency,  ptr[i].bus_master_latency,  ptr[i].control,  ptr[i].status); } }", "target": 0, "idx": 101501, "project": "Xen"}
{"func": "static void * rt_alloc_vdata(const struct scheduler *ops, struct vcpu *vc, void *dd) { struct rt_vcpu *svc;  svc = xzalloc(struct rt_vcpu); if ( svc == NULL ) return NULL; INIT_LIST_HEAD(&svc->q_elem); INIT_LIST_HEAD(&svc->replq_elem); svc->flags = 0U; svc->sdom = dd; svc->vcpu = vc; svc->last_start = 0; __set_bit(__RTDS_extratime, &svc->flags); svc->priority_level = 0; svc->period = RTDS_DEFAULT_PERIOD; if ( !is_idle_vcpu(vc) ) svc->budget = RTDS_DEFAULT_BUDGET; SCHED_STAT_CRANK(vcpu_alloc); return svc; }", "target": 0, "idx": 105622, "project": "Xen"}
{"func": "static int fuzz_wbinvd( struct x86_emulate_ctxt *ctxt) { return maybe_fail(ctxt, \"wbinvd\", true); }", "target": 0, "idx": 102234, "project": "Xen"}
{"func": "static int compare_value(const void *p1, const void *p2) { const struct sym_entry *sym1 = p1; const struct sym_entry *sym2 = p2; if (sym1->addr < sym2->addr) return -1; if (sym1->addr > sym2->addr) return +1;  if (isupper(*sym1->sym)) return -1; if (isupper(*sym2->sym)) return +1; return 0; }", "target": 0, "idx": 105931, "project": "Xen"}
{"func": "static void canonicalize(char *buffer) { char *reader, *writer; reader = writer = buffer; while (*reader) { *writer = *reader; if (*reader != '\\r') writer++; reader++; } *writer = *reader; }", "target": 0, "idx": 101400, "project": "Xen"}
{"func": "static void qos_init_domain(int domid, int idx) { int i; memset(&new_qos->domain_info[idx], 0, sizeof(_domain_info)); new_qos->domain_info[idx].last_update_time = global_now;  new_qos->domain_info[idx].runnable_start_time = 0;  new_qos->domain_info[idx].in_use = 1; new_qos->domain_info[idx].blocked_start_time = 0; new_qos->domain_info[idx].id = domid; if (domid == IDLE_DOMAIN_ID) snprintf(new_qos->domain_info[idx].name, sizeof(new_qos->domain_info[idx].name), \"Idle Task%d\", global_cpu); else snprintf(new_qos->domain_info[idx].name, sizeof(new_qos->domain_info[idx].name), \"Domain#%d\", domid); for (i=0; i<NSAMPLES; i++) { new_qos->qdata[i].ns_gotten[idx] = 0; new_qos->qdata[i].ns_allocated[idx] = 0; new_qos->qdata[i].ns_waiting[idx] = 0; new_qos->qdata[i].ns_blocked[idx] = 0; new_qos->qdata[i].switchin_count[idx] = 0; new_qos->qdata[i].io_count[idx] = 0; } }", "target": 0, "idx": 108159, "project": "Xen"}
{"func": "int xc_flask_getenforce(xc_interface *xch) { DECLARE_FLASK_OP; op.cmd = FLASK_GETENFORCE; return xc_flask_op(xch, &op); }", "target": 0, "idx": 107493, "project": "Xen"}
{"func": "static int __init acpi_parse_slit(struct acpi_table_header *table) { acpi_numa_slit_init((struct acpi_table_slit *)table); return 0; }", "target": 0, "idx": 104924, "project": "Xen"}
{"func": "Bit16u ata_cmd_non_data() {return 0;}", "target": 0, "idx": 105396, "project": "Xen"}
{"func": "int cond_index_bool(void *key, void *datum, void *datap) { struct policydb *p; struct cond_bool_datum *booldatum; booldatum = datum; p = datap; if ( !booldatum->value || booldatum->value > p->p_bools.nprim ) return -EINVAL; p->p_bool_val_to_name[booldatum->value - 1] = key; p->bool_val_to_struct[booldatum->value -1] = booldatum; return 0; }", "target": 0, "idx": 101350, "project": "Xen"}
{"func": "int osdep_gnttab_close(xengnttab_handle *xgt) { if ( xgt->fd == -1 ) return 0; return close(xgt->fd); }", "target": 0, "idx": 104225, "project": "Xen"}
{"func": "static void kdd_handle_setcpu(kdd_state *s) { KDD_LOG(s, \"Switch to CPU %u\\n\", s->rxp.cmd.setcpu.cpu);  s->cpuid = s->rxp.cmd.setcpu.cpu; kdd_break(s);  }", "target": 0, "idx": 102942, "project": "Xen"}
{"func": "static void psr_cmt_print_domain_info(libxl_dominfo *dominfo, libxl_psr_cmt_type type, libxl_bitmap *socketmap) { char *domain_name; uint32_t socketid; uint64_t monitor_data; if (!libxl_psr_cmt_domain_attached(ctx, dominfo->domid)) return; domain_name = libxl_domid_to_name(ctx, dominfo->domid); printf(\"%-40s %5d\", domain_name, dominfo->domid); free(domain_name); libxl_for_each_set_bit(socketid, *socketmap) { switch (type) { case LIBXL_PSR_CMT_TYPE_CACHE_OCCUPANCY: if (!libxl_psr_cmt_get_sample(ctx, dominfo->domid, type, socketid, &monitor_data, NULL)) printf(\"%13\"PRIu64\" KB\", monitor_data / 1024); break; case LIBXL_PSR_CMT_TYPE_TOTAL_MEM_COUNT: case LIBXL_PSR_CMT_TYPE_LOCAL_MEM_COUNT: if (!psr_cmt_get_mem_bandwidth(dominfo->domid, type, socketid,  &monitor_data)) printf(\"%11\"PRIu64\" KB/s\", monitor_data); break; default: return; } } printf(\"\\n\"); }", "target": 0, "idx": 108769, "project": "Xen"}
{"func": "int xc_sched_rtds_vcpu_set(xc_interface *xch,  uint32_t domid,  struct xen_domctl_schedparam_vcpu *vcpus,  uint32_t num_vcpus) { int rc = 0; unsigned processed = 0; DECLARE_DOMCTL; DECLARE_HYPERCALL_BOUNCE(vcpus, sizeof(*vcpus) * num_vcpus,  XC_HYPERCALL_BUFFER_BOUNCE_IN); if ( xc_hypercall_bounce_pre(xch, vcpus) ) return -1; domctl.cmd = XEN_DOMCTL_scheduler_op; domctl.domain = domid; domctl.u.scheduler_op.sched_id = XEN_SCHEDULER_RTDS; domctl.u.scheduler_op.cmd = XEN_DOMCTL_SCHEDOP_putvcpuinfo; while ( processed < num_vcpus ) { domctl.u.scheduler_op.u.v.nr_vcpus = num_vcpus - processed; set_xen_guest_handle_offset(domctl.u.scheduler_op.u.v.vcpus, vcpus, processed); if ( (rc = do_domctl(xch, &domctl)) != 0 ) break; processed += domctl.u.scheduler_op.u.v.nr_vcpus; } xc_hypercall_bounce_post(xch, vcpus); return rc; }", "target": 0, "idx": 107694, "project": "Xen"}
{"func": "static inline int iocb_optimized(struct opioctx *ctx, struct iocb *io) { unsigned long iop = (unsigned long)io->data; unsigned long start = (unsigned long)ctx->opios; unsigned long end = start + (ctx->num_opios * sizeof(struct opio)); return (iop >= start && iop < end); }", "target": 0, "idx": 102760, "project": "Xen"}
{"func": "xen_pfn_t *xc_map_m2p(xc_interface *xch, unsigned long max_mfn, int prot, unsigned long *mfn0) { privcmd_mmap_entry_t *entries; unsigned long m2p_chunks, m2p_size; xen_pfn_t *m2p; xen_pfn_t *extent_start; int i; m2p = NULL; m2p_size = M2P_SIZE(max_mfn); m2p_chunks = M2P_CHUNKS(max_mfn); extent_start = calloc(m2p_chunks, sizeof(xen_pfn_t)); if ( !extent_start ) { ERROR(\"failed to allocate space for m2p mfns\"); goto err0; } if ( xc_machphys_mfn_list(xch, m2p_chunks, extent_start) ) { PERROR(\"xc_get_m2p_mfns\"); goto err1; } entries = calloc(m2p_chunks, sizeof(privcmd_mmap_entry_t)); if (entries == NULL) { ERROR(\"failed to allocate space for mmap entries\"); goto err1; } for ( i = 0; i < m2p_chunks; i++ ) entries[i].mfn = extent_start[i]; m2p = xc_map_foreign_ranges(xch, DOMID_XEN, m2p_size, prot, M2P_CHUNK_SIZE, entries, m2p_chunks); if (m2p == NULL) { PERROR(\"xc_mmap_foreign_ranges failed\"); goto err2; } if (mfn0) *mfn0 = entries[0].mfn; err2: free(entries); err1: free(extent_start); err0: return m2p; }", "target": 0, "idx": 107615, "project": "Xen"}
{"func": "static void vhd_util_scan_print_image_indent(struct vhd_image *image, int tab) { char *pad, *name, *pmsg, *parent; pad= (tab ? \" \" : \"\"); name = image->name; parent = (image->parent ? : \"none\"); if ((flags & VHD_SCAN_PRETTY) && image->parent && !image->parent_image) pmsg = \" (not found in scan)\"; else pmsg = \"\"; if (!(flags & VHD_SCAN_VERBOSE)) { name = basename(image->name); if (image->parent) parent = basename(image->parent); } if (image->error) printf(\"%*svhd=%s scan-error=%d error-message='%s'\\n\",  tab, pad, image->name, image->error, image->message); else printf(\"%*svhd=%s capacity=%\"PRIu64\" size=%\"PRIu64\" hidden=%u \"  \"parent=%s%s\\n\", tab, pad, name, image->capacity,  image->size, image->hidden, parent, pmsg); }", "target": 0, "idx": 106847, "project": "Xen"}
{"func": "void paging_mark_dirty(struct domain *d, unsigned long guest_mfn) { unsigned long pfn; mfn_t gmfn; int changed; mfn_t mfn, *l4, *l3, *l2; unsigned long *l1; int i1, i2, i3, i4; gmfn = _mfn(guest_mfn); if ( !paging_mode_log_dirty(d) || !mfn_valid(gmfn) ||  page_get_owner(mfn_to_page(gmfn)) != d ) return;  pfn = get_gpfn_from_mfn(mfn_x(gmfn));  BUG_ON(SHARED_M2P(pfn));  if ( unlikely(!VALID_M2P(pfn)) ) return; i1 = L1_LOGDIRTY_IDX(pfn); i2 = L2_LOGDIRTY_IDX(pfn); i3 = L3_LOGDIRTY_IDX(pfn); i4 = L4_LOGDIRTY_IDX(pfn);  paging_lock_recursive(d); if ( unlikely(!mfn_valid(d->arch.paging.log_dirty.top)) )  {  d->arch.paging.log_dirty.top = paging_new_log_dirty_node(d);  if ( unlikely(!mfn_valid(d->arch.paging.log_dirty.top)) )  goto out; } l4 = paging_map_log_dirty_bitmap(d); mfn = l4[i4]; if ( !mfn_valid(mfn) ) l4[i4] = mfn = paging_new_log_dirty_node(d); unmap_domain_page(l4); if ( !mfn_valid(mfn) ) goto out; l3 = map_domain_page(mfn_x(mfn)); mfn = l3[i3]; if ( !mfn_valid(mfn) ) l3[i3] = mfn = paging_new_log_dirty_node(d); unmap_domain_page(l3); if ( !mfn_valid(mfn) ) goto out; l2 = map_domain_page(mfn_x(mfn)); mfn = l2[i2]; if ( !mfn_valid(mfn) ) l2[i2] = mfn = paging_new_log_dirty_leaf(d); unmap_domain_page(l2); if ( !mfn_valid(mfn) ) goto out; l1 = map_domain_page(mfn_x(mfn)); changed = !__test_and_set_bit(i1, l1); unmap_domain_page(l1); if ( changed ) { PAGING_DEBUG(LOGDIRTY,   \"marked mfn %\" PRI_mfn \" (pfn=%lx), dom %d\\n\",  mfn_x(gmfn), pfn, d->domain_id); d->arch.paging.log_dirty.dirty_count++; } out:  paging_unlock(d); return; }", "target": 1, "idx": 109559, "project": "Xen"}
{"func": "static void early_init_intel(struct cpuinfo_x86 *c) { u64 misc_enable, disable;  if (c->x86 == 15 && c->x86_cache_alignment == 64) c->x86_cache_alignment = 128;  rdmsrl(MSR_IA32_MISC_ENABLE, misc_enable); disable = misc_enable & (MSR_IA32_MISC_ENABLE_LIMIT_CPUID |  MSR_IA32_MISC_ENABLE_XD_DISABLE); if (disable) { wrmsrl(MSR_IA32_MISC_ENABLE, misc_enable & ~disable); bootsym(trampoline_misc_enable_off) |= disable; } if (disable & MSR_IA32_MISC_ENABLE_LIMIT_CPUID) printk(KERN_INFO \"revised cpuid level: %d\\n\",  cpuid_eax(0)); if (disable & MSR_IA32_MISC_ENABLE_XD_DISABLE) { write_efer(read_efer() | EFER_NX); printk(KERN_INFO  \"re-enabled NX (Execute Disable) protection\\n\"); }  if (boot_cpu_data.x86 == 0xF && boot_cpu_data.x86_model == 3 && (boot_cpu_data.x86_mask == 3 || boot_cpu_data.x86_mask == 4)) paddr_bits = 36; if (c == &boot_cpu_data) intel_init_levelling(); ctxt_switch_levelling(NULL); }", "target": 0, "idx": 102732, "project": "Xen"}
{"func": " */ static always_inline int rc_bit(struct rc_dec *rc, uint16_t *prob) { uint32_t bound; int bit; rc_normalize(rc); bound = (rc->range >> RC_BIT_MODEL_TOTAL_BITS) * *prob; if (rc->code < bound) { rc->range = bound; *prob += (RC_BIT_MODEL_TOTAL - *prob) >> RC_MOVE_BITS; bit = 0; } else { rc->range -= bound; rc->code -= bound; *prob -= *prob >> RC_MOVE_BITS; bit = 1; } return bit; }", "target": 0, "idx": 101612, "project": "Xen"}
{"func": "unsigned int xs_count_strings(const char *strings, unsigned int len) { unsigned int num; const char *p; for (p = strings, num = 0; p < strings + len; p++) if (*p == '\\0') num++; return num; }", "target": 0, "idx": 108959, "project": "Xen"}
{"func": " returning -1,0,1 * for <,=,> */ static int compare_vbd_wr(xenstat_domain *domain1, xenstat_domain *domain2) { return -compare(tot_vbd_reqs(domain1, FIELD_VBD_WR), tot_vbd_reqs(domain2, FIELD_VBD_WR)); }", "target": 0, "idx": 108514, "project": "Xen"}
{"func": "static void block_cache_populate_cache(td_request_t clone, int err) { int i; radix_tree_t *tree; block_cache_t *cache; block_cache_request_t *breq; breq= (block_cache_request_t *)clone.cb_data; cache = breq->cache; tree= &cache->tree; breq->secs -= clone.secs; breq->err = (breq->err ? breq->err : err); if (breq->secs) return; if (breq->err) { free(breq->buf); goto out; } for (i = 0; i < breq->treq.secs; i++) { off_t off = i << RADIX_TREE_NODE_SHIFT; DBG(\"%s: populating sec 0x%08llx\\n\", cache->name, breq->treq.sec + i); memcpy(breq->treq.buf + off,  breq->buf + off, RADIX_TREE_NODE_SIZE); } if (radix_tree_add_leaves(tree, breq->buf, breq->treq.sec, breq->treq.secs)) free(breq->buf); out: td_complete_request(breq->treq, breq->err); block_cache_put_request(cache, breq); }", "target": 0, "idx": 101038, "project": "Xen"}
{"func": "static void _ns16550_resume(struct serial_port *port) { #ifdef CONFIG_HAS_PCI struct ns16550 *uart = port->uart; if ( uart->bar ) {  pci_conf_write32(0, uart->ps_bdf[0], uart->ps_bdf[1], uart->ps_bdf[2], PCI_BASE_ADDRESS_0 + uart->bar_idx*4, uart->bar);  if ( uart->bar & PCI_BASE_ADDRESS_MEM_TYPE_64 ) pci_conf_write32(0, uart->ps_bdf[0], uart->ps_bdf[1], uart->ps_bdf[2], PCI_BASE_ADDRESS_0 + (uart->bar_idx+1)*4, uart->bar64);  pci_conf_write16(0, uart->ps_bdf[0], uart->ps_bdf[1], uart->ps_bdf[2], PCI_COMMAND, uart->cr); } #endif ns16550_setup_preirq(port->uart); ns16550_setup_postirq(port->uart); }", "target": 0, "idx": 104920, "project": "Xen"}
{"func": "static void update_max_weight(struct csched2_runqueue_data *rqd, int new_weight, int old_weight) {  if ( new_weight > rqd->max_weight ) { rqd->max_weight = new_weight; SCHED_STAT_CRANK(upd_max_weight_quick); } else if ( old_weight == rqd->max_weight ) { struct list_head *iter; int max_weight = 1; list_for_each( iter, &rqd->svc ) { struct csched2_vcpu * svc = list_entry(iter, struct csched2_vcpu, rqd_elem); if ( svc->weight > max_weight ) max_weight = svc->weight; } rqd->max_weight = max_weight; SCHED_STAT_CRANK(upd_max_weight_full); } if ( unlikely(tb_init_done) ) { struct { unsigned rqi:16, max_weight:16; } d; d.rqi = rqd->id; d.max_weight = rqd->max_weight; __trace_var(TRC_CSCHED2_RUNQ_MAX_WEIGHT, 1, sizeof(d), (unsigned char *)&d); } }", "target": 0, "idx": 105578, "project": "Xen"}
{"func": "static void p4_stop(struct op_msrs const * const msrs) { unsigned int stag; uint64_t msr_content; int i; stag = get_stagger(); for (i = 0; i < num_counters; ++i) { CCCR_READ(msr_content, VIRT_CTR(stag, i)); CCCR_SET_DISABLE(msr_content); CCCR_WRITE(msr_content, VIRT_CTR(stag, i)); } }", "target": 0, "idx": 104963, "project": "Xen"}
{"func": "static callback_id_pair *qmp_get_callback_from_id(libxl__qmp_handler *qmp, const libxl__json_object *o) { const libxl__json_object *id_object = libxl__json_map_get(\"id\", o, JSON_INTEGER); int id = -1; callback_id_pair *pp = NULL; if (id_object) { id = libxl__json_object_get_integer(id_object); LIBXL_STAILQ_FOREACH(pp, &qmp->callback_list, next) { if (pp->id == id) { return pp; } } } return NULL; }", "target": 0, "idx": 103893, "project": "Xen"}
{"func": "static void _tiffUnmapProc(thandle_t fd, tdata_t base, toff_t size) { }", "target": 0, "idx": 100115, "project": "LibTIFF"}
{"func": "xengntshr_handle *xengntshr_open(xentoollog_logger *logger, unsigned open_flags) { return NULL; }", "target": 0, "idx": 102568, "project": "Xen"}
{"func": "static int swabHorAcc32(TIFF* tif, uint8* cp0, tmsize_t cc) { uint32* wp = (uint32*) cp0; tmsize_t wc = cc / 4; TIFFSwabArrayOfLong(wp, wc); return horAcc32(tif, cp0, cc); }", "target": 0, "idx": 100629, "project": "LibTIFF"}
{"func": "_hidden int libxl__parse_mac(const char *s, libxl_mac mac) { const char *tok; char *endptr; int i; for (i = 0, tok = s; *tok && (i < 6); ++i, tok = endptr) { mac[i] = strtol(tok, &endptr, 16); if (endptr != (tok + 2) || (*endptr != '\\0' && *endptr != ':') ) return ERROR_INVAL; if (*endptr == ':') endptr++; } if ( i != 6 ) return ERROR_INVAL; return 0; }", "target": 0, "idx": 103743, "project": "Xen"}
{"func": "int libxl__cpuid_policy_list_parse_json(libxl__gc *gc, const libxl__json_object *o, libxl_cpuid_policy_list *p) { return 0; }", "target": 0, "idx": 103809, "project": "Xen"}
{"func": " */ void libxl__bitmap_copy_best_effort(libxl__gc *gc, libxl_bitmap *dptr, const libxl_bitmap *sptr) { int sz; sz = dptr->size < sptr->size ? dptr->size : sptr->size; memcpy(dptr->map, sptr->map, sz * sizeof(*dptr->map)); }", "target": 0, "idx": 104143, "project": "Xen"}
{"func": "static u32 adjust_vmx_controls( const char *name, u32 ctl_min, u32 ctl_opt, u32 msr, bool_t *mismatch) { u32 vmx_msr_low, vmx_msr_high, ctl = ctl_min | ctl_opt; rdmsr(msr, vmx_msr_low, vmx_msr_high); ctl &= vmx_msr_high;  ctl |= vmx_msr_low;  if ( ctl_min & ~ctl ) { *mismatch = 1; printk(\"VMX: CPU%d has insufficient %s (%08x; requires %08x)\\n\",  smp_processor_id(), name, ctl, ctl_min); } return ctl; }", "target": 0, "idx": 107001, "project": "Xen"}
{"func": "void __init vesa_endboot(bool_t keep) { if ( keep ) { video_puts = lfb_scroll_puts; lfb_carriage_return(); } else { unsigned int i, bpp = (vlfb_info.bits_per_pixel + 7) >> 3; for ( i = 0; i < vlfb_info.height; i++ ) memset(lfb + i * vlfb_info.bytes_per_line, 0,  vlfb_info.width * bpp); lfb_flush(); lfb_free(); } }", "target": 0, "idx": 106653, "project": "Xen"}
{"func": "int conf_read(const char *name) { struct symbol *sym; int i; sym_set_change_count(0); if (conf_read_simple(name, S_DEF_USER)) return 1; for_all_symbols(i, sym) { sym_calc_value(sym); if (sym_is_choice(sym) || (sym->flags & SYMBOL_AUTO)) continue; if (sym_has_value(sym) && (sym->flags & SYMBOL_WRITE)) {  switch (sym->type) { case S_BOOLEAN: case S_TRISTATE: if (sym->def[S_DEF_USER].tri != sym_get_tristate_value(sym)) break; if (!sym_is_choice(sym)) continue;  default: if (!strcmp(sym->curr.val, sym->def[S_DEF_USER].val)) continue; break; } } else if (!sym_has_value(sym) && !(sym->flags & SYMBOL_WRITE))  continue; conf_unsaved++;  } for_all_symbols(i, sym) { if (sym_has_value(sym) && !sym_is_choice_value(sym)) {  if (sym->visible == no && !conf_unsaved) sym->flags &= ~SYMBOL_DEF_USER; switch (sym->type) { case S_STRING: case S_INT: case S_HEX:  if (sym_string_within_range(sym, sym->def[S_DEF_USER].val)) break; sym->flags &= ~(SYMBOL_VALID|SYMBOL_DEF_USER); conf_unsaved++; break; default: break; } } } sym_add_change_count(conf_warnings || conf_unsaved); return 0; }", "target": 0, "idx": 101381, "project": "Xen"}
{"func": " */ static int set_theme(const char *theme) { int use_color = 1; if (!theme) set_bluetitle_theme(); else if (strcmp(theme, \"classic\") == 0) set_classic_theme(); else if (strcmp(theme, \"bluetitle\") == 0) set_bluetitle_theme(); else if (strcmp(theme, \"blackbg\") == 0) set_blackbg_theme(); else if (strcmp(theme, \"mono\") == 0) use_color = 0; return use_color; }", "target": 0, "idx": 106609, "project": "Xen"}
{"func": "static void mvebu3700_uart_suspend(struct serial_port *port) { BUG(); }", "target": 0, "idx": 104704, "project": "Xen"}
{"func": "static int  vhd_macx_encode_location(char *name, char **out, int *outlen) { iconv_t cd; int len, err; size_t ibl, obl; char *uri, *uri_utf8, *uri_utf8p, *ret; const char *urip; char *codeset; err = 0; ret = NULL; *out= NULL; *outlen = 0; len = strlen(name) + strlen(\"file://\"); ibl = len; obl = len * 2; urip = uri = malloc(ibl + 1); uri_utf8 = uri_utf8p = malloc(obl); if (!uri || !uri_utf8) return -ENOMEM; codeset = nl_langinfo(CODESET); cd = iconv_open(\"UTF-8\", codeset); if (cd == (iconv_t)-1) { err = -errno; goto out; } snprintf(uri, ibl+1, \"file://%s\", name); if (iconv(cd, #ifdef __linux__ (char **) #endif &urip, &ibl, &uri_utf8p, &obl) == (size_t)-1 || ibl) { err = (errno ? -errno : -EIO); goto out; } ret = malloc(len); if (!ret) { err = -ENOMEM; goto out; } memcpy(ret, uri_utf8, len); *outlen = len; *out= ret;  out: free(uri); free(uri_utf8); if (cd != (iconv_t)-1) iconv_close(cd); return err; }", "target": 0, "idx": 103156, "project": "Xen"}
{"func": "static int libxl__device_usbctrl_del_hvm(libxl__gc *gc, uint32_t domid,  int devid) { flexarray_t *qmp_args; qmp_args = flexarray_make(gc, 2, 1); flexarray_append_pair(qmp_args, \"id\", GCSPRINTF(\"xenusb-%d\", devid)); return libxl__qmp_run_command_flexarray(gc, domid, \"device_del\", qmp_args); }", "target": 0, "idx": 104076, "project": "Xen"}
{"func": "static void __init pre_parse(const struct file *cfg) { char *ptr = cfg->ptr, *end = ptr + cfg->size; bool start = true, comment = false; for ( ; ptr < end; ++ptr ) { if ( iscntrl(*ptr) ) { comment = false; start = true; *ptr = 0; } else if ( comment || (start && isspace(*ptr)) ) *ptr = 0; else if ( *ptr == '#' || (start && *ptr == ';') ) { comment = true; *ptr = 0; } else start = 0; } if ( cfg->size && end[-1] )  PrintStr(L\"No newline at end of config file,\"  \" last line will be ignored.\\r\\n\"); }", "target": 0, "idx": 101246, "project": "Xen"}
{"func": "void memshr_vbd_complete_ro_request(share_tuple_t hnd, uint16_t file_id,  uint64_t sec,  int secs) { vbdblk_t blk; if(!vbd_info.enabled)  return; if(secs != 8) return; blk.sec = sec; blk.disk_id = file_id; if(blockshr_insert(memshr.blks, blk, hnd) < 0) DPRINTF(\"Could not insert block hint into hash.\\n\"); }", "target": 0, "idx": 102745, "project": "Xen"}
{"func": "static int get_pxstat_by_cpuid(xc_interface *xc_handle, int cpuid, struct xc_px_stat *pxstat) { int ret = 0; int max_px_num = 0; ret = xc_pm_get_max_px(xc_handle, cpuid, &max_px_num); if ( ret ) return -errno; if ( !pxstat) return -EINVAL; pxstat->trans_pt = malloc(max_px_num * max_px_num * sizeof(uint64_t)); if ( !pxstat->trans_pt ) return -ENOMEM; pxstat->pt = malloc(max_px_num * sizeof(struct xc_px_val)); if ( !pxstat->pt ) { free(pxstat->trans_pt); return -ENOMEM; } ret = xc_pm_get_pxstat(xc_handle, cpuid, pxstat); if( ret ) { ret = -errno; free(pxstat->trans_pt); free(pxstat->pt); pxstat->trans_pt = NULL; pxstat->pt = NULL; } return ret; }", "target": 0, "idx": 108302, "project": "Xen"}
{"func": "long chksum_pmid_get_offset( byte* data, long offset ) { long result = -1L; while ((offset + PMID_LEN) < (bios_len - 1)) { offset = offset + 1; if( *( data + offset + 0 ) == 'P' && \\ *( data + offset + 1 ) == 'M' && \\ *( data + offset + 2 ) == 'I' && \\ *( data + offset + 3 ) == 'D' ) { result = offset; break; } } return( result ); }", "target": 0, "idx": 100992, "project": "Xen"}
{"func": " */ static int write_headers(struct xc_sr_context *ctx, uint16_t guest_type) { xc_interface *xch = ctx->xch; int32_t xen_version = xc_version(xch, XENVER_version, NULL); struct xc_sr_ihdr ihdr = { .marker= IHDR_MARKER, .id= htonl(IHDR_ID), .version = htonl(IHDR_VERSION), .options = htons(IHDR_OPT_LITTLE_ENDIAN), }; struct xc_sr_dhdr dhdr = { .type = guest_type, .page_shift = XC_PAGE_SHIFT, .xen_major= (xen_version >> 16) & 0xffff, .xen_minor= (xen_version) & 0xffff, }; if ( xen_version < 0 ) { PERROR(\"Unable to obtain Xen Version\"); return -1; } if ( write_exact(ctx->fd, &ihdr, sizeof(ihdr)) ) { PERROR(\"Unable to write Image Header to stream\"); return -1; } if ( write_exact(ctx->fd, &dhdr, sizeof(dhdr)) ) { PERROR(\"Unable to write Domain Header to stream\"); return -1; } return 0; }", "target": 0, "idx": 107769, "project": "Xen"}
{"func": "static struct subtitle_list *subtitles; static void set_subtitle(void) { struct subtitle_part *sp; struct subtitle_list *pos, *tmp; for (pos = subtitles; pos != NULL; pos = tmp) { tmp = pos->next; free(pos); } subtitles = NULL; list_for_each_entry(sp, &trail, entries) { if (sp->text) { if (pos) { pos->next = xcalloc(1, sizeof(*pos)); pos = pos->next; } else { subtitles = pos = xcalloc(1, sizeof(*pos)); } pos->text = sp->text; } } set_dialog_subtitles(subtitles); }", "target": 0, "idx": 104424, "project": "Xen"}
{"func": "void finish_daemonize(void) { int devnull = open(\"/dev/null\", O_RDWR); if (devnull == -1) barf_perror(\"Could not open /dev/null\\n\"); dup2(devnull, STDIN_FILENO); dup2(devnull, STDOUT_FILENO); dup2(devnull, STDERR_FILENO); close(devnull); xprintf = trace; }", "target": 0, "idx": 108444, "project": "Xen"}
{"func": "static void vlapic_accept_irq(struct vcpu *v, uint32_t icr_low) { struct vlapic *vlapic = vcpu_vlapic(v); uint8_t vector = (uint8_t)icr_low; switch ( icr_low & APIC_MODE_MASK ) { case APIC_DM_FIXED: case APIC_DM_LOWEST: if ( vlapic_enabled(vlapic) ) vlapic_set_irq(vlapic, vector, 0); break; case APIC_DM_REMRD: gdprintk(XENLOG_WARNING, \"Ignoring delivery mode 3\\n\"); break; case APIC_DM_SMI: gdprintk(XENLOG_WARNING, \"Ignoring guest SMI\\n\"); break; case APIC_DM_NMI: if ( !test_and_set_bool(v->nmi_pending) ) { bool_t wake = 0; domain_lock(v->domain); if ( v->is_initialised ) wake = test_and_clear_bit(_VPF_down, &v->pause_flags); domain_unlock(v->domain); if ( wake ) vcpu_wake(v); vcpu_kick(v); } break; case APIC_DM_INIT: case APIC_DM_STARTUP: BUG();  default: gdprintk(XENLOG_ERR, \"TODO: unsupported delivery mode in ICR %x\\n\",  icr_low); domain_crash(v->domain); } }", "target": 0, "idx": 106925, "project": "Xen"}
{"func": " */ static void pi_desc_init(struct vcpu *v) { v->arch.hvm_vmx.pi_desc.nv = posted_intr_vector;  v->arch.hvm_vmx.pi_desc.ndst = APIC_INVALID_DEST; }", "target": 0, "idx": 107007, "project": "Xen"}
{"func": "static int livepatch_upload(struct xen_sysctl_livepatch_upload *upload) { struct payload *data, *found; char n[XEN_LIVEPATCH_NAME_SIZE]; void *raw_data; int rc; rc = verify_payload(upload, n); if ( rc ) return rc; data = xzalloc(struct payload); raw_data = vmalloc(upload->size); spin_lock(&payload_lock); found = find_payload(n); if ( IS_ERR(found) ) rc = PTR_ERR(found); else if ( found ) rc = -EEXIST; else if ( !data || !raw_data ) rc = -ENOMEM; else if ( __copy_from_guest(raw_data, upload->payload, upload->size) ) rc = -EFAULT; else { memcpy(data->name, n, strlen(n)); rc = load_payload_data(data, raw_data, upload->size); if ( rc ) goto out; data->state = LIVEPATCH_STATE_CHECKED; INIT_LIST_HEAD(&data->list); INIT_LIST_HEAD(&data->applied_list); list_add_tail(&data->list, &payload_list); payload_cnt++; payload_version++; }  out: spin_unlock(&payload_lock); vfree(raw_data); if ( rc && data ) { xfree((void *)data->symtab); xfree((void *)data->strtab); xfree(data); } return rc; }", "target": 0, "idx": 104252, "project": "Xen"}
{"func": "void update_eip(struct eip_list_struct **head, unsigned long long eip, unsigned long long cycles, int type, void * extra) { struct eip_list_struct *p, **last=head; for(p=*head; p; last = (&p->next), p=p->next) if(p->eip >= eip) break; if(!p || p->eip != eip) { p=malloc(sizeof(*p)); if(!p) { perror(\"malloc failed\"); error(ERR_SYSTEM, NULL); } bzero(p, sizeof(*p)); p->eip=eip; p->type = type; if(eip_list_type[type].new) { eip_list_type[type].new(p, extra); } p->next = *last; *last=p; } else if(p->type != type) { fprintf(stderr, \"WARNING, mixed types! %d %d\\n\", p->type, type); } else if(eip_list_type[type].update) { eip_list_type[type].update(p, extra); } update_cycles(&p->summary, cycles); }", "target": 0, "idx": 108115, "project": "Xen"}
{"func": "void vmx_vmexit_handler(struct cpu_user_regs *regs) { unsigned long exit_qualification, exit_reason, idtv_info, intr_info = 0; unsigned int vector = 0; struct vcpu *v = current; __vmread(GUEST_RIP,&regs->rip); __vmread(GUEST_RSP,&regs->rsp); __vmread(GUEST_RFLAGS, &regs->rflags); hvm_invalidate_regs_fields(regs); if ( paging_mode_hap(v->domain) ) { __vmread(GUEST_CR3, &v->arch.hvm_vcpu.hw_cr[3]); if ( vmx_unrestricted_guest(v) || hvm_paging_enabled(v) ) v->arch.hvm_vcpu.guest_cr[3] = v->arch.hvm_vcpu.hw_cr[3]; } __vmread(VM_EXIT_REASON, &exit_reason); if ( hvm_long_mode_enabled(v) ) HVMTRACE_ND(VMEXIT64, 0, 1, 3, exit_reason, (uint32_t)regs->eip, (uint32_t)((uint64_t)regs->eip >> 32), 0, 0, 0); else HVMTRACE_ND(VMEXIT, 0, 1, 2, exit_reason, (uint32_t)regs->eip,  0, 0, 0, 0); perfc_incra(vmexits, exit_reason);  switch ( (uint16_t)exit_reason ) { case EXIT_REASON_EXTERNAL_INTERRUPT: vmx_do_extint(regs); break; case EXIT_REASON_EXCEPTION_NMI: __vmread(VM_EXIT_INTR_INFO, &intr_info); BUG_ON(!(intr_info & INTR_INFO_VALID_MASK)); vector = intr_info & INTR_INFO_VECTOR_MASK; if ( vector == TRAP_machine_check ) do_machine_check(regs); if ( (vector == TRAP_nmi) &&  ((intr_info & INTR_INFO_INTR_TYPE_MASK) == MASK_INSR(X86_EVENTTYPE_NMI, INTR_INFO_INTR_TYPE_MASK)) ) { exception_table[TRAP_nmi](regs); enable_nmis(); } break; case EXIT_REASON_MCE_DURING_VMENTRY: do_machine_check(regs); break; }  local_irq_enable();  if ( altp2m_active(v->domain) && (v->arch.hvm_vmx.secondary_exec_control & SECONDARY_EXEC_ENABLE_VM_FUNCTIONS) ) { unsigned long idx; if ( v->arch.hvm_vmx.secondary_exec_control & SECONDARY_EXEC_ENABLE_VIRT_EXCEPTIONS ) __vmread(EPTP_INDEX, &idx); else { unsigned long eptp; __vmread(EPT_POINTER, &eptp); if ( (idx = p2m_find_altp2m_by_eptp(v->domain, eptp)) ==  INVALID_ALTP2M ) { gdprintk(XENLOG_ERR, \"EPTP not found in alternate p2m list\\n\"); domain_crash(v->domain); } } if ( idx != vcpu_altp2m(v).p2midx ) { BUG_ON(idx >= MAX_ALTP2M); atomic_dec(&p2m_get_altp2m(v)->active_vcpus); vcpu_altp2m(v).p2midx = idx; atomic_inc(&p2m_get_altp2m(v)->active_vcpus); } }  vcpu_nestedhvm(v).nv_vmswitch_in_progress = 0; if ( nestedhvm_vcpu_in_guestmode(v) ) { paging_update_nestedmode(v); if ( nvmx_n2_vmexit_handler(regs, exit_reason) ) goto out; } if ( unlikely(exit_reason & VMX_EXIT_REASONS_FAILED_VMENTRY) ) return vmx_failed_vmentry(exit_reason, regs); if ( v->arch.hvm_vmx.vmx_realmode ) {  regs->eflags &= ~(X86_EFLAGS_VM | X86_EFLAGS_IOPL); regs->eflags |= (v->arch.hvm_vmx.vm86_saved_eflags & X86_EFLAGS_IOPL);  switch ( exit_reason ) { case EXIT_REASON_EXCEPTION_NMI: if ( vector != TRAP_page_fault  && vector != TRAP_nmi   && vector != TRAP_machine_check )  { perfc_incr(realmode_exits); v->arch.hvm_vmx.vmx_emulate = 1; HVMTRACE_0D(REALMODE_EMULATE); return; } case EXIT_REASON_EXTERNAL_INTERRUPT: case EXIT_REASON_INIT: case EXIT_REASON_SIPI: case EXIT_REASON_PENDING_VIRT_INTR: case EXIT_REASON_PENDING_VIRT_NMI: case EXIT_REASON_MCE_DURING_VMENTRY: case EXIT_REASON_GETSEC: case EXIT_REASON_ACCESS_GDTR_OR_IDTR: case EXIT_REASON_ACCESS_LDTR_OR_TR: case EXIT_REASON_VMX_PREEMPTION_TIMER_EXPIRED: case EXIT_REASON_INVEPT: case EXIT_REASON_INVVPID: break; default: v->arch.hvm_vmx.vmx_emulate = 1; perfc_incr(realmode_exits); HVMTRACE_0D(REALMODE_EMULATE); return; } } hvm_maybe_deassert_evtchn_irq(); __vmread(IDT_VECTORING_INFO, &idtv_info); if ( exit_reason != EXIT_REASON_TASK_SWITCH ) vmx_idtv_reinject(idtv_info); switch ( exit_reason ) { unsigned long ecode; case EXIT_REASON_EXCEPTION_NMI: {   if ( unlikely(intr_info & INTR_INFO_NMI_UNBLOCKED_BY_IRET) &&  !(idtv_info & INTR_INFO_VALID_MASK) &&  (vector != TRAP_double_fault) ) { unsigned long guest_info; __vmread(GUEST_INTERRUPTIBILITY_INFO, &guest_info); __vmwrite(GUEST_INTERRUPTIBILITY_INFO, guest_info | VMX_INTR_SHADOW_NMI); } perfc_incra(cause_vector, vector); switch ( vector ) { case TRAP_debug:  __vmread(EXIT_QUALIFICATION, &exit_qualification); HVMTRACE_1D(TRAP_DEBUG, exit_qualification); write_debugreg(6, exit_qualification | DR_STATUS_RESERVED_ONE); if ( !v->domain->debugger_attached || cpu_has_monitor_trap_flag ) goto exit_and_crash; domain_pause_for_debugger(); break; case TRAP_int3:  { HVMTRACE_1D(TRAP, vector); if ( v->domain->debugger_attached ) { update_guest_eip();  v->arch.gdbsx_vcpu_event = TRAP_int3; domain_pause_for_debugger(); break; } else { int handled = hvm_event_int3(regs->eip);  if ( handled < 0 )  { struct hvm_trap trap = { .vector = TRAP_int3, .type = X86_EVENTTYPE_SW_EXCEPTION, .error_code = HVM_DELIVER_NO_ERROR_CODE, }; unsigned long insn_len; __vmread(VM_EXIT_INSTRUCTION_LEN, &insn_len); trap.insn_len = insn_len; hvm_inject_trap(&trap); break; } else if ( handled ) break; } goto exit_and_crash; } case TRAP_no_device: HVMTRACE_1D(TRAP, vector); vmx_fpu_dirty_intercept(); break; case TRAP_page_fault: __vmread(EXIT_QUALIFICATION, &exit_qualification); __vmread(VM_EXIT_INTR_ERROR_CODE, &ecode); regs->error_code = ecode; HVM_DBG_LOG(DBG_LEVEL_VMMU, \"eax=%lx, ebx=%lx, ecx=%lx, edx=%lx, esi=%lx, edi=%lx\", (unsigned long)regs->eax, (unsigned long)regs->ebx, (unsigned long)regs->ecx, (unsigned long)regs->edx, (unsigned long)regs->esi, (unsigned long)regs->edi); if ( paging_fault(exit_qualification, regs) ) { if ( trace_will_trace_event(TRC_SHADOW) ) break; if ( hvm_long_mode_enabled(v) ) HVMTRACE_LONG_2D(PF_XEN, regs->error_code,  TRC_PAR_LONG(exit_qualification) ); else HVMTRACE_2D(PF_XEN, regs->error_code, exit_qualification ); break; } hvm_inject_page_fault(regs->error_code, exit_qualification); break; case TRAP_nmi: if ( MASK_EXTR(intr_info, INTR_INFO_INTR_TYPE_MASK) !=  X86_EVENTTYPE_NMI ) goto exit_and_crash; HVMTRACE_0D(NMI);  break; case TRAP_machine_check: HVMTRACE_0D(MCE);  break; case TRAP_invalid_op: HVMTRACE_1D(TRAP, vector); vmx_vmexit_ud_intercept(regs); break; default: HVMTRACE_1D(TRAP, vector); goto exit_and_crash; } break; } case EXIT_REASON_EXTERNAL_INTERRUPT:  break; case EXIT_REASON_TRIPLE_FAULT: hvm_triple_fault(); break; case EXIT_REASON_PENDING_VIRT_INTR:  v->arch.hvm_vmx.exec_control &= ~CPU_BASED_VIRTUAL_INTR_PENDING; vmx_update_cpu_exec_control(v); break; case EXIT_REASON_PENDING_VIRT_NMI:  v->arch.hvm_vmx.exec_control &= ~CPU_BASED_VIRTUAL_NMI_PENDING; vmx_update_cpu_exec_control(v); break; case EXIT_REASON_TASK_SWITCH: { static const enum hvm_task_switch_reason reasons[] = { TSW_call_or_int, TSW_iret, TSW_jmp, TSW_call_or_int }; unsigned int inst_len, source; __vmread(EXIT_QUALIFICATION, &exit_qualification); source = (exit_qualification >> 30) & 3;  WARN_ON((source == 3) && !(idtv_info & INTR_INFO_VALID_MASK));  inst_len = ((source != 3) || (MASK_EXTR(idtv_info, INTR_INFO_INTR_TYPE_MASK)  > 3))  ? get_instruction_length(): 0; if ( (source == 3) && (idtv_info & INTR_INFO_DELIVER_CODE_MASK) ) __vmread(IDT_VECTORING_ERROR_CODE, &ecode); else  ecode = -1; regs->eip += inst_len; hvm_task_switch((uint16_t)exit_qualification, reasons[source], ecode); break; } case EXIT_REASON_CPUID: is_pvh_vcpu(v) ? pv_cpuid(regs) : vmx_do_cpuid(regs); update_guest_eip();  break; case EXIT_REASON_HLT: update_guest_eip();  hvm_hlt(regs->eflags); break; case EXIT_REASON_INVLPG: update_guest_eip();  __vmread(EXIT_QUALIFICATION, &exit_qualification); vmx_invlpg_intercept(exit_qualification); break; case EXIT_REASON_RDTSCP: regs->ecx = hvm_msr_tsc_aux(v);  case EXIT_REASON_RDTSC: update_guest_eip();  hvm_rdtsc_intercept(regs); break; case EXIT_REASON_VMCALL: { int rc; HVMTRACE_1D(VMMCALL, regs->eax); rc = hvm_do_hypercall(regs); if ( rc != HVM_HCALL_preempted ) { update_guest_eip();  if ( rc == HVM_HCALL_invalidate ) send_invalidate_req(); } break; } case EXIT_REASON_CR_ACCESS: { __vmread(EXIT_QUALIFICATION, &exit_qualification); if ( vmx_cr_access(exit_qualification) == X86EMUL_OKAY ) update_guest_eip();  break; } case EXIT_REASON_DR_ACCESS: __vmread(EXIT_QUALIFICATION, &exit_qualification); vmx_dr_access(exit_qualification, regs); break; case EXIT_REASON_MSR_READ: { uint64_t msr_content; if ( hvm_msr_read_intercept(regs->ecx, &msr_content) == X86EMUL_OKAY ) { regs->eax = (uint32_t)msr_content; regs->edx = (uint32_t)(msr_content >> 32); update_guest_eip();  } break; } case EXIT_REASON_MSR_WRITE: { uint64_t msr_content; msr_content = ((uint64_t)regs->edx << 32) | (uint32_t)regs->eax; if ( hvm_msr_write_intercept(regs->ecx, msr_content, 1) == X86EMUL_OKAY ) update_guest_eip();  break; } case EXIT_REASON_VMXOFF: if ( nvmx_handle_vmxoff(regs) == X86EMUL_OKAY ) update_guest_eip(); break; case EXIT_REASON_VMXON: if ( nvmx_handle_vmxon(regs) == X86EMUL_OKAY ) update_guest_eip(); break; case EXIT_REASON_VMCLEAR: if ( nvmx_handle_vmclear(regs) == X86EMUL_OKAY ) update_guest_eip(); break;   case EXIT_REASON_VMPTRLD: if ( nvmx_handle_vmptrld(regs) == X86EMUL_OKAY ) update_guest_eip(); break; case EXIT_REASON_VMPTRST: if ( nvmx_handle_vmptrst(regs) == X86EMUL_OKAY ) update_guest_eip(); break; case EXIT_REASON_VMREAD: if ( nvmx_handle_vmread(regs) == X86EMUL_OKAY ) update_guest_eip(); break;   case EXIT_REASON_VMWRITE: if ( nvmx_handle_vmwrite(regs) == X86EMUL_OKAY ) update_guest_eip(); break; case EXIT_REASON_VMLAUNCH: if ( nvmx_handle_vmlaunch(regs) == X86EMUL_OKAY ) update_guest_eip(); break; case EXIT_REASON_VMRESUME: if ( nvmx_handle_vmresume(regs) == X86EMUL_OKAY ) update_guest_eip(); break; case EXIT_REASON_INVEPT: if ( nvmx_handle_invept(regs) == X86EMUL_OKAY ) update_guest_eip(); break; case EXIT_REASON_INVVPID: if ( nvmx_handle_invvpid(regs) == X86EMUL_OKAY ) update_guest_eip(); break; case EXIT_REASON_VMFUNC: if ( vmx_vmfunc_intercept(regs) != X86EMUL_OKAY ) hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE); else update_guest_eip(); break; case EXIT_REASON_MWAIT_INSTRUCTION: case EXIT_REASON_MONITOR_INSTRUCTION: case EXIT_REASON_GETSEC:  WARN_ON(exit_reason == EXIT_REASON_GETSEC); hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE); break; case EXIT_REASON_TPR_BELOW_THRESHOLD: break; case EXIT_REASON_APIC_ACCESS: if ( !vmx_handle_eoi_write() && !handle_mmio() ) hvm_inject_hw_exception(TRAP_gp_fault, 0); break; case EXIT_REASON_EOI_INDUCED: __vmread(EXIT_QUALIFICATION, &exit_qualification); ASSERT(cpu_has_vmx_virtual_intr_delivery); vlapic_handle_EOI(vcpu_vlapic(v), exit_qualification); break; case EXIT_REASON_IO_INSTRUCTION: __vmread(EXIT_QUALIFICATION, &exit_qualification); if ( exit_qualification & 0x10 ) {  if ( unlikely(is_pvh_vcpu(v))||  !handle_mmio() ) hvm_inject_hw_exception(TRAP_gp_fault, 0); } else {  uint16_t port = (exit_qualification >> 16) & 0xFFFF; int bytes = (exit_qualification & 0x07) + 1; int dir = (exit_qualification & 0x08) ? IOREQ_READ : IOREQ_WRITE; if ( handle_pio(port, bytes, dir) ) update_guest_eip();  } break; case EXIT_REASON_INVD: case EXIT_REASON_WBINVD: { update_guest_eip();  vmx_wbinvd_intercept(); break; } case EXIT_REASON_EPT_VIOLATION: { paddr_t gpa; __vmread(GUEST_PHYSICAL_ADDRESS, &gpa); __vmread(EXIT_QUALIFICATION, &exit_qualification); ept_handle_violation(exit_qualification, gpa); break; } case EXIT_REASON_EPT_MISCONFIG: { paddr_t gpa; __vmread(GUEST_PHYSICAL_ADDRESS, &gpa); if ( !ept_handle_misconfig(gpa) ) goto exit_and_crash; break; } case EXIT_REASON_MONITOR_TRAP_FLAG: v->arch.hvm_vmx.exec_control &= ~CPU_BASED_MONITOR_TRAP_FLAG; vmx_update_cpu_exec_control(v); if ( v->arch.hvm_vcpu.single_step ) { hvm_event_single_step(regs->eip); if ( v->domain->debugger_attached ) domain_pause_for_debugger(); } break; case EXIT_REASON_PAUSE_INSTRUCTION: perfc_incr(pauseloop_exits); do_sched_op(SCHEDOP_yield, guest_handle_from_ptr(NULL, void)); break; case EXIT_REASON_XSETBV: if ( hvm_handle_xsetbv(regs->ecx,  (regs->rdx << 32) | regs->_eax) == 0 ) update_guest_eip();  break; case EXIT_REASON_APIC_WRITE: vmx_handle_apic_write(); break; case EXIT_REASON_PML_FULL: vmx_vcpu_flush_pml_buffer(v); break; case EXIT_REASON_ACCESS_GDTR_OR_IDTR: case EXIT_REASON_ACCESS_LDTR_OR_TR: case EXIT_REASON_VMX_PREEMPTION_TIMER_EXPIRED: case EXIT_REASON_INVPCID:  default: exit_and_crash: { struct segment_register ss; gdprintk(XENLOG_WARNING, \"Bad vmexit (reason %#lx)\\n\",  exit_reason); vmx_get_segment_register(v, x86_seg_ss, &ss); if ( ss.attr.fields.dpl ) hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE); else domain_crash(v->domain); } break; } out: if ( nestedhvm_vcpu_in_guestmode(v) ) nvmx_idtv_handling(); }", "target": 1, "idx": 109339, "project": "Xen"}
{"func": "int osdep_gnttab_unmap(xengnttab_handle *xgt,  void *start_address,  uint32_t count) { int fd = xgt->fd; struct ioctl_gntdev_get_offset_for_vaddr get_offset; struct ioctl_gntdev_unmap_grant_ref unmap_grant; int rc; if ( start_address == NULL ) { errno = EINVAL; return -1; }  get_offset.vaddr = (unsigned long)start_address; if ( (rc = ioctl(fd, IOCTL_GNTDEV_GET_OFFSET_FOR_VADDR,  &get_offset)) ) return rc; if ( get_offset.count != count ) { errno = EINVAL; return -1; }  if ( (rc = munmap(start_address, count * PAGE_SIZE)) ) return rc;  unmap_grant.index = get_offset.offset; unmap_grant.count = count; if ( (rc = ioctl(fd, IOCTL_GNTDEV_UNMAP_GRANT_REF, &unmap_grant)) ) return rc; return 0; }", "target": 0, "idx": 104229, "project": "Xen"}
{"func": "static int pcompar(const void* va, const void* vb) { const int* pa = (const int*) va; const int* pb = (const int*) vb; return (*pa - *pb); }", "target": 0, "idx": 100010, "project": "LibTIFF"}
{"func": "static void kconfig_print_comment(FILE *fp, const char *value, void *arg) { const char *p = value; size_t l; for (;;) { l = strcspn(p, \"\\n\"); fprintf(fp, \"#\"); if (l) { fprintf(fp, \" \"); xfwrite(p, l, 1, fp); p += l; } fprintf(fp, \"\\n\"); if (*p++ == '\\0') break; } }", "target": 0, "idx": 101394, "project": "Xen"}
{"func": "static void nmi_cpu_stop(void * dummy) { unsigned int v; int cpu = smp_processor_id(); struct op_msrs const * msrs = &cpu_msrs[cpu]; model->stop(msrs);  if ( (apic_read(APIC_LVTPC) & APIC_MODE_MASK) != APIC_DM_NMI  || (apic_read(APIC_LVTPC) & APIC_LVT_MASKED) ) { printk(\"nmi_stop: APIC not good %ul\\n\", apic_read(APIC_LVTPC)); mdelay(5000); } v = apic_read(APIC_LVTERR); apic_write(APIC_LVTERR, v | APIC_LVT_MASKED); apic_write(APIC_LVTPC, saved_lvtpc[cpu]); apic_write(APIC_LVTERR, v); }", "target": 0, "idx": 104845, "project": "Xen"}
{"func": "static int vhd_clobber_block(vhd_journal_t *journal, uint32_t src, uint32_t dest) { int err; off_t off; vhd_context_t *vhd; vhd = &journal->vhd; off = vhd_sectors_to_bytes(vhd->bat.bat[dest]); err = vhd_journal_add_block(journal, dest, VHD_JOURNAL_DATA | VHD_JOURNAL_METADATA); if (err) return err; err = vhd_move_block(journal, src, off); if (err) return err; vhd->bat.bat[dest] = DD_BLK_UNUSED; return 0; }", "target": 0, "idx": 106801, "project": "Xen"}
{"func": "void test_common_afterpoll(void) { test_common_get_now(); libxl_osevent_afterpoll(ctx, poll_nfds, poll_fds, now); }", "target": 0, "idx": 106415, "project": "Xen"}
{"func": "static void tapdisk_control_list(struct tapdisk_control_connection *connection,  tapdisk_message_t *request) { td_vbd_t *vbd; struct list_head *head; tapdisk_message_t response; int count, i; memset(&response, 0, sizeof(response)); response.type = TAPDISK_MESSAGE_LIST_RSP; response.cookie = request->cookie; head = tapdisk_server_get_all_vbds(); count = 0; list_for_each_entry(vbd, head, next) count++; list_for_each_entry(vbd, head, next) { response.u.list.count = count--; response.u.list.minor = vbd->minor; response.u.list.state = vbd->state; response.u.list.path[0] = 0; if (!list_empty(&vbd->images)) { td_image_t *image = list_entry(vbd->images.next,  td_image_t, next); snprintf(response.u.list.path,  sizeof(response.u.list.path),  \"%s:%s\",  tapdisk_disk_types[image->type]->name,  image->name); } tapdisk_control_write_message(connection->socket, &response, 2); } response.u.list.count = count; response.u.list.minor = -1; response.u.list.path[0] = 0; tapdisk_control_write_message(connection->socket, &response, 2); tapdisk_control_close_connection(connection); }", "target": 0, "idx": 106101, "project": "Xen"}
{"func": "static long do_microcode_update(void *_info) { struct microcode_info *info = _info; int error; BUG_ON(info->cpu != smp_processor_id()); error = microcode_update_cpu(info->buffer, info->buffer_size); if ( error ) info->error = error; info->cpu = cpumask_next(info->cpu, &cpu_online_map); if ( info->cpu < nr_cpu_ids ) return continue_hypercall_on_cpu(info->cpu, do_microcode_update, info); error = info->error; xfree(info); return error; }", "target": 0, "idx": 104530, "project": "Xen"}
{"func": "int xlu_cfg_value_get_string(const XLU_Config *cfg, XLU_ConfigValue *value,  char **value_r, int dont_warn) { if (value->type != XLU_STRING) { if (!dont_warn) fprintf(cfg->report, \"%s:%d:%d: warning: value is not a string\\n\", cfg->config_source, value->loc.first_line, value->loc.first_column); *value_r = NULL; return EINVAL; } *value_r = value->u.string; return 0; }", "target": 0, "idx": 103223, "project": "Xen"}
{"func": "static void ept_dump_p2m_table(unsigned char key) { struct domain *d; ept_entry_t *table, *ept_entry; int order; int i; int ret = 0; unsigned long gfn, gfn_remainder; unsigned long record_counter = 0; struct p2m_domain *p2m; struct ept_data *ept; for_each_domain(d) { if ( !hap_enabled(d) ) continue; p2m = p2m_get_hostp2m(d); ept = &p2m->ept; printk(\"\\ndomain%d EPT p2m table:\\n\", d->domain_id); for ( gfn = 0; gfn <= p2m->max_mapped_pfn; gfn += 1UL << order ) { char c = 0; gfn_remainder = gfn; table = map_domain_page(pagetable_get_mfn(p2m_get_pagetable(p2m))); for ( i = ept->wl; i > 0; i-- ) { ept_entry = table + (gfn_remainder >> (i * EPT_TABLE_ORDER)); if ( ept_entry->emt == MTRR_NUM_TYPES ) c = '?'; ret = ept_next_level(p2m, 1, &table, &gfn_remainder, i); if ( ret != GUEST_TABLE_NORMAL_PAGE ) break; } order = i * EPT_TABLE_ORDER; ept_entry = table + (gfn_remainder >> order); if ( ret != GUEST_TABLE_MAP_FAILED && is_epte_valid(ept_entry) ) { if ( ept_entry->sa_p2mt == p2m_populate_on_demand ) printk(\"gfn: %13lx order: %2d PoD\\n\", gfn, order); else printk(\"gfn: %13lx order: %2d mfn: %13lx %c%c%c %c%c%c\\n\",  gfn, order, ept_entry->mfn + 0UL,  ept_entry->r ? 'r' : ' ',  ept_entry->w ? 'w' : ' ',  ept_entry->x ? 'x' : ' ',  memory_type_to_str(ept_entry->emt)[0],  memory_type_to_str(ept_entry->emt)[1]  ?: ept_entry->emt + '0',  c ?: ept_entry->ipat ? '!' : ' '); if ( !(record_counter++ % 100) ) process_pending_softirqs(); } unmap_domain_page(table); } } }", "target": 0, "idx": 104994, "project": "Xen"}
{"func": "static void fill_mp_ioapic_entry(struct mp_ioapic_entry *mpie) { mpie->type = ENTRY_TYPE_IOAPIC; mpie->ioapic_id = IOAPIC_ID; mpie->ioapic_version = ioapic_version; mpie->ioapic_flags = 1;  mpie->ioapic_addr = ioapic_base_address; }", "target": 0, "idx": 104681, "project": "Xen"}
{"func": "static int __get_page_type(struct page_info *page, unsigned long type,  int preemptible) { unsigned long nx, x, y = page->u.inuse.type_info; int rc = 0; ASSERT(!(type & ~(PGT_type_mask | PGT_pae_xen_l2))); for ( ; ; ) { x= y; nx = x + 1; if ( unlikely((nx & PGT_count_mask) == 0) ) { MEM_LOG(\"Type count overflow on pfn %lx\", page_to_mfn(page)); return -EINVAL; } else if ( unlikely((x & PGT_count_mask) == 0) ) { struct domain *d = page_get_owner(page);  if ( d && shadow_mode_enabled(d)  && (page->count_info & PGC_page_table)  && !((page->shadow_flags & (1u<<29)) && type == PGT_writable_page) )  shadow_remove_all_shadows(d, _mfn(page_to_mfn(page))); ASSERT(!(x & PGT_pae_xen_l2)); if ( (x & PGT_type_mask) != type ) {  cpumask_t mask; cpumask_copy(&mask, d->domain_dirty_cpumask);  tlbflush_filter(mask, page->tlbflush_timestamp); if ( unlikely(!cpumask_empty(&mask)) &&    (!shadow_mode_enabled(page_get_owner(page)) || ((nx & PGT_type_mask) == PGT_writable_page)) ) { perfc_incr(need_flush_tlb_flush); flush_tlb_mask(&mask); }  nx &= ~(PGT_type_mask | PGT_validated); nx |= type;   if ( type == PGT_writable_page || type == PGT_shared_page ) nx |= PGT_validated; } } else if ( unlikely((x & (PGT_type_mask|PGT_pae_xen_l2)) != type) ) {  if ( ((x & PGT_type_mask) == PGT_l2_page_table) &&  (type == PGT_l1_page_table) ) return -EINVAL; if ( ((x & PGT_type_mask) == PGT_l3_page_table) &&  (type == PGT_l2_page_table) ) return -EINVAL; if ( ((x & PGT_type_mask) == PGT_l4_page_table) &&  (type == PGT_l3_page_table) ) return -EINVAL; MEM_LOG(\"Bad type (saw %\" PRtype_info \" != exp %\" PRtype_info \") \" \"for mfn %lx (pfn %lx)\", x, type, page_to_mfn(page), get_gpfn_from_mfn(page_to_mfn(page))); return -EINVAL; } else if ( unlikely(!(x & PGT_validated)) ) { if ( !(x & PGT_partial) ) {  while ( (y = page->u.inuse.type_info) == x ) { if ( preemptible && hypercall_preempt_check() ) return -EINTR; cpu_relax(); } continue; }  ASSERT((x & PGT_count_mask) == 1); nx = x & ~PGT_partial; } if ( likely((y = cmpxchg(&page->u.inuse.type_info, x, nx)) == x) ) break; if ( preemptible && hypercall_preempt_check() ) return -EINTR; } if ( unlikely((x & PGT_type_mask) != type) ) {  struct domain *d = page_get_owner(page); if ( d && is_pv_domain(d) && unlikely(need_iommu(d)) ) { if ( (x & PGT_type_mask) == PGT_writable_page ) iommu_unmap_page(d, mfn_to_gmfn(d, page_to_mfn(page))); else if ( type == PGT_writable_page ) iommu_map_page(d, mfn_to_gmfn(d, page_to_mfn(page)),  page_to_mfn(page),  IOMMUF_readable|IOMMUF_writable); } } if ( unlikely(!(nx & PGT_validated)) ) { if ( !(x & PGT_partial) ) { page->nr_validated_ptes = 0; page->partial_pte = 0; } rc = alloc_page_type(page, type, preemptible); } if ( (x & PGT_partial) && !(nx & PGT_partial) ) put_page(page); return rc; }", "target": 1, "idx": 109611, "project": "Xen"}
{"func": "static void l3_cat_write_msr(unsigned int cos, uint32_t val,  enum psr_type type) { wrmsrl(MSR_IA32_PSR_L3_MASK(cos), val); }", "target": 0, "idx": 105197, "project": "Xen"}
{"func": "char * stringify_cpu_hz(long long cpu_hz) { static char cpu_string[20], suffix; float hz; if(cpu_hz > GHZ) { hz = (float)cpu_hz / GHZ; suffix = 'G'; } else if(cpu_hz > MHZ) { hz = (float)cpu_hz / MHZ; suffix = 'M'; } else if(cpu_hz > KHZ) { hz = (float)cpu_hz / KHZ; suffix = 'k'; } else { hz = cpu_hz; suffix = ' '; } snprintf(cpu_string, 20, \"%1.2lf %cHz\", hz, suffix); return cpu_string; }", "target": 0, "idx": 108111, "project": "Xen"}
{"func": "static int _fuzz_rep_read(struct x86_emulate_ctxt *ctxt, const char *why, unsigned long *reps) { int rc; unsigned long bytes_read = 0; rc = data_read(ctxt, x86_seg_none, why, &bytes_read, sizeof(bytes_read)); if ( bytes_read <= *reps ) *reps = bytes_read; switch ( rc ) { case X86EMUL_UNHANDLEABLE:  *reps = 0; break; case X86EMUL_EXCEPTION: case X86EMUL_RETRY:  *reps /= 2; break; } return rc; }", "target": 0, "idx": 102250, "project": "Xen"}
{"func": "static uint16_t get_gv_from_dte(dev_entry_t *dte) { return get_field_from_reg_u32(dte->data[1],IOMMU_DEV_TABLE_GV_MASK, IOMMU_DEV_TABLE_GV_SHIFT); }", "target": 0, "idx": 102809, "project": "Xen"}
{"func": "static struct hvm_vioapic *gsi_vioapic(const struct domain *d,  unsigned int gsi, unsigned int *pin) { unsigned int i; for ( i = 0; i < d->arch.hvm_domain.nr_vioapics; i++ ) { struct hvm_vioapic *vioapic = domain_vioapic(d, i); if ( gsi >= vioapic->base_gsi &&  gsi < vioapic->base_gsi + vioapic->nr_pins ) { *pin = gsi - vioapic->base_gsi; return vioapic; } } return NULL; }", "target": 0, "idx": 106865, "project": "Xen"}
{"func": "void tdaio_queue_read(td_driver_t *driver, td_request_t treq) { int size; uint64_t offset; struct aio_request *aio; struct tdaio_state *prv; prv= (struct tdaio_state *)driver->data; size = treq.secs * driver->info.sector_size; offset = treq.sec* (uint64_t)driver->info.sector_size; if (prv->aio_free_count == 0) goto fail; aio= prv->aio_free_list[--prv->aio_free_count]; aio->treq= treq; aio->state = prv; td_prep_read(&aio->tiocb, prv->fd, treq.buf,  size, offset, tdaio_complete, aio); td_queue_tiocb(driver, &aio->tiocb); return; fail: td_complete_request(treq, -EBUSY); }", "target": 0, "idx": 101027, "project": "Xen"}
{"func": "static int gnttab_copy_claim_buf(const struct gnttab_copy *op,  const struct gnttab_copy_ptr *ptr,  struct gnttab_copy_buf *buf,  unsigned int gref_flag) { int rc; buf->read_only = gref_flag == GNTCOPY_source_gref; if ( op->flags & gref_flag ) { rc = __acquire_grant_for_copy(buf->domain, ptr->u.ref, current->domain->domain_id, buf->read_only, &buf->frame, &buf->page, &buf->ptr.offset, &buf->len, 1); if ( rc != GNTST_okay ) goto out; buf->ptr.u.ref = ptr->u.ref; buf->have_grant = 1; } else { rc = __get_paged_frame(ptr->u.gmfn, &buf->frame, &buf->page,  buf->read_only, buf->domain); if ( rc != GNTST_okay ) PIN_FAIL(out, rc,  \"source frame %\"PRI_xen_pfn\" invalid.\\n\", ptr->u.gmfn); buf->ptr.u.gmfn = ptr->u.gmfn; buf->ptr.offset = 0; buf->len = PAGE_SIZE; } if ( !buf->read_only ) { if ( !get_page_type(buf->page, PGT_writable_page) ) { if ( !buf->domain->is_dying ) gdprintk(XENLOG_WARNING, \"Could not get writable frame %lx\\n\", buf->frame); rc = GNTST_general_error; goto out; } buf->have_type = 1; } buf->virt = map_domain_page(_mfn(buf->frame)); rc = GNTST_okay;  out: return rc; }", "target": 1, "idx": 109591, "project": "Xen"}
{"func": "static int TIFFFetchRationalArray(TIFF* tif, TIFFDirEntry* dir, float* v) { int ok = 0; uint32* l; l = (uint32*)CheckMalloc(tif, dir->tdir_count*TIFFDataWidth(dir->tdir_type), \"to fetch array of rationals\"); if (l) { if (TIFFFetchData(tif, dir, (char *)l)) { uint32 i; for (i = 0; i < dir->tdir_count; i++) { ok = cvtRational(tif, dir, l[2*i+0], l[2*i+1], &v[i]); if (!ok) break; } } _TIFFfree((char *)l); } return (ok); }", "target": 0, "idx": 100250, "project": "LibTIFF"}
{"func": "static void update_iommu_mac(vmac_ctx_t *ctx, uint64_t pt_maddr, int level) { int i; struct dma_pte *pt_vaddr, *pte; int next_level = level - 1; if ( pt_maddr == 0 ) return; pt_vaddr = (struct dma_pte *)map_domain_page(_mfn(paddr_to_pfn(pt_maddr))); vmac_update((void *)pt_vaddr, PAGE_SIZE, ctx); for ( i = 0; i < PTE_NUM; i++ ) { pte = &pt_vaddr[i]; if ( !dma_pte_present(*pte) ) continue; if ( next_level >= 1 ) update_iommu_mac(ctx, dma_pte_addr(*pte), next_level); } unmap_domain_page(pt_vaddr); }", "target": 0, "idx": 106306, "project": "Xen"}
{"func": "static inline int fast_get_data_ready(struct libxenvchan *ctrl, size_t request) { int ready = rd_prod(ctrl) - rd_cons(ctrl); if (ready >= request) return ready;  request_notify(ctrl, VCHAN_NOTIFY_WRITE);  return rd_prod(ctrl) - rd_cons(ctrl); }", "target": 1, "idx": 109161, "project": "Xen"}
{"func": "static int PredictorVGetField(TIFF* tif, uint32 tag, va_list ap) { TIFFPredictorState *sp = PredictorState(tif); assert(sp != NULL); assert(sp->vgetparent != NULL); switch (tag) { case TIFFTAG_PREDICTOR: *va_arg(ap, uint16*) = (uint16)sp->predictor; break; default: return (*sp->vgetparent)(tif, tag, ap); } return 1; }", "target": 0, "idx": 100288, "project": "LibTIFF"}
{"func": "static void xentop_attroff(int attr) { if (!batch) attroff(attr); }", "target": 0, "idx": 108554, "project": "Xen"}
{"func": "bool vmce_has_lmce(const struct vcpu *v) { return v->arch.vmce.mcg_cap & MCG_LMCE_P; }", "target": 0, "idx": 104410, "project": "Xen"}
{"func": " */ static libxl__qmp_message_type qmp_response_type(libxl__qmp_handler *qmp,  const libxl__json_object *o) { libxl__qmp_message_type type; libxl__json_map_node *node = NULL; int i = 0; for (i = 0; (node = libxl__json_map_node_get(o, i)); i++) { if (libxl__qmp_message_type_from_string(node->map_key, &type) == 0) return type; } return LIBXL__QMP_MESSAGE_TYPE_INVALID; }", "target": 0, "idx": 103903, "project": "Xen"}
{"func": "long arch_do_domctl( struct xen_domctl *domctl, struct domain *d, XEN_GUEST_HANDLE_PARAM(xen_domctl_t) u_domctl) { long ret = 0; bool_t copyback = 0; unsigned long i; switch ( domctl->cmd ) { case XEN_DOMCTL_shadow_op: { ret = paging_domctl(d, &domctl->u.shadow_op, guest_handle_cast(u_domctl, void), 0); if ( ret == -ERESTART ) return hypercall_create_continuation(__HYPERVISOR_arch_1,  \"h\", u_domctl); copyback = 1; } break; case XEN_DOMCTL_ioport_permission: { unsigned int fp = domctl->u.ioport_permission.first_port; unsigned int np = domctl->u.ioport_permission.nr_ports; int allow = domctl->u.ioport_permission.allow_access; if ( (fp + np) <= fp || (fp + np) > MAX_IOPORTS ) ret = -EINVAL; else if ( !ioports_access_permitted(current->domain, fp, fp + np - 1) || xsm_ioport_permission(XSM_HOOK, d, fp, fp + np - 1, allow) ) ret = -EPERM; else if ( allow ) ret = ioports_permit_access(d, fp, fp + np - 1); else ret = ioports_deny_access(d, fp, fp + np - 1); if ( !ret ) memory_type_changed(d); } break; case XEN_DOMCTL_getpageframeinfo: { struct page_info *page; unsigned long mfn = domctl->u.getpageframeinfo.gmfn; ret = -EINVAL; if ( unlikely(!mfn_valid(mfn)) ) break; page = mfn_to_page(mfn); if ( likely(get_page(page, d)) ) { ret = 0; domctl->u.getpageframeinfo.type = XEN_DOMCTL_PFINFO_NOTAB; if ( (page->u.inuse.type_info & PGT_count_mask) != 0 ) { switch ( page->u.inuse.type_info & PGT_type_mask ) { case PGT_l1_page_table: domctl->u.getpageframeinfo.type = XEN_DOMCTL_PFINFO_L1TAB; break; case PGT_l2_page_table: domctl->u.getpageframeinfo.type = XEN_DOMCTL_PFINFO_L2TAB; break; case PGT_l3_page_table: domctl->u.getpageframeinfo.type = XEN_DOMCTL_PFINFO_L3TAB; break; case PGT_l4_page_table: domctl->u.getpageframeinfo.type = XEN_DOMCTL_PFINFO_L4TAB; break; } }  put_page(page); } copyback = 1; } break; case XEN_DOMCTL_getpageframeinfo3: if (!has_32bit_shinfo(current->domain)) { unsigned int n, j; unsigned int num = domctl->u.getpageframeinfo3.num; struct page_info *page; xen_pfn_t *arr; if ( unlikely(num > 1024) ||  unlikely(num != domctl->u.getpageframeinfo3.num) ) { ret = -E2BIG; break; } page = alloc_domheap_page(NULL, 0); if ( !page ) { ret = -ENOMEM; break; } arr = __map_domain_page(page); for ( n = ret = 0; n < num; ) { unsigned int k = min_t(unsigned int, num - n,  PAGE_SIZE / sizeof(*arr)); if ( copy_from_guest_offset(arr, domctl->u.getpageframeinfo3.array, n, k) ) { ret = -EFAULT; break; } for ( j = 0; j < k; j++ ) { unsigned long type = 0; p2m_type_t t; page = get_page_from_gfn(d, arr[j], &t, P2M_ALLOC); if ( unlikely(!page) ||  unlikely(is_xen_heap_page(page)) ) { if ( p2m_is_broken(t) ) type = XEN_DOMCTL_PFINFO_BROKEN; else type = XEN_DOMCTL_PFINFO_XTAB; } else { switch( page->u.inuse.type_info & PGT_type_mask ) { case PGT_l1_page_table: type = XEN_DOMCTL_PFINFO_L1TAB; break; case PGT_l2_page_table: type = XEN_DOMCTL_PFINFO_L2TAB; break; case PGT_l3_page_table: type = XEN_DOMCTL_PFINFO_L3TAB; break; case PGT_l4_page_table: type = XEN_DOMCTL_PFINFO_L4TAB; break; } if ( page->u.inuse.type_info & PGT_pinned ) type |= XEN_DOMCTL_PFINFO_LPINTAB; if ( page->count_info & PGC_broken ) type = XEN_DOMCTL_PFINFO_BROKEN; } if ( page ) put_page(page); arr[j] = type; } if ( copy_to_guest_offset(domctl->u.getpageframeinfo3.array, n, arr, k) ) { ret = -EFAULT; break; } n += k; } page = mfn_to_page(domain_page_map_to_mfn(arr)); unmap_domain_page(arr); free_domheap_page(page); break; }  case XEN_DOMCTL_getpageframeinfo2: { int n,j; int num = domctl->u.getpageframeinfo2.num; uint32_t *arr32; if ( unlikely(num > 1024) ) { ret = -E2BIG; break; } arr32 = alloc_xenheap_page(); if ( !arr32 ) { ret = -ENOMEM; break; }   ret = 0; for ( n = 0; n < num; ) { int k = PAGE_SIZE / 4; if ( (num - n) < k ) k = num - n; if ( copy_from_guest_offset(arr32, domctl->u.getpageframeinfo2.array, n, k) ) { ret = -EFAULT; break; }   for ( j = 0; j < k; j++ ) { struct page_info *page; unsigned long gfn = arr32[j]; page = get_page_from_gfn(d, gfn, NULL, P2M_ALLOC); if ( domctl->cmd == XEN_DOMCTL_getpageframeinfo3) arr32[j] = 0; if ( unlikely(!page) ||  unlikely(is_xen_heap_page(page)) ) arr32[j] |= XEN_DOMCTL_PFINFO_XTAB; else { unsigned long type = 0; switch( page->u.inuse.type_info & PGT_type_mask ) { case PGT_l1_page_table: type = XEN_DOMCTL_PFINFO_L1TAB; break; case PGT_l2_page_table: type = XEN_DOMCTL_PFINFO_L2TAB; break; case PGT_l3_page_table: type = XEN_DOMCTL_PFINFO_L3TAB; break; case PGT_l4_page_table: type = XEN_DOMCTL_PFINFO_L4TAB; break; } if ( page->u.inuse.type_info & PGT_pinned ) type |= XEN_DOMCTL_PFINFO_LPINTAB; arr32[j] |= type; } if ( page ) put_page(page); } if ( copy_to_guest_offset(domctl->u.getpageframeinfo2.array, n, arr32, k) ) { ret = -EFAULT; break; } n += k; } free_xenheap_page(arr32); } break; case XEN_DOMCTL_getmemlist: { unsigned long max_pfns = domctl->u.getmemlist.max_pfns; uint64_t mfn; struct page_info *page; if ( unlikely(d->is_dying) ) { ret = -EINVAL; break; }  if (   paging_mode_external(current->domain) ||    max_pfns > GB(4) / PAGE_SIZE ) { ret = -EOPNOTSUPP; break; } spin_lock(&d->page_alloc_lock); ret = i = 0; page_list_for_each(page, &d->page_list) { if ( i >= max_pfns ) break; mfn = page_to_mfn(page); if ( copy_to_guest_offset(domctl->u.getmemlist.buffer, i, &mfn, 1) ) { ret = -EFAULT; break; } ++i; } spin_unlock(&d->page_alloc_lock); domctl->u.getmemlist.num_pfns = i; copyback = 1; } break; case XEN_DOMCTL_hypercall_init: { unsigned long gmfn = domctl->u.hypercall_init.gmfn; struct page_info *page; void *hypercall_page; page = get_page_from_gfn(d, gmfn, NULL, P2M_ALLOC); ret = -EACCES; if ( !page || !get_page_type(page, PGT_writable_page) ) { if ( page ) put_page(page); break; } ret = 0; hypercall_page = __map_domain_page(page); hypercall_page_initialise(d, hypercall_page); unmap_domain_page(hypercall_page); put_page_and_type(page); } break; case XEN_DOMCTL_sethvmcontext: {  struct hvm_domain_context c = { .size = domctl->u.hvmcontext.size }; ret = -EINVAL; if ( !is_hvm_domain(d) )  goto sethvmcontext_out; ret = -ENOMEM; if ( (c.data = xmalloc_bytes(c.size)) == NULL ) goto sethvmcontext_out; ret = -EFAULT; if ( copy_from_guest(c.data, domctl->u.hvmcontext.buffer, c.size) != 0) goto sethvmcontext_out; domain_pause(d); ret = hvm_load(d, &c); domain_unpause(d); sethvmcontext_out: if ( c.data != NULL ) xfree(c.data); } break; case XEN_DOMCTL_gethvmcontext: {  struct hvm_domain_context c = { 0 }; ret = -EINVAL; if ( !is_hvm_domain(d) )  goto gethvmcontext_out; c.size = hvm_save_size(d); if ( guest_handle_is_null(domctl->u.hvmcontext.buffer) ) {  domctl->u.hvmcontext.size = c.size; ret = 0; goto gethvmcontext_out; }  ret = -ENOSPC; if ( domctl->u.hvmcontext.size < c.size )  goto gethvmcontext_out;  ret = -ENOMEM; if ( (c.data = xmalloc_bytes(c.size)) == NULL ) goto gethvmcontext_out; domain_pause(d); ret = hvm_save(d, &c); domain_unpause(d); domctl->u.hvmcontext.size = c.cur; if ( copy_to_guest(domctl->u.hvmcontext.buffer, c.data, c.size) != 0 ) ret = -EFAULT; gethvmcontext_out: copyback = 1; if ( c.data != NULL ) xfree(c.data); } break; case XEN_DOMCTL_gethvmcontext_partial: {  ret = -EINVAL; if ( !is_hvm_domain(d) )  break; domain_pause(d); ret = hvm_save_one(d, domctl->u.hvmcontext_partial.type,  domctl->u.hvmcontext_partial.instance,  domctl->u.hvmcontext_partial.buffer); domain_unpause(d); } break; case XEN_DOMCTL_set_address_size: { switch ( domctl->u.address_size.size ) { case 32: ret = switch_compat(d); break; case 64: ret = switch_native(d); break; default: ret = (domctl->u.address_size.size == BITS_PER_LONG) ? 0 : -EINVAL; break; } } break; case XEN_DOMCTL_get_address_size: { domctl->u.address_size.size = is_pv_32on64_domain(d) ? 32 : BITS_PER_LONG; ret = 0; copyback = 1; } break; case XEN_DOMCTL_set_machine_address_size: { ret = -EBUSY; if ( d->tot_pages > 0 ) break; d->arch.physaddr_bitsize = domctl->u.address_size.size; ret = 0; } break; case XEN_DOMCTL_get_machine_address_size: { domctl->u.address_size.size = d->arch.physaddr_bitsize; ret = 0; copyback = 1; } break; case XEN_DOMCTL_sendtrigger: { struct vcpu *v; ret = -EINVAL; if ( domctl->u.sendtrigger.vcpu >= MAX_VIRT_CPUS ) break; ret = -ESRCH; if ( domctl->u.sendtrigger.vcpu >= d->max_vcpus ||  (v = d->vcpu[domctl->u.sendtrigger.vcpu]) == NULL ) break; switch ( domctl->u.sendtrigger.trigger ) { case XEN_DOMCTL_SENDTRIGGER_NMI: { ret = 0; if ( !test_and_set_bool(v->nmi_pending) ) vcpu_kick(v); } break; case XEN_DOMCTL_SENDTRIGGER_POWER: { ret = -EINVAL; if ( is_hvm_domain(d) )  { ret = 0; hvm_acpi_power_button(d); } } break; case XEN_DOMCTL_SENDTRIGGER_SLEEP: { ret = -EINVAL; if ( is_hvm_domain(d) )  { ret = 0; hvm_acpi_sleep_button(d); } } break; default: ret = -ENOSYS; } } break; case XEN_DOMCTL_bind_pt_irq: { xen_domctl_bind_pt_irq_t *bind = &domctl->u.bind_pt_irq; int irq; ret = -EINVAL; if ( !is_hvm_domain(d) ) break; ret = xsm_bind_pt_irq(XSM_HOOK, d, bind); if ( ret ) break; irq = domain_pirq_to_irq(d, bind->machine_irq); ret = -EPERM; if ( irq <= 0 || !irq_access_permitted(current->domain, irq) ) break; ret = -ESRCH; if ( iommu_enabled ) { spin_lock(&pcidevs_lock); ret = pt_irq_create_bind(d, bind); spin_unlock(&pcidevs_lock); } if ( ret < 0 ) printk(XENLOG_G_ERR \"pt_irq_create_bind failed (%ld) for dom%d\\n\",  ret, d->domain_id); } break; case XEN_DOMCTL_unbind_pt_irq: { xen_domctl_bind_pt_irq_t *bind = &domctl->u.bind_pt_irq; int irq = domain_pirq_to_irq(d, bind->machine_irq); ret = -EPERM; if ( irq <= 0 || !irq_access_permitted(current->domain, irq) ) break; ret = xsm_unbind_pt_irq(XSM_HOOK, d, bind); if ( ret ) break; if ( iommu_enabled ) { spin_lock(&pcidevs_lock); ret = pt_irq_destroy_bind(d, bind); spin_unlock(&pcidevs_lock); } if ( ret < 0 ) printk(XENLOG_G_ERR \"pt_irq_destroy_bind failed (%ld) for dom%d\\n\",  ret, d->domain_id); } break; case XEN_DOMCTL_ioport_mapping: { struct hvm_iommu *hd; unsigned int fgp = domctl->u.ioport_mapping.first_gport; unsigned int fmp = domctl->u.ioport_mapping.first_mport; unsigned int np = domctl->u.ioport_mapping.nr_ports; unsigned int add = domctl->u.ioport_mapping.add_mapping; struct g2m_ioport *g2m_ioport; int found = 0; ret = -EINVAL; if ( ((fgp | fmp | (np - 1)) >= MAX_IOPORTS) || ((fgp + np) > MAX_IOPORTS) || ((fmp + np) > MAX_IOPORTS) ) { printk(XENLOG_G_ERR  \"ioport_map:invalid:dom%d gport=%x mport=%x nr=%x\\n\",  domctl->domain, fgp, fmp, np); break; } ret = -EPERM; if ( !ioports_access_permitted(current->domain, fmp, fmp + np - 1) ) break; ret = xsm_ioport_mapping(XSM_HOOK, d, fmp, fmp + np - 1, add); if ( ret ) break; hd = domain_hvm_iommu(d); if ( add ) { printk(XENLOG_G_INFO  \"ioport_map:add: dom%d gport=%x mport=%x nr=%x\\n\",  d->domain_id, fgp, fmp, np); list_for_each_entry(g2m_ioport, &hd->arch.g2m_ioport_list, list) if (g2m_ioport->mport == fmp ) { g2m_ioport->gport = fgp; g2m_ioport->np = np; found = 1; break; } if ( !found ) { g2m_ioport = xmalloc(struct g2m_ioport); if ( !g2m_ioport ) ret = -ENOMEM; } if ( !found && !ret ) { g2m_ioport->gport = fgp; g2m_ioport->mport = fmp; g2m_ioport->np = np; list_add_tail(&g2m_ioport->list, &hd->arch.g2m_ioport_list); } if ( !ret ) ret = ioports_permit_access(d, fmp, fmp + np - 1); if ( ret && !found && g2m_ioport ) { list_del(&g2m_ioport->list); xfree(g2m_ioport); } } else { printk(XENLOG_G_INFO  \"ioport_map:remove: dom%d gport=%x mport=%x nr=%x\\n\",  d->domain_id, fgp, fmp, np); list_for_each_entry(g2m_ioport, &hd->arch.g2m_ioport_list, list) if ( g2m_ioport->mport == fmp ) { list_del(&g2m_ioport->list); xfree(g2m_ioport); break; } ret = ioports_deny_access(d, fmp, fmp + np - 1); if ( ret && is_hardware_domain(current->domain) ) printk(XENLOG_ERR  \"ioport_map: error %ld denying dom%d access to [%x,%x]\\n\",  ret, d->domain_id, fmp, fmp + np - 1); } if ( !ret ) memory_type_changed(d); } break; case XEN_DOMCTL_pin_mem_cacheattr: { ret = hvm_set_mem_pinned_cacheattr( d, domctl->u.pin_mem_cacheattr.start, domctl->u.pin_mem_cacheattr.end, domctl->u.pin_mem_cacheattr.type); } break; case XEN_DOMCTL_set_ext_vcpucontext: case XEN_DOMCTL_get_ext_vcpucontext: { struct xen_domctl_ext_vcpucontext *evc; struct vcpu *v; evc = &domctl->u.ext_vcpucontext; ret = -ESRCH; if ( (evc->vcpu >= d->max_vcpus) ||  ((v = d->vcpu[evc->vcpu]) == NULL) ) break; if ( domctl->cmd == XEN_DOMCTL_get_ext_vcpucontext ) { if ( v == current )  break; evc->size = sizeof(*evc); vcpu_pause(v); if ( is_pv_domain(d) ) { evc->sysenter_callback_cs= v->arch.pv_vcpu.sysenter_callback_cs; evc->sysenter_callback_eip = v->arch.pv_vcpu.sysenter_callback_eip; evc->sysenter_disables_events= v->arch.pv_vcpu.sysenter_disables_events; evc->syscall32_callback_cs = v->arch.pv_vcpu.syscall32_callback_cs; evc->syscall32_callback_eip= v->arch.pv_vcpu.syscall32_callback_eip; evc->syscall32_disables_events = v->arch.pv_vcpu.syscall32_disables_events; } else { evc->sysenter_callback_cs= 0; evc->sysenter_callback_eip = 0; evc->sysenter_disables_events= 0; evc->syscall32_callback_cs = 0; evc->syscall32_callback_eip= 0; evc->syscall32_disables_events = 0; } evc->vmce.caps = v->arch.vmce.mcg_cap; evc->vmce.mci_ctl2_bank0 = v->arch.vmce.bank[0].mci_ctl2; evc->vmce.mci_ctl2_bank1 = v->arch.vmce.bank[1].mci_ctl2; ret = 0; vcpu_unpause(v); copyback = 1; } else { if ( d == current->domain )  break; ret = -EINVAL; if ( evc->size < offsetof(typeof(*evc), vmce) ) break; if ( is_pv_domain(d) ) { if ( !is_canonical_address(evc->sysenter_callback_eip) ||  !is_canonical_address(evc->syscall32_callback_eip) ) break; domain_pause(d); fixup_guest_code_selector(d, evc->sysenter_callback_cs); v->arch.pv_vcpu.sysenter_callback_cs= evc->sysenter_callback_cs; v->arch.pv_vcpu.sysenter_callback_eip = evc->sysenter_callback_eip; v->arch.pv_vcpu.sysenter_disables_events= evc->sysenter_disables_events; fixup_guest_code_selector(d, evc->syscall32_callback_cs); v->arch.pv_vcpu.syscall32_callback_cs = evc->syscall32_callback_cs; v->arch.pv_vcpu.syscall32_callback_eip= evc->syscall32_callback_eip; v->arch.pv_vcpu.syscall32_disables_events = evc->syscall32_disables_events; } else if ( (evc->sysenter_callback_cs & ~3) || evc->sysenter_callback_eip || (evc->syscall32_callback_cs & ~3) || evc->syscall32_callback_eip ) break; else domain_pause(d); BUILD_BUG_ON(offsetof(struct xen_domctl_ext_vcpucontext, mcg_cap) !=  offsetof(struct xen_domctl_ext_vcpucontext, vmce.caps)); BUILD_BUG_ON(sizeof(evc->mcg_cap) != sizeof(evc->vmce.caps)); if ( evc->size >= offsetof(typeof(*evc), vmce) + sizeof(evc->vmce) ) ret = vmce_restore_vcpu(v, &evc->vmce); else if ( evc->size >= offsetof(typeof(*evc), mcg_cap) +  sizeof(evc->mcg_cap) ) { struct hvm_vmce_vcpu vmce = { .caps = evc->mcg_cap }; ret = vmce_restore_vcpu(v, &vmce); } else ret = 0; domain_unpause(d); } } break; case XEN_DOMCTL_set_cpuid: { xen_domctl_cpuid_t *ctl = &domctl->u.cpuid; cpuid_input_t *cpuid, *unused = NULL; for ( i = 0; i < MAX_CPUID_INPUT; i++ ) { cpuid = &d->arch.cpuids[i]; if ( cpuid->input[0] == XEN_CPUID_INPUT_UNUSED ) { if ( !unused ) unused = cpuid; continue; } if ( (cpuid->input[0] == ctl->input[0]) &&  ((cpuid->input[1] == XEN_CPUID_INPUT_UNUSED) || (cpuid->input[1] == ctl->input[1])) ) break; }  if ( i < MAX_CPUID_INPUT ) *cpuid = *ctl; else if ( unused ) *unused = *ctl; else ret = -ENOENT; } break; case XEN_DOMCTL_gettscinfo: { xen_guest_tsc_info_t info; domain_pause(d); tsc_get_info(d, &info.tsc_mode, &info.elapsed_nsec, &info.gtsc_khz, &info.incarnation); if ( copy_to_guest(domctl->u.tsc_info.out_info, &info, 1) ) ret = -EFAULT; else ret = 0; domain_unpause(d); } break; case XEN_DOMCTL_settscinfo: { domain_pause(d); tsc_set_info(d, domctl->u.tsc_info.info.tsc_mode,  domctl->u.tsc_info.info.elapsed_nsec,  domctl->u.tsc_info.info.gtsc_khz,  domctl->u.tsc_info.info.incarnation); domain_unpause(d); ret = 0; } break; case XEN_DOMCTL_suppress_spurious_page_faults: { d->arch.suppress_spurious_page_faults = 1; ret = 0; } break; case XEN_DOMCTL_debug_op: { struct vcpu *v; ret = -EINVAL; if ( (domctl->u.debug_op.vcpu >= d->max_vcpus) ||  ((v = d->vcpu[domctl->u.debug_op.vcpu]) == NULL) ) break; ret = -EINVAL; if ( !is_hvm_domain(d)) break; ret = hvm_debug_op(v, domctl->u.debug_op.op); } break; case XEN_DOMCTL_gdbsx_guestmemio: { domctl->u.gdbsx_guest_memio.remain = domctl->u.gdbsx_guest_memio.len; ret = gdbsx_guest_mem_io(domctl->domain, &domctl->u.gdbsx_guest_memio); if ( !ret )  copyback = 1; } break; case XEN_DOMCTL_gdbsx_pausevcpu: { struct vcpu *v; ret = -EBUSY; if ( !d->controller_pause_count ) break; ret = -EINVAL; if ( domctl->u.gdbsx_pauseunp_vcpu.vcpu >= d->max_vcpus ||  (v = d->vcpu[domctl->u.gdbsx_pauseunp_vcpu.vcpu]) == NULL ) break; ret = vcpu_pause_by_systemcontroller(v); } break; case XEN_DOMCTL_gdbsx_unpausevcpu: { struct vcpu *v; ret = -EBUSY; if ( !d->controller_pause_count ) break; ret = -EINVAL; if ( domctl->u.gdbsx_pauseunp_vcpu.vcpu >= d->max_vcpus ||  (v = d->vcpu[domctl->u.gdbsx_pauseunp_vcpu.vcpu]) == NULL ) break; ret = vcpu_unpause_by_systemcontroller(v); if ( ret == -EINVAL ) printk(XENLOG_G_WARNING  \"WARN: d%d attempting to unpause %pv which is not paused\\n\",  current->domain->domain_id, v); } break; case XEN_DOMCTL_gdbsx_domstatus: { struct vcpu *v; domctl->u.gdbsx_domstatus.vcpu_id = -1; domctl->u.gdbsx_domstatus.paused = d->controller_pause_count > 0; if ( domctl->u.gdbsx_domstatus.paused ) { for_each_vcpu ( d, v ) { if ( v->arch.gdbsx_vcpu_event ) { domctl->u.gdbsx_domstatus.vcpu_id = v->vcpu_id; domctl->u.gdbsx_domstatus.vcpu_ev = v->arch.gdbsx_vcpu_event; v->arch.gdbsx_vcpu_event = 0; break; } } } ret = 0; copyback = 1; } break; case XEN_DOMCTL_setvcpuextstate: case XEN_DOMCTL_getvcpuextstate: { struct xen_domctl_vcpuextstate *evc; struct vcpu *v; uint32_t offset = 0; #define PV_XSAVE_SIZE(xcr0) (2 * sizeof(uint64_t) + xstate_ctxt_size(xcr0)) evc = &domctl->u.vcpuextstate; ret = -ESRCH; if ( (evc->vcpu >= d->max_vcpus) ||  ((v = d->vcpu[evc->vcpu]) == NULL) ) goto vcpuextstate_out; ret = -EINVAL; if ( v == current )  goto vcpuextstate_out; if ( domctl->cmd == XEN_DOMCTL_getvcpuextstate ) { unsigned int size; ret = 0; vcpu_pause(v); size = PV_XSAVE_SIZE(v->arch.xcr0_accum); if ( (!evc->size && !evc->xfeature_mask) ||  guest_handle_is_null(evc->buffer) ) { evc->xfeature_mask = xfeature_mask; evc->size = size; vcpu_unpause(v); goto vcpuextstate_out; } if ( evc->size != size || evc->xfeature_mask != xfeature_mask ) ret = -EINVAL; if ( !ret && copy_to_guest_offset(evc->buffer, offset, (void *)&v->arch.xcr0, sizeof(v->arch.xcr0)) ) ret = -EFAULT; offset += sizeof(v->arch.xcr0); if ( !ret && copy_to_guest_offset(evc->buffer, offset, (void *)&v->arch.xcr0_accum, sizeof(v->arch.xcr0_accum)) ) ret = -EFAULT; offset += sizeof(v->arch.xcr0_accum); if ( !ret && copy_to_guest_offset(evc->buffer, offset, (void *)v->arch.xsave_area, size - 2 * sizeof(uint64_t)) ) ret = -EFAULT; vcpu_unpause(v); } else { void *receive_buf; uint64_t _xcr0, _xcr0_accum; const struct xsave_struct *_xsave_area; ret = -EINVAL; if ( evc->size < 2 * sizeof(uint64_t) ||  evc->size > 2 * sizeof(uint64_t) +  xstate_ctxt_size(xfeature_mask) ) goto vcpuextstate_out; receive_buf = xmalloc_bytes(evc->size); if ( !receive_buf ) { ret = -ENOMEM; goto vcpuextstate_out; } if ( copy_from_guest_offset(receive_buf, domctl->u.vcpuextstate.buffer, offset, evc->size) ) { ret = -EFAULT; xfree(receive_buf); goto vcpuextstate_out; } _xcr0 = *(uint64_t *)receive_buf; _xcr0_accum = *(uint64_t *)(receive_buf + sizeof(uint64_t)); _xsave_area = receive_buf + 2 * sizeof(uint64_t); if ( _xcr0_accum ) { if ( evc->size >= 2 * sizeof(uint64_t) + XSTATE_AREA_MIN_SIZE ) ret = validate_xstate(_xcr0, _xcr0_accum, _xsave_area->xsave_hdr.xstate_bv); } else if ( !_xcr0 ) ret = 0; if ( ret ) { xfree(receive_buf); goto vcpuextstate_out; } if ( evc->size <= PV_XSAVE_SIZE(_xcr0_accum) ) { vcpu_pause(v); v->arch.xcr0 = _xcr0; v->arch.xcr0_accum = _xcr0_accum; if ( _xcr0_accum & XSTATE_NONLAZY ) v->arch.nonlazy_xstate_used = 1; memcpy(v->arch.xsave_area, _xsave_area,  evc->size - 2 * sizeof(uint64_t)); vcpu_unpause(v); } else ret = -EINVAL; xfree(receive_buf); } vcpuextstate_out: if ( domctl->cmd == XEN_DOMCTL_getvcpuextstate ) copyback = 1; } break; case XEN_DOMCTL_mem_sharing_op: { ret = mem_sharing_domctl(d, &domctl->u.mem_sharing_op); } break; #if P2M_AUDIT case XEN_DOMCTL_audit_p2m: { if ( d == current->domain ) { ret = -EPERM; break; } audit_p2m(d, &domctl->u.audit_p2m.orphans, &domctl->u.audit_p2m.m2p_bad, &domctl->u.audit_p2m.p2m_bad); copyback = 1; } break; #endif  case XEN_DOMCTL_set_broken_page_p2m: { p2m_type_t pt; unsigned long pfn = domctl->u.set_broken_page_p2m.pfn; mfn_t mfn = get_gfn_query(d, pfn, &pt); if ( unlikely(!mfn_valid(mfn_x(mfn))) || unlikely(!p2m_is_ram(pt)) ) ret = -EINVAL; else ret = p2m_change_type_one(d, pfn, pt, p2m_ram_broken); put_gfn(d, pfn); } break; case XEN_DOMCTL_get_vcpu_msrs: case XEN_DOMCTL_set_vcpu_msrs: { struct xen_domctl_vcpu_msrs *vmsrs = &domctl->u.vcpu_msrs; struct xen_domctl_vcpu_msr msr; struct vcpu *v; uint32_t nr_msrs = 0; ret = -ESRCH; if ( (vmsrs->vcpu >= d->max_vcpus) ||  ((v = d->vcpu[vmsrs->vcpu]) == NULL) ) break; ret = -EINVAL; if ( (v == current) ||   !is_pv_domain(d) ) break;  if ( boot_cpu_has(X86_FEATURE_DBEXT) ) nr_msrs += 4; if ( domctl->cmd == XEN_DOMCTL_get_vcpu_msrs ) { ret = 0; copyback = 1;  if ( guest_handle_is_null(vmsrs->msrs) ) vmsrs->msr_count = nr_msrs; else { i = 0; vcpu_pause(v); if ( boot_cpu_has(X86_FEATURE_DBEXT) ) { unsigned int j; if ( v->arch.pv_vcpu.dr_mask[0] ) { if ( i < vmsrs->msr_count && !ret ) { msr.index = MSR_AMD64_DR0_ADDRESS_MASK; msr.reserved = 0; msr.value = v->arch.pv_vcpu.dr_mask[0]; if ( copy_to_guest_offset(vmsrs->msrs, i, &msr, 1) ) ret = -EFAULT; } ++i; } for ( j = 0; j < 3; ++j ) { if ( !v->arch.pv_vcpu.dr_mask[1 + j] ) continue; if ( i < vmsrs->msr_count && !ret ) { msr.index = MSR_AMD64_DR1_ADDRESS_MASK + j; msr.reserved = 0; msr.value = v->arch.pv_vcpu.dr_mask[1 + j]; if ( copy_to_guest_offset(vmsrs->msrs, i, &msr, 1) ) ret = -EFAULT; } ++i; } } vcpu_unpause(v); if ( i > vmsrs->msr_count && !ret ) ret = -ENOBUFS; vmsrs->msr_count = i; } } else { ret = -EINVAL; if ( vmsrs->msr_count > nr_msrs ) break; vcpu_pause(v); for ( i = 0; i < vmsrs->msr_count; ++i ) { ret = -EFAULT; if ( copy_from_guest_offset(&msr, vmsrs->msrs, i, 1) ) break; ret = -EINVAL; if ( msr.reserved ) break; switch ( msr.index ) { case MSR_AMD64_DR0_ADDRESS_MASK: if ( !boot_cpu_has(X86_FEATURE_DBEXT) ||  (msr.value >> 32) ) break; v->arch.pv_vcpu.dr_mask[0] = msr.value; continue; case MSR_AMD64_DR1_ADDRESS_MASK ... MSR_AMD64_DR3_ADDRESS_MASK: if ( !boot_cpu_has(X86_FEATURE_DBEXT) ||  (msr.value >> 32) ) break; msr.index -= MSR_AMD64_DR1_ADDRESS_MASK - 1; v->arch.pv_vcpu.dr_mask[msr.index] = msr.value; continue; } break; } vcpu_unpause(v); if ( i == vmsrs->msr_count ) ret = 0; else { vmsrs->msr_count = i; copyback = 1; } } } break; case XEN_DOMCTL_psr_cmt_op: if ( !psr_cmt_enabled() ) { ret = -ENODEV; break; } switch ( domctl->u.psr_cmt_op.cmd ) { case XEN_DOMCTL_PSR_CMT_OP_ATTACH: ret = psr_alloc_rmid(d); break; case XEN_DOMCTL_PSR_CMT_OP_DETACH: if ( d->arch.psr_rmid > 0 ) psr_free_rmid(d); else ret = -ENOENT; break; case XEN_DOMCTL_PSR_CMT_OP_QUERY_RMID: domctl->u.psr_cmt_op.data = d->arch.psr_rmid; copyback = 1; break; default: ret = -ENOSYS; break; } break; default: ret = iommu_do_domctl(domctl, d, u_domctl); break; } if ( copyback && __copy_to_guest(u_domctl, domctl, 1) ) ret = -EFAULT; return ret; }", "target": 1, "idx": 109286, "project": "Xen"}
{"func": "static int lvm_parse_pv(struct vg *vg, const char *name, int pvs, uint64_t start) { int i, err; struct pv *pv; pv = NULL; if (!vg->pvs) { vg->pvs = calloc(pvs, sizeof(struct pv)); if (!vg->pvs) return -ENOMEM; } for (i = 0; i < pvs; i++) { pv = vg->pvs + i; if (!pv->name[0]) break; if (!strcmp(pv->name, name)) return -EEXIST; } if (!pv) return -ENOENT; if (i == pvs) return -ENOMEM; err = lvm_copy_name(pv->name, name, sizeof(pv->name) - 1); if (err) return err; pv->start = start; return 0; }", "target": 0, "idx": 104296, "project": "Xen"}
{"func": "static void *xmalloc(size_t sz) { if (!sz) return 0; void *r = malloc(sz); if (!r) { perror(\"memory allocation failed\"); exit(-1); } return r; }", "target": 0, "idx": 103968, "project": "Xen"}
{"func": "int tap_ctl_connect_id(int id, int *sfd) { int err; char *name; *sfd = -1; if (id < 0) { EPRINTF(\"invalid id %d\\n\", id); return -EINVAL; } name = tap_ctl_socket_name(id); if (!name) { EPRINTF(\"couldn't name socket for %d\\n\", id); return -ENOMEM; } err = tap_ctl_connect(name, sfd); free(name); return err; }", "target": 0, "idx": 106014, "project": "Xen"}
{"func": "static void show_helptext(const char *title, const char *text) { show_textbox(title, text, 0, 0); }", "target": 0, "idx": 104426, "project": "Xen"}
{"func": "static void make_acpi_gtdt(libxl__gc *gc, struct xc_dom_image *dom,  struct acpitable acpitables[]) { uint64_t offset = acpitables[GTDT].addr - GUEST_ACPI_BASE; struct acpi_table_gtdt *gtdt = (void *)dom->acpi_modules[0].data + offset; gtdt->non_secure_el1_interrupt = GUEST_TIMER_PHYS_NS_PPI; gtdt->non_secure_el1_flags =  (ACPI_LEVEL_SENSITIVE << ACPI_GTDT_INTERRUPT_MODE)  |(ACPI_ACTIVE_LOW << ACPI_GTDT_INTERRUPT_POLARITY); gtdt->virtual_timer_interrupt = GUEST_TIMER_VIRT_PPI; gtdt->virtual_timer_flags =  (ACPI_LEVEL_SENSITIVE << ACPI_GTDT_INTERRUPT_MODE)  |(ACPI_ACTIVE_LOW << ACPI_GTDT_INTERRUPT_POLARITY); gtdt->counter_block_addresss = ~((uint64_t)0); gtdt->counter_read_block_address = ~((uint64_t)0); make_acpi_header(&gtdt->header, \"GTDT\", acpitables[GTDT].size, 2); calculate_checksum(gtdt, offsetof(struct acpi_table_header, checksum),  acpitables[GTDT].size); }", "target": 0, "idx": 103345, "project": "Xen"}
{"func": "static void close_fds_free(struct xs_handle *h) { if (h->watch_pipe[0] != -1) { close(h->watch_pipe[0]); close(h->watch_pipe[1]); } xentoolcore__deregister_active_handle(&h->tc_ah); close(h->fd); free(h); } } static void close_fds_free(struct xs_handle *h) { if (h->watch_pipe[0] != -1) { close(h->watch_pipe[0]); close(h->watch_pipe[1]); } xentoolcore__deregister_active_handle(&h->tc_ah); close(h->fd); free(h); }", "target": 0, "idx": 108904, "project": "Xen"}
{"func": "static void display_tree_part(void) { if (tree2) gtk_tree_store_clear(tree2); if (view_mode == SINGLE_VIEW) display_tree(current); else if (view_mode == SPLIT_VIEW) display_tree(browsed); gtk_tree_view_expand_all(GTK_TREE_VIEW(tree2_w)); }", "target": 0, "idx": 102275, "project": "Xen"}
{"func": "static void dump_ioapic(void)  { int i; HVM_SAVE_TYPE(IOAPIC) p; READ(p); printf(\"IOAPIC: base_address %#llx, ioregsel %#x id %#x\\n\",  (unsigned long long) p.base_address, p.ioregsel, p.id); for ( i = 0; i < VIOAPIC_NUM_PINS; i++ ) { printf(\"pin %.2i: 0x%.16llx\\n\", i,   (unsigned long long) p.redirtbl[i].bits); } }", "target": 0, "idx": 107868, "project": "Xen"}
{"func": "static void nic_teardown(libxl__egc *egc, libxl__checkpoint_device *dev) { int rc; STATE_AO_GC(dev->cds->ao); setup_async_exec(dev, \"teardown\"); rc = libxl__async_exec_start(&dev->aodev.aes); if (rc) goto out; return; out: dev->aodev.rc = rc; dev->aodev.callback(egc, &dev->aodev); }", "target": 0, "idx": 103788, "project": "Xen"}
{"func": "CAMLprim value stub_libxl_ctx_alloc(value logger) { CAMLparam1(logger); CAMLlocal1(handle); libxl_ctx *ctx; int ret; ret = libxl_ctx_alloc(&ctx, LIBXL_VERSION, 0, (xentoollog_logger *) Xtl_val(logger)); if (ret != 0) \\ failwith_xl(ERROR_FAIL, \"cannot init context\"); handle = caml_alloc_custom(&libxl_ctx_custom_operations, sizeof(ctx), 0, 1); Ctx_val(handle) = ctx; CAMLreturn(handle); }", "target": 0, "idx": 108231, "project": "Xen"}
{"func": "static int __vhd_queue_request(struct vhd_state *s, uint8_t op, td_request_t treq) { u32 blk; struct vhd_bitmap*bm; struct vhd_request *req; ASSERT(vhd_type_dynamic(&s->vhd)); blk = treq.sec / s->spb; bm= get_bitmap(s, blk); ASSERT(bm && test_vhd_flag(bm->status, VHD_FLAG_BM_READ_PENDING)); req = alloc_vhd_request(s); if (!req) return -EBUSY; req->treq = treq; req->op = op; req->next = NULL; add_to_tail(&bm->waiting, req); lock_bitmap(bm); DBG(TLOG_DBG, \"%s: lsec: 0x%08\"PRIx64\", blk: 0x%04x nr_secs: 0x%04x, \" \"op: %u\\n\", s->vhd.file, treq.sec, blk, treq.secs, op); TRACE(s); return 0; }", "target": 0, "idx": 101216, "project": "Xen"}
{"func": "static unsigned int __init find_dbgp(struct ehci_dbgp *dbgp,  unsigned int ehci_num) { unsigned int bus, slot, func; for ( bus = 0; bus < 256; bus++ ) { for ( slot = 0; slot < 32; slot++ ) { for ( func = 0; func < 8; func++ ) { unsigned int cap; if ( !pci_device_detect(0, bus, slot, func) ) { if ( !func ) break; continue; } cap = __find_dbgp(bus, slot, func); if ( !cap || ehci_num-- ) { if ( !func && !(pci_conf_read8(0, bus, slot, func,  PCI_HEADER_TYPE) & 0x80) ) break; continue; } dbgp->bus = bus; dbgp->slot = slot; dbgp->func = func; return cap; } } } return 0; }", "target": 0, "idx": 101852, "project": "Xen"}
{"func": "static inline struct csched_vcpu * __runq_elem(struct list_head *elem) { return list_entry(elem, struct csched_vcpu, runq_elem); }", "target": 0, "idx": 105512, "project": "Xen"}
{"func": "static void print_numeric_note(const char *prefix, struct elf_binary *elf,  ELF_HANDLE_DECL(elf_note) note) { uint64_t value = elf_note_numeric(elf, note); unsigned descsz = elf_uval(elf, note, descsz); printf(\"%s: %#*\" PRIx64 \" (%d bytes)\\n\",  prefix, 2+2*descsz, value, descsz); }", "target": 0, "idx": 105366, "project": "Xen"}
{"func": "void td_prep_read(struct tiocb *tiocb, int fd, char *buf, size_t bytes,  long long offset, td_queue_callback_t cb, void *arg) { tapdisk_prep_tiocb(tiocb, fd, 0, buf, bytes, offset, cb, arg); }", "target": 0, "idx": 106166, "project": "Xen"}
{"func": " */ int writev_exact(int fd, const struct iovec *iov, int iovcnt) { int rc, i; for ( i = 0; i < iovcnt; ++i ) { rc = write_exact(fd, iov[i].iov_base, iov[i].iov_len); if ( rc ) return rc; } return 0; } #else int writev_exact(int fd, const struct iovec *iov, int iovcnt) { struct iovec *local_iov = NULL; int rc = 0, iov_idx = 0, saved_errno = 0; ssize_t len; while ( iov_idx < iovcnt ) {  while ( iov[iov_idx].iov_len == 0 ) if ( ++iov_idx == iovcnt ) goto out; len = writev(fd, &iov[iov_idx], min(iovcnt - iov_idx, IOV_MAX)); saved_errno = errno; if ( (len == -1) && (errno == EINTR) ) continue; if ( len <= 0 ) { rc = -1; goto out; }  while ( (len > 0) && (iov_idx < iovcnt) ) { if ( len >= iov[iov_idx].iov_len ) len -= iov[iov_idx++].iov_len; else {  if ( !local_iov ) { local_iov = malloc(iovcnt * sizeof(*iov)); if ( !local_iov ) { saved_errno = ENOMEM; goto out; } iov = memcpy(local_iov, iov, iovcnt * sizeof(*iov)); } local_iov[iov_idx].iov_base += len; local_iov[iov_idx].iov_len-= len; break; } } } saved_errno = 0;  out: free(local_iov); errno = saved_errno; return rc; }", "target": 0, "idx": 107643, "project": "Xen"}
{"func": "void hvm_intr_window_process(struct record_info *ri, struct hvm_data *h) { struct { uint32_t vector; uint32_t source; int32_t intr; } *r = (typeof(r))h->d; char *intsrc_name[] = { \"none\", \"pic\", \"lapic\", \"nmi\", \"mce\", \"vector\" }; if ( opt.dump_all ) { printf(\" %s intr_window vec %u src %u(%s) \",  ri->dump_header,  (unsigned)r->vector,  (unsigned)r->source,  r->source < 6 ? intsrc_name[r->source]: \"?\"); if ( r->intr > 0 ) printf(\"intr %x\\n\",  (unsigned)r->intr); else printf(\"intr #\\n\"); } }", "target": 0, "idx": 107981, "project": "Xen"}
{"func": "static int decode_thumb2(register_t pc, struct hsr_dabt *dabt, uint16_t hw1) { uint16_t hw2; uint16_t rt; if ( raw_copy_from_guest(&hw2, (void *__user)(pc + 2), sizeof (hw2)) ) return -EFAULT; rt = (hw2 >> 12) & 0xf; switch ( (hw1 >> 9) & 0xf ) { case 12: { bool sign = (hw1 & (1u << 8)); bool load = (hw1 & (1u << 4)); if ( (hw1 & 0x0110) == 0x0100 )  goto bad_thumb2; if ( (hw1 & 0x0070) == 0x0070 )  goto bad_thumb2;  if ( rt == 15 )  goto bad_thumb2; if ( !load && sign )  goto bad_thumb2; update_dabt(dabt, rt, (hw1 >> 5) & 3, sign); break; } default: goto bad_thumb2; } return 0; bad_thumb2: gprintk(XENLOG_ERR, \"unhandled THUMB2 instruction 0x%x%x\\n\", hw1, hw2); return 1; }", "target": 0, "idx": 101579, "project": "Xen"}
{"func": "static int server_flush(td_driver_t *driver) { struct tdremus_state *s = (struct tdremus_state *)driver->data;  if (!s->ramdisk.prev) return 0;  return ramdisk_flush(driver, s); }", "target": 0, "idx": 101137, "project": "Xen"}
{"func": "void process_lost_records(struct pcpu_info *p) { struct record_info *ri = &p->ri; struct lost_record_struct *r = (typeof(r))ri->d; tsc_t first_tsc;   if(ri->extra_words != 4) {  fprintf(warn, \"FATAL: Lost record has unexpected extra words %d!\\n\",  ri->extra_words);  error(ERR_RECORD, ri);  return; } first_tsc = r->first_tsc; if(opt.dump_all) { if(p->current) printf(\" %s lost_records count %d d%uv%u (cur d%dv%d) first_tsc %lld\\n\",  ri->dump_header, r->lost_records,  r->did, r->vid,  p->current->d->did, p->current->vid,  r->first_tsc); else printf(\" %s lost_records count %d d%uv%u (cur X) first_tsc %lld\\n\",  ri->dump_header, r->lost_records,  r->did, r->vid,  r->first_tsc); } #if 0 if(opt.dump_trace_volume_on_lost_record) volume_summary(&p->volume.last_buffer); #endif if ( p->current ) { hvm_vlapic_clear(&p->current->vlapic); if(p->current->data_type == VCPU_DATA_HVM) { p->current->hvm.vmexit_valid=0; cr3_switch(0, &p->current->hvm); }  vcpu_prev_update(p, p->current, first_tsc, RUNSTATE_LOST); } #if 0 vcpu_next_update(p, default_domain.vcpu[p->pid], first_tsc); if(p->current->data_type == VCPU_DATA_HVM) { p->current->hvm.vmexit_valid=0; } #endif  if(!p->lost_record.active) { P.lost_cpus++; if(P.lost_cpus > P.max_active_pcpu + 1) { fprintf(warn, \"ERROR: P.lost_cpus %d > P.max_active_pcpu + 1 %d!\\n\", P.lost_cpus, P.max_active_pcpu + 1); error(ERR_ASSERT, NULL); } } else fprintf(warn, \"Strange, lost record for pcpu %d, but lost_record still active!\\n\", p->pid); p->lost_record.active = 1; p->lost_record.tsc = first_tsc; pcpu_string_draw(p); {  struct domain_data *d; int i; for(d=domain_list ; d; d=d->next) { if(d->did != DEFAULT_DOMAIN) { for(i=0; i<MAX_CPUS; i++) if(d->vcpu[i] &&  d->vcpu[i]->runstate.state != RUNSTATE_RUNNING) { if(opt.dump_all) fprintf(warn, \"%s: setting d%dv%d to RUNSTATE_LOST\\n\", __func__, d->did, i); lose_vcpu(d->vcpu[i], first_tsc); } } } } p->lost_record.domain_valid=1; p->lost_record.did=r->did; p->lost_record.vid=r->vid; }", "target": 0, "idx": 108065, "project": "Xen"}
{"func": "const char *conf_get_autoconfig_name(void) { char *name = getenv(\"KCONFIG_AUTOCONFIG\"); return name ? name : \"include/config/auto.conf\"; }", "target": 0, "idx": 101376, "project": "Xen"}
{"func": "static int dup_cloexec(libxl__gc *gc, int fd, const char *what) { int dup_fd = fd; if (fd <= 2) { dup_fd = dup(fd); if (dup_fd < 0) { LOGE(ERROR,\"dup %s\", what); exit(-1); } } libxl_fd_set_cloexec(CTX, dup_fd, 0); return dup_fd; }", "target": 0, "idx": 103940, "project": "Xen"}
{"func": "static int fd_lock = -1; static void pause_domain(uint32_t domid) { libxl_domain_pause(ctx, domid); }", "target": 0, "idx": 108853, "project": "Xen"}
{"func": "static unsigned int mmcfg_pci_segment_shift; static char __iomem *get_virt(unsigned int seg, unsigned int *bus) { struct acpi_mcfg_allocation *cfg; int cfg_num; for (cfg_num = 0; cfg_num < pci_mmcfg_config_num; cfg_num++) { cfg = pci_mmcfg_virt[cfg_num].cfg; if (cfg->pci_segment == seg && (cfg->start_bus_number <= *bus) && (cfg->end_bus_number >= *bus)) { *bus -= cfg->start_bus_number; return pci_mmcfg_virt[cfg_num].virt; } }  return NULL; }", "target": 0, "idx": 104632, "project": "Xen"}
{"func": "void sidtab_set(struct sidtab *dst, struct sidtab *src) { SIDTAB_LOCK(src); dst->htable = src->htable; dst->nel = src->nel; dst->next_sid = src->next_sid; dst->shutdown = 0; SIDTAB_UNLOCK(src); }", "target": 0, "idx": 105766, "project": "Xen"}
{"func": "int libxl__save_emulator_xenstore_data(libxl__domain_save_state *dss,  char **callee_buf,  uint32_t *callee_len) { STATE_AO_GC(dss->ao); const char *xs_root; char **entries, *buf = NULL; unsigned int nr_entries, i, j, len = 0; int rc; const uint32_t domid = dss->domid; const uint32_t dm_domid = libxl_get_stubdom_id(CTX, domid); xs_root = DEVICE_MODEL_XS_PATH(gc, dm_domid, domid, \"\"); entries = libxl__xs_directory(gc, 0, GCSPRINTF(\"%s/physmap\", xs_root), &nr_entries); if (!entries || nr_entries == 0) { rc = 0; goto out; } for (i = 0; i < nr_entries; ++i) { static const char *const physmap_subkeys[] = { \"start_addr\", \"size\", \"name\" }; for (j = 0; j < ARRAY_SIZE(physmap_subkeys); ++j) { const char *key = GCSPRINTF(\"physmap/%s/%s\", entries[i], physmap_subkeys[j]); const char *val = libxl__xs_read(gc, XBT_NULL,  GCSPRINTF(\"%s/%s\", xs_root, key)); if (!val) { rc = ERROR_FAIL; goto out; } append_string(gc, &buf, &len, key); append_string(gc, &buf, &len, val); } } rc = 0;  out: if (!rc) { *callee_buf = buf; *callee_len = len; } return rc; }", "target": 0, "idx": 103571, "project": "Xen"}
{"func": "static void __level_IO_APIC_irq (unsigned int irq) { __modify_IO_APIC_irq(irq, 0x00008000, 0); }", "target": 0, "idx": 102904, "project": "Xen"}
{"func": "int libxl__qmp_pci_add(libxl__gc *gc, int domid, libxl_device_pci *pcidev) { libxl__qmp_handler *qmp = NULL; libxl__json_object *args = NULL; char *hostaddr = NULL; int rc = 0; qmp = libxl__qmp_initialize(gc, domid); if (!qmp) return -1; hostaddr = GCSPRINTF(\"%04x:%02x:%02x.%01x\", pcidev->domain,  pcidev->bus, pcidev->dev, pcidev->func); if (!hostaddr) return -1; qmp_parameters_add_string(gc, &args, \"driver\", \"xen-pci-passthrough\"); QMP_PARAMETERS_SPRINTF(&args, \"id\", PCI_PT_QDEV_ID,  pcidev->bus, pcidev->dev, pcidev->func); qmp_parameters_add_string(gc, &args, \"hostaddr\", hostaddr); if (pcidev->vdevfn) { QMP_PARAMETERS_SPRINTF(&args, \"addr\", \"%x.%x\",  PCI_SLOT(pcidev->vdevfn), PCI_FUNC(pcidev->vdevfn)); }  if (pcidev->permissive) qmp_parameters_add_bool(gc, &args, \"permissive\", true); rc = qmp_synchronous_send(qmp, \"device_add\", args, NULL, NULL, qmp->timeout); if (rc == 0) { rc = qmp_synchronous_send(qmp, \"query-pci\", NULL, pci_add_callback, pcidev, qmp->timeout); } libxl__qmp_close(qmp); return rc; }", "target": 0, "idx": 103873, "project": "Xen"}
{"func": "static int test_ta2_init(uintptr_t par) { return xs_write(xsh, XBT_NULL, paths[0], write_buffers[0], 1) ? 0 : errno; }", "target": 0, "idx": 108895, "project": "Xen"}
{"func": "grant_entry_v1_t *xc_gnttab_map_table_v1(xc_interface *xch, uint32_t domid,  int *gnt_num) { if (xc_gnttab_get_version(xch, domid) == 2) return NULL; return _gnttab_map_table(xch, domid, gnt_num); }", "target": 0, "idx": 107507, "project": "Xen"}
{"func": "void vhd_complete(void *arg, struct tiocb *tiocb, int err) { struct vhd_request *req = (struct vhd_request *)arg; struct vhd_state *s = req->state; struct iocb *io = &tiocb->iocb; s->completed++; TRACE(s); req->error = err; if (req->error) ERR(req->error, \"%s: op: %u, lsec: %\"PRIu64\", secs: %u, \" \"nbytes: %lu, blk: %\"PRIu64\", blk_offset: %u\", s->vhd.file, req->op, req->treq.sec, req->treq.secs, io->u.c.nbytes, req->treq.sec / s->spb, bat_entry(s, req->treq.sec / s->spb)); switch (req->op) { case VHD_OP_DATA_READ: finish_data_read(req); break; case VHD_OP_DATA_WRITE: finish_data_write(req); break; case VHD_OP_BITMAP_READ: finish_bitmap_read(req); break; case VHD_OP_BITMAP_WRITE: finish_bitmap_write(req); break; case VHD_OP_ZERO_BM_WRITE: finish_zero_bm_write(req); break; case VHD_OP_BAT_WRITE: finish_bat_write(req); break; default: ASSERT(0); break; } }", "target": 0, "idx": 101196, "project": "Xen"}
{"func": "static int xc_domain_resume_any(xc_interface *xch, uint32_t domid) { DECLARE_DOMCTL; xc_dominfo_t info; int i, rc = -1; #if defined(__i386__) || defined(__x86_64__) struct domain_info_context _dinfo = { .guest_width = 0, .p2m_size = 0 }; struct domain_info_context *dinfo = &_dinfo; unsigned long mfn; vcpu_guest_context_any_t ctxt; start_info_t *start_info; shared_info_t *shinfo = NULL; xen_pfn_t *p2m_frame_list_list = NULL; xen_pfn_t *p2m_frame_list = NULL; xen_pfn_t *p2m = NULL; #endif if ( xc_domain_getinfo(xch, domid, 1, &info) != 1 ) { PERROR(\"Could not get domain info\"); return rc; }  #if defined(__i386__) || defined(__x86_64__) if ( info.hvm ) return xc_domain_resume_hvm(xch, domid); if ( xc_domain_get_guest_width(xch, domid, &dinfo->guest_width) != 0 ) { PERROR(\"Could not get domain width\"); return rc; } if ( dinfo->guest_width != sizeof(long) ) { ERROR(\"Cannot resume uncooperative cross-address-size guests\"); return rc; }  shinfo = xc_map_foreign_range(xch, domid, PAGE_SIZE, PROT_READ, info.shared_info_frame); if ( shinfo == NULL ) { ERROR(\"Couldn't map shared info\"); goto out; } dinfo->p2m_size = shinfo->arch.max_pfn; p2m_frame_list_list = xc_map_foreign_range(xch, domid, PAGE_SIZE, PROT_READ,  shinfo->arch.pfn_to_mfn_frame_list_list); if ( p2m_frame_list_list == NULL ) { ERROR(\"Couldn't map p2m_frame_list_list\"); goto out; } p2m_frame_list = xc_map_foreign_pages(xch, domid, PROT_READ, p2m_frame_list_list, P2M_FLL_ENTRIES); if ( p2m_frame_list == NULL ) { ERROR(\"Couldn't map p2m_frame_list\"); goto out; }  p2m = xc_map_foreign_pages(xch, domid, PROT_READ,  p2m_frame_list,  P2M_FL_ENTRIES); if ( p2m == NULL ) { ERROR(\"Couldn't map p2m table\"); goto out; } if ( xc_vcpu_getcontext(xch, domid, 0, &ctxt) ) { ERROR(\"Could not get vcpu context\"); goto out; } mfn = GET_FIELD(&ctxt, user_regs.edx, dinfo->guest_width); start_info = xc_map_foreign_range(xch, domid, PAGE_SIZE, PROT_READ | PROT_WRITE, mfn); if ( start_info == NULL ) { ERROR(\"Couldn't map start_info\"); goto out; } start_info->store_mfn= p2m[start_info->store_mfn]; start_info->console.domU.mfn = p2m[start_info->console.domU.mfn]; munmap(start_info, PAGE_SIZE); #endif   for ( i = 1; i <= info.max_vcpu_id; i++ ) if ( xc_vcpu_setcontext(xch, domid, i, NULL) != 0 ) { ERROR(\"Couldn't reset vcpu state\"); goto out; }  domctl.cmd = XEN_DOMCTL_resumedomain; domctl.domain = domid; rc = do_domctl(xch, &domctl); out: #if defined(__i386__) || defined(__x86_64__) if (p2m) munmap(p2m, P2M_FL_ENTRIES*PAGE_SIZE); if (p2m_frame_list) munmap(p2m_frame_list, P2M_FLL_ENTRIES*PAGE_SIZE); if (p2m_frame_list_list) munmap(p2m_frame_list_list, PAGE_SIZE); if (shinfo) munmap(shinfo, PAGE_SIZE); #endif return rc; }", "target": 0, "idx": 107688, "project": "Xen"}
{"func": "int ppro_has_global_ctrl = 0; static void ppro_fill_in_addresses(struct op_msrs * const msrs) { int i; for (i = 0; i < num_counters; i++) msrs->counters[i].addr = MSR_P6_PERFCTR(i); for (i = 0; i < num_counters; i++) msrs->controls[i].addr = MSR_P6_EVNTSEL(i); }", "target": 0, "idx": 104967, "project": "Xen"}
{"func": "static long memory_exchange(XEN_GUEST_HANDLE(xen_memory_exchange_t) arg) { struct xen_memory_exchange exch; PAGE_LIST_HEAD(in_chunk_list); PAGE_LIST_HEAD(out_chunk_list); unsigned long in_chunk_order, out_chunk_order; xen_pfn_t gpfn, gmfn, mfn; unsigned long i, j, k = 0;  unsigned intmemflags = 0; longrc = 0; struct domain *d; struct page_info *page; if ( copy_from_guest(&exch, arg, 1) ) return -EFAULT;  if ( (exch.nr_exchanged > exch.in.nr_extents) ||    (exch.in.domid != exch.out.domid) ||    ((~0UL >> exch.in.extent_order) < exch.in.nr_extents) ||  ((~0UL >> exch.out.extent_order) < exch.out.nr_extents) ||    ((exch.in.nr_extents << exch.in.extent_order) != (exch.out.nr_extents << exch.out.extent_order)) ) { rc = -EINVAL; goto fail_early; }  if ( !multipage_allocation_permitted(current->domain,  exch.in.extent_order) ||  !multipage_allocation_permitted(current->domain,  exch.out.extent_order) ) { rc = -EPERM; goto fail_early; } if ( exch.in.extent_order <= exch.out.extent_order ) { in_chunk_order= exch.out.extent_order - exch.in.extent_order; out_chunk_order = 0; } else { in_chunk_order= 0; out_chunk_order = exch.in.extent_order - exch.out.extent_order; } if ( likely(exch.in.domid == DOMID_SELF) ) { d = rcu_lock_current_domain(); } else { if ( (d = rcu_lock_domain_by_id(exch.in.domid)) == NULL ) goto fail_early; if ( !IS_PRIV_FOR(current->domain, d) ) { rcu_unlock_domain(d); rc = -EPERM; goto fail_early; } } memflags |= MEMF_bits(domain_clamp_alloc_bitsize( d, XENMEMF_get_address_bits(exch.out.mem_flags) ? : (BITS_PER_LONG+PAGE_SHIFT))); memflags |= MEMF_node(XENMEMF_get_node(exch.out.mem_flags)); for ( i = (exch.nr_exchanged >> in_chunk_order); i < (exch.in.nr_extents >> in_chunk_order); i++ ) { if ( hypercall_preempt_check() ) { exch.nr_exchanged = i << in_chunk_order; rcu_unlock_domain(d); if ( copy_field_to_guest(arg, &exch, nr_exchanged) ) return -EFAULT; return hypercall_create_continuation( __HYPERVISOR_memory_op, \"lh\", XENMEM_exchange, arg); }  for ( j = 0; j < (1UL << in_chunk_order); j++ ) { if ( unlikely(__copy_from_guest_offset( &gmfn, exch.in.extent_start, (i<<in_chunk_order)+j, 1)) ) { rc = -EFAULT; goto fail; } for ( k = 0; k < (1UL << exch.in.extent_order); k++ ) { #ifdef CONFIG_X86 p2m_type_t p2mt;  mfn = mfn_x(get_gfn_unshare(d, gmfn + k, &p2mt)); if ( p2m_is_shared(p2mt) ) { put_gfn(d, gmfn + k); rc = -ENOMEM; goto fail;  } #else  mfn = gmfn_to_mfn(d, gmfn + k); #endif if ( unlikely(!mfn_valid(mfn)) ) { put_gfn(d, gmfn + k); rc = -EINVAL; goto fail; } page = mfn_to_page(mfn); if ( unlikely(steal_page(d, page, MEMF_no_refcount)) ) { put_gfn(d, gmfn + k); rc = -EINVAL; goto fail; } page_list_add(page, &in_chunk_list); put_gfn(d, gmfn + k); } }  for ( j = 0; j < (1UL << out_chunk_order); j++ ) { page = alloc_domheap_pages(NULL, exch.out.extent_order, memflags); if ( unlikely(page == NULL) ) { rc = -ENOMEM; goto fail; } page_list_add(page, &out_chunk_list); }   while ( (page = page_list_remove_head(&in_chunk_list)) ) { unsigned long gfn; if ( !test_and_clear_bit(_PGC_allocated, &page->count_info) ) BUG(); mfn = page_to_mfn(page); gfn = mfn_to_gmfn(d, mfn);  BUG_ON(SHARED_M2P(gfn)); guest_physmap_remove_page(d, gfn, mfn, 0); put_page(page); }  j = 0; while ( (page = page_list_remove_head(&out_chunk_list)) ) { if ( assign_pages(d, page, exch.out.extent_order, MEMF_no_refcount) ) { unsigned long dec_count; bool_t drop_dom_ref;  dec_count = (((1UL << exch.in.extent_order) * (1UL << in_chunk_order)) -  (j * (1UL << exch.out.extent_order))); spin_lock(&d->page_alloc_lock); d->tot_pages -= dec_count; drop_dom_ref = (dec_count && !d->tot_pages); spin_unlock(&d->page_alloc_lock); if ( drop_dom_ref ) put_domain(d); free_domheap_pages(page, exch.out.extent_order); goto dying; }  (void)__copy_from_guest_offset( &gpfn, exch.out.extent_start, (i<<out_chunk_order)+j, 1); mfn = page_to_mfn(page); guest_physmap_add_page(d, gpfn, mfn, exch.out.extent_order); if ( !paging_mode_translate(d) ) { for ( k = 0; k < (1UL << exch.out.extent_order); k++ ) set_gpfn_from_mfn(mfn + k, gpfn + k); (void)__copy_to_guest_offset( exch.out.extent_start, (i<<out_chunk_order)+j, &mfn, 1); } j++; } BUG_ON( !(d->is_dying) && (j != (1UL << out_chunk_order)) ); } exch.nr_exchanged = exch.in.nr_extents; if ( copy_field_to_guest(arg, &exch, nr_exchanged) ) rc = -EFAULT; rcu_unlock_domain(d); return rc;   fail:  while ( (page = page_list_remove_head(&in_chunk_list)) ) { put_gfn(d, gmfn + k--); if ( assign_pages(d, page, 0, MEMF_no_refcount) ) BUG(); }  dying: rcu_unlock_domain(d);  while ( (page = page_list_remove_head(&out_chunk_list)) ) free_domheap_pages(page, exch.out.extent_order); exch.nr_exchanged = i << in_chunk_order;  fail_early: if ( copy_field_to_guest(arg, &exch, nr_exchanged) ) rc = -EFAULT; return rc; }", "target": 1, "idx": 109031, "project": "Xen"}
{"func": "int libxl_test_fdevent(libxl_ctx *ctx, int fd, short events,  libxl_asyncop_how *ao_how) { int rc; libxl__test_fdevent *tfe; AO_CREATE(ctx, 0, ao_how); GCNEW(tfe); tfe_init(tfe, ao); rc = libxl__ev_fd_register(gc, &tfe->fd, tfe_fd_cb, fd, events); if (rc) goto out; tfe->abrt.ao = ao; tfe->abrt.callback = tfe_abrt_cb; rc = libxl__ao_abortable_register(&tfe->abrt); if (rc) goto out; return AO_INPROGRESS;  out: tfe_cleanup(gc, tfe); return AO_CREATE_FAIL(rc); }", "target": 0, "idx": 104044, "project": "Xen"}
{"func": "const struct livepatch_elf_sec * livepatch_elf_sec_by_name(const struct livepatch_elf *elf, const char *name) { unsigned int i; for ( i = 1; i < elf->hdr->e_shnum; i++ ) { if ( !strcmp(name, elf->sec[i].name) ) return &elf->sec[i]; } return NULL; }", "target": 0, "idx": 104271, "project": "Xen"}
{"func": " */ static inline void INSERT_BLOCK(struct bhdr *b, struct xmem_pool *p, int fl, int sl) { b->ptr.free_ptr = (struct free_ptr) {NULL, p->matrix[fl][sl]}; if ( p->matrix[fl][sl] ) p->matrix[fl][sl]->ptr.free_ptr.prev = b; p->matrix[fl][sl] = b; set_bit(sl, &p->sl_bitmap[fl]); set_bit(fl, &p->fl_bitmap); }", "target": 0, "idx": 108867, "project": "Xen"}
{"func": "static int horDiff32(TIFF* tif, uint8* cp0, tmsize_t cc) { TIFFPredictorState* sp = PredictorState(tif); tmsize_t stride = sp->stride; uint32 *wp = (uint32*) cp0; tmsize_t wc = cc/4; if((cc%(4*stride))!=0) { TIFFErrorExt(tif->tif_clientdata, \"horDiff32\",  \"%s\", \"(cc%(4*stride))!=0\"); return 0; } if (wc > stride) { wc -= stride; wp += wc - 1; do { REPEAT4(stride, wp[stride] -= wp[0]; wp--) wc -= stride; } while (wc > 0); } return 1; }", "target": 0, "idx": 100298, "project": "LibTIFF"}
{"func": "static void daemonize(void) { pid_t pid; if ( (pid = fork()) < 0 ) exit(1); if ( pid != 0 ) exit(0); setsid(); if ( (pid = fork()) < 0 ) exit(1); if ( pid != 0 ) exit(0); if ( chdir(\"/\") == -1 ) exit(1); umask(0); }", "target": 0, "idx": 108327, "project": "Xen"}
{"func": "int tap_ctl_connect(const char *name, int *sfd) { int fd, err; struct sockaddr_un saddr; *sfd = -1; fd = socket(AF_UNIX, SOCK_STREAM, 0); if (fd == -1) { EPRINTF(\"couldn't create socket for %s: %d\\n\", name, errno); return -errno; } memset(&saddr, 0, sizeof(saddr)); saddr.sun_family = AF_UNIX; strcpy(saddr.sun_path, name); err = connect(fd, (const struct sockaddr *)&saddr, sizeof(saddr)); if (err) { EPRINTF(\"couldn't connect to %s: %d\\n\", name, errno); close(fd); return -errno; } *sfd = fd; return 0; }", "target": 0, "idx": 106013, "project": "Xen"}
{"func": "static int vhd_util_check_differencing_header(vhd_context_t *vhd) { char *msg; msg = vhd_util_check_validate_differencing_header(vhd); if (msg) { printf(\"differencing header is invalid: %s\\n\", msg); return -EINVAL; } return 0; }", "target": 0, "idx": 106752, "project": "Xen"}
{"func": "const char *fdt_string(const void *fdt, int stroffset) { return (const char *)fdt + fdt_off_dt_strings(fdt) + stroffset; }", "target": 0, "idx": 102018, "project": "Xen"}
{"func": "int __init bzimage_parse(void *image_base, void **image_start,  unsigned long *image_len) { struct setup_header *hdr = (struct setup_header *)(*image_start); int err = bzimage_check(hdr, *image_len); unsigned long output_len; if ( err < 0 ) return err; if ( err > 0 ) { *image_start += (hdr->setup_sects + 1) * 512 + hdr->payload_offset; *image_len = hdr->payload_length; } if ( elf_is_elfbinary(*image_start, *image_len) ) return 0; BUG_ON(!(image_base < *image_start)); output_len = output_length(*image_start, orig_image_len); if ( (err = perform_gunzip(image_base, *image_start, orig_image_len)) > 0 ) err = decompress(*image_start, orig_image_len, image_base); if ( !err ) { *image_start = image_base; *image_len = output_len; } return err > 0 ? 0 : err; }", "target": 0, "idx": 101299, "project": "Xen"}
{"func": "physid_mask_t phys_cpu_present_map; void __init set_nr_cpu_ids(unsigned int max_cpus) { unsigned int tot_cpus = num_processors + disabled_cpus; if (!max_cpus) max_cpus = tot_cpus; if (max_cpus > NR_CPUS) max_cpus = NR_CPUS; else if (!max_cpus) max_cpus = 1; printk(XENLOG_INFO \"SMP: Allowing %u CPUs (%d hotplug CPUs)\\n\",  max_cpus, max_t(int, max_cpus - num_processors, 0)); if (!park_offline_cpus) tot_cpus = max_cpus; nr_cpu_ids = min(tot_cpus, NR_CPUS + 0u); if (park_offline_cpus && nr_cpu_ids < num_processors) printk(XENLOG_WARNING \"SMP: Cannot bring up %u further CPUs\\n\",  num_processors - nr_cpu_ids); #ifndef nr_cpumask_bits nr_cpumask_bits = ROUNDUP(nr_cpu_ids, BITS_PER_LONG); printk(XENLOG_DEBUG \"NR_CPUS:%u nr_cpumask_bits:%u\\n\",  NR_CPUS, nr_cpumask_bits); #endif }", "target": 0, "idx": 104674, "project": "Xen"}
{"func": " */ static int evtchn_revents_check(libxl__egc *egc, int revents) { EGC_GC; if (revents & ~POLLIN) { LOG(ERROR, \"unexpected poll event on event channel fd: %x\", revents); LIBXL__EVENT_DISASTER(egc,  \"unexpected poll event on event channel fd\", 0, 0); libxl__ev_fd_deregister(gc, &CTX->evtchn_efd); return ERROR_FAIL; } assert(revents & POLLIN); return 0; }", "target": 0, "idx": 103609, "project": "Xen"}
{"func": "pthread_mutex_t cache_mutex = PTHREAD_MUTEX_INITIALIZER; static void cache_lock(xencall_handle *xcall) { int saved_errno = errno; if ( xcall->flags & XENCALL_OPENFLAG_NON_REENTRANT ) return; pthread_mutex_lock(&cache_mutex);  errno = saved_errno; }", "target": 0, "idx": 101278, "project": "Xen"}
{"func": "static void appleWarningHandler(const char* module, const char* fmt, va_list ap) { if (module != NULL) fprintf(stderr, \"%s: \", module); fprintf(stderr, \"Warning, \"); vfprintf(stderr, fmt, ap); fprintf(stderr, \".\\n\"); }", "target": 0, "idx": 100107, "project": "LibTIFF"}
{"func": "static const char *vusb_be_from_xs_libxl_type(libxl__gc *gc, const char *libxl_path, libxl_usbctrl_type type) { const char *be_path = NULL, *tmp; int r; if (type == LIBXL_USBCTRL_TYPE_AUTO) { r = libxl__xs_read_checked(gc, XBT_NULL,  GCSPRINTF(\"%s/type\", libxl_path), &tmp); if (r || libxl_usbctrl_type_from_string(tmp, &type)) goto out; } if (type == LIBXL_USBCTRL_TYPE_DEVICEMODEL) { be_path = libxl_path; goto out; } r = libxl__xs_read_checked(gc, XBT_NULL,  GCSPRINTF(\"%s/backend\", libxl_path),  &be_path); if (r) be_path = NULL; out: return be_path; }", "target": 0, "idx": 104099, "project": "Xen"}
{"func": "static void libxl__colo_domain_create_cb(libxl__egc *egc,  libxl__domain_create_state *dcs,  int rc, uint32_t domid) { libxl__colo_restore_checkpoint_state *crcs = dcs->crs.crcs; crcs->callback(egc, crcs, rc); }", "target": 0, "idx": 103434, "project": "Xen"}
{"func": " */ static void t2c_update(struct csched2_runqueue_data *rqd, s_time_t time, struct csched2_vcpu *svc) { uint64_t val = time * rqd->max_weight + svc->residual; svc->residual = do_div(val, svc->weight); svc->credit -= val; }", "target": 0, "idx": 105575, "project": "Xen"}
{"func": " */ static unsigned int startup_level_ioapic_irq(struct irq_desc *desc) { unmask_IO_APIC_irq(desc); return 0;  }", "target": 0, "idx": 102894, "project": "Xen"}
{"func": "static void tcpa_reset_acpi_log(void) { unsigned char *lasa = tcpa_get_lasa_base_ptr(); if (lasa) memset(lasa, 0x0, tcpa_get_laml()); }", "target": 0, "idx": 106351, "project": "Xen"}
{"func": "void hvm_vlapic_eoi_handler(struct hvm_data *h) { if(opt.dump_all) printf(\"[vla] d%dv%d eoi\\n\",  h->v->d->did, h->v->vid); }", "target": 0, "idx": 108006, "project": "Xen"}
{"func": "static int vcpu_arm32(struct xc_dom_image *dom) { vcpu_guest_context_any_t any_ctx; vcpu_guest_context_t *ctxt = &any_ctx.c; int rc; DOMPRINTF_CALLED(dom->xch);  memset(ctxt, 0, sizeof(*ctxt)); ctxt->user_regs.pc32 = dom->parms.virt_entry;  ctxt->user_regs.r0_usr = 0;   ctxt->user_regs.r1_usr = 0xffffffff;  ctxt->user_regs.r2_usr = dom->devicetree_blob ? dom->devicetree_seg.vstart : 0xffffffff; ctxt->sctlr = SCTLR_GUEST_INIT; ctxt->ttbr0 = 0; ctxt->ttbr1 = 0; ctxt->ttbcr = 0;  ctxt->user_regs.cpsr = PSR_GUEST32_INIT; ctxt->flags = VGCF_online; DOMPRINTF(\"Initial state CPSR %#\"PRIx32\" PC %#\"PRIx32,  ctxt->user_regs.cpsr, ctxt->user_regs.pc32); rc = xc_vcpu_setcontext(dom->xch, dom->guest_domid, 0, &any_ctx); if ( rc != 0 ) xc_dom_panic(dom->xch, XC_INTERNAL_ERROR,  \"%s: SETVCPUCONTEXT failed (rc=%d)\", __func__, rc); return rc; }", "target": 0, "idx": 107387, "project": "Xen"}
{"func": "int xc_dom_try_gunzip(struct xc_dom_image *dom, void **blob, size_t * size) { void *unzip; size_t unziplen; unziplen = xc_dom_check_gzip(dom->xch, *blob, *size); if ( unziplen == 0 ) return 0; unzip = xc_dom_malloc(dom, unziplen); if ( unzip == NULL ) return -1; if ( xc_dom_do_gunzip(dom->xch, *blob, *size, unzip, unziplen) == -1 ) return -1; *blob = unzip; *size = unziplen; return 0; }", "target": 1, "idx": 109021, "project": "Xen"}
{"func": "static int PredictorVSetField(TIFF* tif, uint32 tag, va_list ap) { TIFFPredictorState *sp = PredictorState(tif); assert(sp != NULL); assert(sp->vsetparent != NULL); switch (tag) { case TIFFTAG_PREDICTOR: sp->predictor = (uint16) va_arg(ap, uint16_vap); TIFFSetFieldBit(tif, FIELD_PREDICTOR); break; default: return (*sp->vsetparent)(tif, tag, ap); } tif->tif_flags |= TIFF_DIRTYDIRECT; return 1; }", "target": 0, "idx": 100628, "project": "LibTIFF"}
{"func": "int xc_mem_paging_prep(xc_interface *xch, uint32_t domain_id, uint64_t gfn) { return xc_mem_paging_memop(xch, domain_id,  XENMEM_paging_op_prep,  gfn, NULL); }", "target": 0, "idx": 107558, "project": "Xen"}
{"func": "static size_t strlen(const char *s) { const char *sc; for ( sc = s; *sc != '\\0'; ++sc ) ; return sc - s; }", "target": 0, "idx": 101339, "project": "Xen"}
{"func": "int nestedsvm_vmcb_map(struct vcpu *v, uint64_t vmcbaddr) { struct nestedvcpu *nv = &vcpu_nestedhvm(v); if (nv->nv_vvmcx != NULL && nv->nv_vvmcxaddr != vmcbaddr) { ASSERT(nv->nv_vvmcxaddr != INVALID_PADDR); hvm_unmap_guest_frame(nv->nv_vvmcx, 1); nv->nv_vvmcx = NULL; nv->nv_vvmcxaddr = INVALID_PADDR; } if ( !nv->nv_vvmcx ) { bool_t writable; void *vvmcx = hvm_map_guest_frame_rw(paddr_to_pfn(vmcbaddr), 1,  &writable); if ( !vvmcx ) return 0; if ( !writable ) { hvm_unmap_guest_frame(vvmcx, 1); return 0; } nv->nv_vvmcx = vvmcx; nv->nv_vvmcxaddr = vmcbaddr; } return 1; }", "target": 0, "idx": 104778, "project": "Xen"}
{"func": "int handle_mmio(void) { struct hvm_emulate_ctxt ctxt; struct vcpu *curr = current; int rc; hvm_emulate_prepare(&ctxt, guest_cpu_user_regs()); rc = hvm_emulate_one(&ctxt); if ( curr->arch.hvm_vcpu.io_state == HVMIO_awaiting_completion ) curr->arch.hvm_vcpu.io_state = HVMIO_handle_mmio_awaiting_completion; else curr->arch.hvm_vcpu.mmio_gva = 0; switch ( rc ) { case X86EMUL_UNHANDLEABLE: gdprintk(XENLOG_WARNING,  \"MMIO emulation failed @ %04x:%lx: \"  \"%02x %02x %02x %02x %02x %02x\\n\",  hvmemul_get_seg_reg(x86_seg_cs, &ctxt)->sel,  ctxt.insn_buf_eip,  ctxt.insn_buf[0], ctxt.insn_buf[1],  ctxt.insn_buf[2], ctxt.insn_buf[3],  ctxt.insn_buf[4], ctxt.insn_buf[5]); return 0; case X86EMUL_EXCEPTION: if ( ctxt.exn_pending ) hvm_inject_exception(ctxt.exn_vector, ctxt.exn_error_code, 0); break; default: break; } hvm_emulate_writeback(&ctxt); return 1; }", "target": 1, "idx": 109002, "project": "Xen"}
{"func": "char *libxl__blktap_devpath(libxl__gc *gc, const char *disk, libxl_disk_format format) { const char *type; char *params, *devname = NULL; tap_list_t tap; int err; type = libxl__device_disk_string_of_format(format); err = tap_ctl_find(type, disk, &tap); if (err == 0) { devname = GCSPRINTF(\"/dev/xen/blktap-2/tapdev%d\", tap.minor); if (devname) return devname; } params = GCSPRINTF(\"%s:%s\", type, disk); err = tap_ctl_create(params, &devname); if (!err) { libxl__ptr_add(gc, devname); return devname; } free(devname); return NULL; }", "target": 0, "idx": 103354, "project": "Xen"}
{"func": "static inline int vhd_journal_sync(vhd_journal_t *j) { int err; err = fdatasync(j->jfd); if (err) return -errno; return 0; }", "target": 0, "idx": 103098, "project": "Xen"}
{"func": "void vhd_batmap_header_in(vhd_batmap_t *batmap) { BE64_IN(&batmap->header.batmap_offset); BE32_IN(&batmap->header.batmap_size); BE32_IN(&batmap->header.batmap_version); BE32_IN(&batmap->header.checksum); }", "target": 0, "idx": 103117, "project": "Xen"}
{"func": "int xc_flask_add_pirq(xc_interface *xch, unsigned int pirq, char *scontext) { return xc_flask_add(xch, OCON_PIRQ, pirq, pirq, scontext); }", "target": 0, "idx": 107481, "project": "Xen"}
{"func": "int security_ocontext_add( u32 ocon, unsigned long low, unsigned long high ,u32 sid ) { int ret = 0; struct ocontext *c; struct ocontext *prev; struct ocontext *add; if ( (add = xzalloc(struct ocontext)) == NULL ) return -ENOMEM; add->sid = sid; POLICY_WRLOCK; switch( ocon ) { case OCON_PIRQ: add->u.pirq = (u16)low; if ( high != low ) { ret = -EINVAL; break; } c = policydb.ocontexts[OCON_PIRQ]; while ( c ) { if ( c->u.pirq == add->u.pirq ) { if ( c->sid == sid ) break; printk(\"flask: Duplicate pirq %d\\n\", add->u.pirq); ret = -EEXIST; break; } c = c->next; } if ( ret == 0 ) { add->next = policydb.ocontexts[OCON_PIRQ]; policydb.ocontexts[OCON_PIRQ] = add; } break; case OCON_IOPORT: add->u.ioport.low_ioport = low; add->u.ioport.high_ioport = high; prev = NULL; c = policydb.ocontexts[OCON_IOPORT]; while ( c && c->u.ioport.high_ioport < low ) { prev = c; c = c->next; } if (c && c->u.ioport.low_ioport <= high) { if (c->u.ioport.low_ioport == low && c->u.ioport.high_ioport == high && c->sid == sid) break; printk(\"flask: IO Port overlap with entry %#x - %#x\\n\",  c->u.ioport.low_ioport, c->u.ioport.high_ioport); ret = -EEXIST; break; } if (prev) { add->next = prev->next; prev->next = add; } else { add->next = policydb.ocontexts[OCON_IOPORT]; policydb.ocontexts[OCON_IOPORT] = add; } break; case OCON_IOMEM: add->u.iomem.low_iomem = low; add->u.iomem.high_iomem = high; prev = NULL; c = policydb.ocontexts[OCON_IOMEM]; while ( c && c->u.iomem.high_iomem < low ) { prev = c; c = c->next; } if (c && c->u.iomem.low_iomem <= high) { if (c->u.iomem.low_iomem == low && c->u.iomem.high_iomem == high && c->sid == sid) break; printk(\"flask: IO Memory overlap with entry %#\"PRIx64\" - %#\"PRIx64\"\\n\",  c->u.iomem.low_iomem, c->u.iomem.high_iomem); ret = -EEXIST; break; } if (prev) { add->next = prev->next; prev->next = add; } else { add->next = policydb.ocontexts[OCON_IOMEM]; policydb.ocontexts[OCON_IOMEM] = add; } break;  case OCON_DEVICE: add->u.device = low; if ( high != low ) { ret = -EINVAL; break; } c = policydb.ocontexts[OCON_DEVICE]; while ( c ) { if ( c->u.device == add->u.device ) { if ( c->sid == sid ) break; printk(\"flask: Duplicate PCI Device %#x\\n\", add->u.device); ret = -EEXIST; break; } c = c->next; } if ( ret == 0 ) { add->next = policydb.ocontexts[OCON_DEVICE]; policydb.ocontexts[OCON_DEVICE] = add; } break;  default:  ret = -EINVAL; } POLICY_WRUNLOCK; if ( ret != 0 ) xfree(add); return ret; }", "target": 0, "idx": 105719, "project": "Xen"}
{"func": "static int have_wrcomb(void) { return (mtrr_if->have_wrcomb ? mtrr_if->have_wrcomb() : 0); }", "target": 0, "idx": 104309, "project": "Xen"}
{"func": "TIFF* TIFFOpen(const char* name, const char* mode) { static const char module[] = \"TIFFOpen\"; int m, fd; m = _TIFFgetMode(mode, module); if (m == -1) { return ((TIFF*) 0); } fd = open(name, 0, m); if (fd < 0) { TIFFErrorExt(0, module, \"%s: Cannot open\", name); return ((TIFF *)0); } return (TIFFFdOpen(fd, name, mode)); }", "target": 0, "idx": 100077, "project": "LibTIFF"}
{"func": "static void sh_set_toplevel_shadow(struct vcpu *v,   int slot,  mfn_t gmfn,   unsigned int root_type)  { mfn_t smfn; pagetable_t old_entry, new_entry; struct domain *d = v->domain;   old_entry = v->arch.shadow_table[slot];  if ( !mfn_valid(gmfn) ) { new_entry = pagetable_null(); goto install_new_entry; }  smfn = get_shadow_status(v, gmfn, root_type); if ( !mfn_valid(smfn) ) {  shadow_prealloc(d, root_type, 1);  smfn = sh_make_shadow(v, gmfn, root_type); } ASSERT(mfn_valid(smfn));   if ( sh_pin(v, smfn) == 0 ) { SHADOW_ERROR(\"can't pin %#lx as toplevel shadow\\n\", mfn_x(smfn)); domain_crash(v->domain); }  if ( !sh_get_ref(v, smfn, 0) ) { SHADOW_ERROR(\"can't install %#lx as toplevel shadow\\n\", mfn_x(smfn)); domain_crash(v->domain); } new_entry = pagetable_from_mfn(smfn);  install_new_entry:  SHADOW_PRINTK(\"%u/%u [%u] gmfn %#\"PRI_mfn\" smfn %#\"PRI_mfn\"\\n\", GUEST_PAGING_LEVELS, SHADOW_PAGING_LEVELS, slot, mfn_x(gmfn), mfn_x(pagetable_get_mfn(new_entry))); v->arch.shadow_table[slot] = new_entry;  if ( !pagetable_is_null(old_entry) ) { mfn_t old_smfn = pagetable_get_mfn(old_entry);  if ( !mfn_to_page(old_smfn)->u.sh.pinned && !sh_pin(v, old_smfn) ) { SHADOW_ERROR(\"can't re-pin %#lx\\n\", mfn_x(old_smfn)); domain_crash(v->domain); } sh_put_ref(v, old_smfn, 0); } }", "target": 1, "idx": 109558, "project": "Xen"}
{"func": "int fd_modify(void *user, int fd, void **for_app_registration_update,  short events) { caml_leave_blocking_section(); CAMLparam0(); CAMLlocalN(args, 4); int ret = 0; static value *func = NULL; value *p = (value *) user; value *for_app = *for_app_registration_update;  assert(for_app); if (func == NULL) {  func = caml_named_value(\"libxl_fd_modify\"); } args[0] = *p; args[1] = Val_int(fd); args[2] = *for_app; args[3] = Val_poll_events(events); *for_app = caml_callbackN_exn(*func, 4, args); if (Is_exception_result(*for_app)) {  ret = ERROR_OSEVENT_REG_FAIL; goto err; } *for_app_registration_update = for_app; err: CAMLdone; caml_enter_blocking_section(); return ret; }", "target": 0, "idx": 108222, "project": "Xen"}
{"func": "static int processCompressOptions(char* opt) { char* cp = NULL; if (strneq(opt, \"none\",4)) { defcompression = COMPRESSION_NONE; } else if (streq(opt, \"packbits\")) { defcompression = COMPRESSION_PACKBITS; } else if (strneq(opt, \"jpeg\", 4)) { cp = strchr(opt, ':'); defcompression = COMPRESSION_JPEG; while (cp) { if (isdigit((int)cp[1])) quality = atoi(cp + 1); else if (strneq(cp + 1, \"raw\", 3 )) jpegcolormode = JPEGCOLORMODE_RAW; else if (strneq(cp + 1, \"rgb\", 3 )) jpegcolormode = JPEGCOLORMODE_RGB; else usage(); cp = strchr(cp + 1, ':'); } } else if (strneq(opt, \"g3\", 2)) { processG3Options(opt); defcompression = COMPRESSION_CCITTFAX3; } else if (streq(opt, \"g4\")) { defcompression = COMPRESSION_CCITTFAX4; } else if (strneq(opt, \"lzw\", 3)) { cp = strchr(opt, ':'); if (cp) defpredictor = atoi(cp+1); defcompression = COMPRESSION_LZW; } else if (strneq(opt, \"zip\", 3)) { cp = strchr(opt, ':'); if (cp) defpredictor = atoi(cp+1); defcompression = COMPRESSION_ADOBE_DEFLATE;  } else return (0); return (1); }", "target": 0, "idx": 100461, "project": "LibTIFF"}
{"func": "int erst_clear(u64 record_id) { int rc; unsigned long flags; if (!erst_enabled) return -ENODEV; spin_lock_irqsave(&erst_lock, flags); if (erst_erange.attr & ERST_RANGE_NVRAM) rc = __erst_clear_from_nvram(record_id); else rc = __erst_clear_from_storage(record_id); spin_unlock_irqrestore(&erst_lock, flags); return rc; }", "target": 0, "idx": 101884, "project": "Xen"}
{"func": "int libxl_device_net2_add(libxl_ctx *ctx, uint32_t domid, libxl_device_net2 *net2) { libxl__gc gc = LIBXL_INIT_GC(ctx); flexarray_t *front, *back; libxl__device device; char *dompath, *dom, **l; unsigned int nb; int rc; front = flexarray_make(16, 1); if (!front) { rc = ERROR_NOMEM; goto err; } back = flexarray_make(16, 1); if (!back) { rc = ERROR_NOMEM; goto err_free; } if (!(dompath = libxl__xs_get_dompath(&gc, domid))) { rc = ERROR_FAIL; goto err_free; } dom = libxl__xs_read(&gc, XBT_NULL, libxl__sprintf(&gc, \"%s/name\", dompath)); if (net2->devid == -1) { if (!(l = libxl__xs_directory(&gc, XBT_NULL,  libxl__sprintf(&gc, \"%s/device/vif2\", dompath), &nb))) { net2->devid = 0; } else { net2->devid = strtoul(l[nb - 1], NULL, 10) + 1; } } device.backend_devid = net2->devid; device.backend_domid = net2->backend_domid; device.backend_kind = DEVICE_VIF2; device.devid = net2->devid; device.domid = net2->domid; device.kind = DEVICE_VIF2; flexarray_append(back, \"domain\"); flexarray_append(back, dom); flexarray_append(back, \"frontend-id\"); flexarray_append(back, libxl__sprintf(&gc, \"%d\", net2->domid)); flexarray_append(back, \"local-trusted\"); flexarray_append(back, libxl__sprintf(&gc, \"%d\", net2->back_trusted)); flexarray_append(back, \"mac\"); flexarray_append(back, libxl__sprintf(&gc, \"%02x:%02x:%02x:%02x:%02x:%02x\",  net2->back_mac[0], net2->back_mac[1],  net2->back_mac[2], net2->back_mac[3],  net2->back_mac[4], net2->back_mac[5])); flexarray_append(back, \"remote-trusted\"); flexarray_append(back, libxl__sprintf(&gc, \"%d\", net2->trusted)); flexarray_append(back, \"remote-mac\"); flexarray_append(back, libxl__sprintf(&gc, \"%02x:%02x:%02x:%02x:%02x:%02x\",  net2->front_mac[0], net2->front_mac[1],  net2->front_mac[2], net2->front_mac[3],  net2->front_mac[4], net2->front_mac[5])); flexarray_append(back, \"max-bypasses\"); flexarray_append(back, libxl__sprintf(&gc, \"%d\", net2->max_bypasses)); flexarray_append(back, \"filter-mac\"); flexarray_append(back, libxl__sprintf(&gc, \"%d\", !!(net2->filter_mac))); flexarray_append(back, \"handle\"); flexarray_append(back, libxl__sprintf(&gc, \"%d\", net2->devid)); flexarray_append(back, \"online\"); flexarray_append(back, \"1\"); flexarray_append(back, \"state\"); flexarray_append(back, \"1\"); flexarray_append(front, \"backend-id\"); flexarray_append(front, libxl__sprintf(&gc, \"%d\", net2->backend_domid)); flexarray_append(front, \"local-trusted\"); flexarray_append(front, libxl__sprintf(&gc, \"%d\", net2->trusted)); flexarray_append(front, \"mac\"); flexarray_append(front, libxl__sprintf(&gc, \"%02x:%02x:%02x:%02x:%02x:%02x\", net2->front_mac[0], net2->front_mac[1], net2->front_mac[2], net2->front_mac[3], net2->front_mac[4], net2->front_mac[5])); flexarray_append(front, \"remote-trusted\"); flexarray_append(front, libxl__sprintf(&gc, \"%d\", net2->back_trusted)); flexarray_append(front, \"remote-mac\"); flexarray_append(front, libxl__sprintf(&gc, \"%02x:%02x:%02x:%02x:%02x:%02x\", net2->back_mac[0], net2->back_mac[1], net2->back_mac[2], net2->back_mac[3], net2->back_mac[4], net2->back_mac[5])); flexarray_append(front, \"filter-mac\"); flexarray_append(front, libxl__sprintf(&gc, \"%d\", !!(net2->filter_mac))); flexarray_append(front, \"state\"); flexarray_append(front, \"1\"); libxl__device_generic_add(ctx, &device,  libxl__xs_kvs_of_flexarray(&gc, back, back->count),  libxl__xs_kvs_of_flexarray(&gc, front, front->count));  rc = 0; err_free: flexarray_free(back); flexarray_free(front); err: libxl__free_all(&gc); return rc; }", "target": 1, "idx": 109118, "project": "Xen"}
{"func": "static pid_t create_migration_child(const char *rune, int *send_fd, int *recv_fd) { int sendpipe[2], recvpipe[2]; pid_t child; if (!rune || !send_fd || !recv_fd) return -1; MUST( libxl_pipe(ctx, sendpipe) ); MUST( libxl_pipe(ctx, recvpipe) ); child = xl_fork(child_migration, \"migration transport process\"); if (!child) { dup2(sendpipe[0], 0); dup2(recvpipe[1], 1); close(sendpipe[0]); close(sendpipe[1]); close(recvpipe[0]); close(recvpipe[1]); execlp(\"sh\",\"sh\",\"-c\",rune,(char*)0); perror(\"failed to exec sh\"); exit(EXIT_FAILURE); } close(sendpipe[0]); close(recvpipe[1]); *send_fd = sendpipe[1]; *recv_fd = recvpipe[0];  signal(SIGPIPE, SIG_IGN); return child; }", "target": 0, "idx": 108701, "project": "Xen"}
{"func": "static void helper_failed(libxl__egc *egc, libxl__save_helper_state *shs, int rc) { STATE_AO_GC(shs->ao); if (!shs->rc) shs->rc = rc; libxl__ev_fd_deregister(gc, &shs->readable); if (!libxl__save_helper_inuse(shs)) { helper_done(egc, shs); return; } libxl__kill(gc, shs->child.pid, SIGKILL, \"save/restore helper\"); }", "target": 0, "idx": 103943, "project": "Xen"}
{"func": "void vhd_bat_in(vhd_bat_t *bat) { int i; for (i = 0; i < bat->entries; i++) BE32_IN(&bat->bat[i]); }", "target": 0, "idx": 103122, "project": "Xen"}
{"func": "static __init int reset_videomode_after_s3(struct dmi_blacklist *d) {  acpi_video_flags |= 2; return 0; }", "target": 0, "idx": 101775, "project": "Xen"}
{"func": "static void dump_cpu(void)  { HVM_SAVE_TYPE(CPU) c; READ(c); printf(\"CPU:rax 0x%16.16llx rbx 0x%16.16llx\\n\"  \"rcx 0x%16.16llx rdx 0x%16.16llx\\n\"  \"rbp 0x%16.16llx rsi 0x%16.16llx\\n\"  \"rdi 0x%16.16llx rsp 0x%16.16llx\\n\"  \" r8 0x%16.16llxr9 0x%16.16llx\\n\"  \"r10 0x%16.16llx r11 0x%16.16llx\\n\"  \"r12 0x%16.16llx r13 0x%16.16llx\\n\"  \"r14 0x%16.16llx r15 0x%16.16llx\\n\"  \"rip 0x%16.16llxrflags 0x%16.16llx\\n\"  \"cr0 0x%16.16llx cr2 0x%16.16llx\\n\"  \"cr3 0x%16.16llx cr4 0x%16.16llx\\n\"  \"dr0 0x%16.16llx dr1 0x%16.16llx\\n\"  \"dr2 0x%16.16llx dr3 0x%16.16llx\\n\"  \"dr6 0x%16.16llx dr7 0x%16.16llx\\n\"  \" cs 0x%8.8x (0x%16.16llx + 0x%8.8x / 0x%5.5x)\\n\"  \" ds 0x%8.8x (0x%16.16llx + 0x%8.8x / 0x%5.5x)\\n\"  \" es 0x%8.8x (0x%16.16llx + 0x%8.8x / 0x%5.5x)\\n\"  \" fs 0x%8.8x (0x%16.16llx + 0x%8.8x / 0x%5.5x)\\n\"  \" gs 0x%8.8x (0x%16.16llx + 0x%8.8x / 0x%5.5x)\\n\"  \" ss 0x%8.8x (0x%16.16llx + 0x%8.8x / 0x%5.5x)\\n\"  \" tr 0x%8.8x (0x%16.16llx + 0x%8.8x / 0x%5.5x)\\n\"  \" ldtr 0x%8.8x (0x%16.16llx + 0x%8.8x / 0x%5.5x)\\n\"  \" idtr(0x%16.16llx + 0x%8.8x)\\n\"  \" gdtr(0x%16.16llx + 0x%8.8x)\\n\"  \"sysenter cs 0x%8.8llxeip 0x%16.16llxesp 0x%16.16llx\\n\"  \"shadow gs 0x%16.16llx\\n\"  \"MSR flags 0x%16.16llxlstar 0x%16.16llx\\n\"  \" star 0x%16.16llxcstar 0x%16.16llx\\n\"  \" sfmask 0x%16.16llx efer 0x%16.16llx\\n\"  \"tsc 0x%16.16llx\\n\"  \"event 0x%8.8lx error 0x%8.8lx\\n\",  (unsigned long long) c.rax, (unsigned long long) c.rbx,  (unsigned long long) c.rcx, (unsigned long long) c.rdx,  (unsigned long long) c.rbp, (unsigned long long) c.rsi,  (unsigned long long) c.rdi, (unsigned long long) c.rsp,  (unsigned long long) c.r8, (unsigned long long) c.r9,  (unsigned long long) c.r10, (unsigned long long) c.r11,  (unsigned long long) c.r12, (unsigned long long) c.r13,  (unsigned long long) c.r14, (unsigned long long) c.r15,  (unsigned long long) c.rip, (unsigned long long) c.rflags,  (unsigned long long) c.cr0, (unsigned long long) c.cr2,  (unsigned long long) c.cr3, (unsigned long long) c.cr4,  (unsigned long long) c.dr0, (unsigned long long) c.dr1,  (unsigned long long) c.dr2, (unsigned long long) c.dr3,  (unsigned long long) c.dr6, (unsigned long long) c.dr7,  c.cs_sel, (unsigned long long) c.cs_base, c.cs_limit, c.cs_arbytes,  c.ds_sel, (unsigned long long) c.ds_base, c.ds_limit, c.ds_arbytes,  c.es_sel, (unsigned long long) c.es_base, c.es_limit, c.es_arbytes,  c.fs_sel, (unsigned long long) c.fs_base, c.fs_limit, c.fs_arbytes,  c.gs_sel, (unsigned long long) c.gs_base, c.gs_limit, c.gs_arbytes,  c.ss_sel, (unsigned long long) c.ss_base, c.ss_limit, c.ss_arbytes,  c.tr_sel, (unsigned long long) c.tr_base, c.tr_limit, c.tr_arbytes,  c.ldtr_sel, (unsigned long long) c.ldtr_base,  c.ldtr_limit, c.ldtr_arbytes,  (unsigned long long) c.idtr_base, c.idtr_limit,   (unsigned long long) c.gdtr_base, c.gdtr_limit,   (unsigned long long) c.sysenter_cs,   (unsigned long long) c.sysenter_eip,   (unsigned long long) c.sysenter_esp,  (unsigned long long) c.shadow_gs,  (unsigned long long) c.msr_flags,  (unsigned long long) c.msr_lstar,  (unsigned long long) c.msr_star,  (unsigned long long) c.msr_cstar,  (unsigned long long) c.msr_syscall_mask,  (unsigned long long) c.msr_efer,  (unsigned long long) c.tsc,  (unsigned long) c.pending_event, (unsigned long) c.error_code); dump_fpu(&c.fpu_regs); }", "target": 0, "idx": 107864, "project": "Xen"}
{"func": "int xc_set_cpufreq_para(xc_interface *xch, int cpuid,  int ctrl_type, int ctrl_value) { DECLARE_SYSCTL; if ( !xch ) { errno = EINVAL; return -1; } sysctl.cmd = XEN_SYSCTL_pm_op; sysctl.u.pm_op.cmd = SET_CPUFREQ_PARA; sysctl.u.pm_op.cpuid = cpuid; sysctl.u.pm_op.u.set_para.ctrl_type = ctrl_type; sysctl.u.pm_op.u.set_para.ctrl_value = ctrl_value; return xc_sysctl(xch, &sysctl); }", "target": 0, "idx": 107636, "project": "Xen"}
{"func": "tsize_t t2p_write_pdf_page(uint32 object, T2P* t2p, TIFF* output){ unsigned int i=0; tsize_t written=0; char buffer[16]; int buflen=0;  written += t2pWriteFile(output, (tdata_t) \"<<\\n/Type /Page \\n/Parent \", 24); buflen=sprintf(buffer, \"%lu\", (unsigned long)t2p->pdf_pages); written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" 0 R \\n\", 6); written += t2pWriteFile(output, (tdata_t) \"/MediaBox [\", 11);  buflen=sprintf(buffer, \"%.4f\",t2p->pdf_mediabox.x1); written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" \", 1);  buflen=sprintf(buffer, \"%.4f\",t2p->pdf_mediabox.y1); written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" \", 1);  buflen=sprintf(buffer, \"%.4f\",t2p->pdf_mediabox.x2); written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" \", 1);  buflen=sprintf(buffer, \"%.4f\",t2p->pdf_mediabox.y2); written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \"] \\n\", 3);  written += t2pWriteFile(output, (tdata_t) \"/Contents \", 10); buflen=sprintf(buffer, \"%lu\", (unsigned long)(object + 1)); written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" 0 R \\n\", 6); written += t2pWriteFile(output, (tdata_t) \"/Resources << \\n\", 15); if( t2p->tiff_tiles[t2p->pdf_page].tiles_tilecount != 0 ){ written += t2pWriteFile(output, (tdata_t) \"/XObject <<\\n\", 12); for(i=0;i<t2p->tiff_tiles[t2p->pdf_page].tiles_tilecount;i++){ written += t2pWriteFile(output, (tdata_t) \"/Im\", 3); buflen = sprintf(buffer, \"%u\", t2p->pdf_page+1); written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \"_\", 1); buflen = sprintf(buffer, \"%u\", i+1); written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" \", 1); buflen = sprintf( buffer,  \"%lu\",  (unsigned long)(object+3+(2*i)+t2p->tiff_pages[t2p->pdf_page].page_extra));  written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" 0 R \", 5); if(i%4==3){ written += t2pWriteFile(output, (tdata_t) \"\\n\", 1); } } written += t2pWriteFile(output, (tdata_t) \">>\\n\", 3); } else { written += t2pWriteFile(output, (tdata_t) \"/XObject <<\\n\", 12); written += t2pWriteFile(output, (tdata_t) \"/Im\", 3); buflen = sprintf(buffer, \"%u\", t2p->pdf_page+1); written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" \", 1); buflen = sprintf( buffer,  \"%lu\",  (unsigned long)(object+3+(2*i)+t2p->tiff_pages[t2p->pdf_page].page_extra));  written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" 0 R \", 5); written += t2pWriteFile(output, (tdata_t) \">>\\n\", 3); } if(t2p->tiff_transferfunctioncount != 0) { written += t2pWriteFile(output, (tdata_t) \"/ExtGState <<\", 13); t2pWriteFile(output, (tdata_t) \"/GS1 \", 5); buflen = sprintf( buffer,  \"%lu\",  (unsigned long)(object + 3));  written += t2pWriteFile(output, (tdata_t) buffer, buflen); written += t2pWriteFile(output, (tdata_t) \" 0 R \", 5); written += t2pWriteFile(output, (tdata_t) \">> \\n\", 4); } written += t2pWriteFile(output, (tdata_t) \"/ProcSet [ \", 11); if(t2p->pdf_colorspace == T2P_CS_BILEVEL  || t2p->pdf_colorspace == T2P_CS_GRAY ){ written += t2pWriteFile(output, (tdata_t) \"/ImageB \", 8); } else { written += t2pWriteFile(output, (tdata_t) \"/ImageC \", 8); if(t2p->pdf_colorspace & T2P_CS_PALETTE){ written += t2pWriteFile(output, (tdata_t) \"/ImageI \", 8); } } written += t2pWriteFile(output, (tdata_t) \"]\\n>>\\n>>\\n\", 8); return(written); }", "target": 1, "idx": 100759, "project": "LibTIFF"}
{"func": " returning -1,0,1 * for <,=,> */ static int compare_vbd_oo(xenstat_domain *domain1, xenstat_domain *domain2) { return -compare(tot_vbd_reqs(domain1, FIELD_VBD_OO), tot_vbd_reqs(domain2, FIELD_VBD_OO)); }", "target": 0, "idx": 108511, "project": "Xen"}
{"func": "int epte_get_entry_emt(struct domain *d, unsigned long gfn, mfn_t mfn,  unsigned int order, uint8_t *ipat, bool_t direct_mmio) { int gmtrr_mtype, hmtrr_mtype; uint32_t type; struct vcpu *v = current; *ipat = 0; if ( v->domain != d ) v = d->vcpu ? d->vcpu[0] : NULL; if ( !mfn_valid(mfn_x(mfn)) ) return MTRR_TYPE_UNCACHABLE; switch ( hvm_get_mem_pinned_cacheattr(d, gfn, order, &type) ) { case 1: *ipat = 1; return type != PAT_TYPE_UC_MINUS ? type : PAT_TYPE_UNCACHABLE; case -1: return -1; } if ( !need_iommu(d) && !cache_flush_permitted(d) ) { ASSERT(!direct_mmio ||  !((mfn_x(mfn) ^ d->arch.hvm_domain.vmx.apic_access_mfn) >>  order)); *ipat = 1; return MTRR_TYPE_WRBACK; } if ( direct_mmio ) { if ( (mfn_x(mfn) ^ d->arch.hvm_domain.vmx.apic_access_mfn) >> order ) return MTRR_TYPE_UNCACHABLE; if ( order ) return -1; *ipat = 1; return MTRR_TYPE_WRBACK; } gmtrr_mtype = is_hvm_domain(d) && v ? get_mtrr_type(&v->arch.hvm_vcpu.mtrr, gfn << PAGE_SHIFT, order) : MTRR_TYPE_WRBACK; hmtrr_mtype = get_mtrr_type(&mtrr_state, mfn_x(mfn) << PAGE_SHIFT, order); if ( gmtrr_mtype < 0 || hmtrr_mtype < 0 ) return -1;  if ( likely(gmtrr_mtype == hmtrr_mtype) ) return hmtrr_mtype;  if ( gmtrr_mtype == MTRR_TYPE_UNCACHABLE ||  hmtrr_mtype == MTRR_TYPE_UNCACHABLE ) return MTRR_TYPE_UNCACHABLE;  if ( gmtrr_mtype == MTRR_TYPE_WRBACK ) return hmtrr_mtype; if ( hmtrr_mtype == MTRR_TYPE_WRBACK ) return gmtrr_mtype;  if ( (gmtrr_mtype == MTRR_TYPE_WRTHROUGH && hmtrr_mtype == MTRR_TYPE_WRPROT) ||  (gmtrr_mtype == MTRR_TYPE_WRPROT && hmtrr_mtype == MTRR_TYPE_WRTHROUGH) ) return MTRR_TYPE_WRPROT; return MTRR_TYPE_UNCACHABLE; }", "target": 1, "idx": 109335, "project": "Xen"}
{"func": "static int powernow_cpufreq_cpu_exit(struct cpufreq_policy *policy) { struct acpi_cpufreq_data *data = cpufreq_drv_data[policy->cpu]; if (data) { cpufreq_drv_data[policy->cpu] = NULL; xfree(data->freq_table); xfree(data); } return 0; }", "target": 0, "idx": 105154, "project": "Xen"}
{"func": "void vlapic_reset(struct vlapic *vlapic) { const struct vcpu *v = vlapic_vcpu(vlapic); if ( !has_vlapic(v->domain) ) return; vlapic->hw.apic_base_msr = (MSR_IA32_APICBASE_ENABLE | APIC_DEFAULT_PHYS_BASE); if ( v->vcpu_id == 0 ) vlapic->hw.apic_base_msr |= MSR_IA32_APICBASE_BSP; vlapic_set_reg(vlapic, APIC_ID, (v->vcpu_id * 2) << 24); vlapic_do_init(vlapic); }", "target": 0, "idx": 106955, "project": "Xen"}
{"func": "void ctrl_alt_del(void) { #if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,27) kill_proc(1, SIGINT, 1);  #else kill_cad_pid(SIGINT, 1); #endif }", "target": 0, "idx": 105062, "project": "Xen"}
{"func": "__init int gzip_check(char *image, unsigned long image_len) { unsigned char magic0, magic1; if ( image_len < 2 ) return 0; magic0 = (unsigned char)image[0]; magic1 = (unsigned char)image[1]; return (magic0 == 0x1f) && ((magic1 == 0x8b) || (magic1 == 0x9e)); }", "target": 0, "idx": 102590, "project": "Xen"}
{"func": "int xc_sched_id(xc_interface *xch, int *sched_id) { int ret; DECLARE_SYSCTL; sysctl.cmd = XEN_SYSCTL_sched_id; if ( (ret = do_sysctl(xch, &sysctl)) != 0 ) return ret; *sched_id = sysctl.u.sched_id.sched_id; return 0; }", "target": 0, "idx": 107590, "project": "Xen"}
{"func": "static inline int pit_channel0_enabled(void) { return pt_active(&current->domain->arch.vpit.pt0); }", "target": 0, "idx": 106869, "project": "Xen"}
{"func": "static void biosfn_alternate_prtsc() { #ifdef DEBUG  unimplemented(); #endif }", "target": 0, "idx": 106665, "project": "Xen"}
{"func": "const void *fdt_getprop_namelen(const void *fdt, int nodeoffset, const char *name, int namelen, int *lenp) { const struct fdt_property *prop; prop = fdt_get_property_namelen(fdt, nodeoffset, name, namelen, lenp); if (! prop) return NULL; return prop->data; }", "target": 0, "idx": 101999, "project": "Xen"}
{"func": "int libxl_device_disk_getinfo(libxl_ctx *ctx, uint32_t domid, libxl_device_disk *disk, libxl_diskinfo *diskinfo) { GC_INIT(ctx); char *dompath, *diskpath; char *val; dompath = libxl__xs_get_dompath(gc, domid); diskinfo->devid = libxl__device_disk_dev_number(disk->vdev, NULL, NULL);  diskpath = libxl__sprintf(gc, \"%s/device/vbd/%d\", dompath, diskinfo->devid); diskinfo->backend = xs_read(ctx->xsh, XBT_NULL, libxl__sprintf(gc, \"%s/backend\", diskpath), NULL); if (!diskinfo->backend) { GC_FREE; return ERROR_FAIL; } val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/backend-id\", diskpath)); diskinfo->backend_id = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/state\", diskpath)); diskinfo->state = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/event-channel\", diskpath)); diskinfo->evtch = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/ring-ref\", diskpath)); diskinfo->rref = val ? strtoul(val, NULL, 10) : -1; diskinfo->frontend = xs_read(ctx->xsh, XBT_NULL,  libxl__sprintf(gc, \"%s/frontend\", diskinfo->backend), NULL); val = libxl__xs_read(gc, XBT_NULL, libxl__sprintf(gc, \"%s/frontend-id\", diskinfo->backend)); diskinfo->frontend_id = val ? strtoul(val, NULL, 10) : -1; GC_FREE; return 0; }", "target": 1, "idx": 109367, "project": "Xen"}
{"func": "libxl_device_usbdev * libxl_device_usbdev_list(libxl_ctx *ctx, uint32_t domid, int *num) { GC_INIT(ctx); libxl_device_usbdev *usbdevs = NULL; const char *libxl_vusbs_path; char **usbctrls; unsigned int nc = 0; int i, j; *num = 0; libxl_vusbs_path = GCSPRINTF(\"%s/device/%s\",  libxl__xs_libxl_path(gc, domid),  libxl__device_kind_to_string(  LIBXL__DEVICE_KIND_VUSB)); usbctrls = libxl__xs_directory(gc, XBT_NULL, libxl_vusbs_path, &nc); for (i = 0; i < nc; i++) { int rc, nd = 0; libxl_device_usbdev *tmp = NULL; rc = libxl__device_usbdev_list_for_usbctrl(gc, domid, atoi(usbctrls[i]), &tmp, &nd); if (rc || !nd) continue; usbdevs = libxl__realloc(NOGC, usbdevs,  sizeof(*usbdevs) * (*num + nd)); for (j = 0; j < nd; j++) { libxl_device_usbdev_copy(ctx, usbdevs + *num, tmp + j); (*num)++; } } GC_FREE; return usbdevs; }", "target": 0, "idx": 104069, "project": "Xen"}
{"func": "bool_t vm_event_check_ring(struct vm_event_domain *ved) { return (ved && ved->ring_page); }", "target": 0, "idx": 107059, "project": "Xen"}
{"func": "static int cat_read(struct policydb *p, struct hashtab *h, void *fp) { char *key = NULL; struct cat_datum *catdatum; int rc; __le32 buf[3]; u32 len; catdatum = xzalloc(struct cat_datum); if ( !catdatum ) { rc = -ENOMEM; goto out; } rc = next_entry(buf, fp, sizeof buf); if ( rc < 0 ) goto bad; len = le32_to_cpu(buf[0]); catdatum->value = le32_to_cpu(buf[1]); catdatum->isalias = le32_to_cpu(buf[2]); key = xmalloc_array(char, len + 1); if ( !key ) { rc = -ENOMEM; goto bad; } rc = next_entry(key, fp, len); if ( rc < 0 ) goto bad; key[len] = 0; rc = hashtab_insert(h, key, catdatum); if ( rc ) goto bad; out: return rc; bad: cat_destroy(key, catdatum, NULL); goto out; }", "target": 0, "idx": 105107, "project": "Xen"}
{"func": "int tdqcow_open (td_driver_t *driver, const char *name, td_flag_t flags) { int fd, len, i, ret, size, o_flags; td_disk_info_t *bs = &(driver->info); struct tdqcow_state *s= (struct tdqcow_state *)driver->data; QCowHeader header; uint64_t final_cluster = 0;  DPRINTF(\"QCOW: Opening %s\\n\", name); o_flags = O_DIRECT | O_LARGEFILE |  ((flags == TD_OPEN_RDONLY) ? O_RDONLY : O_RDWR); fd = open(name, o_flags); if (fd < 0) { DPRINTF(\"Unable to open %s (%d)\\n\", name, -errno); return -1; } s->fd = fd; s->name = strdup(name); if (!s->name) goto fail; if (tdqcow_read_header(fd, &header)) goto fail; if (header.magic != QCOW_MAGIC) goto fail; switch (header.version) { case QCOW_VERSION: break; case 2:     goto fail; default: goto fail; } if (header.size <= 1 || header.cluster_bits < 9) goto fail; if (header.crypt_method > QCOW_CRYPT_AES) goto fail; s->crypt_method_header = header.crypt_method; if (s->crypt_method_header) s->encrypted = 1; s->cluster_bits = header.cluster_bits; s->cluster_size = 1 << s->cluster_bits; s->cluster_sectors = 1 << (s->cluster_bits - 9); s->l2_bits = header.l2_bits; s->l2_size = 1 << s->l2_bits; s->cluster_alloc = s->l2_size; bs->size = header.size / 512; s->cluster_offset_mask = (1LL << (63 - s->cluster_bits)) - 1; s->backing_file_offset = header.backing_file_offset; s->backing_file_size = header.backing_file_size;  if (tdqcow_load_l1_table(s, &header)) goto fail;  size = s->l2_size * L2_CACHE_SIZE * sizeof(uint64_t); ret = posix_memalign((void **)&s->l2_cache, 4096, size); if(ret != 0) goto fail; size = s->cluster_size; ret = posix_memalign((void **)&s->cluster_cache, 4096, size); if(ret != 0) goto fail; ret = posix_memalign((void **)&s->cluster_data, 4096, size); if(ret != 0) goto fail; s->cluster_cache_offset = -1; if (s->backing_file_offset != 0) s->cluster_alloc = 1;  bs->sector_size = 512; bs->info = 0; for(i = 0; i < s->l1_size; i++) if (s->l1_table[i] > final_cluster) final_cluster = s->l1_table[i]; if (init_aio_state(driver)!=0) { DPRINTF(\"Unable to initialise AIO state\\n\"); free_aio_state(s); goto fail; } if (!final_cluster) s->fd_end = s->l1_table_offset + ((s->l1_size * sizeof(uint64_t) + 4095) & ~4095); else { s->fd_end = lseek(fd, 0, SEEK_END); if (s->fd_end == (off_t)-1) goto fail; } return 0; fail: DPRINTF(\"QCOW Open failed\\n\"); free_aio_state(s); free(s->l1_table); free(s->l2_cache); free(s->cluster_cache); free(s->cluster_data); close(fd); return -1; }", "target": 0, "idx": 101085, "project": "Xen"}
{"func": "static int sh_page_fault(struct vcpu *v, unsigned long va, struct cpu_user_regs *regs) { struct domain *d = v->domain; walk_t gw; gfn_t gfn = _gfn(0); mfn_t gmfn, sl1mfn = _mfn(0); shadow_l1e_t sl1e, *ptr_sl1e; paddr_t gpa; struct sh_emulate_ctxt emul_ctxt; const struct x86_emulate_ops *emul_ops; int r; fetch_type_t ft = 0; p2m_type_t p2mt; uint32_t rc; int version; struct npfec access = {  .read_access = 1,  .gla_valid = 1,  .kind = npfec_kind_with_gla }; #if SHADOW_OPTIMIZATIONS & SHOPT_FAST_EMULATION int fast_emul = 0; #endif SHADOW_PRINTK(\"d:v=%u:%u va=%#lx err=%u, rip=%lx\\n\", v->domain->domain_id, v->vcpu_id, va, regs->error_code, regs->eip); perfc_incr(shadow_fault); if ( regs->error_code & PFEC_write_access ) access.write_access = 1; #if SHADOW_OPTIMIZATIONS & SHOPT_FAST_EMULATION  if ( v->arch.paging.last_write_emul_ok  && v->arch.paging.shadow.last_emulated_frame == (va >> PAGE_SHIFT) ) {  if ( regs->error_code == (PFEC_write_access | PFEC_page_present) ) { fast_emul = 1; gmfn = _mfn(v->arch.paging.shadow.last_emulated_mfn); #if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC)  if ( mfn_valid(gmfn) && mfn_is_out_of_sync(gmfn) ) { fast_emul = 0; v->arch.paging.last_write_emul_ok = 0; goto page_fault_slow_path; } #endif  perfc_incr(shadow_fault_fast_emulate); goto early_emulation; } else v->arch.paging.last_write_emul_ok = 0; } #endif      #if (SHADOW_OPTIMIZATIONS & SHOPT_FAST_FAULT_PATH) if ( (regs->error_code & PFEC_reserved_bit) ) { #if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC)  { shadow_l2e_t sl2e; mfn_t gl1mfn; if ( (__copy_from_user(&sl2e,  (sh_linear_l2_table(v) + shadow_l2_linear_offset(va)),  sizeof(sl2e)) != 0)  || !(shadow_l2e_get_flags(sl2e) & _PAGE_PRESENT)  || !mfn_valid(gl1mfn = backpointer(mfn_to_page( shadow_l2e_get_mfn(sl2e))))  || unlikely(mfn_is_out_of_sync(gl1mfn)) ) {  ASSERT(regs->error_code & PFEC_page_present); regs->error_code ^= (PFEC_reserved_bit|PFEC_page_present); goto page_fault_slow_path; } } #endif   if ( likely((__copy_from_user(&sl1e, (sh_linear_l1_table(v)  + shadow_l1_linear_offset(va)), sizeof(sl1e)) == 0) && sh_l1e_is_magic(sl1e)) ) { if ( sh_l1e_is_gnp(sl1e) ) {  ASSERT(regs->error_code & PFEC_page_present); regs->error_code ^= (PFEC_reserved_bit|PFEC_page_present); reset_early_unshadow(v); perfc_incr(shadow_fault_fast_gnp); SHADOW_PRINTK(\"fast path not-present\\n\"); trace_shadow_gen(TRC_SHADOW_FAST_PROPAGATE, va); return 0; } else {  ASSERT(sh_l1e_is_mmio(sl1e)); gpa = (((paddr_t)(gfn_x(sh_l1e_mmio_get_gfn(sl1e))))  << PAGE_SHIFT) | (va & ~PAGE_MASK); } perfc_incr(shadow_fault_fast_mmio); SHADOW_PRINTK(\"fast path mmio %#\"PRIpaddr\"\\n\", gpa); reset_early_unshadow(v); trace_shadow_gen(TRC_SHADOW_FAST_MMIO, va); return (handle_mmio_with_translation(va, gpa >> PAGE_SHIFT, access) ? EXCRET_fault_fixed : 0); } else {  perfc_incr(shadow_fault_fast_fail); SHADOW_PRINTK(\"fast path false alarm!\\n\"); trace_shadow_gen(TRC_SHADOW_FALSE_FAST_PATH, va); return EXCRET_fault_fixed; } } #if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC)  page_fault_slow_path: #endif #endif   if ( unlikely(paging_locked_by_me(d)) ) { SHADOW_ERROR(\"Recursive shadow fault: lock was taken by %s\\n\",  d->arch.paging.lock.locker_function); return 0; }  rewalk:  version = atomic_read(&d->arch.paging.shadow.gtable_dirty_version); rmb(); rc = sh_walk_guest_tables(v, va, &gw, regs->error_code); #if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC) regs->error_code &= ~PFEC_page_present; if ( !(rc & _PAGE_PRESENT) ) regs->error_code |= PFEC_page_present; #endif if ( rc != 0 ) { perfc_incr(shadow_fault_bail_real_fault); SHADOW_PRINTK(\"not a shadow fault\\n\"); reset_early_unshadow(v); if ( (rc & _PAGE_INVALID_BITS) ) regs->error_code |= PFEC_reserved_bit; goto propagate; }  if ( unlikely(d->is_shutting_down && d->shutdown_code == SHUTDOWN_crash) ) { SHADOW_PRINTK(\"guest is shutting down\\n\"); goto propagate; }  ft = ((regs->error_code & PFEC_write_access) ? ft_demand_write : ft_demand_read);  gfn = guest_l1e_get_gfn(gw.l1e); gmfn = get_gfn(d, gfn, &p2mt); if ( shadow_mode_refcounts(d) &&  ((!p2m_is_valid(p2mt) && !p2m_is_grant(p2mt)) || (!p2m_is_mmio(p2mt) && !mfn_valid(gmfn))) ) { perfc_incr(shadow_fault_bail_bad_gfn); SHADOW_PRINTK(\"BAD gfn=%\"SH_PRI_gfn\" gmfn=%\"PRI_mfn\"\\n\", gfn_x(gfn), mfn_x(gmfn)); reset_early_unshadow(v); put_gfn(d, gfn_x(gfn)); goto propagate; } #if (SHADOW_OPTIMIZATIONS & SHOPT_VIRTUAL_TLB)  vtlb_insert(v, va >> PAGE_SHIFT, gfn_x(gfn), regs->error_code | PFEC_page_present); #endif  paging_lock(d); TRACE_CLEAR_PATH_FLAGS;  shadow_prealloc(d, SH_type_l1_shadow, GUEST_PAGING_LEVELS < 4 ? 1 : GUEST_PAGING_LEVELS - 1); rc = gw_remove_write_accesses(v, va, &gw);  if ( rc & GW_RMWR_FLUSHTLB ) {  perfc_incr(shadow_rm_write_flush_tlb); atomic_inc(&d->arch.paging.shadow.gtable_dirty_version); flush_tlb_mask(d->domain_dirty_cpumask); } #if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC)  if ( rc & GW_RMWR_REWALK ) { paging_unlock(d); put_gfn(d, gfn_x(gfn)); goto rewalk; } #endif  if ( !shadow_check_gwalk(v, va, &gw, version) ) { perfc_incr(shadow_inconsistent_gwalk); paging_unlock(d); put_gfn(d, gfn_x(gfn)); goto rewalk; } shadow_audit_tables(v); sh_audit_gw(v, &gw);  ptr_sl1e = shadow_get_and_create_l1e(v, &gw, &sl1mfn, ft); if ( unlikely(ptr_sl1e == NULL) ) {   #if GUEST_PAGING_LEVELS == 3 v->arch.paging.mode->update_cr3(v, 0); #else ASSERT(d->is_shutting_down); #endif paging_unlock(d); put_gfn(d, gfn_x(gfn)); trace_shadow_gen(TRC_SHADOW_DOMF_DYING, va); return 0; } #if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC)  if ( sh_mfn_is_a_page_table(gmfn)  && ft == ft_demand_write ) sh_unsync(v, gmfn); if ( unlikely(d->is_shutting_down && d->shutdown_code == SHUTDOWN_crash) ) {  paging_unlock(d); put_gfn(d, gfn_x(gfn)); return 0; }  if ( shadow_check_gl1e(v, &gw)) { perfc_incr(shadow_inconsistent_gwalk); paging_unlock(d); put_gfn(d, gfn_x(gfn)); goto rewalk; } #endif   l1e_propagate_from_guest(v, gw.l1e, gmfn, &sl1e, ft, p2mt); r = shadow_set_l1e(d, ptr_sl1e, sl1e, p2mt, sl1mfn); #if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC) if ( mfn_valid(gw.l1mfn)  && mfn_is_out_of_sync(gw.l1mfn) ) {  mfn_t snpmfn = oos_snapshot_lookup(d, gw.l1mfn); guest_l1e_t *snp; ASSERT(mfn_valid(snpmfn)); snp = map_domain_page(snpmfn); snp[guest_l1_table_offset(va)] = gw.l1e; unmap_domain_page(snp); } #endif  #if SHADOW_OPTIMIZATIONS & SHOPT_PREFETCH  sh_prefetch(v, &gw, ptr_sl1e, sl1mfn); #endif  if ( sh_mfn_is_a_page_table(gmfn) #if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC)    && !(mfn_is_out_of_sync(gmfn) && !(regs->error_code & PFEC_user_mode)) #endif  && (ft == ft_demand_write) ) { perfc_incr(shadow_fault_emulate_write); goto emulate; }  if ( p2mt == p2m_mmio_dm  || (p2mt == p2m_mmio_write_dm && ft == ft_demand_write) ) { gpa = guest_walk_to_gpa(&gw); goto mmio; }  if ( p2m_is_readonly(p2mt) && (ft == ft_demand_write) ) { static unsigned long lastpage; if ( xchg(&lastpage, va & PAGE_MASK) != (va & PAGE_MASK) ) gdprintk(XENLOG_DEBUG, \"guest attempted write to read-only memory\"  \" page. va page=%#lx, mfn=%#lx\\n\",  va & PAGE_MASK, mfn_x(gmfn)); goto emulate_readonly;  }  if ( is_hvm_domain(d)  && unlikely(!hvm_wp_enabled(v))  && regs->error_code == (PFEC_write_access|PFEC_page_present)  && mfn_valid(gmfn) ) { perfc_incr(shadow_fault_emulate_wp); goto emulate; } perfc_incr(shadow_fault_fixed); d->arch.paging.log_dirty.fault_count++; reset_early_unshadow(v); trace_shadow_fixup(gw.l1e, va);  done: sh_audit_gw(v, &gw); SHADOW_PRINTK(\"fixed\\n\"); shadow_audit_tables(v); paging_unlock(d); put_gfn(d, gfn_x(gfn)); return EXCRET_fault_fixed;  emulate: if ( !shadow_mode_refcounts(d) || !guest_mode(regs) ) goto not_a_shadow_fault;  if ( (regs->error_code & PFEC_user_mode) ) { SHADOW_PRINTK(\"user-mode fault to PT, unshadowing mfn %#lx\\n\", mfn_x(gmfn)); perfc_incr(shadow_fault_emulate_failed); sh_remove_shadows(d, gmfn, 0 , 1 ); trace_shadow_emulate_other(TRC_SHADOW_EMULATE_UNSHADOW_USER, va, gfn); goto done; }   emulate_readonly:  if ( sh_mfn_is_a_page_table(gmfn)  && (mfn_to_page(gmfn)->shadow_flags & SHF_pagetable_dying) ) { int used = 0; struct vcpu *tmp; for_each_vcpu(d, tmp) { #if GUEST_PAGING_LEVELS == 3 int i; for ( i = 0; i < 4; i++ ) { mfn_t smfn = _mfn(pagetable_get_pfn(v->arch.shadow_table[i])); if ( mfn_valid(smfn) && (mfn_x(smfn) != 0) ) { used |= (mfn_to_page(smfn)->v.sh.back == mfn_x(gmfn)); if ( used ) break; } } #else  used = (mfn_x(pagetable_get_mfn(tmp->arch.guest_table)) == mfn_x(gmfn)); #endif if ( used ) break; } if ( !used ) sh_remove_shadows(d, gmfn, 1 , 0 ); }  sh_audit_gw(v, &gw); shadow_audit_tables(v); paging_unlock(d); put_gfn(d, gfn_x(gfn)); this_cpu(trace_emulate_write_val) = 0; #if SHADOW_OPTIMIZATIONS & SHOPT_FAST_EMULATION  early_emulation: #endif if ( is_hvm_domain(d) ) {  if ( unlikely(hvm_event_pending(v)) ) { #if SHADOW_OPTIMIZATIONS & SHOPT_FAST_EMULATION if ( fast_emul ) { perfc_incr(shadow_fault_fast_emulate_fail); v->arch.paging.last_write_emul_ok = 0; } #endif gdprintk(XENLOG_DEBUG, \"write to pagetable during event \"  \"injection: cr2=%#lx, mfn=%#lx\\n\",  va, mfn_x(gmfn)); sh_remove_shadows(d, gmfn, 0 , 1 ); trace_shadow_emulate_other(TRC_SHADOW_EMULATE_UNSHADOW_EVTINJ,  va, gfn); return EXCRET_fault_fixed; } } SHADOW_PRINTK(\"emulate: eip=%#lx esp=%#lx\\n\", (unsigned long)regs->eip, (unsigned long)regs->esp); emul_ops = shadow_init_emulation(&emul_ctxt, regs); r = x86_emulate(&emul_ctxt.ctxt, emul_ops);  if ( r == X86EMUL_UNHANDLEABLE ) { perfc_incr(shadow_fault_emulate_failed); #if SHADOW_OPTIMIZATIONS & SHOPT_FAST_EMULATION if ( fast_emul ) { perfc_incr(shadow_fault_fast_emulate_fail); v->arch.paging.last_write_emul_ok = 0; } #endif SHADOW_PRINTK(\"emulator failure, unshadowing mfn %#lx\\n\",  mfn_x(gmfn));  shadow_remove_all_shadows(d, gmfn); trace_shadow_emulate_other(TRC_SHADOW_EMULATE_UNSHADOW_UNHANDLED,  va, gfn); goto emulate_done; } #if SHADOW_OPTIMIZATIONS & SHOPT_FAST_EMULATION  if ( (r == X86EMUL_OKAY) && sh_mfn_is_a_page_table(gmfn) ) { if ( !fast_emul ) { v->arch.paging.shadow.last_emulated_frame = va >> PAGE_SHIFT; v->arch.paging.shadow.last_emulated_mfn = mfn_x(gmfn); v->arch.paging.last_write_emul_ok = 1; } } else if ( fast_emul ) v->arch.paging.last_write_emul_ok = 0; #endif #if GUEST_PAGING_LEVELS == 3  if ( r == X86EMUL_OKAY ) { int i, emulation_count=0; this_cpu(trace_emulate_initial_va) = va;  for ( i = 0 ; i < 4 ; i++ ) { shadow_continue_emulation(&emul_ctxt, regs); v->arch.paging.last_write_was_pt = 0; r = x86_emulate(&emul_ctxt.ctxt, emul_ops); if ( r == X86EMUL_OKAY ) { emulation_count++; if ( v->arch.paging.last_write_was_pt ) { perfc_incr(shadow_em_ex_pt); TRACE_SHADOW_PATH_FLAG(TRCE_SFLAG_EMULATION_2ND_PT_WRITTEN); break;  } else perfc_incr(shadow_em_ex_non_pt); } else { perfc_incr(shadow_em_ex_fail); TRACE_SHADOW_PATH_FLAG(TRCE_SFLAG_EMULATION_LAST_FAILED); break;  } } this_cpu(trace_extra_emulation_count)=emulation_count; } #endif  trace_shadow_emulate(gw.l1e, va);  emulate_done: SHADOW_PRINTK(\"emulated\\n\"); return EXCRET_fault_fixed;  mmio: if ( !guest_mode(regs) ) goto not_a_shadow_fault; perfc_incr(shadow_fault_mmio); sh_audit_gw(v, &gw); SHADOW_PRINTK(\"mmio %#\"PRIpaddr\"\\n\", gpa); shadow_audit_tables(v); reset_early_unshadow(v); paging_unlock(d); put_gfn(d, gfn_x(gfn)); trace_shadow_gen(TRC_SHADOW_MMIO, va); return (handle_mmio_with_translation(va, gpa >> PAGE_SHIFT, access) ? EXCRET_fault_fixed : 0);  not_a_shadow_fault: sh_audit_gw(v, &gw); SHADOW_PRINTK(\"not a shadow fault\\n\"); shadow_audit_tables(v); reset_early_unshadow(v); paging_unlock(d); put_gfn(d, gfn_x(gfn)); propagate: trace_not_shadow_fault(gw.l1e, va); return 0; }", "target": 1, "idx": 109608, "project": "Xen"}
{"func": "int libxl_psr_cmt_get_cache_occupancy(libxl_ctx *ctx, uint32_t domid, uint32_t socketid, uint32_t *l3_cache_occupancy) { uint64_t data; int rc; rc = libxl_psr_cmt_get_sample(ctx, domid, LIBXL_PSR_CMT_TYPE_CACHE_OCCUPANCY, socketid, &data, NULL); if (rc < 0) goto out; *l3_cache_occupancy = data / 1024; out: return rc; }", "target": 0, "idx": 103843, "project": "Xen"}
{"func": "static void nmi_restore_registers(struct op_msrs * msrs) { unsigned int const nr_ctrs = model->num_counters; unsigned int const nr_ctrls = model->num_controls; struct op_msr * counters = msrs->counters; struct op_msr * controls = msrs->controls; unsigned int i; for (i = 0; i < nr_ctrls; ++i) { wrmsrl(controls[i].addr, controls[i].value); } for (i = 0; i < nr_ctrs; ++i) { wrmsrl(counters[i].addr, counters[i].value); } }", "target": 0, "idx": 104851, "project": "Xen"}
{"func": "int fdt_first_subnode(const void *fdt, int offset) { int depth = 0; offset = fdt_next_node(fdt, offset, &depth); if (offset < 0 || depth != 1) return -FDT_ERR_NOTFOUND; return offset; }", "target": 0, "idx": 101987, "project": "Xen"}
{"func": "static int vhd_util_check_zeros(void *buf, size_t size) { int i; char *p; p = buf; for (i = 0; i < size; i++) if (p[i]) return i; return 0; }", "target": 0, "idx": 106763, "project": "Xen"}
{"func": "int x86_emulate( struct x86_emulate_ctxt *ctxt, const struct x86_emulate_ops*ops) {  struct cpu_user_regs _regs = *ctxt->regs; uint8_t b, d, sib, sib_index, sib_base, twobyte = 0, rex_prefix = 0; uint8_t modrm = 0, modrm_mod = 0, modrm_reg = 0, modrm_rm = 0; union vex vex = {}; unsigned int op_bytes, def_op_bytes, ad_bytes, def_ad_bytes; bool_t lock_prefix = 0; int override_seg = -1, rc = X86EMUL_OKAY; struct operand src = { .reg = REG_POISON }; struct operand dst = { .reg = REG_POISON }; enum x86_swint_type swint_type; struct x86_emulate_stub stub = {}; DECLARE_ALIGNED(mmval_t, mmval);  struct operand ea = { .type = OP_MEM, .reg = REG_POISON }; ea.mem.seg = x86_seg_ds;  ctxt->retire.byte = 0; op_bytes = def_op_bytes = ad_bytes = def_ad_bytes = ctxt->addr_size/8; if ( op_bytes == 8 ) { op_bytes = def_op_bytes = 4; #ifndef __x86_64__ return X86EMUL_UNHANDLEABLE; #endif }  for ( ; ; ) { switch ( b = insn_fetch_type(uint8_t) ) { case 0x66:  op_bytes = def_op_bytes ^ 6; if ( !vex.pfx ) vex.pfx = vex_66; break; case 0x67:  ad_bytes = def_ad_bytes ^ (mode_64bit() ? 12 : 6); break; case 0x2e:  override_seg = x86_seg_cs; break; case 0x3e:  override_seg = x86_seg_ds; break; case 0x26:  override_seg = x86_seg_es; break; case 0x64:  override_seg = x86_seg_fs; break; case 0x65:  override_seg = x86_seg_gs; break; case 0x36:  override_seg = x86_seg_ss; break; case 0xf0:  lock_prefix = 1; break; case 0xf2:  vex.pfx = vex_f2; break; case 0xf3:  vex.pfx = vex_f3; break; case 0x40 ... 0x4f:  if ( !mode_64bit() ) goto done_prefixes; rex_prefix = b; continue; default: goto done_prefixes; }  rex_prefix = 0; }  done_prefixes: if ( rex_prefix & REX_W ) op_bytes = 8;  d = opcode_table[b]; if ( d == 0 ) {  if ( b == 0x0f ) { twobyte = 1; b = insn_fetch_type(uint8_t); d = twobyte_table[b]; }  if ( d == 0 ) goto cannot_emulate; }  generate_exception_if((d & Mov) && lock_prefix, EXC_UD, -1);  if ( d & ModRM ) { modrm = insn_fetch_type(uint8_t); modrm_mod = (modrm & 0xc0) >> 6; if ( !twobyte && ((b & ~1) == 0xc4) ) switch ( def_ad_bytes ) { default: BUG(); case 2: if ( in_realmode(ctxt, ops) || (_regs.eflags & EFLG_VM) ) break;  case 4: if ( modrm_mod != 3 ) break;  case 8:  generate_exception_if(rex_prefix || vex.pfx, EXC_UD, -1); vex.raw[0] = modrm; if ( b & 1 ) { vex.raw[1] = modrm; vex.opcx = vex_0f; vex.x = 1; vex.b = 1; vex.w = 0; } else { vex.raw[1] = insn_fetch_type(uint8_t); if ( mode_64bit() ) { if ( !vex.b ) rex_prefix |= REX_B; if ( !vex.x ) rex_prefix |= REX_X; if ( vex.w ) { rex_prefix |= REX_W; op_bytes = 8; } } } if ( mode_64bit() && !vex.r ) rex_prefix |= REX_R; fail_if(vex.opcx != vex_0f); twobyte = 1; b = insn_fetch_type(uint8_t); d = twobyte_table[b];  if ( d == 0 ) goto cannot_emulate; modrm = insn_fetch_type(uint8_t); modrm_mod = (modrm & 0xc0) >> 6; break; } modrm_reg = ((rex_prefix & 4) << 1) | ((modrm & 0x38) >> 3); modrm_rm= modrm & 0x07; if ( modrm_mod == 3 ) { modrm_rm |= (rex_prefix & 1) << 3; ea.type = OP_REG; ea.reg= decode_register( modrm_rm, &_regs, (d & ByteOp) && (rex_prefix == 0)); } else if ( ad_bytes == 2 ) {  switch ( modrm_rm ) { case 0: ea.mem.off = _regs.ebx + _regs.esi; break; case 1: ea.mem.off = _regs.ebx + _regs.edi; break; case 2: ea.mem.seg = x86_seg_ss; ea.mem.off = _regs.ebp + _regs.esi; break; case 3: ea.mem.seg = x86_seg_ss; ea.mem.off = _regs.ebp + _regs.edi; break; case 4: ea.mem.off = _regs.esi; break; case 5: ea.mem.off = _regs.edi; break; case 6: if ( modrm_mod == 0 ) break; ea.mem.seg = x86_seg_ss; ea.mem.off = _regs.ebp; break; case 7: ea.mem.off = _regs.ebx; break; } switch ( modrm_mod ) { case 0: if ( modrm_rm == 6 ) ea.mem.off = insn_fetch_type(int16_t); break; case 1: ea.mem.off += insn_fetch_type(int8_t); break; case 2: ea.mem.off += insn_fetch_type(int16_t); break; } ea.mem.off = truncate_ea(ea.mem.off); } else {  if ( modrm_rm == 4 ) { sib = insn_fetch_type(uint8_t); sib_index = ((sib >> 3) & 7) | ((rex_prefix << 2) & 8); sib_base= (sib & 7) | ((rex_prefix << 3) & 8); if ( sib_index != 4 ) ea.mem.off = *(long*)decode_register(sib_index, &_regs, 0); ea.mem.off <<= (sib >> 6) & 3; if ( (modrm_mod == 0) && ((sib_base & 7) == 5) ) ea.mem.off += insn_fetch_type(int32_t); else if ( sib_base == 4 ) { ea.mem.seg= x86_seg_ss; ea.mem.off += _regs.esp; if ( !twobyte && (b == 0x8f) )  ea.mem.off += ((mode_64bit() && (op_bytes == 4))  ? 8 : op_bytes); } else if ( sib_base == 5 ) { ea.mem.seg= x86_seg_ss; ea.mem.off += _regs.ebp; } else ea.mem.off += *(long*)decode_register(sib_base, &_regs, 0); } else { modrm_rm |= (rex_prefix & 1) << 3; ea.mem.off = *(long *)decode_register(modrm_rm, &_regs, 0); if ( (modrm_rm == 5) && (modrm_mod != 0) ) ea.mem.seg = x86_seg_ss; } switch ( modrm_mod ) { case 0: if ( (modrm_rm & 7) != 5 ) break; ea.mem.off = insn_fetch_type(int32_t); if ( !mode_64bit() ) break;  ea.mem.off += _regs.eip; if ( (d & SrcMask) == SrcImm ) ea.mem.off += (d & ByteOp) ? 1 : ((op_bytes == 8) ? 4 : op_bytes); else if ( (d & SrcMask) == SrcImmByte ) ea.mem.off += 1; else if ( !twobyte && ((b & 0xfe) == 0xf6) && ((modrm_reg & 7) <= 1) )  ea.mem.off += (d & ByteOp) ? 1 : ((op_bytes == 8) ? 4 : op_bytes); else if ( twobyte && ((b & 0xf7) == 0xa4) )  ea.mem.off++; break; case 1: ea.mem.off += insn_fetch_type(int8_t); break; case 2: ea.mem.off += insn_fetch_type(int32_t); break; } ea.mem.off = truncate_ea(ea.mem.off); } } if ( override_seg != -1 && ea.type == OP_MEM ) ea.mem.seg = override_seg;  if ( !twobyte ) switch ( b ) { case 0xf6 ... 0xf7:  switch ( modrm_reg & 7 ) { case 0 ... 1:  d = (d & ~SrcMask) | SrcImm; break; case 4:  case 5:  case 6:  case 7:  d = (d & (ByteOp | ModRM)) | DstImplicit | SrcMem; break; } break; case 0xff:  switch ( modrm_reg & 7 ) { case 2:  case 4:  case 6:  if ( mode_64bit() && op_bytes == 4 ) op_bytes = 8;  case 3:  case 5:  d = DstNone|SrcMem|ModRM; break; } break; }  switch ( d & SrcMask ) { case SrcNone:  src.type = OP_NONE; break; case SrcReg: src.type = OP_REG; if ( d & ByteOp ) { src.reg = decode_register(modrm_reg, &_regs, (rex_prefix == 0)); src.val = *(uint8_t *)src.reg; src.bytes = 1; } else { src.reg = decode_register(modrm_reg, &_regs, 0); switch ( (src.bytes = op_bytes) ) { case 2: src.val = *(uint16_t *)src.reg; break; case 4: src.val = *(uint32_t *)src.reg; break; case 8: src.val = *(uint64_t *)src.reg; break; } } break; case SrcMem16: ea.bytes = 2; goto srcmem_common; case SrcMem: ea.bytes = (d & ByteOp) ? 1 : op_bytes; srcmem_common: src = ea; if ( src.type == OP_REG ) { switch ( src.bytes ) { case 1: src.val = *(uint8_t*)src.reg; break; case 2: src.val = *(uint16_t *)src.reg; break; case 4: src.val = *(uint32_t *)src.reg; break; case 8: src.val = *(uint64_t *)src.reg; break; } } else if ( (rc = read_ulong(src.mem.seg, src.mem.off,  &src.val, src.bytes, ctxt, ops)) ) goto done; break; case SrcImm: src.type= OP_IMM; src.bytes = (d & ByteOp) ? 1 : op_bytes; if ( src.bytes == 8 ) src.bytes = 4;  switch ( src.bytes ) { case 1: src.val = insn_fetch_type(int8_t);break; case 2: src.val = insn_fetch_type(int16_t); break; case 4: src.val = insn_fetch_type(int32_t); break; } break; case SrcImmByte: src.type= OP_IMM; src.bytes = 1; src.val = insn_fetch_type(int8_t); break; }  switch ( d & DstMask ) { case DstNone:   generate_exception_if( lock_prefix && ((b < 0x20) || (b > 0x23)) &&  (b != 0xc7), EXC_UD, -1); dst.type = OP_NONE; break; case DstReg: generate_exception_if(lock_prefix, EXC_UD, -1); dst.type = OP_REG; if ( d & ByteOp ) { dst.reg = decode_register(modrm_reg, &_regs, (rex_prefix == 0)); dst.val = *(uint8_t *)dst.reg; dst.bytes = 1; } else { dst.reg = decode_register(modrm_reg, &_regs, 0); switch ( (dst.bytes = op_bytes) ) { case 2: dst.val = *(uint16_t *)dst.reg; break; case 4: dst.val = *(uint32_t *)dst.reg; break; case 8: dst.val = *(uint64_t *)dst.reg; break; } } break; case DstBitBase: if ( ((d & SrcMask) == SrcImmByte) || (ea.type == OP_REG) ) { src.val &= (op_bytes << 3) - 1; } else {  if ( op_bytes == 2 ) src.val = (int16_t)src.val; else if ( op_bytes == 4 ) src.val = (int32_t)src.val; if ( (long)src.val < 0 ) { unsigned long byte_offset; byte_offset = op_bytes + (((-src.val-1) >> 3) & ~(op_bytes-1)); ea.mem.off -= byte_offset; src.val = (byte_offset << 3) + src.val; } else { ea.mem.off += (src.val >> 3) & ~(op_bytes - 1); src.val &= (op_bytes << 3) - 1; } }  d = (d & ~DstMask) | DstMem; case DstMem: ea.bytes = (d & ByteOp) ? 1 : op_bytes; dst = ea; if ( dst.type == OP_REG ) { generate_exception_if(lock_prefix, EXC_UD, -1); switch ( dst.bytes ) { case 1: dst.val = *(uint8_t*)dst.reg; break; case 2: dst.val = *(uint16_t *)dst.reg; break; case 4: dst.val = *(uint32_t *)dst.reg; break; case 8: dst.val = *(uint64_t *)dst.reg; break; } } else if ( !(d & Mov) )  { if ( (rc = read_ulong(dst.mem.seg, dst.mem.off, &dst.val, dst.bytes, ctxt, ops)) ) goto done; dst.orig_val = dst.val; } break; } if ( twobyte ) goto twobyte_insn; switch ( b ) { case 0x00 ... 0x05: add:  emulate_2op_SrcV(\"add\", src, dst, _regs.eflags); break; case 0x08 ... 0x0d: or: emulate_2op_SrcV(\"or\", src, dst, _regs.eflags); break; case 0x10 ... 0x15: adc:  emulate_2op_SrcV(\"adc\", src, dst, _regs.eflags); break; case 0x18 ... 0x1d: sbb:  emulate_2op_SrcV(\"sbb\", src, dst, _regs.eflags); break; case 0x20 ... 0x25: and:  emulate_2op_SrcV(\"and\", src, dst, _regs.eflags); break; case 0x28 ... 0x2d: sub:  emulate_2op_SrcV(\"sub\", src, dst, _regs.eflags); break; case 0x30 ... 0x35: xor:  emulate_2op_SrcV(\"xor\", src, dst, _regs.eflags); break; case 0x38 ... 0x3d: cmp:  emulate_2op_SrcV(\"cmp\", src, dst, _regs.eflags); dst.type = OP_NONE; break; case 0x06:{ struct segment_register reg; src.val = x86_seg_es; push_seg: generate_exception_if(mode_64bit() && !twobyte, EXC_UD, -1); fail_if(ops->read_segment == NULL); if ( (rc = ops->read_segment(src.val, &reg, ctxt)) != 0 ) return rc;  if ( mode_64bit() && (op_bytes == 4) ) op_bytes = 8; if ( (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &reg.sel, op_bytes, ctxt)) != 0 ) goto done; break; } case 0x07:  src.val = x86_seg_es; pop_seg: generate_exception_if(mode_64bit() && !twobyte, EXC_UD, -1); fail_if(ops->write_segment == NULL);  if ( mode_64bit() && (op_bytes == 4) ) op_bytes = 8; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &dst.val, op_bytes, ctxt, ops)) != 0 ) goto done; if ( (rc = load_seg(src.val, dst.val, 0, ctxt, ops)) != 0 ) return rc; break; case 0x0e:  src.val = x86_seg_cs; goto push_seg; case 0x16:  src.val = x86_seg_ss; goto push_seg; case 0x17:  src.val = x86_seg_ss; ctxt->retire.flags.mov_ss = 1; goto pop_seg; case 0x1e:  src.val = x86_seg_ds; goto push_seg; case 0x1f:  src.val = x86_seg_ds; goto pop_seg; case 0x27:{ uint8_t al = _regs.eax; unsigned long eflags = _regs.eflags; generate_exception_if(mode_64bit(), EXC_UD, -1); _regs.eflags &= ~(EFLG_CF|EFLG_AF); if ( ((al & 0x0f) > 9) || (eflags & EFLG_AF) ) { *(uint8_t *)&_regs.eax += 6; _regs.eflags |= EFLG_AF; } if ( (al > 0x99) || (eflags & EFLG_CF) ) { *(uint8_t *)&_regs.eax += 0x60; _regs.eflags |= EFLG_CF; } _regs.eflags &= ~(EFLG_SF|EFLG_ZF|EFLG_PF); _regs.eflags |= ((uint8_t)_regs.eax == 0) ? EFLG_ZF : 0; _regs.eflags |= (( int8_t)_regs.eax <0) ? EFLG_SF : 0; _regs.eflags |= even_parity(_regs.eax) ? EFLG_PF : 0; break; } case 0x2f:{ uint8_t al = _regs.eax; unsigned long eflags = _regs.eflags; generate_exception_if(mode_64bit(), EXC_UD, -1); _regs.eflags &= ~(EFLG_CF|EFLG_AF); if ( ((al & 0x0f) > 9) || (eflags & EFLG_AF) ) { _regs.eflags |= EFLG_AF; if ( (al < 6) || (eflags & EFLG_CF) ) _regs.eflags |= EFLG_CF; *(uint8_t *)&_regs.eax -= 6; } if ( (al > 0x99) || (eflags & EFLG_CF) ) { *(uint8_t *)&_regs.eax -= 0x60; _regs.eflags |= EFLG_CF; } _regs.eflags &= ~(EFLG_SF|EFLG_ZF|EFLG_PF); _regs.eflags |= ((uint8_t)_regs.eax == 0) ? EFLG_ZF : 0; _regs.eflags |= (( int8_t)_regs.eax <0) ? EFLG_SF : 0; _regs.eflags |= even_parity(_regs.eax) ? EFLG_PF : 0; break; } case 0x37:  case 0x3f:  generate_exception_if(mode_64bit(), EXC_UD, -1); _regs.eflags &= ~EFLG_CF; if ( ((uint8_t)_regs.eax > 9) || (_regs.eflags & EFLG_AF) ) { ((uint8_t *)&_regs.eax)[0] += (b == 0x37) ? 6 : -6; ((uint8_t *)&_regs.eax)[1] += (b == 0x37) ? 1 : -1; _regs.eflags |= EFLG_CF | EFLG_AF; } ((uint8_t *)&_regs.eax)[0] &= 0x0f; break; case 0x40 ... 0x4f:  dst.type= OP_REG; dst.reg = decode_register(b & 7, &_regs, 0); dst.bytes = op_bytes; dst.val = *dst.reg; if ( b & 8 ) emulate_1op(\"dec\", dst, _regs.eflags); else emulate_1op(\"inc\", dst, _regs.eflags); break; case 0x50 ... 0x57:  src.val = *(unsigned long *)decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); goto push; case 0x58 ... 0x5f:  dst.type= OP_REG; dst.reg = decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); dst.bytes = op_bytes; if ( mode_64bit() && (dst.bytes == 4) ) dst.bytes = 8; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(dst.bytes), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; break; case 0x60:{ int i; unsigned long regs[] = { _regs.eax, _regs.ecx, _regs.edx, _regs.ebx, _regs.esp, _regs.ebp, _regs.esi, _regs.edi }; generate_exception_if(mode_64bit(), EXC_UD, -1); for ( i = 0; i < 8; i++ ) if ( (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &regs[i], op_bytes, ctxt)) != 0 ) goto done; break; } case 0x61:{ int i; unsigned long dummy_esp, *regs[] = { (unsigned long *)&_regs.edi, (unsigned long *)&_regs.esi, (unsigned long *)&_regs.ebp, (unsigned long *)&dummy_esp, (unsigned long *)&_regs.ebx, (unsigned long *)&_regs.edx, (unsigned long *)&_regs.ecx, (unsigned long *)&_regs.eax }; generate_exception_if(mode_64bit(), EXC_UD, -1); for ( i = 0; i < 8; i++ ) { if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &dst.val, op_bytes, ctxt, ops)) != 0 ) goto done; if ( op_bytes == 2 ) *(uint16_t *)regs[i] = (uint16_t)dst.val; else *regs[i] = dst.val;  } break; } case 0x62:{ unsigned long src_val2; int lb, ub, idx; generate_exception_if(mode_64bit() || (src.type != OP_MEM), EXC_UD, -1); if ( (rc = read_ulong(src.mem.seg, src.mem.off + op_bytes, &src_val2, op_bytes, ctxt, ops)) ) goto done; ub= (op_bytes == 2) ? (int16_t)src_val2 : (int32_t)src_val2; lb= (op_bytes == 2) ? (int16_t)src.val: (int32_t)src.val; idx = (op_bytes == 2) ? (int16_t)dst.val: (int32_t)dst.val; generate_exception_if((idx < lb) || (idx > ub), EXC_BR, -1); dst.type = OP_NONE; break; } case 0x63:  if ( mode_64bit() ) {  if ( ea.type == OP_REG ) src.val = *ea.reg; else if ( (rc = read_ulong(ea.mem.seg, ea.mem.off,  &src.val, 4, ctxt, ops)) ) goto done; dst.val = (int32_t)src.val; } else {  unsigned int src_rpl = dst.val & 3; dst = ea; dst.bytes = 2; if ( dst.type == OP_REG ) dst.val = *dst.reg; else if ( (rc = read_ulong(dst.mem.seg, dst.mem.off,  &dst.val, 2, ctxt, ops)) ) goto done; if ( src_rpl > (dst.val & 3) ) { _regs.eflags |= EFLG_ZF; dst.val = (dst.val & ~3) | src_rpl; } else { _regs.eflags &= ~EFLG_ZF; dst.type = OP_NONE; } generate_exception_if(!in_protmode(ctxt, ops), EXC_UD, -1); } break; case 0x68:  src.val = ((op_bytes == 2)  ? (int32_t)insn_fetch_type(int16_t)  : insn_fetch_type(int32_t)); goto push; case 0x69:  case 0x6b:  if ( ea.type == OP_REG ) dst.val = *ea.reg; else if ( (rc = read_ulong(ea.mem.seg, ea.mem.off,  &dst.val, op_bytes, ctxt, ops)) ) goto done; goto imul; case 0x6a:  src.val = insn_fetch_type(int8_t); push: d |= Mov;  dst.type= OP_MEM; dst.bytes = op_bytes; if ( mode_64bit() && (dst.bytes == 4) ) dst.bytes = 8; dst.val = src.val; dst.mem.seg = x86_seg_ss; dst.mem.off = sp_pre_dec(dst.bytes); break; case 0x6c ... 0x6d:{ unsigned long nr_reps = get_rep_prefix(); unsigned int port = (uint16_t)_regs.edx; dst.bytes = !(b & 1) ? 1 : (op_bytes == 8) ? 4 : op_bytes; dst.mem.seg = x86_seg_es; dst.mem.off = truncate_ea_and_reps(_regs.edi, nr_reps, dst.bytes); if ( (rc = ioport_access_check(port, dst.bytes, ctxt, ops)) != 0 ) goto done; if ( (nr_reps > 1) && (ops->rep_ins != NULL) &&  ((rc = ops->rep_ins(port, dst.mem.seg, dst.mem.off, dst.bytes,  &nr_reps, ctxt)) != X86EMUL_UNHANDLEABLE) ) { if ( rc != 0 ) goto done; } else { fail_if(ops->read_io == NULL); if ( (rc = ops->read_io(port, dst.bytes, &dst.val, ctxt)) != 0 ) goto done; dst.type = OP_MEM; nr_reps = 1; } register_address_increment( _regs.edi, nr_reps * ((_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes)); put_rep_prefix(nr_reps); break; } case 0x6e ... 0x6f:{ unsigned long nr_reps = get_rep_prefix(); unsigned int port = (uint16_t)_regs.edx; dst.bytes = !(b & 1) ? 1 : (op_bytes == 8) ? 4 : op_bytes; ea.mem.off = truncate_ea_and_reps(_regs.esi, nr_reps, dst.bytes); if ( (rc = ioport_access_check(port, dst.bytes, ctxt, ops)) != 0 ) goto done; if ( (nr_reps > 1) && (ops->rep_outs != NULL) &&  ((rc = ops->rep_outs(ea.mem.seg, ea.mem.off, port, dst.bytes, &nr_reps, ctxt)) != X86EMUL_UNHANDLEABLE) ) { if ( rc != 0 ) goto done; } else { if ( (rc = read_ulong(ea.mem.seg, truncate_ea(_regs.esi), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; fail_if(ops->write_io == NULL); if ( (rc = ops->write_io(port, dst.bytes, dst.val, ctxt)) != 0 ) goto done; nr_reps = 1; } register_address_increment( _regs.esi, nr_reps * ((_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes)); put_rep_prefix(nr_reps); break; } case 0x70 ... 0x7f:{ int rel = insn_fetch_type(int8_t); if ( test_cc(b, _regs.eflags) ) jmp_rel(rel); break; } case 0x82:  generate_exception_if(mode_64bit(), EXC_UD, -1); case 0x80: case 0x81: case 0x83:  switch ( modrm_reg & 7 ) { case 0: goto add; case 1: goto or; case 2: goto adc; case 3: goto sbb; case 4: goto and; case 5: goto sub; case 6: goto xor; case 7: goto cmp; } break; case 0xa8 ... 0xa9:  case 0x84 ... 0x85: test:  emulate_2op_SrcV(\"test\", src, dst, _regs.eflags); dst.type = OP_NONE; break; case 0x86 ... 0x87: xchg:   switch ( dst.bytes ) { case 1: *(uint8_t*)src.reg = (uint8_t)dst.val; break; case 2: *(uint16_t *)src.reg = (uint16_t)dst.val; break; case 4: *src.reg = (uint32_t)dst.val; break;  case 8: *src.reg = dst.val; break; }  dst.val = src.val; lock_prefix = 1; break; case 0xc6 ... 0xc7:  generate_exception_if((modrm_reg & 7) != 0, EXC_UD, -1); case 0x88 ... 0x8b:  dst.val = src.val; break; case 0x8c:{ struct segment_register reg; enum x86_segment seg = decode_segment(modrm_reg); generate_exception_if(seg == decode_segment_failed, EXC_UD, -1); fail_if(ops->read_segment == NULL); if ( (rc = ops->read_segment(seg, &reg, ctxt)) != 0 ) goto done; dst.val = reg.sel; if ( dst.type == OP_MEM ) dst.bytes = 2; break; } case 0x8e:{ enum x86_segment seg = decode_segment(modrm_reg); generate_exception_if(seg == decode_segment_failed, EXC_UD, -1); generate_exception_if(seg == x86_seg_cs, EXC_UD, -1); if ( (rc = load_seg(seg, src.val, 0, ctxt, ops)) != 0 ) goto done; if ( seg == x86_seg_ss ) ctxt->retire.flags.mov_ss = 1; dst.type = OP_NONE; break; } case 0x8d:  generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); dst.val = ea.mem.off; break; case 0x8f:  generate_exception_if((modrm_reg & 7) != 0, EXC_UD, -1);  if ( mode_64bit() && (dst.bytes == 4) ) dst.bytes = 8; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(dst.bytes), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; break; case 0x90:  if ( !(rex_prefix & 1) ) break;  case 0x91 ... 0x97:  src.type = dst.type = OP_REG; src.bytes = dst.bytes = op_bytes; src.reg= (unsigned long *)&_regs.eax; src.val= *src.reg; dst.reg= decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); dst.val= *dst.reg; goto xchg; case 0x98:  switch ( op_bytes ) { case 2: *(int16_t *)&_regs.eax = (int8_t)_regs.eax; break;  case 4: _regs.eax = (uint32_t)(int16_t)_regs.eax; break;  case 8: _regs.eax = (int32_t)_regs.eax; break;  } break; case 0x99:  switch ( op_bytes ) { case 2: *(int16_t *)&_regs.edx = ((int16_t)_regs.eax < 0) ? -1 : 0; break; case 4: _regs.edx = (uint32_t)(((int32_t)_regs.eax < 0) ? -1 : 0); break; #ifdef __x86_64__  case 8: _regs.edx = ((int64_t)_regs.eax < 0) ? -1 : 0; break; #endif } break; case 0x9a:{ struct segment_register reg; uint16_t sel; uint32_t eip; generate_exception_if(mode_64bit(), EXC_UD, -1); fail_if(ops->read_segment == NULL); eip = insn_fetch_bytes(op_bytes); sel = insn_fetch_type(uint16_t); if ( (rc = ops->read_segment(x86_seg_cs, &reg, ctxt)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &reg.sel, op_bytes, ctxt)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &_regs.eip, op_bytes, ctxt)) ) goto done; if ( (rc = load_seg(x86_seg_cs, sel, 0, ctxt, ops)) != 0 ) goto done; _regs.eip = eip; break; } case 0x9b: emulate_fpu_insn(\"fwait\"); break; case 0x9c:  src.val = _regs.eflags; goto push; case 0x9d:{ uint32_t mask = EFLG_VIP | EFLG_VIF | EFLG_VM; if ( !mode_ring0() ) mask |= EFLG_IOPL; if ( !mode_iopl() ) mask |= EFLG_IF;  if ( mode_64bit() && (op_bytes == 4) ) op_bytes = 8; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &dst.val, op_bytes, ctxt, ops)) != 0 ) goto done; if ( op_bytes == 2 ) dst.val = (uint16_t)dst.val | (_regs.eflags & 0xffff0000u); dst.val &= 0x257fd5; _regs.eflags &= mask; _regs.eflags |= (uint32_t)(dst.val & ~mask) | 0x02; break; } case 0x9e:  *(uint8_t *)&_regs.eflags = (((uint8_t *)&_regs.eax)[1] & 0xd7) | 0x02; break; case 0x9f:  ((uint8_t *)&_regs.eax)[1] = (_regs.eflags & 0xd7) | 0x02; break; case 0xa0 ... 0xa1:   dst.type= OP_REG; dst.reg = (unsigned long *)&_regs.eax; dst.bytes = (d & ByteOp) ? 1 : op_bytes; if ( (rc = read_ulong(ea.mem.seg, insn_fetch_bytes(ad_bytes), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; break; case 0xa2 ... 0xa3:   dst.type= OP_MEM; dst.mem.seg = ea.mem.seg; dst.mem.off = insn_fetch_bytes(ad_bytes); dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.val = (unsigned long)_regs.eax; break; case 0xa4 ... 0xa5:{ unsigned long nr_reps = get_rep_prefix(); dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.mem.seg = x86_seg_es; dst.mem.off = truncate_ea_and_reps(_regs.edi, nr_reps, dst.bytes); src.mem.off = truncate_ea_and_reps(_regs.esi, nr_reps, dst.bytes); if ( (nr_reps > 1) && (ops->rep_movs != NULL) &&  ((rc = ops->rep_movs(ea.mem.seg, src.mem.off, dst.mem.seg, dst.mem.off, dst.bytes, &nr_reps, ctxt)) != X86EMUL_UNHANDLEABLE) ) { if ( rc != 0 ) goto done; } else { if ( (rc = read_ulong(ea.mem.seg, src.mem.off, &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; dst.type = OP_MEM; nr_reps = 1; } register_address_increment( _regs.esi, nr_reps * ((_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes)); register_address_increment( _regs.edi, nr_reps * ((_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes)); put_rep_prefix(nr_reps); break; } case 0xa6 ... 0xa7:{ unsigned long next_eip = _regs.eip; get_rep_prefix(); src.bytes = dst.bytes = (d & ByteOp) ? 1 : op_bytes; if ( (rc = read_ulong(ea.mem.seg, truncate_ea(_regs.esi), &dst.val, dst.bytes, ctxt, ops)) ||  (rc = read_ulong(x86_seg_es, truncate_ea(_regs.edi), &src.val, src.bytes, ctxt, ops)) ) goto done; register_address_increment( _regs.esi, (_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes); register_address_increment( _regs.edi, (_regs.eflags & EFLG_DF) ? -src.bytes : src.bytes); put_rep_prefix(1);  emulate_2op_SrcV(\"cmp\", src, dst, _regs.eflags); if ( (repe_prefix() && !(_regs.eflags & EFLG_ZF)) ||  (repne_prefix() && (_regs.eflags & EFLG_ZF)) ) _regs.eip = next_eip; break; } case 0xaa ... 0xab:{ unsigned long nr_reps = get_rep_prefix(); dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.mem.seg = x86_seg_es; dst.mem.off = truncate_ea(_regs.edi); if ( (nr_reps == 1) || !ops->rep_stos ||  ((rc = ops->rep_stos(&_regs.eax, dst.mem.seg, dst.mem.off, dst.bytes, &nr_reps, ctxt)) == X86EMUL_UNHANDLEABLE) ) { dst.val = _regs.eax; dst.type = OP_MEM; nr_reps = 1; } else if ( rc != X86EMUL_OKAY ) goto done; register_address_increment( _regs.edi, nr_reps * ((_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes)); put_rep_prefix(nr_reps); break; } case 0xac ... 0xad:{ get_rep_prefix(); dst.type= OP_REG; dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.reg = (unsigned long *)&_regs.eax; if ( (rc = read_ulong(ea.mem.seg, truncate_ea(_regs.esi), &dst.val, dst.bytes, ctxt, ops)) != 0 ) goto done; register_address_increment( _regs.esi, (_regs.eflags & EFLG_DF) ? -dst.bytes : dst.bytes); put_rep_prefix(1); break; } case 0xae ... 0xaf:{ unsigned long next_eip = _regs.eip; get_rep_prefix(); src.bytes = dst.bytes = (d & ByteOp) ? 1 : op_bytes; dst.val = _regs.eax; if ( (rc = read_ulong(x86_seg_es, truncate_ea(_regs.edi), &src.val, src.bytes, ctxt, ops)) != 0 ) goto done; register_address_increment( _regs.edi, (_regs.eflags & EFLG_DF) ? -src.bytes : src.bytes); put_rep_prefix(1);  emulate_2op_SrcV(\"cmp\", src, dst, _regs.eflags); if ( (repe_prefix() && !(_regs.eflags & EFLG_ZF)) ||  (repne_prefix() && (_regs.eflags & EFLG_ZF)) ) _regs.eip = next_eip; break; } case 0xb0 ... 0xb7:  dst.reg = decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, (rex_prefix == 0)); dst.val = src.val; break; case 0xb8 ... 0xbf:  if ( dst.bytes == 8 )  src.val = ((uint32_t)src.val |  ((uint64_t)insn_fetch_type(uint32_t) << 32)); dst.reg = decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); dst.val = src.val; break; case 0xc0 ... 0xc1: grp2:  switch ( modrm_reg & 7 ) { case 0:  emulate_2op_SrcB(\"rol\", src, dst, _regs.eflags); break; case 1:  emulate_2op_SrcB(\"ror\", src, dst, _regs.eflags); break; case 2:  emulate_2op_SrcB(\"rcl\", src, dst, _regs.eflags); break; case 3:  emulate_2op_SrcB(\"rcr\", src, dst, _regs.eflags); break; case 4:  case 6:  emulate_2op_SrcB(\"sal\", src, dst, _regs.eflags); break; case 5:  emulate_2op_SrcB(\"shr\", src, dst, _regs.eflags); break; case 7:  emulate_2op_SrcB(\"sar\", src, dst, _regs.eflags); break; } break; case 0xc2:  case 0xc3:{ int offset = (b == 0xc2) ? insn_fetch_type(uint16_t) : 0; op_bytes = ((op_bytes == 4) && mode_64bit()) ? 8 : op_bytes; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes + offset), &dst.val, op_bytes, ctxt, ops)) != 0 ) goto done; _regs.eip = dst.val; break; } case 0xc4:{ unsigned long sel; dst.val = x86_seg_es; les:  generate_exception_if(mode_64bit() && !twobyte, EXC_UD, -1); generate_exception_if(src.type != OP_MEM, EXC_UD, -1); if ( (rc = read_ulong(src.mem.seg, src.mem.off + src.bytes, &sel, 2, ctxt, ops)) != 0 ) goto done; if ( (rc = load_seg(dst.val, sel, 0, ctxt, ops)) != 0 ) goto done; dst.val = src.val; break; } case 0xc5:  dst.val = x86_seg_ds; goto les; case 0xc8:{ uint16_t size = insn_fetch_type(uint16_t); uint8_t depth = insn_fetch_type(uint8_t) & 31; int i; dst.type = OP_REG; dst.bytes = (mode_64bit() && (op_bytes == 4)) ? 8 : op_bytes; dst.reg = (unsigned long *)&_regs.ebp; if ( (rc = ops->write(x86_seg_ss, sp_pre_dec(dst.bytes), &_regs.ebp, dst.bytes, ctxt)) ) goto done; dst.val = _regs.esp; if ( depth > 0 ) { for ( i = 1; i < depth; i++ ) { unsigned long ebp, temp_data; ebp = truncate_word(_regs.ebp - i*dst.bytes, ctxt->sp_size/8); if ( (rc = read_ulong(x86_seg_ss, ebp, &temp_data, dst.bytes, ctxt, ops)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(dst.bytes), &temp_data, dst.bytes, ctxt)) ) goto done; } if ( (rc = ops->write(x86_seg_ss, sp_pre_dec(dst.bytes), &dst.val, dst.bytes, ctxt)) ) goto done; } sp_pre_dec(size); break; } case 0xc9:   dst.type = OP_REG; dst.bytes = (mode_64bit() && (op_bytes == 4)) ? 8 : op_bytes; dst.reg = (unsigned long *)&_regs.esp; dst.val = _regs.ebp;  switch ( dst.bytes ) { case 1: *(uint8_t*)dst.reg = (uint8_t)dst.val; break; case 2: *(uint16_t *)dst.reg = (uint16_t)dst.val; break; case 4: *dst.reg = (uint32_t)dst.val; break;  case 8: *dst.reg = dst.val; break; }  dst.reg = (unsigned long *)&_regs.ebp; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(dst.bytes), &dst.val, dst.bytes, ctxt, ops)) ) goto done; break; case 0xca:  case 0xcb:{ int offset = (b == 0xca) ? insn_fetch_type(uint16_t) : 0; if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &dst.val, op_bytes, ctxt, ops)) ||  (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes + offset), &src.val, op_bytes, ctxt, ops)) ||  (rc = load_seg(x86_seg_cs, src.val, 1, ctxt, ops)) ) goto done; _regs.eip = dst.val; break; } case 0xcc:  src.val = EXC_BP; swint_type = x86_swint_int3; goto swint; case 0xcd:  src.val = insn_fetch_type(uint8_t); swint_type = x86_swint_int; swint: rc = inject_swint(swint_type, src.val, _regs.eip - ctxt->regs->eip, ctxt, ops) ? : X86EMUL_EXCEPTION; goto done; case 0xce:  generate_exception_if(mode_64bit(), EXC_UD, -1); if ( !(_regs.eflags & EFLG_OF) ) break; src.val = EXC_OF; swint_type = x86_swint_into; goto swint; case 0xcf:{ unsigned long cs, eip, eflags; uint32_t mask = EFLG_VIP | EFLG_VIF | EFLG_VM; if ( !mode_ring0() ) mask |= EFLG_IOPL; if ( !mode_iopl() ) mask |= EFLG_IF; fail_if(!in_realmode(ctxt, ops)); if ( (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &eip, op_bytes, ctxt, ops)) ||  (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &cs, op_bytes, ctxt, ops)) ||  (rc = read_ulong(x86_seg_ss, sp_post_inc(op_bytes), &eflags, op_bytes, ctxt, ops)) ) goto done; if ( op_bytes == 2 ) eflags = (uint16_t)eflags | (_regs.eflags & 0xffff0000u); eflags &= 0x257fd5; _regs.eflags &= mask; _regs.eflags |= (uint32_t)(eflags & ~mask) | 0x02; _regs.eip = eip; if ( (rc = load_seg(x86_seg_cs, cs, 1, ctxt, ops)) != 0 ) goto done; break; } case 0xd0 ... 0xd1:  src.val = 1; goto grp2; case 0xd2 ... 0xd3:  src.val = _regs.ecx; goto grp2; case 0xd4:{ unsigned int base = insn_fetch_type(uint8_t); uint8_t al = _regs.eax; generate_exception_if(mode_64bit(), EXC_UD, -1); generate_exception_if(base == 0, EXC_DE, -1); *(uint16_t *)&_regs.eax = ((al / base) << 8) | (al % base); _regs.eflags &= ~(EFLG_SF|EFLG_ZF|EFLG_PF); _regs.eflags |= ((uint8_t)_regs.eax == 0) ? EFLG_ZF : 0; _regs.eflags |= (( int8_t)_regs.eax <0) ? EFLG_SF : 0; _regs.eflags |= even_parity(_regs.eax) ? EFLG_PF : 0; break; } case 0xd5:{ unsigned int base = insn_fetch_type(uint8_t); uint16_t ax = _regs.eax; generate_exception_if(mode_64bit(), EXC_UD, -1); *(uint16_t *)&_regs.eax = (uint8_t)(ax + ((ax >> 8) * base)); _regs.eflags &= ~(EFLG_SF|EFLG_ZF|EFLG_PF); _regs.eflags |= ((uint8_t)_regs.eax == 0) ? EFLG_ZF : 0; _regs.eflags |= (( int8_t)_regs.eax <0) ? EFLG_SF : 0; _regs.eflags |= even_parity(_regs.eax) ? EFLG_PF : 0; break; } case 0xd6:  generate_exception_if(mode_64bit(), EXC_UD, -1); *(uint8_t *)&_regs.eax = (_regs.eflags & EFLG_CF) ? 0xff : 0x00; break; case 0xd7:{ unsigned long al = (uint8_t)_regs.eax; if ( (rc = read_ulong(ea.mem.seg, truncate_ea(_regs.ebx + al), &al, 1, ctxt, ops)) != 0 ) goto done; *(uint8_t *)&_regs.eax = al; break; } case 0xd8:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd0 ... 0xd7:  case 0xd8 ... 0xdf:  case 0xe0 ... 0xe7:  case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  case 0xf8 ... 0xff:  emulate_fpu_insn_stub(0xd8, modrm); break; default: fail_if(modrm >= 0xc0); ea.bytes = 4; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; switch ( modrm_reg & 7 ) { case 0:  emulate_fpu_insn_memsrc(\"fadds\", src.val); break; case 1:  emulate_fpu_insn_memsrc(\"fmuls\", src.val); break; case 2:  emulate_fpu_insn_memsrc(\"fcoms\", src.val); break; case 3:  emulate_fpu_insn_memsrc(\"fcomps\", src.val); break; case 4:  emulate_fpu_insn_memsrc(\"fsubs\", src.val); break; case 5:  emulate_fpu_insn_memsrc(\"fsubrs\", src.val); break; case 6:  emulate_fpu_insn_memsrc(\"fdivs\", src.val); break; case 7:  emulate_fpu_insn_memsrc(\"fdivrs\", src.val); break; default: goto cannot_emulate; } } break; case 0xd9:  switch ( modrm ) { case 0xfb:  fail_if(cpu_has_amd_erratum(573));  case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd0:  case 0xe0:  case 0xe1:  case 0xe4:  case 0xe5:  case 0xe8:  case 0xe9:  case 0xea:  case 0xeb:  case 0xec:  case 0xed:  case 0xee:  case 0xf0:  case 0xf1:  case 0xf2:  case 0xf3:  case 0xf4:  case 0xf5:  case 0xf6:  case 0xf7:  case 0xf8:  case 0xf9:  case 0xfa:  case 0xfc:  case 0xfd:  case 0xfe:  case 0xff:  emulate_fpu_insn_stub(0xd9, modrm); break; default: fail_if(modrm >= 0xc0); switch ( modrm_reg & 7 ) { case 0:  ea.bytes = 4; src = ea; if ( (rc = ops->read(ea.mem.seg, ea.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"flds\", src.val); break; case 2:  ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fsts\", dst.val); break; case 3:  ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fstps\", dst.val); break;  case 5:  ea.bytes = 2; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fldcw\", src.val); break;  case 7:  ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fnstcw\", dst.val); break; default: goto cannot_emulate; } } break; case 0xda:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd0 ... 0xd7:  case 0xd8 ... 0xdf:  case 0xe9: emulate_fpu_insn_stub(0xda, modrm); break; default: fail_if(modrm >= 0xc0); ea.bytes = 4; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; switch ( modrm_reg & 7 ) { case 0:  emulate_fpu_insn_memsrc(\"fiaddl\", src.val); break; case 1:  emulate_fpu_insn_memsrc(\"fimull\", src.val); break; case 2:  emulate_fpu_insn_memsrc(\"ficoml\", src.val); break; case 3:  emulate_fpu_insn_memsrc(\"ficompl\", src.val); break; case 4:  emulate_fpu_insn_memsrc(\"fisubl\", src.val); break; case 5:  emulate_fpu_insn_memsrc(\"fisubrl\", src.val); break; case 6:  emulate_fpu_insn_memsrc(\"fidivl\", src.val); break; case 7:  emulate_fpu_insn_memsrc(\"fidivrl\", src.val); break; default: goto cannot_emulate; } } break; case 0xdb:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd0 ... 0xd7:  case 0xd8 ... 0xdf:  emulate_fpu_insn_stub(0xdb, modrm); break; case 0xe2:  emulate_fpu_insn(\"fnclex\"); break; case 0xe3:  emulate_fpu_insn(\"fninit\"); break; case 0xe4:  break; case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  emulate_fpu_insn_stub(0xdb, modrm); break; default: fail_if(modrm >= 0xc0); switch ( modrm_reg & 7 ) { case 0:  ea.bytes = 4; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fildl\", src.val); break; case 1:  vcpu_must_have_sse3(); ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fisttpl\", dst.val); break; case 2:  ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fistl\", dst.val); break; case 3:  ea.bytes = 4; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fistpl\", dst.val); break; case 5:  ea.bytes = 10; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off,  &src.val, src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memdst(\"fldt\", src.val); break; case 7:  ea.bytes = 10; dst.type = OP_MEM; dst = ea; emulate_fpu_insn_memdst(\"fstpt\", dst.val); break; default: goto cannot_emulate; } } break; case 0xdc:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xe0 ... 0xe7:  case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  case 0xf8 ... 0xff:  emulate_fpu_insn_stub(0xdc, modrm); break; default: fail_if(modrm >= 0xc0); ea.bytes = 8; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; switch ( modrm_reg & 7 ) { case 0:  emulate_fpu_insn_memsrc(\"faddl\", src.val); break; case 1:  emulate_fpu_insn_memsrc(\"fmull\", src.val); break; case 2:  emulate_fpu_insn_memsrc(\"fcoml\", src.val); break; case 3:  emulate_fpu_insn_memsrc(\"fcompl\", src.val); break; case 4:  emulate_fpu_insn_memsrc(\"fsubl\", src.val); break; case 5:  emulate_fpu_insn_memsrc(\"fsubrl\", src.val); break; case 6:  emulate_fpu_insn_memsrc(\"fdivl\", src.val); break; case 7:  emulate_fpu_insn_memsrc(\"fdivrl\", src.val); break; } } break; case 0xdd:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xd0 ... 0xd7:  case 0xd8 ... 0xdf:  case 0xe0 ... 0xe7:  case 0xe8 ... 0xef:  emulate_fpu_insn_stub(0xdd, modrm); break; default: fail_if(modrm >= 0xc0); switch ( modrm_reg & 7 ) { case 0: ; ea.bytes = 8; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fldl\", src.val); break; case 1:  vcpu_must_have_sse3(); ea.bytes = 8; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fisttpll\", dst.val); break; case 2:  ea.bytes = 8; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memsrc(\"fstl\", dst.val); break; case 3:  ea.bytes = 8; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fstpl\", dst.val); break; case 7:  ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fnstsw\", dst.val); break; default: goto cannot_emulate; } } break; case 0xde:  switch ( modrm ) { case 0xc0 ... 0xc7:  case 0xc8 ... 0xcf:  case 0xd9:  case 0xe0 ... 0xe7:  case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  case 0xf8 ... 0xff:  emulate_fpu_insn_stub(0xde, modrm); break; default: fail_if(modrm >= 0xc0); ea.bytes = 2; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; switch ( modrm_reg & 7 ) { case 0:  emulate_fpu_insn_memsrc(\"fiadds\", src.val); break; case 1:  emulate_fpu_insn_memsrc(\"fimuls\", src.val); break; case 2:  emulate_fpu_insn_memsrc(\"ficoms\", src.val); break; case 3:  emulate_fpu_insn_memsrc(\"ficomps\", src.val); break; case 4:  emulate_fpu_insn_memsrc(\"fisubs\", src.val); break; case 5:  emulate_fpu_insn_memsrc(\"fisubrs\", src.val); break; case 6:  emulate_fpu_insn_memsrc(\"fidivs\", src.val); break; case 7:  emulate_fpu_insn_memsrc(\"fidivrs\", src.val); break; default: goto cannot_emulate; } } break; case 0xdf:  switch ( modrm ) { case 0xe0:  dst.bytes = 2; dst.type = OP_REG; dst.reg = (unsigned long *)&_regs.eax; emulate_fpu_insn_memdst(\"fnstsw\", dst.val); break; case 0xe8 ... 0xef:  case 0xf0 ... 0xf7:  emulate_fpu_insn_stub(0xdf, modrm); break; default: fail_if(modrm >= 0xc0); switch ( modrm_reg & 7 ) { case 0:  ea.bytes = 2; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"filds\", src.val); break; case 1:  vcpu_must_have_sse3(); ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fisttps\", dst.val); break; case 2:  ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fists\", dst.val); break; case 3:  ea.bytes = 2; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fistps\", dst.val); break; case 4:  ea.bytes = 10; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off,  &src.val, src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fbld\", src.val); break; case 5:  ea.bytes = 8; src = ea; if ( (rc = ops->read(src.mem.seg, src.mem.off, &src.val,  src.bytes, ctxt)) != 0 ) goto done; emulate_fpu_insn_memsrc(\"fildll\", src.val); break; case 6:  ea.bytes = 10; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fbstp\", dst.val); break; case 7:  ea.bytes = 8; dst = ea; dst.type = OP_MEM; emulate_fpu_insn_memdst(\"fistpll\", dst.val); break; default: goto cannot_emulate; } } break; case 0xe0 ... 0xe2:{ int rel = insn_fetch_type(int8_t); int do_jmp = !(_regs.eflags & EFLG_ZF);  if ( b == 0xe1 ) do_jmp = !do_jmp;  else if ( b == 0xe2 ) do_jmp = 1;  switch ( ad_bytes ) { case 2: do_jmp &= --(*(uint16_t *)&_regs.ecx) != 0; break; case 4: do_jmp &= --(*(uint32_t *)&_regs.ecx) != 0; _regs.ecx = (uint32_t)_regs.ecx;  break; default:  do_jmp &= --_regs.ecx != 0; break; } if ( do_jmp ) jmp_rel(rel); break; } case 0xe3:{ int rel = insn_fetch_type(int8_t); if ( (ad_bytes == 2) ? !(uint16_t)_regs.ecx :  (ad_bytes == 4) ? !(uint32_t)_regs.ecx : !_regs.ecx ) jmp_rel(rel); break; } case 0xe4:  case 0xe5:  case 0xe6:  case 0xe7:  case 0xec:  case 0xed:  case 0xee:  case 0xef:{ unsigned int port = ((b < 0xe8)  ? insn_fetch_type(uint8_t)  : (uint16_t)_regs.edx); op_bytes = !(b & 1) ? 1 : (op_bytes == 8) ? 4 : op_bytes; if ( (rc = ioport_access_check(port, op_bytes, ctxt, ops)) != 0 ) goto done; if ( b & 2 ) {  fail_if(ops->write_io == NULL); rc = ops->write_io(port, op_bytes, _regs.eax, ctxt); } else {  dst.type= OP_REG; dst.bytes = op_bytes; dst.reg = (unsigned long *)&_regs.eax; fail_if(ops->read_io == NULL); rc = ops->read_io(port, dst.bytes, &dst.val, ctxt); } if ( rc != 0 ) goto done; break; } case 0xe8:{ int rel = ((op_bytes == 2)  ? (int32_t)insn_fetch_type(int16_t)  : insn_fetch_type(int32_t)); op_bytes = ((op_bytes == 4) && mode_64bit()) ? 8 : op_bytes; src.val = _regs.eip; jmp_rel(rel); goto push; } case 0xe9:{ int rel = ((op_bytes == 2)  ? (int32_t)insn_fetch_type(int16_t)  : insn_fetch_type(int32_t)); jmp_rel(rel); break; } case 0xea:{ uint16_t sel; uint32_t eip; generate_exception_if(mode_64bit(), EXC_UD, -1); eip = insn_fetch_bytes(op_bytes); sel = insn_fetch_type(uint16_t); if ( (rc = load_seg(x86_seg_cs, sel, 0, ctxt, ops)) != 0 ) goto done; _regs.eip = eip; break; } case 0xeb:{ int rel = insn_fetch_type(int8_t); jmp_rel(rel); break; } case 0xf1:  src.val = EXC_DB; swint_type = x86_swint_icebp; goto swint; case 0xf4:  generate_exception_if(!mode_ring0(), EXC_GP, 0); ctxt->retire.flags.hlt = 1; break; case 0xf5:  _regs.eflags ^= EFLG_CF; break; case 0xf6 ... 0xf7:  switch ( modrm_reg & 7 ) { case 0 ... 1:  goto test; case 2:  dst.val = ~dst.val; break; case 3:  emulate_1op(\"neg\", dst, _regs.eflags); break; case 4:  dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; dst.val= *dst.reg; _regs.eflags &= ~(EFLG_OF|EFLG_CF); switch ( dst.bytes = src.bytes ) { case 1: dst.val = (uint8_t)dst.val; dst.val *= src.val; if ( (uint8_t)dst.val != (uint16_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; dst.bytes = 2; break; case 2: dst.val = (uint16_t)dst.val; dst.val *= src.val; if ( (uint16_t)dst.val != (uint32_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; *(uint16_t *)&_regs.edx = dst.val >> 16; break; #ifdef __x86_64__ case 4: dst.val = (uint32_t)dst.val; dst.val *= src.val; if ( (uint32_t)dst.val != dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; _regs.edx = (uint32_t)(dst.val >> 32); break; #endif default: { unsigned long m[2] = { src.val, dst.val }; if ( mul_dbl(m) ) _regs.eflags |= EFLG_OF|EFLG_CF; _regs.edx = m[1]; dst.val= m[0]; break; } } break; case 5:  dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; dst.val= *dst.reg; dst.bytes = src.bytes; imul: _regs.eflags &= ~(EFLG_OF|EFLG_CF); switch ( dst.bytes ) { case 1: dst.val = (int8_t)src.val * (int8_t)dst.val; if ( (int8_t)dst.val != (int16_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; ASSERT(b > 0x6b); dst.bytes = 2; break; case 2: dst.val = ((uint32_t)(int16_t)src.val *  (uint32_t)(int16_t)dst.val); if ( (int16_t)dst.val != (int32_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; if ( b > 0x6b ) *(uint16_t *)&_regs.edx = dst.val >> 16; break; #ifdef __x86_64__ case 4: dst.val = ((uint64_t)(int32_t)src.val *  (uint64_t)(int32_t)dst.val); if ( (int32_t)dst.val != dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; if ( b > 0x6b ) _regs.edx = (uint32_t)(dst.val >> 32); break; #endif default: { unsigned long m[2] = { src.val, dst.val }; if ( imul_dbl(m) ) _regs.eflags |= EFLG_OF|EFLG_CF; if ( b > 0x6b ) _regs.edx = m[1]; dst.val= m[0]; break; } } break; case 6:{ unsigned long u[2], v; dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; switch ( dst.bytes = src.bytes ) { case 1: u[0] = (uint16_t)_regs.eax; u[1] = 0; v= (uint8_t)src.val; generate_exception_if( div_dbl(u, v) || ((uint8_t)u[0] != (uint16_t)u[0]), EXC_DE, -1); dst.val = (uint8_t)u[0]; ((uint8_t *)&_regs.eax)[1] = u[1]; break; case 2: u[0] = ((uint32_t)_regs.edx << 16) | (uint16_t)_regs.eax; u[1] = 0; v= (uint16_t)src.val; generate_exception_if( div_dbl(u, v) || ((uint16_t)u[0] != (uint32_t)u[0]), EXC_DE, -1); dst.val = (uint16_t)u[0]; *(uint16_t *)&_regs.edx = u[1]; break; #ifdef __x86_64__ case 4: u[0] = (_regs.edx << 32) | (uint32_t)_regs.eax; u[1] = 0; v= (uint32_t)src.val; generate_exception_if( div_dbl(u, v) || ((uint32_t)u[0] != u[0]), EXC_DE, -1); dst.val = (uint32_t)u[0]; _regs.edx = (uint32_t)u[1]; break; #endif default: u[0] = _regs.eax; u[1] = _regs.edx; v= src.val; generate_exception_if(div_dbl(u, v), EXC_DE, -1); dst.val = u[0]; _regs.edx = u[1]; break; } break; } case 7:{ unsigned long u[2], v; dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; switch ( dst.bytes = src.bytes ) { case 1: u[0] = (int16_t)_regs.eax; u[1] = ((long)u[0] < 0) ? ~0UL : 0UL; v= (int8_t)src.val; generate_exception_if( idiv_dbl(u, v) || ((int8_t)u[0] != (int16_t)u[0]), EXC_DE, -1); dst.val = (int8_t)u[0]; ((int8_t *)&_regs.eax)[1] = u[1]; break; case 2: u[0] = (int32_t)((_regs.edx << 16) | (uint16_t)_regs.eax); u[1] = ((long)u[0] < 0) ? ~0UL : 0UL; v= (int16_t)src.val; generate_exception_if( idiv_dbl(u, v) || ((int16_t)u[0] != (int32_t)u[0]), EXC_DE, -1); dst.val = (int16_t)u[0]; *(int16_t *)&_regs.edx = u[1]; break; #ifdef __x86_64__ case 4: u[0] = (_regs.edx << 32) | (uint32_t)_regs.eax; u[1] = ((long)u[0] < 0) ? ~0UL : 0UL; v= (int32_t)src.val; generate_exception_if( idiv_dbl(u, v) || ((int32_t)u[0] != u[0]), EXC_DE, -1); dst.val = (int32_t)u[0]; _regs.edx = (uint32_t)u[1]; break; #endif default: u[0] = _regs.eax; u[1] = _regs.edx; v= src.val; generate_exception_if(idiv_dbl(u, v), EXC_DE, -1); dst.val = u[0]; _regs.edx = u[1]; break; } break; } default: goto cannot_emulate; } break; case 0xf8:  _regs.eflags &= ~EFLG_CF; break; case 0xf9:  _regs.eflags |= EFLG_CF; break; case 0xfa:  generate_exception_if(!mode_iopl(), EXC_GP, 0); _regs.eflags &= ~EFLG_IF; break; case 0xfb:  generate_exception_if(!mode_iopl(), EXC_GP, 0); if ( !(_regs.eflags & EFLG_IF) ) { _regs.eflags |= EFLG_IF; ctxt->retire.flags.sti = 1; } break; case 0xfc:  _regs.eflags &= ~EFLG_DF; break; case 0xfd:  _regs.eflags |= EFLG_DF; break; case 0xfe:  generate_exception_if((modrm_reg & 7) >= 2, EXC_UD, -1); case 0xff:  switch ( modrm_reg & 7 ) { case 0:  emulate_1op(\"inc\", dst, _regs.eflags); break; case 1:  emulate_1op(\"dec\", dst, _regs.eflags); break; case 2:  dst.val = _regs.eip; _regs.eip = src.val; src.val = dst.val; goto push; case 4:  _regs.eip = src.val; dst.type = OP_NONE; break; case 3:  case 5:{ unsigned long sel; generate_exception_if(src.type != OP_MEM, EXC_UD, -1); if ( (rc = read_ulong(src.mem.seg, src.mem.off + op_bytes, &sel, 2, ctxt, ops)) ) goto done; if ( (modrm_reg & 7) == 3 )  { struct segment_register reg; fail_if(ops->read_segment == NULL); if ( (rc = ops->read_segment(x86_seg_cs, &reg, ctxt)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &reg.sel, op_bytes, ctxt)) ||  (rc = ops->write(x86_seg_ss, sp_pre_dec(op_bytes), &_regs.eip, op_bytes, ctxt)) ) goto done; } if ( (rc = load_seg(x86_seg_cs, sel, 0, ctxt, ops)) != 0 ) goto done; _regs.eip = src.val; dst.type = OP_NONE; break; } case 6:  goto push; case 7: generate_exception_if(1, EXC_UD, -1); default: goto cannot_emulate; } break; }  writeback: switch ( dst.type ) { case OP_REG:  switch ( dst.bytes ) { case 1: *(uint8_t*)dst.reg = (uint8_t)dst.val; break; case 2: *(uint16_t *)dst.reg = (uint16_t)dst.val; break; case 4: *dst.reg = (uint32_t)dst.val; break;  case 8: *dst.reg = dst.val; break; } break; case OP_MEM: if ( !(d & Mov) && (dst.orig_val == dst.val) &&  !ctxt->force_writeback ) ; else if ( lock_prefix ) rc = ops->cmpxchg( dst.mem.seg, dst.mem.off, &dst.orig_val, &dst.val, dst.bytes, ctxt); else rc = ops->write( dst.mem.seg, dst.mem.off, &dst.val, dst.bytes, ctxt); if ( rc != 0 ) goto done; default: break; }  no_writeback:  if ( (ctxt->regs->eflags & EFLG_TF) && (rc == X86EMUL_OKAY) &&  (ops->inject_hw_exception != NULL) ) rc = ops->inject_hw_exception(EXC_DB, -1, ctxt) ? : X86EMUL_EXCEPTION;  _regs.eflags &= ~EFLG_RF; *ctxt->regs = _regs;  done: _put_fpu(); put_stub(stub); return rc;  twobyte_insn: switch ( b ) { case 0x00:  fail_if((modrm_reg & 6) != 2); generate_exception_if(!in_protmode(ctxt, ops), EXC_UD, -1); generate_exception_if(!mode_ring0(), EXC_GP, 0); if ( (rc = load_seg((modrm_reg & 1) ? x86_seg_tr : x86_seg_ldtr, src.val, 0, ctxt, ops)) != 0 ) goto done; break; case 0x01:{ struct segment_register reg; unsigned long base, limit, cr0, cr0w; switch( modrm ) { case 0xdf:  generate_exception_if(!in_protmode(ctxt, ops), EXC_UD, -1); generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if(ops->invlpg == NULL); if ( (rc = ops->invlpg(x86_seg_none, truncate_ea(_regs.eax),  ctxt)) ) goto done; goto no_writeback; case 0xf9:{ uint64_t tsc_aux; fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_TSC_AUX, &tsc_aux, ctxt)) != 0 ) goto done; _regs.ecx = (uint32_t)tsc_aux; goto rdtsc; } case 0xd4:  generate_exception_if(lock_prefix | rep_prefix() | (vex.pfx == vex_66), EXC_UD, -1); fail_if(ops->vmfunc == NULL); if ( (rc = ops->vmfunc(ctxt) != X86EMUL_OKAY) ) goto done; goto no_writeback; } switch ( modrm_reg & 7 ) { case 0:  case 1:  generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); fail_if(ops->read_segment == NULL); if ( (rc = ops->read_segment((modrm_reg & 1) ?  x86_seg_idtr : x86_seg_gdtr,  &reg, ctxt)) ) goto done; if ( op_bytes == 2 ) reg.base &= 0xffffff; if ( (rc = ops->write(ea.mem.seg, ea.mem.off+0, &reg.limit, 2, ctxt)) ||  (rc = ops->write(ea.mem.seg, ea.mem.off+2, &reg.base, mode_64bit() ? 8 : 4, ctxt)) ) goto done; break; case 2:  case 3:  generate_exception_if(!mode_ring0(), EXC_GP, 0); generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); fail_if(ops->write_segment == NULL); memset(&reg, 0, sizeof(reg)); if ( (rc = read_ulong(ea.mem.seg, ea.mem.off+0, &limit, 2, ctxt, ops)) ||  (rc = read_ulong(ea.mem.seg, ea.mem.off+2, &base, mode_64bit() ? 8 : 4, ctxt, ops)) ) goto done; reg.base = base; reg.limit = limit; if ( op_bytes == 2 ) reg.base &= 0xffffff; if ( (rc = ops->write_segment((modrm_reg & 1) ? x86_seg_idtr : x86_seg_gdtr, &reg, ctxt)) ) goto done; break; case 4:  ea.bytes = (ea.type == OP_MEM) ? 2 : op_bytes; dst = ea; fail_if(ops->read_cr == NULL); if ( (rc = ops->read_cr(0, &dst.val, ctxt)) ) goto done; d |= Mov;  break; case 6:  fail_if(ops->read_cr == NULL); fail_if(ops->write_cr == NULL); generate_exception_if(!mode_ring0(), EXC_GP, 0); if ( (rc = ops->read_cr(0, &cr0, ctxt)) ) goto done; if ( ea.type == OP_REG ) cr0w = *ea.reg; else if ( (rc = read_ulong(ea.mem.seg, ea.mem.off,  &cr0w, 2, ctxt, ops)) ) goto done;  cr0 = (cr0 & ~0xe) | (cr0w & 0xf); if ( (rc = ops->write_cr(0, cr0, ctxt)) ) goto done; break; case 7:  generate_exception_if(!mode_ring0(), EXC_GP, 0); generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); fail_if(ops->invlpg == NULL); if ( (rc = ops->invlpg(ea.mem.seg, ea.mem.off, ctxt)) ) goto done; break; default: goto cannot_emulate; } break; } case 0x05:{ uint64_t msr_content; struct segment_register cs, ss; generate_exception_if(in_realmode(ctxt, ops), EXC_UD, -1); generate_exception_if(!in_protmode(ctxt, ops), EXC_UD, -1);  fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_EFER, &msr_content, ctxt)) != 0 ) goto done; generate_exception_if((msr_content & EFER_SCE) == 0, EXC_UD, -1); if ( (rc = ops->read_msr(MSR_STAR, &msr_content, ctxt)) != 0 ) goto done; cs.sel = (msr_content >> 32) & ~3;  ss.sel = cs.sel + 8; cs.base = ss.base = 0;  cs.limit = ss.limit = ~0u; ss.attr.bytes = 0xc93;  #ifdef __x86_64__ rc = in_longmode(ctxt, ops); if ( rc < 0 ) goto cannot_emulate; if ( rc ) { cs.attr.bytes = 0xa9b;  _regs.rcx = _regs.rip; _regs.r11 = _regs.eflags & ~EFLG_RF; if ( (rc = ops->read_msr(mode_64bit() ? MSR_LSTAR : MSR_CSTAR,  &msr_content, ctxt)) != 0 ) goto done; _regs.rip = msr_content; if ( (rc = ops->read_msr(MSR_FMASK, &msr_content, ctxt)) != 0 ) goto done; _regs.eflags &= ~(msr_content | EFLG_RF); } else #endif { cs.attr.bytes = 0xc9b;  _regs.ecx = (uint32_t)_regs.eip; _regs.eip = (uint32_t)msr_content; _regs.eflags &= ~(EFLG_VM | EFLG_IF | EFLG_RF); } fail_if(ops->write_segment == NULL); if ( (rc = ops->write_segment(x86_seg_cs, &cs, ctxt)) ||  (rc = ops->write_segment(x86_seg_ss, &ss, ctxt)) ) goto done; break; } case 0x06:  generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if((ops->read_cr == NULL) || (ops->write_cr == NULL)); if ( (rc = ops->read_cr(0, &dst.val, ctxt)) ||  (rc = ops->write_cr(0, dst.val&~8, ctxt)) ) goto done; break; case 0x08:  case 0x09:  generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if(ops->wbinvd == NULL); if ( (rc = ops->wbinvd(ctxt)) != 0 ) goto done; break; case 0x0d:  case 0x18:  case 0x19 ... 0x1f:  break; case 0x2b:    fail_if(ea.type != OP_MEM);  case 0x28:    case 0x29:    fail_if(vex.pfx & VEX_PREFIX_SCALAR_MASK);  case 0x10:        case 0x11:        { uint8_t *buf = get_stub(stub); struct fpu_insn_ctxt fic = { .insn_bytes = 5 }; buf[0] = 0x3e; buf[1] = 0x3e; buf[2] = 0x0f; buf[3] = b; buf[4] = modrm; buf[5] = 0xc3; if ( vex.opcx == vex_none ) { if ( vex.pfx & VEX_PREFIX_DOUBLE_MASK ) vcpu_must_have_sse2(); else vcpu_must_have_sse(); ea.bytes = 16; SET_SSE_PREFIX(buf[0], vex.pfx); get_fpu(X86EMUL_FPU_xmm, &fic); } else { fail_if((vex.opcx != vex_0f) || ((vex.reg != 0xf) &&  ((ea.type == OP_MEM) || !(vex.pfx & VEX_PREFIX_SCALAR_MASK)))); vcpu_must_have_avx(); get_fpu(X86EMUL_FPU_ymm, &fic); ea.bytes = 16 << vex.l; } if ( vex.pfx & VEX_PREFIX_SCALAR_MASK ) ea.bytes = vex.pfx & VEX_PREFIX_DOUBLE_MASK ? 8 : 4; if ( ea.type == OP_MEM ) {  if ( !(b & 1) ) rc = ops->read(ea.mem.seg, ea.mem.off+0, mmvalp,  ea.bytes, ctxt);  rex_prefix &= ~REX_B; vex.b = 1; buf[4] &= 0x38; } if ( !rc ) {  copy_REX_VEX(buf, rex_prefix, vex);  asm volatile ( \"call *%0\" : : \"r\" (stub.func), \"a\" (mmvalp)  : \"memory\" ); } put_fpu(&fic); put_stub(stub); if ( !rc && (b & 1) && (ea.type == OP_MEM) ) rc = ops->write(ea.mem.seg, ea.mem.off, mmvalp, ea.bytes, ctxt); dst.type = OP_NONE; break; } case 0x20:  case 0x21:  case 0x22:  case 0x23:  generate_exception_if(ea.type != OP_REG, EXC_UD, -1); generate_exception_if(!mode_ring0(), EXC_GP, 0); modrm_reg |= lock_prefix << 3; if ( b & 2 ) {  src.val = *(unsigned long *)decode_register(modrm_rm, &_regs, 0); if ( !mode_64bit() ) src.val = (uint32_t)src.val; rc = ((b & 1) ? (ops->write_dr  ? ops->write_dr(modrm_reg, src.val, ctxt)  : X86EMUL_UNHANDLEABLE) : (ops->write_cr  ? ops->write_cr(modrm_reg, src.val, ctxt)  : X86EMUL_UNHANDLEABLE)); } else {  dst.type= OP_REG; dst.bytes = mode_64bit() ? 8 : 4; dst.reg = decode_register(modrm_rm, &_regs, 0); rc = ((b & 1) ? (ops->read_dr  ? ops->read_dr(modrm_reg, &dst.val, ctxt)  : X86EMUL_UNHANDLEABLE) : (ops->read_cr  ? ops->read_cr(modrm_reg, &dst.val, ctxt)  : X86EMUL_UNHANDLEABLE)); } if ( rc != 0 ) goto done; break; case 0x30:{ uint64_t val = ((uint64_t)_regs.edx << 32) | (uint32_t)_regs.eax; generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if(ops->write_msr == NULL); if ( (rc = ops->write_msr((uint32_t)_regs.ecx, val, ctxt)) != 0 ) goto done; break; } case 0x31: rdtsc:{ unsigned long cr4; uint64_t val; if ( !mode_ring0() ) { fail_if(ops->read_cr == NULL); if ( (rc = ops->read_cr(4, &cr4, ctxt)) ) goto done; generate_exception_if(cr4 & CR4_TSD, EXC_GP, 0); } fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_TSC, &val, ctxt)) != 0 ) goto done; _regs.edx = (uint32_t)(val >> 32); _regs.eax = (uint32_t)(val >>0); break; } case 0x32:{ uint64_t val; generate_exception_if(!mode_ring0(), EXC_GP, 0); fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr((uint32_t)_regs.ecx, &val, ctxt)) != 0 ) goto done; _regs.edx = (uint32_t)(val >> 32); _regs.eax = (uint32_t)(val >>0); break; } case 0x40 ... 0x4f:  dst.val = src.val; if ( !test_cc(b, _regs.eflags) ) dst.type = OP_NONE; break; case 0x34:{ uint64_t msr_content; struct segment_register cs, ss; int lm; generate_exception_if(mode_ring0(), EXC_GP, 0); generate_exception_if(in_realmode(ctxt, ops), EXC_GP, 0); generate_exception_if(!in_protmode(ctxt, ops), EXC_GP, 0); fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_SYSENTER_CS, &msr_content, ctxt)) != 0 ) goto done; generate_exception_if(!(msr_content & 0xfffc), EXC_GP, 0); lm = in_longmode(ctxt, ops); if ( lm < 0 ) goto cannot_emulate; _regs.eflags &= ~(EFLG_VM | EFLG_IF | EFLG_RF); fail_if(ops->read_segment == NULL); ops->read_segment(x86_seg_cs, &cs, ctxt); cs.sel = msr_content & ~3;  cs.base = 0;  cs.limit = ~0u; cs.attr.bytes = lm ? 0xa9b  : 0xc9b;  ss.sel = cs.sel + 8; ss.base = 0;  ss.limit = ~0u; ss.attr.bytes = 0xc93;  fail_if(ops->write_segment == NULL); if ( (rc = ops->write_segment(x86_seg_cs, &cs, ctxt)) != 0 ||  (rc = ops->write_segment(x86_seg_ss, &ss, ctxt)) != 0 ) goto done; if ( (rc = ops->read_msr(MSR_SYSENTER_EIP, &msr_content, ctxt)) != 0 ) goto done; _regs.eip = lm ? msr_content : (uint32_t)msr_content; if ( (rc = ops->read_msr(MSR_SYSENTER_ESP, &msr_content, ctxt)) != 0 ) goto done; _regs.esp = lm ? msr_content : (uint32_t)msr_content; break; } case 0x35:{ uint64_t msr_content; struct segment_register cs, ss; bool_t user64 = !!(rex_prefix & REX_W); generate_exception_if(!mode_ring0(), EXC_GP, 0); generate_exception_if(in_realmode(ctxt, ops), EXC_GP, 0); generate_exception_if(!in_protmode(ctxt, ops), EXC_GP, 0); fail_if(ops->read_msr == NULL); if ( (rc = ops->read_msr(MSR_SYSENTER_CS, &msr_content, ctxt)) != 0 ) goto done; generate_exception_if(!(msr_content & 0xfffc), EXC_GP, 0); cs.sel = (msr_content | 3) +   (user64 ? 32 : 16); cs.base = 0;  cs.limit = ~0u; cs.attr.bytes = user64 ? 0xafb  : 0xcfb;  ss.sel = cs.sel + 8; ss.base = 0;  ss.limit = ~0u; ss.attr.bytes = 0xcf3;  fail_if(ops->write_segment == NULL); if ( (rc = ops->write_segment(x86_seg_cs, &cs, ctxt)) != 0 ||  (rc = ops->write_segment(x86_seg_ss, &ss, ctxt)) != 0 ) goto done; _regs.eip = user64 ? _regs.edx : (uint32_t)_regs.edx; _regs.esp = user64 ? _regs.ecx : (uint32_t)_regs.ecx; break; } case 0xe7:      fail_if(ea.type != OP_MEM); fail_if(vex.pfx == vex_f3);  case 0x6f:      case 0x7f:      { uint8_t *buf = get_stub(stub); struct fpu_insn_ctxt fic = { .insn_bytes = 5 }; buf[0] = 0x3e; buf[1] = 0x3e; buf[2] = 0x0f; buf[3] = b; buf[4] = modrm; buf[5] = 0xc3; if ( vex.opcx == vex_none ) { switch ( vex.pfx ) { case vex_66: case vex_f3: vcpu_must_have_sse2(); buf[0] = 0x66;  get_fpu(X86EMUL_FPU_xmm, &fic); ea.bytes = 16; break; case vex_none: if ( b != 0xe7 ) vcpu_must_have_mmx(); else vcpu_must_have_sse(); get_fpu(X86EMUL_FPU_mmx, &fic); ea.bytes = 8; break; default: goto cannot_emulate; } } else { fail_if((vex.opcx != vex_0f) || (vex.reg != 0xf) || ((vex.pfx != vex_66) && (vex.pfx != vex_f3))); vcpu_must_have_avx(); get_fpu(X86EMUL_FPU_ymm, &fic); ea.bytes = 16 << vex.l; } if ( ea.type == OP_MEM ) {  if ( b == 0x6f ) rc = ops->read(ea.mem.seg, ea.mem.off+0, mmvalp,  ea.bytes, ctxt);  rex_prefix &= ~REX_B; vex.b = 1; buf[4] &= 0x38; } if ( !rc ) {  copy_REX_VEX(buf, rex_prefix, vex);  asm volatile ( \"call *%0\" : : \"r\" (stub.func), \"a\" (mmvalp)  : \"memory\" ); } put_fpu(&fic); put_stub(stub); if ( !rc && (b != 0x6f) && (ea.type == OP_MEM) ) rc = ops->write(ea.mem.seg, ea.mem.off, mmvalp, ea.bytes, ctxt); dst.type = OP_NONE; break; } case 0x80 ... 0x8f:{ int rel = ((op_bytes == 2)  ? (int32_t)insn_fetch_type(int16_t)  : insn_fetch_type(int32_t)); if ( test_cc(b, _regs.eflags) ) jmp_rel(rel); break; } case 0x90 ... 0x9f:  dst.val = test_cc(b, _regs.eflags); break; case 0xa0:  src.val = x86_seg_fs; goto push_seg; case 0xa1:  src.val = x86_seg_fs; goto pop_seg; case 0xa2:{ unsigned int eax = _regs.eax, ebx = _regs.ebx; unsigned int ecx = _regs.ecx, edx = _regs.edx; fail_if(ops->cpuid == NULL); if ( (rc = ops->cpuid(&eax, &ebx, &ecx, &edx, ctxt)) != 0 ) goto done; _regs.eax = eax; _regs.ebx = ebx; _regs.ecx = ecx; _regs.edx = edx; break; } case 0xa8:  src.val = x86_seg_gs; goto push_seg; case 0xa9:  src.val = x86_seg_gs; goto pop_seg; case 0xb0 ... 0xb1:   src.orig_val = src.val; src.val = _regs.eax;  emulate_2op_SrcV(\"cmp\", dst, src, _regs.eflags); if ( _regs.eflags & EFLG_ZF ) {  dst.val = src.orig_val; } else {  dst.type = OP_REG; dst.reg= (unsigned long *)&_regs.eax; } break; case 0xa3: bt:  emulate_2op_SrcV_nobyte(\"bt\", src, dst, _regs.eflags); dst.type = OP_NONE; break; case 0xa4:  case 0xa5:  case 0xac:  case 0xad:{ uint8_t shift, width = dst.bytes << 3; shift = (b & 1) ? (uint8_t)_regs.ecx : insn_fetch_type(uint8_t); if ( (shift &= width - 1) == 0 ) break; dst.orig_val = truncate_word(dst.val, dst.bytes); dst.val = ((shift == width) ? src.val :  (b & 8) ?    ((dst.orig_val >> shift) | truncate_word(src.val << (width - shift), dst.bytes)) :    ((dst.orig_val << shift) | ((src.val >> (width - shift)) & ((1ull << shift) - 1)))); dst.val = truncate_word(dst.val, dst.bytes); _regs.eflags &= ~(EFLG_OF|EFLG_SF|EFLG_ZF|EFLG_PF|EFLG_CF); if ( (dst.val >> ((b & 8) ? (shift - 1) : (width - shift))) & 1 ) _regs.eflags |= EFLG_CF; if ( ((dst.val ^ dst.orig_val) >> (width - 1)) & 1 ) _regs.eflags |= EFLG_OF; _regs.eflags |= ((dst.val >> (width - 1)) & 1) ? EFLG_SF : 0; _regs.eflags |= (dst.val == 0) ? EFLG_ZF : 0; _regs.eflags |= even_parity(dst.val) ? EFLG_PF : 0; break; } case 0xb3: btr:  emulate_2op_SrcV_nobyte(\"btr\", src, dst, _regs.eflags); break; case 0xab: bts:  emulate_2op_SrcV_nobyte(\"bts\", src, dst, _regs.eflags); break; case 0xae:  switch ( modrm_reg & 7 ) { case 7:  fail_if(modrm_mod == 3); fail_if(rep_prefix()); fail_if(ops->wbinvd == NULL); if ( (rc = ops->wbinvd(ctxt)) != 0 ) goto done; break; default: goto cannot_emulate; } break; case 0xaf:  _regs.eflags &= ~(EFLG_OF|EFLG_CF); switch ( dst.bytes ) { case 2: dst.val = ((uint32_t)(int16_t)src.val *  (uint32_t)(int16_t)dst.val); if ( (int16_t)dst.val != (uint32_t)dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; break; #ifdef __x86_64__ case 4: dst.val = ((uint64_t)(int32_t)src.val *  (uint64_t)(int32_t)dst.val); if ( (int32_t)dst.val != dst.val ) _regs.eflags |= EFLG_OF|EFLG_CF; break; #endif default: { unsigned long m[2] = { src.val, dst.val }; if ( imul_dbl(m) ) _regs.eflags |= EFLG_OF|EFLG_CF; dst.val = m[0]; break; } } break; case 0xb2:  dst.val = x86_seg_ss; goto les; case 0xb4:  dst.val = x86_seg_fs; goto les; case 0xb5:  dst.val = x86_seg_gs; goto les; case 0xb6:   dst.reg = decode_register(modrm_reg, &_regs, 0); dst.bytes = op_bytes; dst.val = (uint8_t)src.val; break; case 0xbc:{ bool_t zf; asm ( \"bsf %2,%0; setz %b1\" : \"=r\" (dst.val), \"=q\" (zf) : \"r\" (src.val) ); _regs.eflags &= ~EFLG_ZF; if ( (vex.pfx == vex_f3) && vcpu_has_bmi1() ) { _regs.eflags &= ~EFLG_CF; if ( zf ) { _regs.eflags |= EFLG_CF; dst.val = op_bytes * 8; } else if ( !dst.val ) _regs.eflags |= EFLG_ZF; } else if ( zf ) { _regs.eflags |= EFLG_ZF; dst.type = OP_NONE; } break; } case 0xbd:{ bool_t zf; asm ( \"bsr %2,%0; setz %b1\" : \"=r\" (dst.val), \"=q\" (zf) : \"r\" (src.val) ); _regs.eflags &= ~EFLG_ZF; if ( (vex.pfx == vex_f3) && vcpu_has_lzcnt() ) { _regs.eflags &= ~EFLG_CF; if ( zf ) { _regs.eflags |= EFLG_CF; dst.val = op_bytes * 8; } else { dst.val = op_bytes * 8 - 1 - dst.val; if ( !dst.val ) _regs.eflags |= EFLG_ZF; } } else if ( zf ) { _regs.eflags |= EFLG_ZF; dst.type = OP_NONE; } break; } case 0xb7:  dst.val = (uint16_t)src.val; break; case 0xbb: btc:  emulate_2op_SrcV_nobyte(\"btc\", src, dst, _regs.eflags); break; case 0xba:  switch ( modrm_reg & 7 ) { case 4: goto bt; case 5: goto bts; case 6: goto btr; case 7: goto btc; default: generate_exception_if(1, EXC_UD, -1); } break; case 0xbe:   dst.reg = decode_register(modrm_reg, &_regs, 0); dst.bytes = op_bytes; dst.val = (int8_t)src.val; break; case 0xbf:  dst.val = (int16_t)src.val; break; case 0xc0 ... 0xc1:   switch ( dst.bytes ) { case 1: *(uint8_t*)src.reg = (uint8_t)dst.val; break; case 2: *(uint16_t *)src.reg = (uint16_t)dst.val; break; case 4: *src.reg = (uint32_t)dst.val; break;  case 8: *src.reg = dst.val; break; } goto add; case 0xc3:   vcpu_must_have_sse2(); generate_exception_if(dst.bytes <= 2, EXC_UD, -1); dst.val = src.val; break; case 0xc7:{ unsigned long old[2], exp[2], new[2]; generate_exception_if((modrm_reg & 7) != 1, EXC_UD, -1); generate_exception_if(ea.type != OP_MEM, EXC_UD, -1); if ( op_bytes == 8 ) vcpu_must_have_cx16(); op_bytes *= 2;  if ( (rc = ops->read(ea.mem.seg, ea.mem.off, old, op_bytes,  ctxt)) != 0 ) goto done;  if ( op_bytes == 8 ) { ((uint32_t *)exp)[0] = _regs.eax; ((uint32_t *)exp)[1] = _regs.edx; ((uint32_t *)new)[0] = _regs.ebx; ((uint32_t *)new)[1] = _regs.ecx; } else { exp[0] = _regs.eax; exp[1] = _regs.edx; new[0] = _regs.ebx; new[1] = _regs.ecx; } if ( memcmp(old, exp, op_bytes) ) {  _regs.eax = (op_bytes == 8) ? ((uint32_t *)old)[0] : old[0]; _regs.edx = (op_bytes == 8) ? ((uint32_t *)old)[1] : old[1]; _regs.eflags &= ~EFLG_ZF; } else {  if ( (rc = ops->cmpxchg(ea.mem.seg, ea.mem.off, old, new, op_bytes, ctxt)) != 0 ) goto done; _regs.eflags |= EFLG_ZF; } break; } case 0xc8 ... 0xcf:  dst.type = OP_REG; dst.reg= decode_register( (b & 7) | ((rex_prefix & 1) << 3), &_regs, 0); switch ( dst.bytes = op_bytes ) { default:   dst.val = 0; break; case 4: #ifdef __x86_64__ asm ( \"bswap %k0\" : \"=r\" (dst.val) : \"0\" (*dst.reg) ); break; case 8: #endif asm ( \"bswap %0\" : \"=r\" (dst.val) : \"0\" (*dst.reg) ); break; } break; } goto writeback;  cannot_emulate: _put_fpu(); put_stub(stub); return X86EMUL_UNHANDLEABLE; }", "target": 1, "idx": 109409, "project": "Xen"}
{"func": "static void horizontalAccumulate16(uint16 *wp, int n, int stride, uint16 *op, uint16 *ToLinear16) { register unsigned intcr, cg, cb, ca, mask; if (n >= stride) { mask = CODE_MASK; if (stride == 3) { op[0] = ToLinear16[cr = (wp[0] & mask)]; op[1] = ToLinear16[cg = (wp[1] & mask)]; op[2] = ToLinear16[cb = (wp[2] & mask)]; n -= 3; while (n > 0) { wp += 3; op += 3; n -= 3; op[0] = ToLinear16[(cr += wp[0]) & mask]; op[1] = ToLinear16[(cg += wp[1]) & mask]; op[2] = ToLinear16[(cb += wp[2]) & mask]; } } else if (stride == 4) { op[0] = ToLinear16[cr = (wp[0] & mask)]; op[1] = ToLinear16[cg = (wp[1] & mask)]; op[2] = ToLinear16[cb = (wp[2] & mask)]; op[3] = ToLinear16[ca = (wp[3] & mask)]; n -= 4; while (n > 0) { wp += 4; op += 4; n -= 4; op[0] = ToLinear16[(cr += wp[0]) & mask]; op[1] = ToLinear16[(cg += wp[1]) & mask]; op[2] = ToLinear16[(cb += wp[2]) & mask]; op[3] = ToLinear16[(ca += wp[3]) & mask]; } } else { REPEAT(stride, *op = ToLinear16[*wp&mask]; wp++; op++) n -= stride; while (n > 0) { REPEAT(stride, wp[stride] += *wp; *op = ToLinear16[*wp&mask]; wp++; op++) n -= stride; } } } }", "target": 0, "idx": 100280, "project": "LibTIFF"}
{"func": "void *xc_map_foreign_bulk(xc_interface *xch, uint32_t dom, int prot, const xen_pfn_t *arr, int *err, unsigned int num) { return xenforeignmemory_map(xch->fmem, dom, prot, num, arr, err); }", "target": 0, "idx": 107502, "project": "Xen"}
{"func": "int expr_contains_symbol(struct expr *dep, struct symbol *sym) { if (!dep) return 0; switch (dep->type) { case E_AND: case E_OR: return expr_contains_symbol(dep->left.expr, sym) ||  expr_contains_symbol(dep->right.expr, sym); case E_SYMBOL: return dep->left.sym == sym; case E_EQUAL: case E_GEQ: case E_GTH: case E_LEQ: case E_LTH: case E_UNEQUAL: return dep->left.sym == sym ||  dep->right.sym == sym; case E_NOT: return expr_contains_symbol(dep->left.expr, sym); default: ; } return 0; }", "target": 0, "idx": 101935, "project": "Xen"}
{"func": "static void bootloader_finished(libxl__egc *egc, libxl__ev_child *child, pid_t pid, int status) { libxl__bootloader_state *bl = CONTAINER_OF(child, *bl, child); STATE_AO_GC(bl->ao); int rc; libxl__datacopier_kill(&bl->keystrokes); libxl__datacopier_kill(&bl->display); if (status) { if (bl->got_pollhup && WIFSIGNALED(status) && WTERMSIG(status)==SIGTERM) LOGD(ERROR, bl->domid, \"got POLLHUP, sent SIGTERM\"); LOGD(ERROR, bl->domid,  \"bootloader failed - consult logfile %s\", bl->logfile); libxl_report_child_exitstatus(CTX, XTL_ERROR, \"bootloader\", pid, status); rc = ERROR_FAIL; goto out; } else { LOGD(DEBUG, bl->domid, \"bootloader completed\"); } if (bl->rc) {  rc = bl->rc; goto out; } rc = parse_bootloader_result(egc, bl); if (rc) goto out; rc = 0; LOGD(DEBUG, bl->domid, \"bootloader execution successful\");  out: bootloader_callback(egc, bl, rc); }", "target": 0, "idx": 103363, "project": "Xen"}
{"func": "int libxl_bitmap_is_full(const libxl_bitmap *bitmap) { int i; for (i = 0; i < bitmap->size; i++) if (bitmap->map[i] != (uint8_t)-1) return 0;  return 1; }", "target": 0, "idx": 104108, "project": "Xen"}
{"func": "const char *xc_set_progress_prefix(xc_interface *xch, const char *doing) { const char *old = xch->currently_progress_reporting; xch->currently_progress_reporting = doing; return old; }", "target": 0, "idx": 107667, "project": "Xen"}
{"func": "static void colo_read_svm_resumed_done(libxl__egc *egc,  libxl__colo_save_state *css,  int id) { int ok = 0; libxl__domain_save_state *dss = CONTAINER_OF(css, *dss, css); EGC_GC; if (id != CHECKPOINT_SVM_RESUMED) { LOGD(ERROR, dss->domid, \"invalid section: %d, expected: %d\", id, CHECKPOINT_SVM_RESUMED); goto out; } colo_proxy_postresume(&css->cps); ok = 1; out: libxl__xc_domain_saverestore_async_callback_done(egc, &dss->sws.shs, ok); }", "target": 0, "idx": 103451, "project": "Xen"}
{"func": "static void qos_switch_out(int cpu, int domid, uint64_t now, unsigned long gotten) { int idx = indexof(domid); int n; if (!is_current(domid, cpu)) {  } if (gotten == 0) { printf(\"gotten==0 in qos_switchout(domid=%d)\\n\", domid); } if (gotten < 100) { printf(\"gotten<100ns in qos_switchout(domid=%d)\\n\", domid); } n = new_qos->next_datapoint; #if 0 new_qos->qdata[n].ns_gotten[idx] += gotten; if (gotten > new_qos->qdata[n].ns_passed) printf(\"inconsistency #257, diff = %lld\\n\",  gotten - new_qos->qdata[n].ns_passed ); #endif new_qos->domain_info[idx].ns_oncpu_since_boot += gotten; new_qos->domain_info[idx].runnable_start_time = now;  qos_update_thread_stats(cpu, domid, now);  if (domid == 0) if (dom0_flips == 0) new_qos->qdata[n].flip_free_periods++; }", "target": 0, "idx": 108164, "project": "Xen"}
{"func": "static void * smbios_type_2_init(void *start) { struct smbios_type_2 *p = (struct smbios_type_2 *)start; uint8_t *ptr; void *pts; uint32_t length; pts = get_smbios_pt_struct(2, &length); if ( (pts != NULL)&&(length > 0) ) { memcpy(start, pts, length); p->header.handle = SMBIOS_HANDLE_TYPE2;  if ( p->header.length > 13 ) { ptr = ((uint8_t*)start) + 11; if ( *((uint16_t*)ptr) != 0 ) *((uint16_t*)ptr) = SMBIOS_HANDLE_TYPE3; } return (start + length); }  return start; }", "target": 0, "idx": 105786, "project": "Xen"}
{"func": "static void conf_usage(const char *progname) { printf(\"Usage: %s [-s] [option] <kconfig-file>\\n\", progname); printf(\"[option] is _one_ of the following:\\n\"); printf(\"--listnewconfig List new options\\n\"); printf(\"--oldaskconfigStart a new configuration using a line-oriented program\\n\"); printf(\"--oldconfig Update a configuration using a provided .config as base\\n\"); printf(\"--silentoldconfig Same as oldconfig, but quietly, additionally update deps\\n\"); printf(\"--olddefconfigSame as silentoldconfig but sets new symbols to their default value\\n\"); printf(\"--oldnoconfig An alias of olddefconfig\\n\"); printf(\"--defconfig <file>New config with default defined in <file>\\n\"); printf(\"--savedefconfig <file>Save the minimal current configuration to <file>\\n\"); printf(\"--allnoconfig New config where all options are answered with no\\n\"); printf(\"--allyesconfigNew config where all options are answered with yes\\n\"); printf(\"--allmodconfigNew config where all options are answered with mod\\n\"); printf(\"--alldefconfigNew config with all symbols set to default\\n\"); printf(\"--randconfigNew config with random answer to all options\\n\"); }", "target": 0, "idx": 101367, "project": "Xen"}
{"func": "int main(int argc, char **argv) { int ret; struct sigaction act; time(&start_time); opts.poll_sleep = millis_to_timespec(POLL_SLEEP_MILLIS); opts.new_data_thresh = NEW_DATA_THRESH; opts.ms_per_sample = MS_PER_SAMPLE; opts.cpu_freq = CPU_FREQ; parse_args(argc, argv); fprintf(stderr, \"ms_per_sample = %ld\\n\", opts.ms_per_sample);  act.sa_handler = close_handler; act.sa_flags = 0; sigemptyset(&act.sa_mask); sigaction(SIGHUP,&act, NULL); sigaction(SIGTERM, &act, NULL); sigaction(SIGINT,&act, NULL); ret = monitor_tbufs(); dump_stats(); msync(new_qos, sizeof(_new_qos_data), MS_SYNC); disable_tracing(); return ret; }", "target": 0, "idx": 108153, "project": "Xen"}
{"func": "static value Val_mac (libxl_mac *c_val) { CAMLparam0(); CAMLlocal1(v); int i; v = caml_alloc_tuple(6); for(i=0; i<6; i++) Store_field(v, i, Val_int((*c_val)[i])); CAMLreturn(v); }", "target": 0, "idx": 108266, "project": "Xen"}
{"func": "static int rec_write(TDB_CONTEXT *tdb, tdb_off offset, struct list_struct *rec) { struct list_struct r = *rec; return tdb_write(tdb, offset, CONVERT(r), sizeof(r)); }", "target": 0, "idx": 106375, "project": "Xen"}
{"func": "struct xc_dom_image *xc_dom_allocate(xc_interface *xch,  const char *cmdline, const char *features) { struct xc_dom_image *dom; xc_dom_printf(xch, \"%s: cmdline=\\\"%s\\\", features=\\\"%s\\\"\", __FUNCTION__, cmdline, features); dom = malloc(sizeof(*dom)); if ( !dom ) goto err; memset(dom, 0, sizeof(*dom)); dom->xch = xch; if ( cmdline ) dom->cmdline = xc_dom_strdup(dom, cmdline); if ( features ) elf_xen_parse_features(features, dom->f_requested, NULL); dom->parms.virt_base = UNSET_ADDR; dom->parms.virt_entry = UNSET_ADDR; dom->parms.virt_hypercall = UNSET_ADDR; dom->parms.virt_hv_start_low = UNSET_ADDR; dom->parms.elf_paddr_offset = UNSET_ADDR; dom->alloc_malloc += sizeof(*dom); return dom;  err: if ( dom ) xc_dom_release(dom); return NULL; }", "target": 1, "idx": 109022, "project": "Xen"}
{"func": "void *xc__hypercall_buffer_alloc(xc_interface *xch, xc_hypercall_buffer_t *b, size_t size) { void *p = xencall_alloc_buffer(xch->xcall, size); if (!p) return NULL; b->hbuf = p; return b->hbuf; }", "target": 0, "idx": 107526, "project": "Xen"}
{"func": "static int __init brcm_smp_init(void) { u32 __iomem *scratch; u32 target_pc; scratch = ioremap_nocache(regs.scratch_reg, sizeof(u32)); if ( !scratch ) { dprintk(XENLOG_ERR, \"%s: Unable to map \\\"scratch_reg\\\"\\n\", __func__); return -EFAULT; }  brcm_boot_continuation_pc = readl(scratch); target_pc = __pa(init_secondary); writel(target_pc, scratch); iounmap(scratch); dprintk(XENLOG_INFO, \"%s: target_pc 0x%x boot continuation pc 0x%x\\n\", __func__, target_pc, brcm_boot_continuation_pc); return 0; }", "target": 0, "idx": 101274, "project": "Xen"}
{"func": "int guest_remove_page(struct domain *d, unsigned long gmfn) { struct page_info *page; #ifdef CONFIG_X86 p2m_type_t p2mt; #endif mfn_t mfn; int rc; #ifdef CONFIG_X86 mfn = get_gfn_query(d, gmfn, &p2mt); if ( unlikely(p2m_is_paging(p2mt)) ) { rc = guest_physmap_remove_page(d, _gfn(gmfn), mfn, 0); put_gfn(d, gmfn); if ( rc ) return rc;  if ( p2mt == p2m_ram_paging_out ) { ASSERT(mfn_valid(mfn)); page = mfn_to_page(mfn_x(mfn)); if ( test_and_clear_bit(_PGC_allocated, &page->count_info) ) put_page(page); } p2m_mem_paging_drop_page(d, gmfn, p2mt); return 0; } if ( p2mt == p2m_mmio_direct ) { rc = clear_mmio_p2m_entry(d, gmfn, mfn, PAGE_ORDER_4K); put_gfn(d, gmfn); return rc; } #else mfn = gfn_to_mfn(d, _gfn(gmfn)); #endif if ( unlikely(!mfn_valid(mfn)) ) { put_gfn(d, gmfn); gdprintk(XENLOG_INFO, \"Domain %u page number %lx invalid\\n\", d->domain_id, gmfn); return -EINVAL; }  #ifdef CONFIG_X86 if ( p2m_is_shared(p2mt) ) {  rc = mem_sharing_unshare_page(d, gmfn, 0); if ( rc ) { put_gfn(d, gmfn); (void)mem_sharing_notify_enomem(d, gmfn, 0); return rc; }  mfn = get_gfn_query_unlocked(d, gmfn, &p2mt); ASSERT(!p2m_is_shared(p2mt)); } #endif  page = mfn_to_page(mfn_x(mfn)); if ( unlikely(!get_page(page, d)) ) { put_gfn(d, gmfn); gdprintk(XENLOG_INFO, \"Bad page free for domain %u\\n\", d->domain_id); return -ENXIO; } rc = guest_physmap_remove_page(d, _gfn(gmfn), mfn, 0); #ifdef _PGT_pinned if ( !rc && test_and_clear_bit(_PGT_pinned, &page->u.inuse.type_info) ) put_page_and_type(page); #endif  if ( !rc && !is_domain_direct_mapped(d) &&  test_and_clear_bit(_PGC_allocated, &page->count_info) ) put_page(page); put_page(page); put_gfn(d, gmfn); return rc; }", "target": 1, "idx": 109639, "project": "Xen"}
{"func": "static int xc_tmem_uuid_parse(char *uuid_str, uint64_t *uuid_lo, uint64_t *uuid_hi) { char *p = uuid_str; uint64_t *x = uuid_hi; int i = 0, digit; *uuid_lo = 0; *uuid_hi = 0; for ( p = uuid_str, i = 0; i != 36 && *p != '\\0'; p++, i++ ) { if ( (i == 8 || i == 13 || i == 18 || i == 23) ) { if ( *p != '-' ) return -1; if ( i == 18 ) x = uuid_lo; continue; } else if ( *p >= '0' && *p <= '9' ) digit = *p - '0'; else if ( *p >= 'A' && *p <= 'F' ) digit = *p - 'A' + 10; else if ( *p >= 'a' && *p <= 'f' ) digit = *p - 'a' + 10; else return -1; *x = (*x << 4) | digit; } if ( (i != 1 && i != 36) || *p != '\\0' ) return -1; return 0; }", "target": 0, "idx": 107825, "project": "Xen"}
{"func": "int arch_set_info_guest( struct vcpu *v, vcpu_guest_context_u c) { struct domain *d = v->domain; unsigned long cr3_gfn; struct page_info *cr3_page; unsigned long flags, cr4; unsigned int i; int rc = 0, compat;  compat = is_pv_32bit_domain(d); #define c(fld) (compat ? (c.cmp->fld) : (c.nat->fld)) flags = c(flags); if ( is_pv_domain(d) ) { if ( !compat ) { if ( !is_canonical_address(c.nat->user_regs.eip) ||  !is_canonical_address(c.nat->event_callback_eip) ||  !is_canonical_address(c.nat->syscall_callback_eip) ||  !is_canonical_address(c.nat->failsafe_callback_eip) ) return -EINVAL; fixup_guest_stack_selector(d, c.nat->user_regs.ss); fixup_guest_stack_selector(d, c.nat->kernel_ss); fixup_guest_code_selector(d, c.nat->user_regs.cs); for ( i = 0; i < ARRAY_SIZE(c.nat->trap_ctxt); i++ ) { if ( !is_canonical_address(c.nat->trap_ctxt[i].address) ) return -EINVAL; fixup_guest_code_selector(d, c.nat->trap_ctxt[i].cs); } if ( !__addr_ok(c.nat->ldt_base) ) return -EINVAL; } else { fixup_guest_stack_selector(d, c.cmp->user_regs.ss); fixup_guest_stack_selector(d, c.cmp->kernel_ss); fixup_guest_code_selector(d, c.cmp->user_regs.cs); fixup_guest_code_selector(d, c.cmp->event_callback_cs); fixup_guest_code_selector(d, c.cmp->failsafe_callback_cs); for ( i = 0; i < ARRAY_SIZE(c.cmp->trap_ctxt); i++ ) fixup_guest_code_selector(d, c.cmp->trap_ctxt[i].cs); }  if ( ((c(ldt_base) & (PAGE_SIZE - 1)) != 0) ||  (c(ldt_ents) > 8192) ) return -EINVAL; } else if ( is_pvh_domain(d) ) { if ( c(ctrlreg[0]) || c(ctrlreg[1]) || c(ctrlreg[2]) ||  c(ctrlreg[4]) || c(ctrlreg[5]) || c(ctrlreg[6]) ||  c(ctrlreg[7]) ||c(ldt_base) || c(ldt_ents) ||  c(user_regs.cs) || c(user_regs.ss) || c(user_regs.es) ||  c(user_regs.ds) || c(user_regs.fs) || c(user_regs.gs) ||  c(kernel_ss) || c(kernel_sp) || c(gdt_ents) ||  (!compat && (c.nat->gs_base_kernel || c.nat->fs_base || c.nat->gs_base_user)) ) return -EINVAL; } v->fpu_initialised = !!(flags & VGCF_I387_VALID); v->arch.flags &= ~TF_kernel_mode; if ( (flags & VGCF_in_kernel) || has_hvm_container_domain(d) ) v->arch.flags |= TF_kernel_mode; v->arch.vgc_flags = flags; if ( flags & VGCF_I387_VALID ) { memcpy(v->arch.fpu_ctxt, &c.nat->fpu_ctxt, sizeof(c.nat->fpu_ctxt)); if ( v->arch.xsave_area )  v->arch.xsave_area->xsave_hdr.xstate_bv = XSTATE_FP_SSE; } if ( !compat ) { memcpy(&v->arch.user_regs, &c.nat->user_regs, sizeof(c.nat->user_regs)); if ( is_pv_domain(d) ) memcpy(v->arch.pv_vcpu.trap_ctxt, c.nat->trap_ctxt,  sizeof(c.nat->trap_ctxt)); } else { XLAT_cpu_user_regs(&v->arch.user_regs, &c.cmp->user_regs); if ( is_pv_domain(d) ) { for ( i = 0; i < ARRAY_SIZE(c.cmp->trap_ctxt); ++i ) XLAT_trap_info(v->arch.pv_vcpu.trap_ctxt + i,  c.cmp->trap_ctxt + i); } } if ( has_hvm_container_domain(d) ) { for ( i = 0; i < ARRAY_SIZE(v->arch.debugreg); ++i ) v->arch.debugreg[i] = c(debugreg[i]); hvm_set_info_guest(v); if ( is_hvm_domain(d) || v->is_initialised ) goto out;  cr3_gfn = c(ctrlreg[3]) >> PAGE_SHIFT; cr3_page = get_page_from_gfn(d, cr3_gfn, NULL, P2M_ALLOC); v->arch.cr3 = page_to_maddr(cr3_page); v->arch.hvm_vcpu.guest_cr[3] = c(ctrlreg[3]); v->arch.guest_table = pagetable_from_page(cr3_page); ASSERT(paging_mode_enabled(d)); goto pvh_skip_pv_stuff; } init_int80_direct_trap(v);  v->arch.pv_vcpu.iopl = (v->arch.user_regs.eflags >> 12) & 3; v->arch.user_regs.eflags &= ~X86_EFLAGS_IOPL;  v->arch.user_regs.eflags |= X86_EFLAGS_IF; if ( !v->is_initialised ) { if ( !compat && !(flags & VGCF_in_kernel) && !c.nat->ctrlreg[1] ) return -EINVAL; v->arch.pv_vcpu.ldt_base = c(ldt_base); v->arch.pv_vcpu.ldt_ents = c(ldt_ents); } else { unsigned long pfn = pagetable_get_pfn(v->arch.guest_table); bool_t fail; if ( !compat ) { fail = xen_pfn_to_cr3(pfn) != c.nat->ctrlreg[3]; if ( pagetable_is_null(v->arch.guest_table_user) ) fail |= c.nat->ctrlreg[1] || !(flags & VGCF_in_kernel); else { pfn = pagetable_get_pfn(v->arch.guest_table_user); fail |= xen_pfn_to_cr3(pfn) != c.nat->ctrlreg[1]; } } else { l4_pgentry_t *l4tab = map_domain_page(_mfn(pfn)); pfn = l4e_get_pfn(*l4tab); unmap_domain_page(l4tab); fail = compat_pfn_to_cr3(pfn) != c.cmp->ctrlreg[3]; } for ( i = 0; i < ARRAY_SIZE(v->arch.pv_vcpu.gdt_frames); ++i ) fail |= v->arch.pv_vcpu.gdt_frames[i] != c(gdt_frames[i]); fail |= v->arch.pv_vcpu.gdt_ents != c(gdt_ents); fail |= v->arch.pv_vcpu.ldt_base != c(ldt_base); fail |= v->arch.pv_vcpu.ldt_ents != c(ldt_ents); if ( fail )  return -EOPNOTSUPP; } v->arch.pv_vcpu.kernel_ss = c(kernel_ss); v->arch.pv_vcpu.kernel_sp = c(kernel_sp); for ( i = 0; i < ARRAY_SIZE(v->arch.pv_vcpu.ctrlreg); ++i ) v->arch.pv_vcpu.ctrlreg[i] = c(ctrlreg[i]); v->arch.pv_vcpu.event_callback_eip = c(event_callback_eip); v->arch.pv_vcpu.failsafe_callback_eip = c(failsafe_callback_eip); if ( !compat ) { v->arch.pv_vcpu.syscall_callback_eip = c.nat->syscall_callback_eip; v->arch.pv_vcpu.fs_base = c.nat->fs_base; v->arch.pv_vcpu.gs_base_kernel = c.nat->gs_base_kernel; v->arch.pv_vcpu.gs_base_user = c.nat->gs_base_user; } else { v->arch.pv_vcpu.event_callback_cs = c(event_callback_cs); v->arch.pv_vcpu.failsafe_callback_cs = c(failsafe_callback_cs); }  v->arch.pv_vcpu.ctrlreg[0] &= X86_CR0_TS; v->arch.pv_vcpu.ctrlreg[0] |= read_cr0() & ~X86_CR0_TS; cr4 = v->arch.pv_vcpu.ctrlreg[4]; v->arch.pv_vcpu.ctrlreg[4] = cr4 ? pv_guest_cr4_fixup(v, cr4) : real_cr4_to_pv_guest_cr4(mmu_cr4_features); memset(v->arch.debugreg, 0, sizeof(v->arch.debugreg)); for ( i = 0; i < 8; i++ ) (void)set_debugreg(v, i, c(debugreg[i])); if ( v->is_initialised ) goto out; if ( v->vcpu_id == 0 ) d->vm_assist = c(vm_assist); rc = put_old_guest_table(current); if ( rc ) return rc; if ( !compat ) rc = (int)set_gdt(v, c.nat->gdt_frames, c.nat->gdt_ents); else { unsigned long gdt_frames[ARRAY_SIZE(v->arch.pv_vcpu.gdt_frames)]; unsigned int n = (c.cmp->gdt_ents + 511) / 512; if ( n > ARRAY_SIZE(v->arch.pv_vcpu.gdt_frames) ) return -EINVAL; for ( i = 0; i < n; ++i ) gdt_frames[i] = c.cmp->gdt_frames[i]; rc = (int)set_gdt(v, gdt_frames, c.cmp->gdt_ents); } if ( rc != 0 ) return rc; set_bit(_VPF_in_reset, &v->pause_flags); if ( !compat ) cr3_gfn = xen_cr3_to_pfn(c.nat->ctrlreg[3]); else cr3_gfn = compat_cr3_to_pfn(c.cmp->ctrlreg[3]); cr3_page = get_page_from_gfn(d, cr3_gfn, NULL, P2M_ALLOC); if ( !cr3_page ) rc = -EINVAL; else if ( paging_mode_refcounts(d) ) ; else if ( cr3_page == v->arch.old_guest_table ) { v->arch.old_guest_table = NULL; put_page(cr3_page); } else { if ( !compat ) rc = put_old_guest_table(v); if ( !rc ) rc = get_page_type_preemptible(cr3_page,  !compat ? PGT_root_page_table  : PGT_l3_page_table); switch ( rc ) { case -EINTR: rc = -ERESTART; case -ERESTART: break; case 0: if ( !compat && !VM_ASSIST(d, m2p_strict) &&  !paging_mode_refcounts(d) ) fill_ro_mpt(cr3_gfn); break; default: if ( cr3_page == current->arch.old_guest_table ) cr3_page = NULL; break; } } if ( rc ) ; else if ( !compat ) { v->arch.guest_table = pagetable_from_page(cr3_page); if ( c.nat->ctrlreg[1] ) { cr3_gfn = xen_cr3_to_pfn(c.nat->ctrlreg[1]); cr3_page = get_page_from_gfn(d, cr3_gfn, NULL, P2M_ALLOC); if ( !cr3_page ) rc = -EINVAL; else if ( !paging_mode_refcounts(d) ) { rc = get_page_type_preemptible(cr3_page, PGT_root_page_table); switch ( rc ) { case -EINTR: rc = -ERESTART; case -ERESTART: v->arch.old_guest_table = pagetable_get_page(v->arch.guest_table); v->arch.guest_table = pagetable_null(); break; default: if ( cr3_page == current->arch.old_guest_table ) cr3_page = NULL; break; case 0: if ( VM_ASSIST(d, m2p_strict) ) zap_ro_mpt(cr3_gfn); break; } } if ( !rc )  v->arch.guest_table_user = pagetable_from_page(cr3_page); } } else { l4_pgentry_t *l4tab; l4tab = map_domain_page(_mfn(pagetable_get_pfn(v->arch.guest_table))); *l4tab = l4e_from_pfn(page_to_mfn(cr3_page), _PAGE_PRESENT|_PAGE_RW|_PAGE_USER|_PAGE_ACCESSED); unmap_domain_page(l4tab); } if ( rc ) { if ( cr3_page ) put_page(cr3_page); destroy_gdt(v); return rc; } clear_bit(_VPF_in_reset, &v->pause_flags);  pvh_skip_pv_stuff: if ( v->vcpu_id == 0 ) update_domain_wallclock_time(d);  v->is_initialised = 1; if ( paging_mode_enabled(d) ) paging_update_paging_modes(v); update_cr3(v);  out: if ( flags & VGCF_online ) clear_bit(_VPF_down, &v->pause_flags); else set_bit(_VPF_down, &v->pause_flags); return 0; #undef c }", "target": 1, "idx": 109326, "project": "Xen"}
{"func": "uint64_t nept_get_ept_vpid_cap(void) { uint64_t caps = 0; if ( cpu_has_vmx_ept ) caps |= NEPT_CAP_BITS; if ( !cpu_has_vmx_ept_exec_only_supported ) caps &= ~VMX_EPT_EXEC_ONLY_SUPPORTED; if ( cpu_has_vmx_vpid ) caps |= NVPID_CAP_BITS; return caps; }", "target": 0, "idx": 104803, "project": "Xen"}
{"func": "int xc_tmem_restore_extra(xc_interface *xch, uint32_t domid, int io_fd) { uint32_t pool_id; struct xen_tmem_oid oid; uint32_t index; int count = 0; int checksum = 0; while ( read_exact(io_fd, &pool_id, sizeof(pool_id)) == 0 && pool_id != -1 ) { if ( read_exact(io_fd, &oid, sizeof(oid)) ) return -1; if ( read_exact(io_fd, &index, sizeof(index)) ) return -1; if ( xc_tmem_control_oid(  xch, pool_id, XEN_SYSCTL_TMEM_OP_RESTORE_FLUSH_PAGE,  domid, 0, index, oid, NULL) <= 0 ) return -1; count++; checksum += pool_id + oid.oid[0] + oid.oid[1] + oid.oid[2] + index; } if ( pool_id != -1 ) return -1; if ( count ) DPRINTF(\"invalidated %d tmem pages, check=%d\\n\",count,checksum); return 0; }", "target": 0, "idx": 107821, "project": "Xen"}
{"func": "void WriteImage(TIFF *tif) { int i; char buffer[WIDTH]; memset(buffer,0,sizeof(buffer)); for (i=0;i<HEIGHT;i++) if (!TIFFWriteScanline(tif, buffer, i, 0)) TIFFErrorExt(tif->tif_clientdata, \"WriteImage\",\"failure in WriteScanline\\n\"); }", "target": 0, "idx": 100119, "project": "LibTIFF"}
{"func": "static int LZWSetupDecode(TIFF* tif) { static const char module[] = \"LZWSetupDecode\"; LZWCodecState* sp = DecoderState(tif); int code; if( sp == NULL ) {  tif->tif_data = (uint8*) _TIFFmalloc(sizeof(LZWCodecState)); if (tif->tif_data == NULL) { TIFFErrorExt(tif->tif_clientdata, module, \"No space for LZW state block\"); return (0); } DecoderState(tif)->dec_codetab = NULL; DecoderState(tif)->dec_decode = NULL;  (void) TIFFPredictorInit(tif); sp = DecoderState(tif); } assert(sp != NULL); if (sp->dec_codetab == NULL) { sp->dec_codetab = (code_t*)_TIFFmalloc(CSIZE*sizeof (code_t)); if (sp->dec_codetab == NULL) { TIFFErrorExt(tif->tif_clientdata, module,  \"No space for LZW code table\"); return (0); }  code = 255; do { sp->dec_codetab[code].value = (unsigned char)code; sp->dec_codetab[code].firstchar = (unsigned char)code; sp->dec_codetab[code].length = 1; sp->dec_codetab[code].next = NULL; } while (code--);   _TIFFmemset(&sp->dec_codetab[CODE_CLEAR], 0,  (CODE_FIRST - CODE_CLEAR) * sizeof (code_t)); } return (1); }", "target": 0, "idx": 100589, "project": "LibTIFF"}
{"func": "int blk_getimagesize(int fd, uint64_t *size) { int rc; *size = 0; rc = ioctl(fd, BLKGETSIZE, size); if (rc) { DPRINTF(\"ERR: BLKGETSIZE failed, couldn't stat image\"); return -EINVAL; } return 0; }", "target": 0, "idx": 101019, "project": "Xen"}
{"func": " */ static int __init hest_parse_cmc(const struct acpi_hest_header *hest_hdr,  void *data) { #ifdef CONFIG_X86_MCE unsigned int i; const struct acpi_hest_ia_corrected *cmc; const struct acpi_hest_ia_error_bank *mc_bank; if (hest_hdr->type != ACPI_HEST_TYPE_IA32_CORRECTED_CHECK) return 0; cmc = container_of(hest_hdr, const struct acpi_hest_ia_corrected, header); if (!cmc->enabled) return 0;  if (!(cmc->flags & ACPI_HEST_FIRMWARE_FIRST) || !cmc->num_hardware_banks) return 1; printk(XENLOG_INFO HEST_PFX \"Enabling Firmware First mode for corrected errors.\\n\"); mc_bank = (const struct acpi_hest_ia_error_bank *)(cmc + 1); for (i = 0; i < cmc->num_hardware_banks; i++, mc_bank++) mce_disable_bank(mc_bank->bank_number); #else # define acpi_disable_cmcff 1 #endif return 1; }", "target": 0, "idx": 102661, "project": "Xen"}
{"func": "int tapdisk_cancel_tiocbs(struct tqueue *queue) { return cancel_tiocbs(queue, -EIO); }", "target": 0, "idx": 106185, "project": "Xen"}
{"func": "int vhd_has_batmap(vhd_context_t *ctx) { if (!vhd_type_dynamic(ctx)) return 0; if (!vhd_creator_tapdisk(ctx)) return 0; if (ctx->footer.crtr_ver <= VHD_VERSION(0, 1)) return 0; if (ctx->footer.crtr_ver >= VHD_VERSION(1, 2)) return 1;  if (!vhd_validate_batmap_header(&ctx->batmap)) return 1; if (vhd_read_batmap_header(ctx, &ctx->batmap)) return 0; return (!vhd_validate_batmap_header(&ctx->batmap)); }", "target": 0, "idx": 103145, "project": "Xen"}
{"func": "static void * csched2_alloc_vdata(const struct scheduler *ops, struct vcpu *vc, void *dd) { struct csched2_vcpu *svc;  svc = xzalloc(struct csched2_vcpu); if ( svc == NULL ) return NULL; INIT_LIST_HEAD(&svc->rqd_elem); INIT_LIST_HEAD(&svc->runq_elem); svc->sdom = dd; svc->vcpu = vc; svc->flags = 0U; if ( ! is_idle_vcpu(vc) ) { ASSERT(svc->sdom != NULL); svc->credit = CSCHED2_CREDIT_INIT; svc->weight = svc->sdom->weight;  svc->avgload = 1ULL << (csched2_priv(ops)->load_precision_shift - 1); svc->load_last_update = NOW() >> LOADAVG_GRANULARITY_SHIFT; } else { ASSERT(svc->sdom == NULL); svc->credit = CSCHED2_IDLE_CREDIT; svc->weight = 0; } svc->tickled_cpu = -1; svc->budget = STIME_MAX; svc->budget_quota = 0; INIT_LIST_HEAD(&svc->parked_elem); SCHED_STAT_CRANK(vcpu_alloc); return svc; }", "target": 0, "idx": 105527, "project": "Xen"}
{"func": "static unsigned yy_location_print_ (FILE *yyo, YYLTYPE const * const yylocp) { unsigned res = 0; int end_col = 0 != yylocp->last_column ? yylocp->last_column - 1 : 0; if (0 <= yylocp->first_line) { res += YYFPRINTF (yyo, \"%d\", yylocp->first_line); if (0 <= yylocp->first_column) res += YYFPRINTF (yyo, \".%d\", yylocp->first_column); } if (0 <= yylocp->last_line) { if (yylocp->first_line < yylocp->last_line) { res += YYFPRINTF (yyo, \"-%d\", yylocp->last_line); if (0 <= end_col) res += YYFPRINTF (yyo, \".%d\", end_col); } else if (0 <= end_col && yylocp->first_column < end_col) res += YYFPRINTF (yyo, \"-%d\", end_col); } return res;  }", "target": 0, "idx": 103251, "project": "Xen"}
{"func": "int ebitmap_cpy(struct ebitmap *dst, struct ebitmap *src) { struct ebitmap_node *n, *new, *prev; ebitmap_init(dst); n = src->node; prev = NULL; while ( n ) { new = xzalloc(struct ebitmap_node); if ( !new ) { ebitmap_destroy(dst); return -ENOMEM; } new->startbit = n->startbit; memcpy(new->maps, n->maps, EBITMAP_SIZE / 8); new->next = NULL; if ( prev ) prev->next = new; else dst->node = new; prev = new; n = n->next; } dst->highbit = src->highbit; return 0; }", "target": 0, "idx": 101807, "project": "Xen"}
{"func": "int __init xsm_dt_init(void) { int ret = 0; void *policy_buffer = NULL; size_t policy_size = 0; printk(\"XSM Framework v\" XSM_FRAMEWORK_VERSION \" initialized\\n\"); if ( XSM_MAGIC ) { ret = xsm_dt_policy_init(&policy_buffer, &policy_size); if ( ret ) { printk(XENLOG_ERR \"Error %d initializing XSM policy\\n\", ret); return -EINVAL; } } ret = xsm_core_init(policy_buffer, policy_size); xfree(policy_buffer); return ret; }", "target": 0, "idx": 108956, "project": "Xen"}
{"func": "int main(int argc, char **argv) { struct xs_handle *xsh; xs_transaction_t xth = XBT_NULL; int ret = 0, socket = 0; int prefix = 0; int tidy = 0; int upto = 0; int recurse = 0; int nr_watches = -1; int transaction; struct winsize ws; enum mode mode; const char *_command = strrchr(argv[0], '/'); const char *command = _command ? &_command[1] : argv[0]; int switch_argv = -1;  if (strncmp(command, \"xenstore-\", strlen(\"xenstore-\")) == 0) { switch_argv = 0; command = command + strlen(\"xenstore-\"); } else if (argc < 2) usage(MODE_unknown, 0, argv[0]); else { command = argv[1]; switch_argv = 1; } mode = lookup_mode(command); while (1) { int c, index = 0; static struct option long_options[] = { {\"help\",0, 0, 'h'}, {\"flat\",0, 0, 'f'},  {\"socket\",0, 0, 's'}, {\"prefix\",0, 0, 'p'},  {\"tidy\",0, 0, 't'},  {\"upto\",0, 0, 'u'},  {\"recurse\", 0, 0, 'r'},  {\"number\",1, 0, 'n'},  {0, 0, 0, 0} }; c = getopt_long(argc - switch_argv, argv + switch_argv, \"hfspturn:\", long_options, &index); if (c == -1) break; switch (c) { case 'h': usage(mode, switch_argv, argv[0]);  case 'f': if ( mode == MODE_ls ) { max_width = INT_MAX/2; desired_width = 0; show_whole_path = 1; } else { usage(mode, switch_argv, argv[0]); } break; case 's': socket = 1; break; case 'p': if ( mode == MODE_read || mode == MODE_list || mode == MODE_ls ) prefix = 1; else usage(mode, switch_argv, argv[0]); break; case 't': if ( mode == MODE_rm ) tidy = 1; else usage(mode, switch_argv, argv[0]); break; case 'u': if ( mode == MODE_chmod ) upto = 1; else usage(mode, switch_argv, argv[0]); break; case 'r': if ( mode == MODE_chmod ) recurse = 1; else usage(mode, switch_argv, argv[0]); break; case 'n': if ( mode == MODE_watch ) nr_watches = atoi(optarg); else usage(mode, switch_argv, argv[0]); break; } } switch (mode) { case MODE_ls: break; case MODE_write: if ((argc - switch_argv - optind) % 2 == 1) { usage(mode, switch_argv, argv[0]);  }  default: if (optind == argc - switch_argv) { usage(mode, switch_argv, argv[0]);  } } switch (mode) { case MODE_read: transaction = (argc - switch_argv - optind) > 1; break; case MODE_write: transaction = (argc - switch_argv - optind) > 2; break; case MODE_ls: case MODE_watch: transaction = 0; break; default: transaction = 1; break; } if ( mode == MODE_ls ) { memset(&ws, 0, sizeof(ws)); ret = ioctl(STDOUT_FILENO, TIOCGWINSZ, &ws); if (!ret) max_width = ws.ws_col - 2; } xsh = xs_open(socket ? XS_OPEN_SOCKETONLY : 0); if (xsh == NULL) err(1, \"xs_open\"); again: if (transaction) { xth = xs_transaction_start(xsh); if (xth == XBT_NULL) errx(1, \"couldn't start transaction\"); } ret = perform(mode, optind, argc - switch_argv, argv + switch_argv, xsh, xth, prefix, tidy, upto, recurse, nr_watches); if (transaction && !xs_transaction_end(xsh, xth, ret)) { if (ret == 0 && errno == EAGAIN) { output_pos = 0; goto again; } errx(1, \"couldn't end transaction\"); } if (output_pos) printf(\"%s\", output_buf); free(output_buf); free(ebuf.buf); if (xsh) xs_close(xsh); return ret; }", "target": 0, "idx": 108483, "project": "Xen"}
{"func": "const libxl__srm_restore_autogen_callbacks* libxl__srm_callout_get_callbacks_restore(void *user) { libxl__save_helper_state *shs = user; return &shs->callbacks.restore.a; }", "target": 0, "idx": 103951, "project": "Xen"}
{"func": "grub_daddr32_t sbmap(fsi_file_t *ffi, grub_daddr32_t bn) { int level, bound, i, index; grub_daddr32_t nb, blkno; grub_daddr32_t *db = INODE->ic_db;  if (bn < UFS_NDADDR) { return db[bn]; }  level = 0; bn -= UFS_NDADDR; bound = UFS_NINDIR(SUPERBLOCK); while (bn >= bound) { level++; bn -= bound; bound *= UFS_NINDIR(SUPERBLOCK); } if (level >= UFS_NIADDR) return ((grub_daddr32_t)0);  nb = INODE->ic_ib[level]; if (nb == 0) { return ((grub_daddr32_t)0); } if (indirblk0 != nb) { indirblk0 = 0; blkno = fsbtodb(SUPERBLOCK, nb); if (!devread(ffi, blkno, 0, SUPERBLOCK->fs_bsize, (char *)INDIRBLK0)) return (0); indirblk0 = nb; } bound /= UFS_NINDIR(SUPERBLOCK); index = (bn / bound) % UFS_NINDIR(SUPERBLOCK); nb = INDIRBLK0[index];  for (i = 1; i <= level; i++) { if (indirblk1 != nb) { blkno = fsbtodb(SUPERBLOCK, nb); if (!devread(ffi, blkno, 0, SUPERBLOCK->fs_bsize, (char *)INDIRBLK1)) return (0); indirblk1 = nb; } bound /= UFS_NINDIR(SUPERBLOCK); index = (bn / bound) % UFS_NINDIR(SUPERBLOCK); nb = INDIRBLK1[index]; if (nb == 0) return ((grub_daddr32_t)0); } return (nb); }", "target": 0, "idx": 102162, "project": "Xen"}
{"func": " */ static int calculate_tbuf_size(unsigned int pages, uint16_t t_info_first_offset) { struct t_buf dummy_size; typeof(dummy_size.prod) max_size; struct t_info dummy_pages; typeof(dummy_pages.tbuf_size) max_pages; typeof(dummy_pages.mfn_offset[0]) max_mfn_offset; unsigned int max_cpus = num_online_cpus(); unsigned int t_info_words;  max_size = -1; max_pages = -1; max_mfn_offset = -1;  max_size /= PAGE_SIZE; if ( max_size < max_pages ) max_pages = max_size;  max_mfn_offset -= t_info_first_offset; max_cpus--; if ( max_cpus ) max_mfn_offset /= max_cpus; if ( max_mfn_offset < max_pages ) max_pages = max_mfn_offset; if ( pages > max_pages ) { printk(XENLOG_INFO \"xentrace: requested number of %u pages \"  \"reduced to %u\\n\",  pages, max_pages); pages = max_pages; }  t_info_words = num_online_cpus() * pages + t_info_first_offset; t_info_pages = PFN_UP(t_info_words * sizeof(uint32_t)); printk(XENLOG_INFO \"xentrace: requesting %u t_info pages \"  \"for %u trace pages on %u cpus\\n\",  t_info_pages, pages, num_online_cpus()); return pages; }", "target": 0, "idx": 106499, "project": "Xen"}
{"func": "static inline void radix_tree_clear_link(radix_tree_link_t *link) { if (link) memset(link, 0, sizeof(radix_tree_link_t)); }", "target": 0, "idx": 101049, "project": "Xen"}
{"func": " */ int mls_context_to_sid(char oldc, char **scontext,  struct context *context, struct sidtab *s) { char delim; char *scontextp, *p, *rngptr; struct level_datum *levdatum; struct cat_datum *catdatum, *rngdatum; int l, rc = -EINVAL; if ( !flask_mls_enabled ) return 0;  if ( !oldc ) goto out;  scontextp = p = *scontext; while ( *p && *p != ':' && *p != '-' ) p++; delim = *p; if ( delim != 0 ) *p++ = 0; for ( l = 0; l < 2; l++ ) { levdatum = hashtab_search(policydb.p_levels.table, scontextp); if ( !levdatum ) { rc = -EINVAL; goto out; } context->range.level[l].sens = levdatum->level->sens; if ( delim == ':' ) {  while ( 1 ) { scontextp = p; while ( *p && *p != ',' && *p != '-' ) p++; delim = *p; if ( delim != 0 ) *p++ = 0;  if ( (rngptr = strchr(scontextp, '.')) != NULL ) {  *rngptr++ = 0; } catdatum = hashtab_search(policydb.p_cats.table, scontextp); if ( !catdatum ) { rc = -EINVAL; goto out; } rc = ebitmap_set_bit(&context->range.level[l].cat, catdatum->value - 1, 1); if ( rc ) goto out;  if ( rngptr ) { int i; rngdatum = hashtab_search(policydb.p_cats.table, rngptr); if ( !rngdatum ) { rc = -EINVAL; goto out; } if ( catdatum->value >= rngdatum->value ) { rc = -EINVAL; goto out; } for ( i = catdatum->value; i < rngdatum->value; i++ ) { rc = ebitmap_set_bit(&context->range.level[l].cat, i, 1); if ( rc ) goto out; } } if ( delim != ',' ) break; } } if ( delim == '-' ) {  scontextp = p; while ( *p && *p != ':' ) p++; delim = *p; if ( delim != 0 ) *p++ = 0; } else break; } if ( l == 0 ) { context->range.level[1].sens = context->range.level[0].sens; rc = ebitmap_cpy(&context->range.level[1].cat,  &context->range.level[0].cat); if ( rc ) goto out; } *scontext = ++p; rc = 0; out: return rc; }", "target": 0, "idx": 104614, "project": "Xen"}
{"func": "static inline u32 get_xen_cpu_khz(void) { u32 cpu_khz, dummy1, dummy2, dummy3; pv_cpuid(0x40000003,2,&cpu_khz,&dummy1,&dummy2,&dummy3); return cpu_khz; }", "target": 0, "idx": 105230, "project": "Xen"}
{"func": "static value Val_some(value v) { CAMLparam1(v); CAMLlocal1(some); some = caml_alloc(1, 0); Store_field(some, 0, v); CAMLreturn(some); }", "target": 0, "idx": 108494, "project": "Xen"}
{"func": "static struct page_info *kimage_alloc_normal_control_page( struct kexec_image *image, unsigned memflags) {  struct page_list_head extra_pages; struct page_info *page = NULL; INIT_PAGE_LIST_HEAD(&extra_pages);  do { paddr_t addr, eaddr; page = kimage_alloc_zeroed_page(memflags); if ( !page ) break; addr= page_to_maddr(page); eaddr = addr + PAGE_SIZE; if ( kimage_is_destination_range(image, addr, eaddr) ) { page_list_add(page, &extra_pages); page = NULL; } } while ( !page ); if ( page ) {  page_list_add(page, &image->control_pages);  }  kimage_free_page_list(&extra_pages); return page; }", "target": 0, "idx": 102984, "project": "Xen"}
{"func": "int libxl__qmp_insert_cdrom(libxl__gc *gc, int domid, const libxl_device_disk *disk) { libxl__json_object *args = NULL; int dev_number = libxl__device_disk_dev_number(disk->vdev, NULL, NULL); QMP_PARAMETERS_SPRINTF(&args, \"device\", \"ide-%i\", dev_number); if (disk->format == LIBXL_DISK_FORMAT_EMPTY) { return qmp_run_command(gc, domid, \"eject\", args, NULL, NULL); } else { qmp_parameters_add_string(gc, &args, \"target\", disk->pdev_path); qmp_parameters_add_string(gc, &args, \"arg\", libxl__qemu_disk_format_string(disk->format)); return qmp_run_command(gc, domid, \"change\", args, NULL, NULL); } }", "target": 0, "idx": 103869, "project": "Xen"}
{"func": "static void virt_timer_expired(void *data) { struct vtimer *t = data; t->ctl |= CNTx_CTL_MASK; vgic_inject_irq(t->v->domain, t->v, t->irq, true); perfc_incr(vtimer_virt_inject); }", "target": 0, "idx": 107166, "project": "Xen"}
{"func": "static int compare_cpu(xenstat_domain *domain1, xenstat_domain *domain2) { return -compare(xenstat_domain_cpu_ns(domain1), xenstat_domain_cpu_ns(domain2)); }", "target": 0, "idx": 108501, "project": "Xen"}
{"func": "static inline int ring_isempty(struct req_ring* ring) { return ring->head == ring->tail; }", "target": 0, "idx": 101131, "project": "Xen"}
{"func": "static int lvm_parse_lv_devices(struct vg *vg, struct lv_segment *seg, char *devices) { int i; uint64_t start, pe_start; for (i = 0; i < strlen(devices); i++) if (strchr(\",()\", devices[i])) devices[i] = ' '; if (sscanf(devices, _NAME\" %\"SCNu64, seg->device, &start) != 2) return -EINVAL; pe_start = -1; for (i = 0; i < vg->pv_cnt; i++) if (!strcmp(vg->pvs[i].name, seg->device)) { pe_start = vg->pvs[i].start; break; } if (pe_start == -1) return -EINVAL; seg->pe_start = (start * vg->extent_size) + pe_start; return 0; }", "target": 0, "idx": 104295, "project": "Xen"}
{"func": "void *xc_gnttab_map_grant_ref_notify(xc_gnttab *xcg,  uint32_t domid,  uint32_t ref,  int prot,  uint32_t notify_offset,  evtchn_port_t notify_port) { return xengnttab_map_grant_ref_notify(xcg, domid, ref, prot, notify_offset, notify_port); }", "target": 0, "idx": 107518, "project": "Xen"}
{"func": "int xc_tmem_auth(xc_interface *xch,  int cli_id,  char *uuid_str,  int enable) { xen_tmem_pool_info_t pool = { .flags.u.auth = enable, .id = 0, .n_pages = 0, .uuid[0] = 0, .uuid[1] = 0, }; if ( xc_tmem_uuid_parse(uuid_str, &pool.uuid[0], &pool.uuid[1]) < 0 ) { PERROR(\"Can't parse uuid, use xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"); return -1; } return xc_tmem_control(xch, 0 ,  XEN_SYSCTL_TMEM_OP_SET_AUTH,  cli_id, sizeof(pool),  0 , &pool); }", "target": 0, "idx": 107818, "project": "Xen"}
{"func": "static toff_t _tiffSeekProc(thandle_t fd, toff_t off, int whence) { return (lseek((int) fd, (off_t) off, whence)); }", "target": 0, "idx": 100224, "project": "LibTIFF"}
{"func": "static int vioapic_write( struct vcpu *v, unsigned long addr, unsigned int length, unsigned long val) { struct hvm_vioapic *vioapic; vioapic = addr_vioapic(v->domain, addr); ASSERT(vioapic); switch ( addr & 0xff ) { case VIOAPIC_REG_SELECT: vioapic->ioregsel = val; break; case VIOAPIC_REG_WINDOW: vioapic_write_indirect(vioapic, val); break; #if VIOAPIC_VERSION_ID >= 0x20 case VIOAPIC_REG_EOI: vioapic_update_EOI(v->domain, val); break; #endif default: break; } return X86EMUL_OKAY; }", "target": 0, "idx": 106884, "project": "Xen"}
{"func": "void* _TIFFmalloc(tsize_t s) { return (malloc((size_t) s)); }", "target": 0, "idx": 100079, "project": "LibTIFF"}
{"func": "void libxl__poller_put(libxl_ctx *ctx, libxl__poller *p) { if (!p) return; LIBXL_LIST_REMOVE(p, fds_changed_entry); LIBXL_LIST_INSERT_HEAD(&ctx->pollers_idle, p, entry); }", "target": 0, "idx": 103658, "project": "Xen"}
{"func": "static void pt_lock(struct periodic_time *pt) { struct vcpu *v; for ( ; ; ) { v = pt->vcpu; spin_lock(&v->arch.hvm_vcpu.tm_lock); if ( likely(pt->vcpu == v) ) break; spin_unlock(&v->arch.hvm_vcpu.tm_lock); } }", "target": 1, "idx": 109582, "project": "Xen"}
{"func": "static void dump_guest_os_id(const struct domain *d) { const union viridian_guest_os_id *goi; goi = &d->arch.hvm_domain.viridian.guest_os_id; printk(XENLOG_G_INFO  \"d%d: VIRIDIAN GUEST_OS_ID: vendor: %x os: %x major: %x minor: %x sp: %x build: %x\\n\",  d->domain_id,  goi->fields.vendor, goi->fields.os,  goi->fields.major, goi->fields.minor,  goi->fields.service_pack, goi->fields.build_number); }", "target": 0, "idx": 106888, "project": "Xen"}
{"func": "static int microcode_sanity_check(void *mc) { struct microcode_header_intel *mc_header = mc; struct extended_sigtable *ext_header = NULL; struct extended_signature *ext_sig; unsigned long total_size, data_size, ext_table_size; unsigned int ext_sigcount = 0, i; uint32_t sum, orig_sum; total_size = get_totalsize(mc_header); data_size = get_datasize(mc_header); if ( (data_size + MC_HEADER_SIZE) > total_size ) { printk(KERN_ERR \"microcode: error! \"  \"Bad data size in microcode data file\\n\"); return -EINVAL; } if ( (mc_header->ldrver != 1) || (mc_header->hdrver != 1) ) { printk(KERN_ERR \"microcode: error! \"  \"Unknown microcode update format\\n\"); return -EINVAL; } ext_table_size = total_size - (MC_HEADER_SIZE + data_size); if ( ext_table_size ) { if ( (ext_table_size < EXT_HEADER_SIZE) ||  ((ext_table_size - EXT_HEADER_SIZE) % EXT_SIGNATURE_SIZE) ) { printk(KERN_ERR \"microcode: error! \"  \"Small exttable size in microcode data file\\n\"); return -EINVAL; } ext_header = mc + MC_HEADER_SIZE + data_size; if ( ext_table_size != exttable_size(ext_header) ) { printk(KERN_ERR \"microcode: error! \"  \"Bad exttable size in microcode data file\\n\"); return -EFAULT; } ext_sigcount = ext_header->count; }  if ( ext_table_size ) { uint32_t ext_table_sum = 0; uint32_t *ext_tablep = (uint32_t *)ext_header; i = ext_table_size / DWSIZE; while ( i-- ) ext_table_sum += ext_tablep[i]; if ( ext_table_sum ) { printk(KERN_WARNING \"microcode: aborting, \"  \"bad extended signature table checksum\\n\"); return -EINVAL; } }  orig_sum = 0; i = (MC_HEADER_SIZE + data_size) / DWSIZE; while ( i-- ) orig_sum += ((uint32_t *)mc)[i]; if ( orig_sum ) { printk(KERN_ERR \"microcode: aborting, bad checksum\\n\"); return -EINVAL; } if ( !ext_table_size ) return 0;  for ( i = 0; i < ext_sigcount; i++ ) { ext_sig = (void *)ext_header + EXT_HEADER_SIZE + EXT_SIGNATURE_SIZE * i; sum = orig_sum - (mc_header->sig + mc_header->pf + mc_header->cksum) + (ext_sig->sig + ext_sig->pf + ext_sig->cksum); if ( sum ) { printk(KERN_ERR \"microcode: aborting, bad checksum\\n\"); return -EINVAL; } } return 0; }", "target": 0, "idx": 104557, "project": "Xen"}
{"func": "static int vhd_util_check_batmap(vhd_context_t *vhd) { char *msg; int i, err; err = vhd_get_bat(vhd); if (err) { printf(\"error reading bat: %d\\n\", err); return err; } err = vhd_get_batmap(vhd); if (err) { printf(\"error reading batmap: %d\\n\", err); return err; } msg = vhd_util_check_validate_batmap(vhd, &vhd->batmap); if (msg) { printf(\"batmap is invalid: %s\\n\", msg); return -EINVAL; } for (i = 0; i < vhd->header.max_bat_size; i++) { if (!vhd_batmap_test(vhd, &vhd->batmap, i)) continue; if (vhd->bat.bat[i] == DD_BLK_UNUSED) { printf(\"batmap shows unallocated block %d full\\n\", i); return -EINVAL; } } return 0; }", "target": 0, "idx": 106751, "project": "Xen"}
{"func": "static int psr_val_show(uint32_t domid, libxl_psr_feat_type type, unsigned int lvl) { unsigned int i, nr; int rc; libxl_psr_hw_info *info; switch (type) { case LIBXL_PSR_FEAT_TYPE_CAT: if (lvl != 2 && lvl != 3) { fprintf(stderr, \"Input lvl %d is wrong\\n\", lvl); return EXIT_FAILURE; } break; case LIBXL_PSR_FEAT_TYPE_MBA: if (lvl) { fprintf(stderr, \"Unexpected lvl parameter %d for MBA feature\\n\", lvl); return EXIT_FAILURE; } break; default: fprintf(stderr, \"Input feature type %d is wrong\\n\", type); return EXIT_FAILURE; } rc = libxl_psr_get_hw_info(ctx, type, lvl, &nr, &info); if (rc) { fprintf(stderr, \"Failed to get info\\n\"); return rc; } for (i = 0; i < nr; i++) { rc = psr_print_socket(domid, info + i, type, lvl); if (rc) goto out; } out: libxl_psr_hw_info_list_free(info, nr); return rc; }", "target": 0, "idx": 108777, "project": "Xen"}
{"func": "void mce_barrier_exit(struct mce_softirq_barrier *bar, bool wait) { int gen; if ( !wait ) return; atomic_inc(&bar->outgen); gen = atomic_read(&bar->ingen); smp_mb(); atomic_dec(&bar->val); while ( atomic_read(&bar->val) != 0 && atomic_read(&bar->ingen) == gen ) { smp_mb(); mce_panic_check(); } }", "target": 0, "idx": 100950, "project": "Xen"}
{"func": "static void usage(char** argv) { fprintf(stderr, \"usage:\\n\" \"\\t%s [client|server] domainid nodepath [rbufsiz wbufsiz]\\n\", argv[0]); exit(1); }", "target": 0, "idx": 104866, "project": "Xen"}
{"func": "static inline xc_psr_type libxl__psr_type_to_libxc_psr_type( libxl_psr_type type) { BUILD_BUG_ON(sizeof(libxl_psr_type) != sizeof(xc_psr_type)); return (xc_psr_type)type; }", "target": 0, "idx": 103857, "project": "Xen"}
{"func": "static void __devinit init_amd(struct cpuinfo_x86 *c) { u32 l, h; unsigned long long value;  if (c->x86 == 15) { rdmsrl(MSR_K7_HWCR, value); value |= 1 << 6; wrmsrl(MSR_K7_HWCR, value); }   clear_bit(0*32+31, c->x86_capability);  #ifdef CONFIG_X86_64 if (c->x86 == 0xf && c->x86_model < 0x14 && cpu_has(c, X86_FEATURE_LAHF_LM)) {  unsigned int lo, hi; clear_bit(X86_FEATURE_LAHF_LM, c->x86_capability); if (!rdmsr_amd_safe(0xc001100d, &lo, &hi)) { hi &= ~1; wrmsr_amd_safe(0xc001100d, lo, hi); } } #endif switch(c->x86) { case 6:     if (c->x86_model >= 6 && c->x86_model <= 10) { if (!cpu_has(c, X86_FEATURE_XMM)) { printk(KERN_INFO \"Enabling disabled K7/SSE Support.\\n\"); rdmsr(MSR_K7_HWCR, l, h); l &= ~0x00008000; wrmsr(MSR_K7_HWCR, l, h); set_bit(X86_FEATURE_XMM, c->x86_capability); } }  if ((c->x86_model == 8 && c->x86_mask>=1) || (c->x86_model > 8)) { rdmsr(MSR_K7_CLK_CTL, l, h); if ((l & 0xfff00000) != 0x20000000) { printk (\"CPU: CLK_CTL MSR was %x. Reprogramming to %x\\n\", l, ((l & 0x000fffff)|0x20000000)); wrmsr(MSR_K7_CLK_CTL, (l & 0x000fffff)|0x20000000, h); } } set_bit(X86_FEATURE_K7, c->x86_capability); break; case 0xf:  case 0x10 ... 0x17: set_bit(X86_FEATURE_K8, c->x86_capability); disable_c1e(NULL); if (acpi_smi_cmd && (acpi_enable_value | acpi_disable_value)) pv_post_outb_hook = check_disable_c1e; break; } display_cacheinfo(c); if (cpuid_eax(0x80000000) >= 0x80000008) { c->x86_max_cores = (cpuid_ecx(0x80000008) & 0xff) + 1; } if (cpuid_eax(0x80000000) >= 0x80000007) { c->x86_power = cpuid_edx(0x80000007); if (c->x86_power & (1<<8)) { set_bit(X86_FEATURE_CONSTANT_TSC, c->x86_capability); set_bit(X86_FEATURE_NONSTOP_TSC, c->x86_capability); if (c->x86 != 0x11) set_bit(X86_FEATURE_TSC_RELIABLE, c->x86_capability); } }  if ((c->x86 == 0x15) && (c->x86_model >= 0x10) && (c->x86_model <= 0x1f) && !cpu_has(c, X86_FEATURE_TOPOEXT) && !rdmsr_safe(MSR_K8_EXT_FEATURE_MASK, value)) { value |= 1ULL << 54; wrmsr_safe(MSR_K8_EXT_FEATURE_MASK, value); rdmsrl(MSR_K8_EXT_FEATURE_MASK, value); if (value & (1ULL << 54)) { set_bit(X86_FEATURE_TOPOEXT, c->x86_capability); printk(KERN_INFO \"CPU: Re-enabling disabled \"  \"Topology Extensions Support\\n\"); } } amd_get_topology(c);  if (c->x86 >= 0x10 && !force_mwait) clear_bit(X86_FEATURE_MWAIT, c->x86_capability); #ifdef __x86_64__ if (!cpu_has_amd_erratum(c, AMD_ERRATUM_121)) opt_allow_unsafe = 1; else if (opt_allow_unsafe < 0) panic(\"Xen will not boot on this CPU for security reasons.\\n\" \"Pass \\\"allow_unsafe\\\" if you're trusting all your\" \" (PV) guest kernels.\\n\"); else if (!opt_allow_unsafe && c == &boot_cpu_data) printk(KERN_WARNING  \"*** Xen will not allow creation of DomU-s on\"  \" this CPU for security reasons. ***\\n\"  KERN_WARNING  \"*** Pass \\\"allow_unsafe\\\" if you're trusting\"  \" all your (PV) guest kernels. ***\\n\");  clear_bit(X86_FEATURE_SEP, c->x86_capability); if (c->x86 == 0x10) {  if (c == &boot_cpu_data) check_enable_amd_mmconf_dmi(); fam10h_check_enable_mmcfg(); } #endif  if (c->x86 > 0x11) set_bit(X86_FEATURE_ARAT, c->x86_capability); if (cpuid_edx(0x80000007) & (1 << 10)) { rdmsr(MSR_K7_HWCR, l, h); l |= (1 << 27);  wrmsr(MSR_K7_HWCR, l, h); }  if ((smp_processor_id() == 1) && c1_ramping_may_cause_clock_drift(c)) disable_c1_ramping(); set_cpuidmask(c); check_syscfg_dram_mod_en(); }", "target": 1, "idx": 109148, "project": "Xen"}
{"func": "void *xengnttab_map_domain_grant_refs(xengnttab_handle *xgt, uint32_t count, uint32_t domid, uint32_t *refs, int prot) { abort(); }", "target": 0, "idx": 102582, "project": "Xen"}
{"func": "int libxl__resolve_domid(libxl__gc *gc, const char *name, uint32_t *domid) { if (!name) return 0; return libxl_domain_qualifier_to_domid(CTX, name, domid); }", "target": 0, "idx": 103555, "project": "Xen"}
{"func": "static unsigned long raw_copy_to_guest_helper(void *to, const void *from, unsigned len, int flush_dcache) {  unsigned offset = (vaddr_t)to & ~PAGE_MASK; while ( len ) { paddr_t g; void *p; unsigned size = min(len, (unsigned)PAGE_SIZE - offset); if ( gvirt_to_maddr((vaddr_t) to, &g) ) return len; p = map_domain_page(g>>PAGE_SHIFT); p += offset; memcpy(p, from, size); if ( flush_dcache ) clean_xen_dcache_va_range(p, size); unmap_domain_page(p - offset); len -= size; from += size; to += size;  offset = 0; } return 0; }", "target": 1, "idx": 109184, "project": "Xen"}
{"func": "static int vhd_util_scan_get_volume_parent(vhd_context_t *vhd, struct vhd_image *image) { int err; char name[VHD_MAX_NAME_LEN]; vhd_parent_locator_t *loc, copy; if (flags & VHD_SCAN_FAST) { err = vhd_header_decode_parent(vhd,  &vhd->header, &image->parent); if (!err) goto found; } loc = vhd_util_scan_get_parent_locator(vhd); if (!loc) return -EINVAL; copy = *loc; copy.data_offset += image->target->start; err = vhd_parent_locator_read(vhd, &copy, &image->parent); if (err) return err; found: err = vhd_util_scan_extract_volume_name(name, image->parent); if (!err) return copy_name(image->parent, name); return 0; }", "target": 0, "idx": 106836, "project": "Xen"}
{"func": "static tsize_t _tiffReadProc(thandle_t fd, tdata_t buf, tsize_t size) { long r; r = Fread((int) fd, size, buf); if (r < 0) { errno = (int)-r; r = -1; } return r; }", "target": 0, "idx": 100482, "project": "LibTIFF"}
{"func": "static int check_platform_magic(struct device *dev, long ioaddr, long iolen) { short magic, unplug = 0; char protocol, *p, *q, *err;  if (!dev_unplug) unplug = UNPLUG_ALL; for (p = dev_unplug; p; p = q) { q = strchr(dev_unplug, ','); if (q) *q++ = '\\0'; if (!strcmp(p, \"all\")) unplug |= UNPLUG_ALL; else if (!strcmp(p, \"ide-disks\")) unplug |= UNPLUG_ALL_IDE_DISKS; else if (!strcmp(p, \"aux-ide-disks\")) unplug |= UNPLUG_AUX_IDE_DISKS; else if (!strcmp(p, \"nics\")) unplug |= UNPLUG_ALL_NICS; else if (!strcmp(p, \"never\")) unplug = 0; else dev_warn(dev, \"unrecognised option '%s' \"  \"in module parameter 'dev_unplug'\\n\", p); } if (iolen < 0x16) { err = \"backend too old\"; goto no_dev; } magic = inw(XEN_IOPORT_MAGIC); if (magic != XEN_IOPORT_MAGIC_VAL) { err = \"unrecognised magic value\"; goto no_dev; } protocol = inb(XEN_IOPORT_PROTOVER); dev_info(dev, \"I/O protocol version %d\\n\", protocol); switch (protocol) { case 1: outw(XEN_IOPORT_LINUX_PRODNUM, XEN_IOPORT_PRODNUM); outl(XEN_IOPORT_LINUX_DRVVER, XEN_IOPORT_DRVVER); if (inw(XEN_IOPORT_MAGIC) != XEN_IOPORT_MAGIC_VAL) { dev_err(dev, \"blacklisted by host\\n\"); return -ENODEV; }  case 0: outw(unplug, XEN_IOPORT_UNPLUG); break; default: err = \"unknown I/O protocol version\"; goto no_dev; } return 0;  no_dev: dev_warn(dev, \"failed backend handshake: %s\\n\", err); if (!unplug) return 0; dev_err(dev, \"failed to execute specified dev_unplug options!\\n\"); return -ENODEV; }", "target": 0, "idx": 105068, "project": "Xen"}
{"func": "int libxl_device_vtpm_getinfo(libxl_ctx *ctx, uint32_t domid, libxl_device_vtpm *vtpm, libxl_vtpminfo *vtpminfo) { GC_INIT(ctx); char *dompath, *vtpmpath; char *val; int rc = 0; libxl_vtpminfo_init(vtpminfo); dompath = libxl__xs_get_dompath(gc, domid); vtpminfo->devid = vtpm->devid; vtpmpath = GCSPRINTF(\"%s/device/vtpm/%d\", dompath, vtpminfo->devid); vtpminfo->backend = xs_read(ctx->xsh, XBT_NULL, GCSPRINTF(\"%s/backend\", vtpmpath), NULL); if (!vtpminfo->backend) { goto err; } if(!libxl__xs_read(gc, XBT_NULL, vtpminfo->backend)) {  goto err; } val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/backend-id\", vtpmpath)); vtpminfo->backend_id = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/state\", vtpmpath)); vtpminfo->state = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/event-channel\", vtpmpath)); vtpminfo->evtch = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/ring-ref\", vtpmpath)); vtpminfo->rref = val ? strtoul(val, NULL, 10) : -1; vtpminfo->frontend = xs_read(ctx->xsh, XBT_NULL, GCSPRINTF(\"%s/frontend\", vtpminfo->backend), NULL); val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/frontend-id\", vtpminfo->backend)); vtpminfo->frontend_id = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/uuid\", vtpminfo->backend)); if(val == NULL) {  LOG(ERROR, \"%s/uuid does not exist!\", vtpminfo->backend);  goto err; } if(libxl_uuid_from_string(&(vtpminfo->uuid), val)) {  LOG(ERROR,  \"%s/uuid is a malformed uuid?? (%s) Probably a bug!\\n\",  vtpminfo->backend, val);  goto err; } goto exit; err: rc = ERROR_FAIL; exit: GC_FREE; return rc; }", "target": 1, "idx": 109354, "project": "Xen"}
{"func": "static void bootloader_copyfail(libxl__egc *egc, const char *which, libxl__bootloader_state *bl, int ondisplay, int rc, int onwrite, int errnoval) { STATE_AO_GC(bl->ao); if (errnoval==-1) {  if (!!ondisplay != !!onwrite) { rc = 0; bl->got_pollhup = 1; } else { LOGD(ERROR, bl->domid, \"unexpected POLLHUP on %s\", which); } } else if (!rc) { LOGD(ERROR, bl->domid, \"unexpected eof copying %s\", which); rc = ERROR_FAIL; } bootloader_stop(egc, bl, rc); } static void bootloader_copyfail(libxl__egc *egc, const char *which, libxl__bootloader_state *bl, int ondisplay, int rc, int onwrite, int errnoval) { STATE_AO_GC(bl->ao); if (errnoval==-1) {  if (!!ondisplay != !!onwrite) { rc = 0; bl->got_pollhup = 1; } else { LOGD(ERROR, bl->domid, \"unexpected POLLHUP on %s\", which); } } else if (!rc) { LOGD(ERROR, bl->domid, \"unexpected eof copying %s\", which); rc = ERROR_FAIL; }", "target": 0, "idx": 103359, "project": "Xen"}
{"func": "void cpu_raise_softirq_batch_begin(void) { ++this_cpu(batching); }", "target": 0, "idx": 105797, "project": "Xen"}
{"func": "static void print_vbd_oo(xenstat_domain *domain) { print(\"%8llu\", tot_vbd_reqs(domain, FIELD_VBD_OO)); }", "target": 0, "idx": 108539, "project": "Xen"}
{"func": "int xg_attach(domid_t domid) { return 2; }", "target": 0, "idx": 108605, "project": "Xen"}
{"func": "static int invertImage(uint16 photometric, uint16 spp, uint16 bps, uint32 width, uint32 length, unsigned char *work_buff) { uint32 row, col; unsigned charbytebuff1, bytebuff2, bytebuff3, bytebuff4; unsigned char *src; uint16*src_uint16; uint32*src_uint32; if (spp != 1) { TIFFError(\"invertImage\", \"Image inversion not supported for more than one sample per pixel\"); return (-1); } if (photometric !=PHOTOMETRIC_MINISWHITE && photometric !=PHOTOMETRIC_MINISBLACK) { TIFFError(\"invertImage\", \"Only black and white and grayscale images can be inverted\"); return (-1); } src = work_buff; if (src == NULL) { TIFFError (\"invertImage\", \"Invalid crop buffer passed to invertImage\"); return (-1); } switch (bps) { case 32: src_uint32 = (uint32 *)src;  for (row = 0; row < length; row++)  for (col = 0; col < width; col++)  {  *src_uint32 = (uint32)0xFFFFFFFF - *src_uint32; src_uint32++;  } break; case 16: src_uint16 = (uint16 *)src;  for (row = 0; row < length; row++)  for (col = 0; col < width; col++)  {  *src_uint16 = (uint16)0xFFFF - *src_uint16; src_uint16++;  } break; case 8: for (row = 0; row < length; row++) for (col = 0; col < width; col++) { *src = (uint8)255 - *src;  src++; } break; case 4: for (row = 0; row < length; row++) for (col = 0; col < width; col++) { bytebuff1 = 16 - (uint8)(*src & 240 >> 4); bytebuff2 = 16 - (*src & 15); *src = bytebuff1 << 4 & bytebuff2; src++; } break; case 2: for (row = 0; row < length; row++) for (col = 0; col < width; col++) { bytebuff1 = 4 - (uint8)(*src & 192 >> 6); bytebuff2 = 4 - (uint8)(*src & 48>> 4); bytebuff3 = 4 - (uint8)(*src & 12>> 2); bytebuff4 = 4 - (uint8)(*src & 3); *src = (bytebuff1 << 6) || (bytebuff2 << 4) || (bytebuff3 << 2) || bytebuff4; src++; } break; case 1: for (row = 0; row < length; row++) for (col = 0; col < width; col += 8 /(spp * bps)) { *src = ~(*src); src++; } break; default: TIFFError(\"invertImage\", \"Unsupported bit depth %d\", bps); return (-1); } return (0); }", "target": 0, "idx": 100695, "project": "LibTIFF"}
{"func": "char *libxl__xs_libxl_path(libxl__gc *gc, uint32_t domid) { char *s = GCSPRINTF(\"/libxl/%i\", domid); if (!s) LOGD(ERROR, domid, \"cannot allocate create paths\"); return s; }", "target": 0, "idx": 104206, "project": "Xen"}
{"func": "static bool val_is_negative(struct type_descriptor *type, unsigned long val) { return type_is_signed(type) && get_signed_val(type, val) < 0; }", "target": 0, "idx": 106528, "project": "Xen"}
{"func": "static int start_update(void) {  svm_host_osvw_reset(); return 0; }", "target": 0, "idx": 104551, "project": "Xen"}
{"func": "void vmac_set_key(unsigned char user_key[], vmac_ctx_t *ctx) { uint64_t in[2] = {0}, out[2]; unsigned i; aes_key_setup(user_key, &ctx->cipher_key);  ((unsigned char *)in)[0] = 0x80;  for (i = 0; i < sizeof(ctx->nhkey)/8; i+=2) { aes_encryption((unsigned char *)in, (unsigned char *)out,  &ctx->cipher_key); ctx->nhkey[i] = get64BE(out); ctx->nhkey[i+1] = get64BE(out+1); ((unsigned char *)in)[15] += 1; }  ((unsigned char *)in)[0] = 0xC0;  in[1] = 0; for (i = 0; i < sizeof(ctx->polykey)/8; i+=2) { aes_encryption((unsigned char *)in, (unsigned char *)out,  &ctx->cipher_key); ctx->polytmp[i] = ctx->polykey[i] = get64BE(out) & mpoly; ctx->polytmp[i+1] = ctx->polykey[i+1] = get64BE(out+1) & mpoly; ((unsigned char *)in)[15] += 1; }  ((unsigned char *)in)[0] = 0xE0; in[1] = 0; for (i = 0; i < sizeof(ctx->l3key)/8; i+=2) { do { aes_encryption((unsigned char *)in, (unsigned char *)out,  &ctx->cipher_key); ctx->l3key[i] = get64BE(out); ctx->l3key[i+1] = get64BE(out+1); ((unsigned char *)in)[15] += 1; } while (ctx->l3key[i] >= p64 || ctx->l3key[i+1] >= p64); }  #if (VMAC_TAG_LEN == 64) && (VMAC_CACHE_NONCES) ctx->cached_nonce[0] = (uint64_t)-1;  ctx->cached_nonce[1] = (uint64_t)0; #endif ctx->first_block_processed = 0; }", "target": 0, "idx": 106971, "project": "Xen"}
{"func": "static TPM_RESULT vtpmmgr_VtpmDel(tpmcmd_t* tpmcmd) { CMD_BEGIN; uuid_t uuid; struct mem_group *group; struct mem_vtpm *vtpm; int rc; UNPACK_IN(BUFFER, uuid, 16); UNPACK_DONE(); rc = find_vtpm(&group, &vtpm, uuid); if (rc) { status = TPM_FAIL; goto abort_egress; } if (vtpm->flags & VTPM_FLAG_OPEN) { status = TPM_FAIL; goto abort_egress; } delete_vtpm(group, vtpm); CMD_END; }", "target": 0, "idx": 107226, "project": "Xen"}
{"func": "int qcow_create(const char *filename, uint64_t total_size, const char *backing_file, int sparse) { int fd, header_size, backing_filename_len, l1_size, i; int shift, length, adjust, flags = 0, ret = 0; QCowHeader header; QCowHeader_ext exthdr; char backing_filename[PATH_MAX], *ptr; uint64_t tmp, size, total_length; struct stat st; DPRINTF(\"Qcow_create: size %\"PRIu64\"\\n\",total_size); fd = open(filename,  O_WRONLY | O_CREAT | O_TRUNC | O_BINARY | O_LARGEFILE, 0644); if (fd < 0) return -1; memset(&header, 0, sizeof(header)); header.magic = cpu_to_be32(QCOW_MAGIC); header.version = cpu_to_be32(QCOW_VERSION);  exthdr.xmagic = cpu_to_be32(XEN_MAGIC); header_size = sizeof(header) + sizeof(QCowHeader_ext); backing_filename_len = 0; size = (total_size >> SECTOR_SHIFT); if (backing_file) { if (strcmp(backing_file, \"fat:\")) { const char *p;  p = strchr(backing_file, ':'); if (p && (p - backing_file) >= 2) {  strncpy(backing_filename, backing_file, sizeof(backing_filename) - 1); backing_filename[sizeof(backing_filename) - 1] = '\\0'; } else { if (realpath(backing_file, backing_filename) == NULL || stat(backing_filename, &st) != 0) { return -1; } } header.backing_file_offset = cpu_to_be64(header_size); backing_filename_len = strlen(backing_filename); header.backing_file_size = cpu_to_be32( backing_filename_len); header_size += backing_filename_len;  if(get_filesize(backing_filename, &size, &st)) { return -1; } DPRINTF(\"Backing file size detected: %\"PRId64\" sectors\"  \"(total %\"PRId64\" [%\"PRId64\" MB])\\n\",  size,  (uint64_t)(size << SECTOR_SHIFT),  (uint64_t)(size >> 11)); } else { backing_file = NULL; DPRINTF(\"Setting file size: %\"PRId64\" (total %\"PRId64\")\\n\",  total_size,  (uint64_t) (total_size << SECTOR_SHIFT)); } header.mtime = cpu_to_be32(st.st_mtime); header.cluster_bits = 9;  header.l2_bits = 12;  exthdr.min_cluster_alloc = cpu_to_be32(1); } else { DPRINTF(\"Setting file size: %\"PRId64\" sectors\"  \"(total %\"PRId64\" [%\"PRId64\" MB])\\n\",  size,  (uint64_t) (size << SECTOR_SHIFT),  (uint64_t) (size >> 11)); header.cluster_bits = 12;  header.l2_bits = 9;  exthdr.min_cluster_alloc = cpu_to_be32(1 << 9); }  header.size = cpu_to_be64(size * 512); header_size = (header_size + 7) & ~7; if (header_size % 4096 > 0) { header_size = ((header_size >> 12) + 1) << 12; } shift = header.cluster_bits + header.l2_bits; l1_size = ((size * 512) + (1LL << shift) - 1) >> shift; header.l1_table_offset = cpu_to_be64(header_size); DPRINTF(\"L1 Table offset: %d, size %d\\n\", header_size, (int)(l1_size * sizeof(uint64_t))); header.crypt_method = cpu_to_be32(QCOW_CRYPT_NONE); ptr = calloc(1, l1_size * sizeof(uint64_t)); exthdr.cksum = cpu_to_be32(gen_cksum(ptr, l1_size * sizeof(uint64_t))); printf(\"Created cksum: %d\\n\",exthdr.cksum); free(ptr);  length = ROUNDUP(header_size + (l1_size * sizeof(uint64_t)), getpagesize()); if (qtruncate(fd, length, 0)!=0) { DPRINTF(\"ERROR truncating file\\n\"); return -1; } if (sparse == 0) {  total_length = length + (l1_size * (1 << 9)) + (size * 512); if (qtruncate(fd, total_length, 0)!=0) { DPRINTF(\"ERROR truncating file\\n\"); return -1; } printf(\"File truncated to length %\"PRIu64\"\\n\",total_length); } else flags = SPARSE_FILE; flags |= EXTHDR_L1_BIG_ENDIAN; exthdr.flags = cpu_to_be32(flags);  lseek(fd, 0, SEEK_SET); ret += write(fd, &header, sizeof(header)); ret += write(fd, &exthdr, sizeof(exthdr)); if (backing_file) ret += write(fd, backing_filename, backing_filename_len); lseek(fd, header_size, SEEK_SET); tmp = 0; for (i = 0;i < l1_size; i++) { ret += write(fd, &tmp, sizeof(tmp)); } close(fd); return 0; }", "target": 0, "idx": 101074, "project": "Xen"}
{"func": "int __hwdom_init vpci_add_handlers(struct pci_dev *pdev) { unsigned int i; int rc = 0; if ( !has_vpci(pdev->domain) ) return 0; pdev->vpci = xzalloc(struct vpci); if ( !pdev->vpci ) return -ENOMEM; INIT_LIST_HEAD(&pdev->vpci->handlers); spin_lock_init(&pdev->vpci->lock); for ( i = 0; i < NUM_VPCI_INIT; i++ ) { rc = __start_vpci_array[i](pdev); if ( rc ) break; } if ( rc ) vpci_remove_device(pdev); return rc; }", "target": 0, "idx": 107080, "project": "Xen"}
{"func": "int xc_flask_del_pirq(xc_interface *xch, unsigned int pirq) { return xc_flask_del(xch, OCON_PIRQ, pirq, pirq); }", "target": 0, "idx": 107489, "project": "Xen"}
{"func": "struct expr *expr_alloc_and(struct expr *e1, struct expr *e2) { if (!e1) return e2; return e2 ? expr_alloc_two(E_AND, e1, e2) : e1; }", "target": 0, "idx": 101927, "project": "Xen"}
{"func": "int xc_domain_pin_memory_cacheattr( xc_interface *xch, uint32_t domid, uint64_t start, uint64_t end, uint32_t type) { return xendevicemodel_pin_memory_cacheattr(xch->dmod, domid, start, end,  type); }", "target": 0, "idx": 107359, "project": "Xen"}
{"func": "static int flask_copyin_string(XEN_GUEST_HANDLE_PARAM(char) u_buf, char **buf, uint32_t size) { char *tmp = xmalloc_bytes(size + 1); if ( !tmp ) return -ENOMEM; if ( copy_from_guest(tmp, u_buf, size) ) { xfree(tmp); return -EFAULT; } tmp[size] = 0; *buf = tmp; return 0; }", "target": 1, "idx": 109154, "project": "Xen"}
{"func": " * span and are also set in suitable_cpumap. */ static int nodemap_to_nr_cpus(libxl_cputopology *tinfo, int nr_cpus, const libxl_bitmap *suitable_cpumap, const libxl_bitmap *nodemap) { int i, nodes_cpus = 0; for (i = 0; i < nr_cpus; i++) { if (libxl_bitmap_test(suitable_cpumap, i) && libxl_bitmap_test(nodemap, tinfo[i].node)) nodes_cpus++; } return nodes_cpus; }", "target": 0, "idx": 103825, "project": "Xen"}
{"func": " */ static int update_guest_p2m(struct xc_sr_context *ctx) { xc_interface *xch = ctx->xch; xen_pfn_t mfn, pfn, *guest_p2m = NULL; unsigned i; int rc = -1; for ( i = 0; i < ctx->x86_pv.p2m_frames; ++i ) { pfn = ctx->x86_pv.p2m_pfns[i]; if ( pfn > ctx->x86_pv.max_pfn ) { ERROR(\"pfn (%#lx) for p2m_frame_list[%u] out of range\", pfn, i); goto err; } else if ( (ctx->x86_pv.restore.pfn_types[pfn] !=  XEN_DOMCTL_PFINFO_NOTAB) ) { ERROR(\"pfn (%#lx) for p2m_frame_list[%u] has bad type %u\", pfn, i, (ctx->x86_pv.restore.pfn_types[pfn] >>  XEN_DOMCTL_PFINFO_LTAB_SHIFT)); goto err; } mfn = pfn_to_mfn(ctx, pfn); if ( !mfn_in_pseudophysmap(ctx, mfn) ) { ERROR(\"p2m_frame_list[%u] has bad mfn\", i); dump_bad_pseudophysmap_entry(ctx, mfn); goto err; } ctx->x86_pv.p2m_pfns[i] = mfn; } guest_p2m = xc_map_foreign_pages(xch, ctx->domid, PROT_WRITE,  ctx->x86_pv.p2m_pfns,  ctx->x86_pv.p2m_frames ); if ( !guest_p2m ) { PERROR(\"Failed to map p2m frames\"); goto err; } memcpy(guest_p2m, ctx->x86_pv.p2m,  (ctx->x86_pv.max_pfn + 1) * ctx->x86_pv.width); rc = 0;  err: if ( guest_p2m ) munmap(guest_p2m, ctx->x86_pv.p2m_frames * PAGE_SIZE); return rc; }", "target": 0, "idx": 107743, "project": "Xen"}
{"func": "static uint64 checkMultiply64(uint64 first, uint64 second, T2P* t2p) { uint64 bytes = first * second; if (second && bytes / second != first) { TIFFError(TIFF2PDF_MODULE, \"Integer overflow\"); t2p->t2p_error = T2P_ERR_ERROR; bytes = 0; } return bytes; }", "target": 0, "idx": 100664, "project": "LibTIFF"}
{"func": "static int setup_read(libxl__stream_read_state *stream, const char *what, void *ptr, size_t nr_bytes, libxl__datacopier_callback cb) { libxl__datacopier_state *dc = &stream->dc; dc->readwhat= what; dc->readbuf = ptr; dc->bytes_to_read = nr_bytes; dc->used= 0; dc->callback= cb; return libxl__datacopier_start(dc); }", "target": 0, "idx": 104010, "project": "Xen"}
{"func": "static void checkpoint_state_done(libxl__egc *egc, libxl__stream_write_state *stream, int rc) { assert(stream->in_checkpoint_state); stream->in_checkpoint_state = false; stream->checkpoint_callback(egc, stream, rc); }", "target": 0, "idx": 104020, "project": "Xen"}
{"func": "static void __cpuinit generic_identify(struct cpuinfo_x86 *c) { u32 tfms, capability, excap, ebx;  cpuid(0x00000000, &c->cpuid_level, (int *)&c->x86_vendor_id[0], (int *)&c->x86_vendor_id[8], (int *)&c->x86_vendor_id[4]);  c->x86_vendor = get_cpu_vendor(c->x86_vendor_id, gcv_host_late);     cpuid(0x00000001, &tfms, &ebx, &excap, &capability); c->x86_capability[0] = capability; c->x86_capability[4] = excap; c->x86 = (tfms >> 8) & 15; c->x86_model = (tfms >> 4) & 15; if (c->x86 == 0xf) c->x86 += (tfms >> 20) & 0xff; if (c->x86 >= 0x6) c->x86_model += ((tfms >> 16) & 0xF) << 4; c->x86_mask = tfms & 15; c->apicid = phys_pkg_id((ebx >> 24) & 0xFF, 0); c->phys_proc_id = c->apicid; if ( cpu_has(c, X86_FEATURE_CLFLSH) ) c->x86_clflush_size = ((ebx >> 8) & 0xff) * 8;  c->extended_cpuid_level = cpuid_eax(0x80000000); if ( (c->extended_cpuid_level & 0xffff0000) == 0x80000000 ) { if ( c->extended_cpuid_level >= 0x80000001 ) { c->x86_capability[1] = cpuid_edx(0x80000001); c->x86_capability[6] = cpuid_ecx(0x80000001); } if ( c->extended_cpuid_level >= 0x80000004 ) get_model_name(c);  if ( c->extended_cpuid_level >= 0x80000008 ) paddr_bits = cpuid_eax(0x80000008) & 0xff; }  early_intel_workaround(c);  if ( c->cpuid_level >= 0x00000007 ) { u32 dummy; cpuid_count(0x00000007, 0, &dummy, &ebx, &dummy, &dummy); c->x86_capability[X86_FEATURE_FSGSBASE / 32] = ebx; } }", "target": 1, "idx": 109344, "project": "Xen"}
{"func": "long chksum_bios_get_offset( byte* data, long offset ) { return (bios_len - 1); }", "target": 0, "idx": 100989, "project": "Xen"}
{"func": "int _write_trylock(rwlock_t *lock) { check_lock(&lock->debug); if ( !_raw_write_trylock(&lock->raw) ) return 0; preempt_disable(); return 1; }", "target": 1, "idx": 109243, "project": "Xen"}
{"func": "static void csched_init_pdata(const struct scheduler *ops, void *pdata, int cpu) { unsigned long flags; struct csched_private *prv = CSCHED_PRIV(ops); struct schedule_data *sd = &per_cpu(schedule_data, cpu);  ASSERT(sd->schedule_lock == &sd->_lock && !spin_is_locked(&sd->_lock)); spin_lock_irqsave(&prv->lock, flags); init_pdata(prv, pdata, cpu); spin_unlock_irqrestore(&prv->lock, flags); }", "target": 0, "idx": 105485, "project": "Xen"}
{"func": "static int set_cpufreq_gov(struct xen_sysctl_pm_op *op) { struct cpufreq_policy new_policy, *old_policy; old_policy = per_cpu(cpufreq_cpu_policy, op->cpuid); if ( !old_policy ) return -EINVAL; memcpy(&new_policy, old_policy, sizeof(struct cpufreq_policy)); new_policy.governor = __find_governor(op->u.set_gov.scaling_governor); if (new_policy.governor == NULL) return -EINVAL; return __cpufreq_set_policy(old_policy, &new_policy); }", "target": 0, "idx": 105103, "project": "Xen"}
{"func": "static uint64_t __init mtrr_top_of_ram(void) { uint32_t eax, ebx, ecx, edx; uint64_t mtrr_cap, mtrr_def, addr_mask, base, mask, top; unsigned int i, phys_bits = 36;  if ( e820_mtrr_clip == -1 ) { char vendor[13]; cpuid(0x00000000, &eax, (uint32_t *)&vendor[0], (uint32_t *)&vendor[8], (uint32_t *)&vendor[4]); vendor[12] = '\\0'; e820_mtrr_clip = !strcmp(vendor, \"GenuineIntel\"); } if ( !e820_mtrr_clip ) return 0; if ( e820_verbose ) printk(\"Checking MTRR ranges...\\n\");  cpuid(0x00000001, &eax, &ebx, &ecx, &edx); if ( !test_bit(X86_FEATURE_MTRR & 31, &edx) )  return 0;  eax = cpuid_eax(0x80000000); if ( (eax >> 16) == 0x8000 && eax >= 0x80000008 ) { phys_bits = (uint8_t)cpuid_eax(0x80000008); if ( phys_bits > PADDR_BITS ) phys_bits = PADDR_BITS; } addr_mask = ((1ull << phys_bits) - 1) & ~((1ull << 12) - 1); rdmsrl(MSR_MTRRcap, mtrr_cap); rdmsrl(MSR_MTRRdefType, mtrr_def); if ( e820_verbose ) printk(\" MTRR cap: %\"PRIx64\" type: %\"PRIx64\"\\n\", mtrr_cap, mtrr_def);  if ( !test_bit(11, &mtrr_def) || ((uint8_t)mtrr_def == MTRR_TYPE_WRBACK) ) return 0;  top = 0; for ( i = 0; i < (uint8_t)mtrr_cap; i++ ) { rdmsrl(MSR_IA32_MTRR_PHYSBASE(i), base); rdmsrl(MSR_IA32_MTRR_PHYSMASK(i), mask); if ( e820_verbose ) printk(\" MTRR[%d]: base %\"PRIx64\" mask %\"PRIx64\"\\n\",  i, base, mask); if ( !test_bit(11, &mask) || ((uint8_t)base != MTRR_TYPE_WRBACK) ) continue; base &= addr_mask; mask &= addr_mask; top = max_t(uint64_t, top, ((base | ~mask) & addr_mask) + PAGE_SIZE); } return top; }", "target": 0, "idx": 101799, "project": "Xen"}
{"func": "static void raster_keys(unsigned char key, int x, int y) { switch (key) { case 'b':  photo = PHOTOMETRIC_MINISBLACK; initImage(); break; case 'l':  order = FILLORDER_LSB2MSB; initImage(); break; case 'm':  order = FILLORDER_MSB2LSB; initImage(); break; case 'w':  photo = PHOTOMETRIC_MINISWHITE; initImage(); break; case 'W':  owarning = TIFFSetWarningHandler(owarning); initImage(); break; case 'E':  oerror = TIFFSetErrorHandler(oerror); initImage(); break; case 'z':  case 'Z': order = order0; photo = photo0; if (owarning == NULL) owarning = TIFFSetWarningHandler(NULL); if (oerror == NULL) oerror = TIFFSetErrorHandler(NULL); initImage(); break; case 'q':  case '\\033': cleanup_and_exit(); } glutPostRedisplay(); }", "target": 0, "idx": 100501, "project": "LibTIFF"}
{"func": " */ void print_autowrap(WINDOW * win, const char *prompt, int width, int y, int x) { int newl, cur_x, cur_y; int prompt_len, room, wlen; char tempstr[MAX_LEN + 1], *word, *sp, *sp2, *newline_separator = 0; strcpy(tempstr, prompt); prompt_len = strlen(tempstr); if (prompt_len <= width - x * 2) { wmove(win, y, (width - prompt_len) / 2); waddstr(win, tempstr); } else { cur_x = x; cur_y = y; newl = 1; word = tempstr; while (word && *word) { sp = strpbrk(word, \"\\n \"); if (sp && *sp == '\\n') newline_separator = sp; if (sp) *sp++ = 0;  room = width - cur_x; wlen = strlen(word); if (wlen > room || (newl && wlen < 4 && sp  && wlen + 1 + strlen(sp) > room  && (!(sp2 = strpbrk(sp, \"\\n \"))  || wlen + 1 + (sp2 - sp) > room))) { cur_y++; cur_x = x; } wmove(win, cur_y, cur_x); waddstr(win, word); getyx(win, cur_y, cur_x);  if (newline_separator) { cur_y++; cur_x = x; newline_separator = 0; } else cur_x++; if (sp && *sp == ' ') { cur_x++; while (*++sp == ' ') ; newl = 1; } else newl = 0; word = sp; } } }", "target": 0, "idx": 106601, "project": "Xen"}
{"func": "void cacheattr_init(void) { uint32_t eax, ebx, ecx, edx; uint64_t mtrr_cap, mtrr_def, content, addr_mask; unsigned int i, nr_var_ranges, phys_bits;  cpuid(0x00000001, &eax, &ebx, &ecx, &edx); if ( !(edx & (1u << 12)) )  return; phys_bits = cpu_phys_addr(); printf(\"%u-bit phys ... \", phys_bits); addr_mask = ((1ull << phys_bits) - 1) & ~((1ull << 12) - 1); mtrr_cap = rdmsr(MSR_MTRRcap); mtrr_def = (1u << 11) | 6;   if ( mtrr_cap & (1u << 8) ) {  content = 0x0606060606060606ull; wrmsr(MSR_MTRRfix64K_00000, content); wrmsr(MSR_MTRRfix16K_80000, content);  if ( mtrr_cap & (1u << 10) )  content = 0x0101010101010101ull; wrmsr(MSR_MTRRfix16K_A0000, content);  content = 0x0606060606060606ull; for ( i = 0; i < 8; i++ ) wrmsr(MSR_MTRRfix4K_C0000 + i, content); mtrr_def |= 1u << 10;  printf(\"fixed MTRRs ... \"); }  nr_var_ranges = (uint8_t)mtrr_cap; if ( nr_var_ranges != 0 ) { uint64_t base = pci_mem_start, size; for ( i = 0; !(base >> 32) && (i < nr_var_ranges); i++ ) { size = PAGE_SIZE; while ( !(base & size) ) size <<= 1; while ( ((base + size) < base) || ((base + size - 1) >> 32) ) size >>= 1; wrmsr(MSR_MTRRphysBase(i), base); wrmsr(MSR_MTRRphysMask(i), (~(size - 1) & addr_mask) | (1u << 11)); base += size; } for ( base = pci_hi_mem_start; (base != pci_hi_mem_end) && (i < nr_var_ranges); i++ ) { size = PAGE_SIZE; while ( !(base & size) ) size <<= 1; while ( (base + size < base) || (base + size > pci_hi_mem_end) ) size >>= 1; wrmsr(MSR_MTRRphysBase(i), base); wrmsr(MSR_MTRRphysMask(i), (~(size - 1) & addr_mask) | (1u << 11)); base += size; } printf(\"var MTRRs [%d/%d] ... \", i, nr_var_ranges); } wrmsr(MSR_MTRRdefType, mtrr_def); }", "target": 0, "idx": 101301, "project": "Xen"}
{"func": "static x86_pgentry_t get_pg_prot_x86(struct xc_dom_image *dom, int l,  xen_pfn_t pfn) { struct xc_dom_image_x86 *domx86 = dom->arch_private; struct xc_dom_x86_mapping *map; xen_pfn_t pfn_s, pfn_e; x86_pgentry_t prot; unsigned m; prot = domx86->params->lvl_prot[l]; if ( l > 0 ) return prot; for ( m = 0; m < domx86->n_mappings; m++ ) { map = domx86->maps + m; pfn_s = map->lvls[domx86->params->levels - 1].pfn; pfn_e = map->area.pgtables + pfn_s; if ( pfn >= pfn_s && pfn < pfn_e ) return prot & ~_PAGE_RW; } return prot; }", "target": 0, "idx": 107445, "project": "Xen"}
{"func": "void __init init_ioapic_mappings(void) { unsigned long ioapic_phys; unsigned int i, idx = FIX_IO_APIC_BASE_0; union IO_APIC_reg_01 reg_01; if ( smp_found_config ) nr_irqs_gsi = 0; for ( i = 0; i < nr_ioapics; i++ ) { if ( smp_found_config ) { ioapic_phys = mp_ioapics[i].mpc_apicaddr; if ( !ioapic_phys ) { printk(KERN_ERR \"WARNING: bogus zero IO-APIC address \"  \"found in MPTABLE, disabling IO/APIC support!\\n\"); smp_found_config = false; skip_ioapic_setup = true; goto fake_ioapic_page; } } else {  fake_ioapic_page: ioapic_phys = __pa(alloc_xenheap_page()); clear_page(__va(ioapic_phys)); } set_fixmap_nocache(idx, ioapic_phys); apic_printk(APIC_VERBOSE, \"mapped IOAPIC to %08Lx (%08lx)\\n\", __fix_to_virt(idx), ioapic_phys); idx++; if ( bad_ioapic_register(i) ) { clear_fixmap(idx); continue; } if ( smp_found_config ) {  reg_01.raw = io_apic_read(i, 1); nr_ioapic_entries[i] = reg_01.bits.entries + 1; nr_irqs_gsi += nr_ioapic_entries[i]; if ( rangeset_add_singleton(mmio_ro_ranges, ioapic_phys >> PAGE_SHIFT) ) printk(KERN_ERR \"Failed to mark IO-APIC page %lx read-only\\n\",  ioapic_phys); } } nr_irqs_gsi = max(nr_irqs_gsi, highest_gsi() + 1); if ( max_gsi_irqs == 0 ) max_gsi_irqs = nr_irqs ? nr_irqs / 8 : PAGE_SIZE; else if ( nr_irqs != 0 && max_gsi_irqs > nr_irqs ) { printk(XENLOG_WARNING \"\\\"max_gsi_irqs=\\\" cannot be specified larger\" \" than \\\"nr_irqs=\\\"\\n\"); max_gsi_irqs = nr_irqs; } if ( max_gsi_irqs < 16 ) max_gsi_irqs = 16;  if ( max_gsi_irqs > PAGE_SIZE * 8 ) max_gsi_irqs = PAGE_SIZE * 8; if ( !smp_found_config || skip_ioapic_setup || nr_irqs_gsi < 16 ) nr_irqs_gsi = 16; else if ( nr_irqs_gsi > max_gsi_irqs ) { printk(XENLOG_WARNING \"Limiting to %u GSI IRQs (found %u)\\n\",  max_gsi_irqs, nr_irqs_gsi); nr_irqs_gsi = max_gsi_irqs; } if ( nr_irqs == 0 ) nr_irqs = cpu_has_apic ? max(16U + num_present_cpus() * NR_DYNAMIC_VECTORS, 8 * nr_irqs_gsi) : nr_irqs_gsi; else if ( nr_irqs < 16 ) nr_irqs = 16; printk(XENLOG_INFO \"IRQ limits: %u GSI, %u MSI/MSI-X\\n\",  nr_irqs_gsi, nr_irqs - nr_irqs_gsi); }", "target": 0, "idx": 102857, "project": "Xen"}
{"func": "static void ubsan_epilogue(unsigned long *flags) { dump_stack(); pr_err(\"========================================\" \"========================================\\n\"); spin_unlock_irqrestore(&report_lock, *flags); current->in_ubsan--; }", "target": 0, "idx": 106526, "project": "Xen"}
{"func": "static int decompress_cluster(struct tdqcow_state *s, uint64_t cluster_offset); uint32_t gen_cksum(char *ptr, int len) { int i; uint32_t md[4];  md5_sum((const uint8_t*)ptr, len, (uint8_t*)md); return md[0]; }", "target": 0, "idx": 101069, "project": "Xen"}
{"func": " */ static struct expr *expr_join_or(struct expr *e1, struct expr *e2) { struct expr *tmp; struct symbol *sym1, *sym2; if (expr_eq(e1, e2)) return expr_copy(e1); if (e1->type != E_EQUAL && e1->type != E_UNEQUAL && e1->type != E_SYMBOL && e1->type != E_NOT) return NULL; if (e2->type != E_EQUAL && e2->type != E_UNEQUAL && e2->type != E_SYMBOL && e2->type != E_NOT) return NULL; if (e1->type == E_NOT) { tmp = e1->left.expr; if (tmp->type != E_EQUAL && tmp->type != E_UNEQUAL && tmp->type != E_SYMBOL) return NULL; sym1 = tmp->left.sym; } else sym1 = e1->left.sym; if (e2->type == E_NOT) { if (e2->left.expr->type != E_SYMBOL) return NULL; sym2 = e2->left.expr->left.sym; } else sym2 = e2->left.sym; if (sym1 != sym2) return NULL; if (sym1->type != S_BOOLEAN && sym1->type != S_TRISTATE) return NULL; if (sym1->type == S_TRISTATE) { if (e1->type == E_EQUAL && e2->type == E_EQUAL && ((e1->right.sym == &symbol_yes && e2->right.sym == &symbol_mod) ||  (e1->right.sym == &symbol_mod && e2->right.sym == &symbol_yes))) {  return expr_alloc_comp(E_UNEQUAL, sym1, &symbol_no); } if (e1->type == E_EQUAL && e2->type == E_EQUAL && ((e1->right.sym == &symbol_yes && e2->right.sym == &symbol_no) ||  (e1->right.sym == &symbol_no && e2->right.sym == &symbol_yes))) {  return expr_alloc_comp(E_UNEQUAL, sym1, &symbol_mod); } if (e1->type == E_EQUAL && e2->type == E_EQUAL && ((e1->right.sym == &symbol_mod && e2->right.sym == &symbol_no) ||  (e1->right.sym == &symbol_no && e2->right.sym == &symbol_mod))) {  return expr_alloc_comp(E_UNEQUAL, sym1, &symbol_yes); } } if (sym1->type == S_BOOLEAN && sym1 == sym2) { if ((e1->type == E_NOT && e1->left.expr->type == E_SYMBOL && e2->type == E_SYMBOL) || (e2->type == E_NOT && e2->left.expr->type == E_SYMBOL && e1->type == E_SYMBOL)) return expr_alloc_symbol(&symbol_yes); } if (DEBUG_EXPR) { printf(\"optimize (\"); expr_fprint(e1, stdout); printf(\") || (\"); expr_fprint(e2, stdout); printf(\")?\\n\"); } return NULL; }", "target": 0, "idx": 101946, "project": "Xen"}
{"func": "static void unlock(void) { int e = pthread_mutex_unlock(&handles_lock); assert(!e); }", "target": 0, "idx": 102626, "project": "Xen"}
{"func": "int fdt_add_reservemap_entry(void *fdt, uint64_t addr, uint64_t size) { struct fdt_reserve_entry *re; int offset; FDT_SW_CHECK_HEADER(fdt); if (fdt_size_dt_struct(fdt)) return -FDT_ERR_BADSTATE; offset = fdt_off_dt_struct(fdt); if ((offset + sizeof(*re)) > fdt_totalsize(fdt)) return -FDT_ERR_NOSPACE; re = (struct fdt_reserve_entry *)((char *)fdt + offset); re->address = cpu_to_fdt64(addr); re->size = cpu_to_fdt64(size); fdt_set_off_dt_struct(fdt, offset + sizeof(*re)); return 0; }", "target": 0, "idx": 102049, "project": "Xen"}
{"func": "int xc_psr_cmt_get_total_rmid(xc_interface *xch, uint32_t *total_rmid) { static int val = 0; int rc; DECLARE_SYSCTL; if ( val ) { *total_rmid = val; return 0; } sysctl.cmd = XEN_SYSCTL_psr_cmt_op; sysctl.u.psr_cmt_op.cmd = XEN_SYSCTL_PSR_CMT_get_total_rmid; sysctl.u.psr_cmt_op.flags = 0; rc = xc_sysctl(xch, &sysctl); if ( !rc ) val = *total_rmid = sysctl.u.psr_cmt_op.u.data; return rc; }", "target": 0, "idx": 107680, "project": "Xen"}
{"func": "static int libxl__primary_console_find(libxl_ctx *ctx, uint32_t domid_vm,  uint32_t *domid, int *cons_num,  libxl_console_type *type) { GC_INIT(ctx); uint32_t stubdomid = libxl_get_stubdom_id(ctx, domid_vm); int rc; if (stubdomid) { *domid = stubdomid; *cons_num = STUBDOM_CONSOLE_SERIAL; *type = LIBXL_CONSOLE_TYPE_PV; } else { switch (libxl__domain_type(gc, domid_vm)) { case LIBXL_DOMAIN_TYPE_HVM: *domid = domid_vm; *cons_num = 0; *type = LIBXL_CONSOLE_TYPE_SERIAL; break; case LIBXL_DOMAIN_TYPE_PVH: case LIBXL_DOMAIN_TYPE_PV: *domid = domid_vm; *cons_num = 0; *type = LIBXL_CONSOLE_TYPE_PV; break; case LIBXL_DOMAIN_TYPE_INVALID: rc = ERROR_INVAL; goto out; default: abort(); } } rc = 0; out: GC_FREE; return rc; }", "target": 0, "idx": 103481, "project": "Xen"}
{"func": "int mce_verbosity; static int __init mce_set_verbosity(const char *str) { if ( strcmp(\"verbose\", str) == 0 ) mce_verbosity = MCE_VERBOSE; else return -EINVAL; return 0; }", "target": 0, "idx": 104351, "project": "Xen"}
{"func": "void serial_end_log_everything(int handle) { struct serial_port *port; unsigned long flags; if ( handle == -1 ) return; port = &com[handle & SERHND_IDX]; spin_lock_irqsave(&port->tx_lock, flags); port->tx_log_everything--; spin_unlock_irqrestore(&port->tx_lock, flags); }", "target": 0, "idx": 105672, "project": "Xen"}
{"func": "static void pmm_init_heap(heap_t *heap, uint32_t from_addr, uint32_t to_addr) { memblk_t *mb = (memblk_t *)ALIGN_UP(from_addr, HEAP_ALIGNMENT); mb->next = (memblk_t *)ALIGN_DOWN(to_addr, HEAP_ALIGNMENT); set_avail(mb); heap->head = mb; heap->end = mb->next; }", "target": 0, "idx": 105094, "project": "Xen"}
{"func": "void _TIFFmemcpy(tdata_t d, const tdata_t s, size_t c) { memcpy(d, s, (size_t) c); }", "target": 0, "idx": 100449, "project": "LibTIFF"}
{"func": "static void decrease_reservation(struct memop_args *a) { unsigned long i, j; xen_pfn_t gmfn; if ( !guest_handle_subrange_okay(a->extent_list, a->nr_done,  a->nr_extents-1) ||  a->extent_order > MAX_ORDER ) return; for ( i = a->nr_done; i < a->nr_extents; i++ ) { if ( hypercall_preempt_check() ) { a->preempted = 1; goto out; } if ( unlikely(__copy_from_guest_offset(&gmfn, a->extent_list, i, 1)) ) goto out; if ( tb_init_done ) { struct { u64 gfn; int d:16,order:16; } t; t.gfn = gmfn; t.d = a->domain->domain_id; t.order = a->extent_order;  __trace_var(TRC_MEM_DECREASE_RESERVATION, 0, sizeof(t), &t); }  if ( is_hvm_domain(a->domain)  && p2m_pod_decrease_reservation(a->domain, gmfn, a->extent_order) ) continue;  if ( is_domain_direct_mapped(a->domain) ) continue; for ( j = 0; j < (1 << a->extent_order); j++ ) if ( !guest_remove_page(a->domain, gmfn + j) ) goto out; }  out: a->nr_done = i; }", "target": 1, "idx": 109317, "project": "Xen"}
{"func": "static void gcov_reset_all_counters(void) { struct gcov_info *info = NULL; while ( (info = gcov_info_next(info)) ) gcov_info_reset(info); }", "target": 0, "idx": 102322, "project": "Xen"}
{"func": "static int _hvm_dpci_isairq_eoi(struct domain *d, struct hvm_pirq_dpci *pirq_dpci, void *arg) { struct hvm_irq *hvm_irq = hvm_domain_irq(d); unsigned int isairq = (long)arg; const struct dev_intx_gsi_link *digl; list_for_each_entry ( digl, &pirq_dpci->digl_list, list ) { unsigned int link = hvm_pci_intx_link(digl->device, digl->intx); if ( hvm_irq->pci_link.route[link] == isairq ) { hvm_pci_intx_deassert(d, digl->device, digl->intx); if ( --pirq_dpci->pending == 0 ) { stop_timer(&pirq_dpci->timer); pirq_guest_eoi(dpci_pirq(pirq_dpci)); } } } return 0; }", "target": 0, "idx": 107161, "project": "Xen"}
{"func": "static int writeCroppedImage(TIFF *in, TIFF *out, struct image_data *image,  struct dump_opts *dump, uint32 width, uint32 length,  unsigned char *crop_buff, int pagenum, int total_pages) { uint16 bps, spp; uint16 input_compression, input_photometric; uint16 input_planar; struct cpTag* p; input_compression = image->compression; input_photometric = image->photometric; spp = image->spp; bps = image->bps; TIFFSetField(out, TIFFTAG_IMAGEWIDTH, width); TIFFSetField(out, TIFFTAG_IMAGELENGTH, length); TIFFSetField(out, TIFFTAG_BITSPERSAMPLE, bps); TIFFSetField(out, TIFFTAG_SAMPLESPERPIXEL, spp); #ifdef DEBUG2 TIFFError(\"writeCroppedImage\", \"Input compression: %s\", (input_compression == COMPRESSION_OJPEG) ? \"Old Jpeg\" : ((input_compression == COMPRESSION_JPEG) ?\"New Jpeg\" : \"Non Jpeg\")); #endif if (compression != (uint16)-1) TIFFSetField(out, TIFFTAG_COMPRESSION, compression); else { if (input_compression == COMPRESSION_OJPEG) { compression = COMPRESSION_JPEG; jpegcolormode = JPEGCOLORMODE_RAW; TIFFSetField(out, TIFFTAG_COMPRESSION, COMPRESSION_JPEG); } else CopyField(TIFFTAG_COMPRESSION, compression); } if (compression == COMPRESSION_JPEG) { if ((input_photometric == PHOTOMETRIC_PALETTE) || (input_photometric == PHOTOMETRIC_MASK))  { TIFFError (\"writeCroppedImage\",  \"JPEG compression cannot be used with %s image data\", (input_photometric == PHOTOMETRIC_PALETTE) ?  \"palette\" : \"mask\"); return (-1); } if ((input_photometric == PHOTOMETRIC_RGB) && (jpegcolormode == JPEGCOLORMODE_RGB)) TIFFSetField(out, TIFFTAG_PHOTOMETRIC, PHOTOMETRIC_YCBCR); else TIFFSetField(out, TIFFTAG_PHOTOMETRIC, input_photometric); } else { if (compression == COMPRESSION_SGILOG || compression == COMPRESSION_SGILOG24) { TIFFSetField(out, TIFFTAG_PHOTOMETRIC, spp == 1 ? PHOTOMETRIC_LOGL : PHOTOMETRIC_LOGLUV); } else { if (input_compression == COMPRESSION_SGILOG || input_compression == COMPRESSION_SGILOG24) { TIFFSetField(out, TIFFTAG_PHOTOMETRIC, spp == 1 ? PHOTOMETRIC_LOGL : PHOTOMETRIC_LOGLUV); } else TIFFSetField(out, TIFFTAG_PHOTOMETRIC, image->photometric); } } if (((input_photometric == PHOTOMETRIC_LOGL) ||  (input_photometric ==PHOTOMETRIC_LOGLUV)) && ((compression != COMPRESSION_SGILOG) &&   (compression != COMPRESSION_SGILOG24))) { TIFFError(\"writeCroppedImage\", \"LogL and LogLuv source data require SGI_LOG or SGI_LOG24 compression\"); return (-1); } if (fillorder != 0) TIFFSetField(out, TIFFTAG_FILLORDER, fillorder); else CopyTag(TIFFTAG_FILLORDER, 1, TIFF_SHORT);  TIFFSetField(out, TIFFTAG_ORIENTATION, image->orientation);  if (outtiled == -1) outtiled = TIFFIsTiled(in); if (outtiled) {  if (tilewidth == (uint32) 0) TIFFGetField(in, TIFFTAG_TILEWIDTH, &tilewidth); if (tilelength == (uint32) 0) TIFFGetField(in, TIFFTAG_TILELENGTH, &tilelength); if (tilewidth == 0 || tilelength == 0) TIFFDefaultTileSize(out, &tilewidth, &tilelength); TIFFSetField(out, TIFFTAG_TILEWIDTH, tilewidth); TIFFSetField(out, TIFFTAG_TILELENGTH, tilelength); } else {   if (rowsperstrip == (uint32) 0) { if (!TIFFGetField(in, TIFFTAG_ROWSPERSTRIP, &rowsperstrip)) rowsperstrip = TIFFDefaultStripSize(out, rowsperstrip); if (compression != COMPRESSION_JPEG) { if (rowsperstrip > length) rowsperstrip = length; } } else  if (rowsperstrip == (uint32) -1) rowsperstrip = length; TIFFSetField(out, TIFFTAG_ROWSPERSTRIP, rowsperstrip); } TIFFGetFieldDefaulted(in, TIFFTAG_PLANARCONFIG, &input_planar); if (config != (uint16) -1) TIFFSetField(out, TIFFTAG_PLANARCONFIG, config); else CopyField(TIFFTAG_PLANARCONFIG, config); if (spp <= 4) CopyTag(TIFFTAG_TRANSFERFUNCTION, 4, TIFF_SHORT); CopyTag(TIFFTAG_COLORMAP, 4, TIFF_SHORT); switch (compression) { case COMPRESSION_JPEG:  if (((bps % 8) == 0) || ((bps % 12) == 0))  {  TIFFSetField(out, TIFFTAG_JPEGQUALITY, quality);  TIFFSetField(out, TIFFTAG_JPEGCOLORMODE, JPEGCOLORMODE_RGB);  }  else  {  TIFFError(\"writeCroppedImage\",  \"JPEG compression requires 8 or 12 bits per sample\");  return (-1);  }  break;  case COMPRESSION_LZW:  case COMPRESSION_ADOBE_DEFLATE:  case COMPRESSION_DEFLATE: if (predictor != (uint16)-1) TIFFSetField(out, TIFFTAG_PREDICTOR, predictor); else CopyField(TIFFTAG_PREDICTOR, predictor); break;  case COMPRESSION_CCITTFAX3:  case COMPRESSION_CCITTFAX4: if (bps != 1) { TIFFError(\"writeCroppedImage\", \"Group 3/4 compression is not usable with bps > 1\"); return (-1); } if (compression == COMPRESSION_CCITTFAX3) { if (g3opts != (uint32) -1) TIFFSetField(out, TIFFTAG_GROUP3OPTIONS, g3opts); else CopyField(TIFFTAG_GROUP3OPTIONS, g3opts); } else { CopyTag(TIFFTAG_GROUP4OPTIONS, 1, TIFF_LONG); } CopyTag(TIFFTAG_BADFAXLINES, 1, TIFF_LONG); CopyTag(TIFFTAG_CLEANFAXDATA, 1, TIFF_LONG); CopyTag(TIFFTAG_CONSECUTIVEBADFAXLINES, 1, TIFF_LONG); CopyTag(TIFFTAG_FAXRECVPARAMS, 1, TIFF_LONG); CopyTag(TIFFTAG_FAXRECVTIME, 1, TIFF_LONG); CopyTag(TIFFTAG_FAXSUBADDRESS, 1, TIFF_ASCII); break; case COMPRESSION_NONE:  break; default: break;  }  { uint32 len32;  void** data;  if (TIFFGetField(in, TIFFTAG_ICCPROFILE, &len32, &data))  TIFFSetField(out, TIFFTAG_ICCPROFILE, len32, data);  }  { uint16 ninks;  const char* inknames;  if (TIFFGetField(in, TIFFTAG_NUMBEROFINKS, &ninks)) {  TIFFSetField(out, TIFFTAG_NUMBEROFINKS, ninks);  if (TIFFGetField(in, TIFFTAG_INKNAMES, &inknames)) {  int inknameslen = strlen(inknames) + 1;  const char* cp = inknames;  while (ninks > 1) {  cp = strchr(cp, '\\0');  if (cp) {  cp++;  inknameslen += (strlen(cp) + 1);  }  ninks--;  }  TIFFSetField(out, TIFFTAG_INKNAMES, inknameslen, inknames);  }  }  }  {  unsigned short pg0, pg1;  if (TIFFGetField(in, TIFFTAG_PAGENUMBER, &pg0, &pg1)) {  TIFFSetField(out, TIFFTAG_PAGENUMBER, pagenum, total_pages);  }  } for (p = tags; p < &tags[NTAGS]; p++) CopyTag(p->tag, p->count, p->type);  if (outtiled) { if (config == PLANARCONFIG_CONTIG) { if (writeBufferToContigTiles (out, crop_buff, length, width, spp, dump)) TIFFError(\"\",\"Unable to write contiguous tile data for page %d\", pagenum); } else { if (writeBufferToSeparateTiles (out, crop_buff, length, width, spp, dump)) TIFFError(\"\",\"Unable to write separate tile data for page %d\", pagenum); } } else { if (config == PLANARCONFIG_CONTIG) { if (writeBufferToContigStrips (out, crop_buff, length)) TIFFError(\"\",\"Unable to write contiguous strip data for page %d\", pagenum); } else { if (writeBufferToSeparateStrips(out, crop_buff, length, width, spp, dump)) TIFFError(\"\",\"Unable to write separate strip data for page %d\", pagenum); } } if (!TIFFWriteDirectory(out)) { TIFFError(\"\",\"Failed to write IFD for page number %d\", pagenum); TIFFClose(out); return (-1); } return (0); } ", "target": 0, "idx": 100478, "project": "LibTIFF"}
{"func": "static void migrate_timers_from_cpu(unsigned int old_cpu) { unsigned int new_cpu = cpumask_any(&cpu_online_map); struct timers *old_ts, *new_ts; struct timer *t; bool_t notify = 0; ASSERT(!cpu_online(old_cpu) && cpu_online(new_cpu)); old_ts = &per_cpu(timers, old_cpu); new_ts = &per_cpu(timers, new_cpu); if ( old_cpu < new_cpu ) { spin_lock_irq(&old_ts->lock); spin_lock(&new_ts->lock); } else { spin_lock_irq(&new_ts->lock); spin_lock(&old_ts->lock); } while ( (t = GET_HEAP_SIZE(old_ts->heap)  ? old_ts->heap[1] : old_ts->list) != NULL ) { remove_entry(t); write_atomic(&t->cpu, new_cpu); notify |= add_entry(t); } while ( !list_empty(&old_ts->inactive) ) { t = list_entry(old_ts->inactive.next, struct timer, inactive); list_del(&t->inactive); write_atomic(&t->cpu, new_cpu); list_add(&t->inactive, &new_ts->inactive); } spin_unlock(&old_ts->lock); spin_unlock_irq(&new_ts->lock); if ( notify ) cpu_raise_softirq(new_cpu, TIMER_SOFTIRQ); }", "target": 0, "idx": 106441, "project": "Xen"}
{"func": "int main(int argc, char *argv[]) { char **cargv; struct command *cmd; int cargc, i, cnt, ret; #ifdef CORE_DUMP #include <sys/resource.h> struct rlimit rlim; rlim.rlim_cur = RLIM_INFINITY; rlim.rlim_max = RLIM_INFINITY; if (setrlimit(RLIMIT_CORE, &rlim) < 0) fprintf(stderr, \"setrlimit failed: %d\\n\", errno); #endif setlocale(LC_CTYPE, \"\"); ret = 0; if (argc < 2) help(); cargc = argc - 1; cmd = get_command(argv[1]); if (!cmd) { fprintf(stderr, \"invalid COMMAND %s\\n\", argv[1]); help(); } cargv = malloc(sizeof(char *) * cargc); if (!cargv) exit(ENOMEM); cnt= 1; cargv[0] = cmd->name; for (i = 1; i < cargc; i++) { char *arg = argv[i + (argc - cargc)]; if (!strcmp(arg, \"--debug\")) { libvhd_set_log_level(1); continue; } cargv[cnt++] = arg; } #ifdef ENABLE_FAILURE_TESTING for (i = 0; i < NUM_FAIL_TESTS; i++) { TEST_FAIL[i] = 0; if (getenv(ENV_VAR_FAIL[i])) TEST_FAIL[i] = 1; } #endif  ret = cmd->func(cnt, cargv); free(cargv); return (ret >= 0 ? ret : -ret); }", "target": 0, "idx": 106863, "project": "Xen"}
{"func": "int libxl_sched_credit_params_get(libxl_ctx *ctx, uint32_t poolid, libxl_sched_credit_params *scinfo) { struct xen_sysctl_credit_schedule sparam; int r, rc; GC_INIT(ctx); r = xc_sched_credit_params_get(ctx->xch, poolid, &sparam); if (r < 0) { LOGE(ERROR, \"getting Credit scheduler parameters\"); rc = ERROR_FAIL; goto out; } scinfo->tslice_ms = sparam.tslice_ms; scinfo->ratelimit_us = sparam.ratelimit_us; scinfo->vcpu_migr_delay_us = sparam.vcpu_migr_delay_us; rc = 0;  out: GC_FREE; return rc; }", "target": 0, "idx": 103976, "project": "Xen"}
{"func": "void do_tasklet(void) { unsigned int cpu = smp_processor_id(); unsigned long *work_to_do = &per_cpu(tasklet_work_to_do, cpu); struct list_head *list = &per_cpu(tasklet_list, cpu);  ASSERT(tasklet_work_to_do(cpu)); spin_lock_irq(&tasklet_lock); do_tasklet_work(cpu, list); if ( list_empty(list) ) { clear_bit(_TASKLET_enqueued, work_to_do); raise_softirq(SCHEDULE_SOFTIRQ); } spin_unlock_irq(&tasklet_lock); }", "target": 0, "idx": 106278, "project": "Xen"}
{"func": "void __init mp_config_acpi_legacy_irqs (void) { struct mpc_config_intsrc intsrc; inti = 0; intioapic = -1;  mp_bus_id_to_type[MP_ISA_BUS] = MP_BUS_ISA; Dprintk(\"Bus #%d is ISA\\n\", MP_ISA_BUS);  ioapic = mp_find_ioapic(0); if (ioapic < 0) return; intsrc.mpc_type = MP_INTSRC; intsrc.mpc_irqflag = 0; intsrc.mpc_srcbus = MP_ISA_BUS; intsrc.mpc_dstapic = mp_ioapics[ioapic].mpc_apicid;  for (i = 0; platform_legacy_irq(i); i++) { int idx; for (idx = 0; idx < mp_irq_entries; idx++) { struct mpc_config_intsrc *irq = mp_irqs + idx;  if (irq->mpc_srcbus == MP_ISA_BUS && irq->mpc_srcbusirq == i) break;  if ((irq->mpc_dstapic == intsrc.mpc_dstapic) && (irq->mpc_dstirq == i)) break; } if (idx != mp_irq_entries) { printk(KERN_DEBUG \"ACPI: IRQ%d used by override.\\n\", i); continue; } intsrc.mpc_irqtype = mp_INT; intsrc.mpc_srcbusirq = i;  intsrc.mpc_dstirq = i; Dprintk(\"Int: type %d, pol %d, trig %d, bus %d, irq %d, \" \"%d-%d\\n\", intsrc.mpc_irqtype, intsrc.mpc_irqflag & 3,  (intsrc.mpc_irqflag >> 2) & 3, intsrc.mpc_srcbus,  intsrc.mpc_srcbusirq, intsrc.mpc_dstapic,  intsrc.mpc_dstirq); mp_irqs[mp_irq_entries] = intsrc; if (++mp_irq_entries == MAX_IRQ_SOURCES) panic(\"Max # of irq sources exceeded\"); } }", "target": 0, "idx": 104661, "project": "Xen"}
{"func": "static void mc_panic_dump(void) { int cpu; dprintk(XENLOG_ERR, \"Begin dump mc_info\\n\"); for_each_online_cpu(cpu) mctelem_process_deferred(cpu, x86_mcinfo_dump_panic,  mctelem_has_deferred_lmce(cpu)); dprintk(XENLOG_ERR, \"End dump mc_info, %x mcinfo dumped\\n\", mcinfo_dumpped); }", "target": 0, "idx": 104361, "project": "Xen"}
{"func": "static void tap_cli_open_usage(FILE *stream) { fprintf(stream, \"usage: open <-p pid> <-m minor> <-a args>\\n\"); }", "target": 0, "idx": 106064, "project": "Xen"}
{"func": "void serial_start_sync(int handle) { struct serial_port *port; unsigned long flags; if ( handle == -1 ) return; port = &com[handle & SERHND_IDX]; spin_lock_irqsave(&port->tx_lock, flags); if ( port->sync++ == 0 ) { while ( (port->txbufp - port->txbufc) != 0 ) { int n; while ( !(n = port->driver->tx_ready(port)) ) cpu_relax(); if ( n < 0 )  break; serial_start_tx(port); port->driver->putc( port, port->txbuf[mask_serial_txbuf_idx(port->txbufc++)]); } if ( port->driver->flush ) port->driver->flush(port); } spin_unlock_irqrestore(&port->tx_lock, flags); }", "target": 0, "idx": 105686, "project": "Xen"}
{"func": "_hidden int libxl__compare_macs(libxl_mac *a, libxl_mac *b) { int i; for (i = 0; i<6; i++) { if ((*a)[i] != (*b)[i]) return (*a)[i] - (*b)[i]; } return 0; }", "target": 0, "idx": 103732, "project": "Xen"}
{"func": "static inline struct list_head *rt_runq(const struct scheduler *ops) { return &rt_priv(ops)->runq; }", "target": 0, "idx": 105637, "project": "Xen"}
{"func": "ssize_t apei_read_mce(struct mce *m, u64 *record_id) { struct cper_mce_record rcd; ssize_t len; if (!m || !record_id) return -EINVAL; len = erst_read_next(&rcd.hdr, sizeof(rcd)); if (len <= 0) return len;  else if (len != sizeof(rcd) ||  uuid_le_cmp(rcd.hdr.creator_id, CPER_CREATOR_MCE)) { printk(KERN_WARNING \"MCE-APEI: Can not skip the unknown record in ERST\"); return -EIO; } memcpy(m, &rcd.mce, sizeof(*m)); *record_id = rcd.hdr.record_id; return sizeof(*m); }", "target": 0, "idx": 104330, "project": "Xen"}
{"func": "static bool intel_srao_check(uint64_t status) { return (intel_check_mce_type(status) == intel_mce_ucr_srao); }", "target": 0, "idx": 104406, "project": "Xen"}
{"func": "int main_psr_cmt_show(int argc, char **argv) { int opt, ret = 0; uint32_t domid; libxl_psr_cmt_type type; SWITCH_FOREACH_OPT(opt, \"\", NULL, \"psr-cmt-show\", 1) {  } if (!strcmp(argv[optind], \"cache-occupancy\")) type = LIBXL_PSR_CMT_TYPE_CACHE_OCCUPANCY; else if (!strcmp(argv[optind], \"total-mem-bandwidth\")) type = LIBXL_PSR_CMT_TYPE_TOTAL_MEM_COUNT; else if (!strcmp(argv[optind], \"local-mem-bandwidth\")) type = LIBXL_PSR_CMT_TYPE_LOCAL_MEM_COUNT; else { help(\"psr-cmt-show\"); return 2; } if (optind + 1 >= argc) domid = INVALID_DOMID; else if (optind + 1 == argc - 1) domid = find_domain(argv[optind + 1]); else { help(\"psr-cmt-show\"); return 2; } ret = psr_cmt_show(type, domid); return ret; }", "target": 0, "idx": 108763, "project": "Xen"}
{"func": "void tasklet_init( struct tasklet *t, void (*func)(unsigned long), unsigned long data) { memset(t, 0, sizeof(*t)); INIT_LIST_HEAD(&t->list); t->scheduled_on = -1; t->func = func; t->data = data; }", "target": 0, "idx": 106283, "project": "Xen"}
{"func": "char *talloc_describe_all(void) { ssize_t len = 0; size_t buflen = 512; char *s = NULL; if (null_context == NULL) { return NULL; } sprintf_append(NULL, &s, &len, &buflen, \"full talloc report on '%s' (total %lu bytes in %lu blocks)\\n\",  talloc_get_name(null_context),  (unsigned long)talloc_total_size(null_context), (unsigned long)talloc_total_blocks(null_context)); if (!s) { return NULL; } talloc_report_depth_str(null_context, &s, &len, &buflen, 1); return s; }", "target": 0, "idx": 105958, "project": "Xen"}
{"func": "static void _rcu_node_free(struct rcu_head *head) { struct rcu_node *rcu_node = container_of(head, struct rcu_node, rcu_head); xfree(rcu_node); }", "target": 0, "idx": 105301, "project": "Xen"}
{"func": "static int fixup_page_fault(unsigned long addr, struct cpu_user_regs *regs) { struct vcpu *v = current; struct domain *d = v->domain;  if ( in_irq() || !(regs->eflags & X86_EFLAGS_IF) ) return 0;  if ( paging_mode_external(d) && guest_mode(regs) ) { int ret = paging_fault(addr, regs); if ( ret == EXCRET_fault_fixed ) trace_trap_two_addr(TRC_PV_PAGING_FIXUP, regs->eip, addr); return ret; } if ( !(regs->error_code & PFEC_page_present) && (pagefault_by_memadd(addr, regs)) ) return handle_memadd_fault(addr, regs); if ( unlikely(IN_HYPERVISOR_RANGE(addr)) ) { if ( !(regs->error_code & PFEC_reserved_bit) &&  (addr >= GDT_LDT_VIRT_START) && (addr < GDT_LDT_VIRT_END) ) return handle_gdt_ldt_mapping_fault( addr - GDT_LDT_VIRT_START, regs); return 0; } if ( VM_ASSIST(d, VMASST_TYPE_writable_pagetables) &&  guest_kernel_mode(v, regs) &&    ((regs->error_code & (PFEC_write_access|PFEC_reserved_bit)) == PFEC_write_access) &&  ptwr_do_page_fault(v, addr, regs) ) return EXCRET_fault_fixed;  if ( paging_mode_enabled(d) && !paging_mode_external(d) ) { int ret = paging_fault(addr, regs); if ( ret == EXCRET_fault_fixed ) trace_trap_two_addr(TRC_PV_PAGING_FIXUP, regs->eip, addr); return ret; } return 0; }", "target": 1, "idx": 108987, "project": "Xen"}
{"func": "static int csched2_cpu_pick(const struct scheduler *ops, struct vcpu *vc) { struct csched2_private *prv = csched2_priv(ops); int i, min_rqi = -1, min_s_rqi = -1; unsigned int new_cpu, cpu = vc->processor; struct csched2_vcpu *svc = csched2_vcpu(vc); s_time_t min_avgload = MAX_LOAD, min_s_avgload = MAX_LOAD; bool has_soft; ASSERT(!cpumask_empty(&prv->active_queues)); SCHED_STAT_CRANK(pick_cpu);  ASSERT(spin_is_locked(per_cpu(schedule_data, cpu).schedule_lock)); if ( !read_trylock(&prv->lock) ) {  __clear_bit(__CSFLAG_runq_migrate_request, &svc->flags); new_cpu = get_fallback_cpu(svc);  goto out; } cpumask_and(cpumask_scratch_cpu(cpu), vc->cpu_hard_affinity, cpupool_domain_cpumask(vc->domain));  if ( __test_and_clear_bit(__CSFLAG_runq_migrate_request, &svc->flags) ) { if ( unlikely(svc->migrate_rqd->id < 0) ) { printk(XENLOG_WARNING \"%s: target runqueue disappeared!\\n\",  __func__); } else if ( cpumask_intersects(cpumask_scratch_cpu(cpu),  &svc->migrate_rqd->active) ) {  cpumask_and(cpumask_scratch_cpu(cpu), cpumask_scratch_cpu(cpu), &svc->migrate_rqd->active); new_cpu = cpumask_cycle(svc->migrate_rqd->pick_bias, cpumask_scratch_cpu(cpu)); svc->migrate_rqd->pick_bias = new_cpu; goto out_up; }  }  has_soft = has_soft_affinity(vc); for_each_cpu(i, &prv->active_queues) { struct csched2_runqueue_data *rqd; s_time_t rqd_avgload = MAX_LOAD; rqd = prv->rqd + i;  if ( !cpumask_intersects(cpumask_scratch_cpu(cpu), &rqd->active) ) continue;  if ( rqd == svc->rqd ) { rqd_avgload = max_t(s_time_t, rqd->b_avgload - svc->avgload, 0); } else if ( spin_trylock(&rqd->lock) ) { rqd_avgload = rqd->b_avgload; spin_unlock(&rqd->lock); }  if ( has_soft &&  rqd_avgload < min_s_avgload ) { cpumask_t mask; cpumask_and(&mask, cpumask_scratch_cpu(cpu), &rqd->active); if ( cpumask_intersects(&mask, svc->vcpu->cpu_soft_affinity) ) { min_s_avgload = rqd_avgload; min_s_rqi = i; } }  if ( rqd_avgload < min_avgload ) { min_avgload = rqd_avgload; min_rqi = i; } } if ( has_soft && min_s_rqi != -1 ) {  cpumask_and(cpumask_scratch_cpu(cpu), cpumask_scratch_cpu(cpu), vc->cpu_soft_affinity); cpumask_and(cpumask_scratch_cpu(cpu), cpumask_scratch_cpu(cpu), &prv->rqd[min_s_rqi].active); } else if ( min_rqi != -1 ) {  cpumask_and(cpumask_scratch_cpu(cpu), cpumask_scratch_cpu(cpu), &prv->rqd[min_rqi].active); } else {  new_cpu = get_fallback_cpu(svc); min_rqi = c2r(new_cpu); min_avgload = prv->rqd[min_rqi].b_avgload; goto out_up; } new_cpu = cpumask_cycle(prv->rqd[min_rqi].pick_bias, cpumask_scratch_cpu(cpu)); prv->rqd[min_rqi].pick_bias = new_cpu; BUG_ON(new_cpu >= nr_cpu_ids);  out_up: read_unlock(&prv->lock);  out: if ( unlikely(tb_init_done) ) { struct { uint64_t b_avgload; unsigned vcpu:16, dom:16; unsigned rq_id:16, new_cpu:16; } d; d.dom = vc->domain->domain_id; d.vcpu = vc->vcpu_id; d.rq_id = min_rqi; d.b_avgload = min_avgload; d.new_cpu = new_cpu; __trace_var(TRC_CSCHED2_PICKED_CPU, 1, sizeof(d), (unsigned char *)&d); } return new_cpu; }", "target": 0, "idx": 105529, "project": "Xen"}
{"func": " */ int vgic_vcpu_pending_irq(struct vcpu *v) { struct pending_irq *p; unsigned long flags; const unsigned long apr = gic_hw_ops->read_apr(0); int mask_priority; int active_priority; int rc = 0;  ASSERT(v == current); mask_priority = gic_hw_ops->read_vmcr_priority(); active_priority = find_next_bit(&apr, 32, 0); spin_lock_irqsave(&v->arch.vgic.lock, flags);   list_for_each_entry( p, &v->arch.vgic.inflight_irqs, inflight ) { if ( GIC_PRI_TO_GUEST(p->priority) >= mask_priority ) goto out; if ( GIC_PRI_TO_GUEST(p->priority) >= active_priority ) goto out; if ( test_bit(GIC_IRQ_GUEST_ENABLED, &p->status) ) { rc = 1; goto out; } } out: spin_unlock_irqrestore(&v->arch.vgic.lock, flags); return rc; }", "target": 0, "idx": 102561, "project": "Xen"}
{"func": "static void csched_vcpu_wake(const struct scheduler *ops, struct vcpu *vc) { struct csched_vcpu * const svc = CSCHED_VCPU(vc); bool_t migrating; BUG_ON( is_idle_vcpu(vc) ); if ( unlikely(curr_on_cpu(vc->processor) == vc) ) { SCHED_STAT_CRANK(vcpu_wake_running); return; } if ( unlikely(__vcpu_on_runq(svc)) ) { SCHED_STAT_CRANK(vcpu_wake_onrunq); return; } if ( likely(vcpu_runnable(vc)) ) SCHED_STAT_CRANK(vcpu_wake_runnable); else SCHED_STAT_CRANK(vcpu_wake_not_runnable);  migrating = test_and_clear_bit(CSCHED_FLAG_VCPU_MIGRATING, &svc->flags); if ( !migrating && svc->pri == CSCHED_PRI_TS_UNDER &&  !test_bit(CSCHED_FLAG_VCPU_PARKED, &svc->flags) ) { TRACE_2D(TRC_CSCHED_BOOST_START, vc->domain->domain_id, vc->vcpu_id); SCHED_STAT_CRANK(vcpu_boost); svc->pri = CSCHED_PRI_TS_BOOST; }  runq_insert(svc); __runq_tickle(svc); }", "target": 0, "idx": 105499, "project": "Xen"}
{"func": "static void __iomem *sunxi_map_watchdog(bool *new_wdt) { void __iomem *wdt; struct dt_device_node *node; paddr_t wdt_start, wdt_len; bool _new_wdt = false; int ret; node = dt_find_compatible_node(NULL, NULL, \"allwinner,sun6i-a31-wdt\"); if ( node )  _new_wdt = true; else node = dt_find_compatible_node(NULL, NULL, \"allwinner,sun4i-a10-wdt\"); if ( !node ) { dprintk(XENLOG_ERR, \"Cannot find matching watchdog node in DT\\n\"); return NULL; } ret = dt_device_get_address(node, 0, &wdt_start, &wdt_len); if ( ret ) { dprintk(XENLOG_ERR, \"Cannot read watchdog register address\\n\"); return NULL; } wdt = ioremap_nocache(wdt_start & PAGE_MASK, PAGE_SIZE); if ( !wdt ) { dprintk(XENLOG_ERR, \"Unable to map watchdog register!\\n\"); return NULL; } if ( new_wdt ) *new_wdt = _new_wdt; return wdt + (wdt_start & ~PAGE_MASK); }", "target": 0, "idx": 105885, "project": "Xen"}
{"func": "static void __vhd_io_dynamic_copy_data(vhd_context_t *ctx,  char *map, int map_off,  char *bitmap, int bitmap_off,  char *dst, char *src, int secs) { int i; for (i = 0; i < secs; i++) { if (test_bit(map, map_off + i)) goto next; if (ctx && !vhd_bitmap_test(ctx, bitmap, bitmap_off + i)) goto next; memcpy(dst, src, VHD_SECTOR_SIZE); set_bit(map, map_off + i); next: src += VHD_SECTOR_SIZE; dst += VHD_SECTOR_SIZE; } }", "target": 0, "idx": 103202, "project": "Xen"}
{"func": "static int sched_domain_output(libxl_scheduler sched, int (*output)(int),  int (*pooloutput)(uint32_t), const char *cpupool) { libxl_dominfo *info; libxl_cpupoolinfo *poolinfo = NULL; uint32_t poolid; int nb_domain, n_pools = 0, i, p; int rc = 0; if (cpupool) { if (libxl_cpupool_qualifier_to_cpupoolid(ctx, cpupool, &poolid, NULL) || !libxl_cpupoolid_is_valid(ctx, poolid)) { fprintf(stderr, \"unknown cpupool \\'%s\\'\\n\", cpupool); return 1; } } info = libxl_list_domain(ctx, &nb_domain); if (!info) { fprintf(stderr, \"libxl_list_domain failed.\\n\"); return 1; } poolinfo = libxl_list_cpupool(ctx, &n_pools); if (!poolinfo) { fprintf(stderr, \"error getting cpupool info\\n\"); libxl_dominfo_list_free(info, nb_domain); return 1; } for (p = 0; !rc && (p < n_pools); p++) { if ((poolinfo[p].sched != sched) || (cpupool && (poolid != poolinfo[p].poolid))) continue; pooloutput(poolinfo[p].poolid); output(-1); for (i = 0; i < nb_domain; i++) { if (info[i].cpupool != poolinfo[p].poolid) continue; rc = output(info[i].domid); if (rc) break; } } libxl_cpupoolinfo_list_free(poolinfo, n_pools); libxl_dominfo_list_free(info, nb_domain); return 0; }", "target": 0, "idx": 108793, "project": "Xen"}
{"func": "static inline void unlock_bitmap(struct vhd_bitmap *bm) { clear_vhd_flag(bm->status, VHD_FLAG_BM_LOCKED); }", "target": 0, "idx": 101194, "project": "Xen"}
{"func": "static void ack_lapic_irq(struct irq_desc *desc) { ack_APIC_irq(); }", "target": 0, "idx": 102834, "project": "Xen"}
{"func": "int libxl_device_vtpm_getinfo(libxl_ctx *ctx, uint32_t domid, libxl_device_vtpm *vtpm, libxl_vtpminfo *vtpminfo) { GC_INIT(ctx); char *dompath, *vtpmpath; char *val; int rc = 0; libxl_vtpminfo_init(vtpminfo); dompath = libxl__xs_get_dompath(gc, domid); vtpminfo->devid = vtpm->devid; vtpmpath = GCSPRINTF(\"%s/device/vtpm/%d\", dompath, vtpminfo->devid); vtpminfo->backend = xs_read(ctx->xsh, XBT_NULL, GCSPRINTF(\"%s/backend\", vtpmpath), NULL); if (!vtpminfo->backend) { goto err; } if(!libxl__xs_read(gc, XBT_NULL, vtpminfo->backend)) {  goto err; } val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/backend-id\", vtpmpath)); vtpminfo->backend_id = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/state\", vtpmpath)); vtpminfo->state = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/event-channel\", vtpmpath)); vtpminfo->evtch = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/ring-ref\", vtpmpath)); vtpminfo->rref = val ? strtoul(val, NULL, 10) : -1; vtpminfo->frontend = xs_read(ctx->xsh, XBT_NULL, GCSPRINTF(\"%s/frontend\", vtpminfo->backend), NULL); val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/frontend-id\", vtpminfo->backend)); vtpminfo->frontend_id = val ? strtoul(val, NULL, 10) : -1; val = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/uuid\", vtpminfo->backend)); if(val == NULL) {  LOG(ERROR, \"%s/uuid does not exist!\", vtpminfo->backend);  goto err; } if(libxl_uuid_from_string(&(vtpminfo->uuid), val)) {  LOG(ERROR,  \"%s/uuid is a malformed uuid?? (%s) Probably a bug!\\n\",  vtpminfo->backend, val);  goto err; } goto exit; err: rc = ERROR_FAIL; exit: GC_FREE; return rc; }", "target": 1, "idx": 109382, "project": "Xen"}
{"func": "static void tboot_gen_frametable_integrity(const uint8_t key[TB_KEY_SIZE],  vmac_t *mac) { unsigned int sidx, eidx, nidx; unsigned int max_idx = (max_pdx + PDX_GROUP_COUNT - 1)/PDX_GROUP_COUNT; uint8_t nonce[16] = {}; vmac_ctx_t ctx; vmac_set_key((uint8_t *)key, &ctx); for ( sidx = 0; ; sidx = nidx ) { eidx = find_next_zero_bit(pdx_group_valid, max_idx, sidx); nidx = find_next_bit(pdx_group_valid, max_idx, eidx); if ( nidx >= max_idx ) break; vmac_update((uint8_t *)pdx_to_page(sidx * PDX_GROUP_COUNT),  pdx_to_page(eidx * PDX_GROUP_COUNT)  - pdx_to_page(sidx * PDX_GROUP_COUNT), &ctx); } vmac_update((uint8_t *)pdx_to_page(sidx * PDX_GROUP_COUNT),  pdx_to_page(max_pdx - 1) + 1  - pdx_to_page(sidx * PDX_GROUP_COUNT), &ctx); *mac = vmac(NULL, 0, nonce, NULL, &ctx);  memset(&ctx, 0, sizeof(ctx)); }", "target": 0, "idx": 106298, "project": "Xen"}
{"func": "int vioapic_get_trigger_mode(const struct domain *d, unsigned int gsi) { unsigned int pin; const struct hvm_vioapic *vioapic = gsi_vioapic(d, gsi, &pin); if ( !vioapic ) return -EINVAL; return vioapic->redirtbl[pin].fields.trig_mode; }", "target": 0, "idx": 106874, "project": "Xen"}
{"func": "static int PixarLogSetupEncode(TIFF* tif) { static const char module[] = \"PixarLogSetupEncode\"; TIFFDirectory *td = &tif->tif_dir; PixarLogState* sp = EncoderState(tif); tmsize_t tbuf_size; assert(sp != NULL);  sp->stride = (td->td_planarconfig == PLANARCONFIG_CONTIG ? td->td_samplesperpixel : 1); tbuf_size = multiply_ms(multiply_ms(multiply_ms(sp->stride, td->td_imagewidth), td->td_rowsperstrip), sizeof(uint16)); if (tbuf_size == 0) return (0); sp->tbuf = (uint16 *) _TIFFmalloc(tbuf_size); if (sp->tbuf == NULL) return (0); if (sp->user_datafmt == PIXARLOGDATAFMT_UNKNOWN) sp->user_datafmt = PixarLogGuessDataFmt(td); if (sp->user_datafmt == PIXARLOGDATAFMT_UNKNOWN) { TIFFErrorExt(tif->tif_clientdata, module, \"PixarLog compression can't handle %d bit linear encodings\", td->td_bitspersample); return (0); } if (deflateInit(&sp->stream, sp->quality) != Z_OK) { TIFFErrorExt(tif->tif_clientdata, module, \"%s\", sp->stream.msg ? sp->stream.msg : \"(null)\"); return (0); } else { sp->state |= PLSTATE_INIT; return (1); } }", "target": 0, "idx": 100271, "project": "LibTIFF"}
{"func": "static void shutdown_domain(uint32_t domid, libxl_evgen_domain_death **deathw, libxl_ev_user for_user, int fallback_trigger) { int rc; fprintf(stderr, \"Shutting down domain %u\\n\", domid); rc=libxl_domain_shutdown(ctx, domid); if (rc == ERROR_NOPARAVIRT) { if (fallback_trigger) { fprintf(stderr, \"PV control interface not available:\" \" sending ACPI power button event.\\n\"); rc = libxl_send_trigger(ctx, domid, LIBXL_TRIGGER_POWER, 0); } else { fprintf(stderr, \"PV control interface not available:\" \" external graceful shutdown not possible.\\n\"); fprintf(stderr, \"Use \\\"-F\\\" to fallback to ACPI power event.\\n\"); } } if (rc) { fprintf(stderr,\"shutdown failed (rc=%d)\\n\",rc);exit(EXIT_FAILURE); } if (deathw) { rc = libxl_evenable_domain_death(ctx, domid, for_user, deathw); if (rc) { fprintf(stderr,\"wait for death failed (evgen, rc=%d)\\n\",rc); exit(EXIT_FAILURE); } } }", "target": 0, "idx": 108858, "project": "Xen"}
{"func": "static bool_t acpi_hpet_device_match( struct list_head *list, unsigned int hpet_id) { struct acpi_hpet_unit *hpet; list_for_each_entry( hpet, list, list ) if (hpet->id == hpet_id) return 1; return 0; }", "target": 0, "idx": 101734, "project": "Xen"}
{"func": "static void ShowStrip(tstrip_t strip, unsigned char* pp, uint32 nrow, tsize_t scanline) { register tsize_t cc; printf(\"Strip %lu:\\n\", (unsigned long) strip); while (nrow-- > 0) { for (cc = 0; cc < scanline; cc++) { printf(\" %02x\", *pp++); if (((cc+1) % 24) == 0) putchar('\\n'); } putchar('\\n'); } }", "target": 0, "idx": 100714, "project": "LibTIFF"}
{"func": "static void xmalloc_pool_put(void *p) { free_xenheap_page(p); }", "target": 0, "idx": 108873, "project": "Xen"}
{"func": "static bool_t ehci_dbgp_setup_preirq(struct ehci_dbgp *dbgp) { if ( !ehci_dbgp_setup(dbgp) ) return 1; dbgp_printk(\"ehci_dbgp_setup failed\\n\"); dbgp->ehci_debug = NULL; return 0; }", "target": 0, "idx": 101846, "project": "Xen"}
{"func": "static inline struct csched2_vcpu *csched2_vcpu(const struct vcpu *v) { return v->sched_priv; }", "target": 0, "idx": 105546, "project": "Xen"}
{"func": "static bool __maybe_unused is_affected_midr_range(const struct arm_cpu_capabilities *entry) { return MIDR_IS_CPU_MODEL_RANGE(current_cpu_data.midr.bits, entry->midr_model,  entry->midr_range_min,  entry->midr_range_max); }", "target": 0, "idx": 101486, "project": "Xen"}
{"func": "static void read_symbol_table(const char *symtab) { char type, line[256]; char *p; struct symbol *symbol; FILE *f; guest_word_t address; f = fopen(symtab, \"r\"); if(f == NULL) { fprintf(stderr, \"failed to open symbol table %s\\n\", symtab); exit(-1); } while(!feof(f)) { if(fgets(line,256,f)==NULL) break;  address = strtoull(line, &p, 16); if (!isspace((uint8_t)*p++)) continue; type = *p++; if (!isalpha((uint8_t)type) && type != '?') continue; if (!isspace((uint8_t)*p++)) continue;  if (p[strlen(p)-1] == '\\n') p[strlen(p)-1] = '\\0'; switch (type) { case 'A':  case 'a':  break; case 'U':  case 'v':  case 'w':  continue; default: symbol = malloc(sizeof(*symbol)); if (symbol == NULL) { fclose(f); return; } symbol->address = address; symbol->name = strdup(p); if (symbol->name == NULL) { free(symbol); fclose(f); return; } insert_symbol(symbol); break; } if (strcmp(p, \"_stext\") == 0) kernel_stext = address; else if (strcmp(p, \"_etext\") == 0) kernel_etext = address; else if ( strcmp(p, \"_text\") == 0 ) kernel_text = address; else if ( strcmp(p, \"_end\") == 0 || strcmp(p, \"__bss_stop\") == 0 ) kernel_end = address; else if (strcmp(p, \"_sinittext\") == 0) kernel_sinittext = address; else if (strcmp(p, \"_einittext\") == 0) kernel_einittext = address; else if (strcmp(p, \"hypercall_page\") == 0) kernel_hypercallpage = address; } fclose(f); }", "target": 0, "idx": 108200, "project": "Xen"}
{"func": "static int PixarLogMakeTables(PixarLogState *sp) { intnlin, lt2size; inti, j; doubleb, c, linstep, v; float *ToLinearF; uint16 *ToLinear16; unsigned char *ToLinear8; uint16*FromLT2; uint16*From14;  uint16*From8; c = log(RATIO); nlin = (int)(1./c); c = 1./nlin; b = exp(-c*ONE); linstep = b*c*exp(1.); LogK1 = (float)(1./c); LogK2 = (float)(1./b); lt2size = (int)(2./linstep) + 1; FromLT2 = (uint16 *)_TIFFmalloc(lt2size*sizeof(uint16)); From14 = (uint16 *)_TIFFmalloc(16384*sizeof(uint16)); From8 = (uint16 *)_TIFFmalloc(256*sizeof(uint16)); ToLinearF = (float *)_TIFFmalloc(TSIZEP1 * sizeof(float)); ToLinear16 = (uint16 *)_TIFFmalloc(TSIZEP1 * sizeof(uint16)); ToLinear8 = (unsigned char *)_TIFFmalloc(TSIZEP1 * sizeof(unsigned char)); if (FromLT2 == NULL || From14== NULL || From8 == NULL ||  ToLinearF == NULL || ToLinear16 == NULL || ToLinear8 == NULL) { if (FromLT2) _TIFFfree(FromLT2); if (From14) _TIFFfree(From14); if (From8) _TIFFfree(From8); if (ToLinearF) _TIFFfree(ToLinearF); if (ToLinear16) _TIFFfree(ToLinear16); if (ToLinear8) _TIFFfree(ToLinear8); sp->FromLT2 = NULL; sp->From14 = NULL; sp->From8 = NULL; sp->ToLinearF = NULL; sp->ToLinear16 = NULL; sp->ToLinear8 = NULL; return 0; } j = 0; for (i = 0; i < nlin; i++){ v = i * linstep; ToLinearF[j++] = (float)v; } for (i = nlin; i < TSIZE; i++) ToLinearF[j++] = (float)(b*exp(c*i)); ToLinearF[2048] = ToLinearF[2047]; for (i = 0; i < TSIZEP1; i++){ v = ToLinearF[i]*65535.0 + 0.5; ToLinear16[i] = (v > 65535.0) ? 65535 : (uint16)v; v = ToLinearF[i]*255.0+ 0.5; ToLinear8[i]= (v > 255.0) ? 255 : (unsigned char)v; } j = 0; for (i = 0; i < lt2size; i++){ if ((i*linstep)*(i*linstep) > ToLinearF[j]*ToLinearF[j+1]) j++; FromLT2[i] = (uint16)j; }  j = 0; for (i = 0; i < 16384; i++){ while ((i/16383.)*(i/16383.) > ToLinearF[j]*ToLinearF[j+1]) j++; From14[i] = (uint16)j; } j = 0; for (i = 0; i < 256; i++){ while ((i/255.)*(i/255.) > ToLinearF[j]*ToLinearF[j+1]) j++; From8[i] = (uint16)j; } Fltsize = (float)(lt2size/2); sp->ToLinearF = ToLinearF; sp->ToLinear16 = ToLinear16; sp->ToLinear8 = ToLinear8; sp->FromLT2 = FromLT2; sp->From14 = From14; sp->From8 = From8; return 1; }", "target": 0, "idx": 100269, "project": "LibTIFF"}
{"func": "static inline void vhd_initialize_footer(vhd_context_t *ctx, int type, uint64_t size) { memset(&ctx->footer, 0, sizeof(vhd_footer_t)); memcpy(ctx->footer.cookie, HD_COOKIE, sizeof(ctx->footer.cookie)); ctx->footer.features = HD_RESERVED; ctx->footer.ff_version = HD_FF_VERSION; ctx->footer.timestamp= vhd_time(time(NULL)); ctx->footer.crtr_ver = VHD_CURRENT_VERSION; ctx->footer.crtr_os= 0x00000000; ctx->footer.orig_size= size; ctx->footer.curr_size= size; ctx->footer.geometry = vhd_chs(size); ctx->footer.type = type; ctx->footer.saved= 0; ctx->footer.data_offset= 0xFFFFFFFFFFFFFFFF; strcpy(ctx->footer.crtr_app, \"tap\"); vhd_uuid_generate(&ctx->footer.uuid); }", "target": 0, "idx": 103150, "project": "Xen"}
{"func": "static unsigned int qinval_next_index(struct iommu *iommu) { u64 tail; tail = dmar_readq(iommu->reg, DMAR_IQT_REG); tail >>= QINVAL_INDEX_SHIFT;  while ( ( tail + 1 ) % QINVAL_ENTRY_NR == ( dmar_readq(iommu->reg, DMAR_IQH_REG) >> QINVAL_INDEX_SHIFT ) ) cpu_relax(); return tail; }", "target": 0, "idx": 105258, "project": "Xen"}
{"func": "unsigned long gicv3_its_make_hwdom_madt(const struct domain *d, void *base_ptr) { unsigned int i; void *fw_its; struct acpi_madt_generic_translator *hwdom_its; hwdom_its = base_ptr; for ( i = 0; i < vgic_v3_its_count(d); i++ ) { fw_its = acpi_table_get_entry_madt(ACPI_MADT_TYPE_GENERIC_TRANSLATOR,  i); memcpy(hwdom_its, fw_its, sizeof(struct acpi_madt_generic_translator)); hwdom_its++; } return sizeof(struct acpi_madt_generic_translator) * vgic_v3_its_count(d); }", "target": 0, "idx": 102460, "project": "Xen"}
{"func": "uint32_t vhd_chs(uint64_t size) { uint32_t secs, cylinders, heads, spt, cth; secs = secs_round_up_no_zero(size); if (secs > 65535 * 16 * 255) secs = 65535 * 16 * 255; if (secs >= 65535 * 16 * 63) { spt = 255; cth = secs / spt; heads = 16; } else { spt = 17; cth = secs / spt; heads = (cth + 1023) / 1024; if (heads < 4) heads = 4; if (cth >= (heads * 1024) || heads > 16) { spt = 31; cth = secs / spt; heads = 16; } if (cth >= heads * 1024) { spt = 63; cth = secs / spt; heads = 16; } } cylinders = cth / heads; return GEOM_ENCODE(cylinders, heads, spt); }", "target": 0, "idx": 103131, "project": "Xen"}
{"func": "void *_talloc_memdup(const void *t, const void *p, size_t size, const char *name) { void *newp = talloc_named_const(t, size, name); if (newp) { memcpy(newp, p, size); } return newp; }", "target": 0, "idx": 105995, "project": "Xen"}
{"func": "static int update_progress_string(struct xc_sr_context *ctx, char **str) { xc_interface *xch = ctx->xch; char *new_str = NULL; unsigned int iter = ctx->save.stats.iteration; if ( asprintf(&new_str, \"Frames iteration %u\", iter) == -1 ) { PERROR(\"Unable to allocate new progress string\"); return -1; } free(*str); *str = new_str; xc_set_progress_prefix(xch, *str); return 0; }", "target": 0, "idx": 107764, "project": "Xen"}
{"func": "static void osevent_hook_pre_release(libxl__gc *gc, void *ev,  libxl__osevent_hook_nexi *nexi_idle,  libxl__osevent_hook_nexus **nexus) { osevent_release_nexus(gc, nexi_idle, *nexus); }", "target": 0, "idx": 103666, "project": "Xen"}
{"func": "int write_tsc_info(struct xc_sr_context *ctx) { xc_interface *xch = ctx->xch; struct xc_sr_rec_tsc_info tsc = { 0 }; struct xc_sr_record rec = { .type = REC_TYPE_TSC_INFO, .length = sizeof(tsc), .data = &tsc }; if ( xc_domain_get_tsc_info(xch, ctx->domid, &tsc.mode, &tsc.nsec, &tsc.khz, &tsc.incarnation) < 0 ) { PERROR(\"Unable to obtain TSC information\"); return -1; } return write_record(ctx, &rec); }", "target": 0, "idx": 107702, "project": "Xen"}
{"func": "evtchn_port_or_error_t xc_evtchn_bind_interdomain(xc_evtchn *xce, uint32_t domid,  evtchn_port_t remote_port) { return xenevtchn_bind_interdomain(xce, domid, remote_port); }", "target": 0, "idx": 107466, "project": "Xen"}
{"func": "static int libxl__append_channel_list_of_type(libxl__gc *gc, uint32_t domid, const char *type, libxl_device_channel **channels, int *nchannels) { char *fe_path = NULL, *be_path = NULL; char **dir = NULL; unsigned int n = 0, devid = 0; libxl_device_channel *next = NULL; int rc = 0, i; fe_path = GCSPRINTF(\"%s/device/%s\", libxl__xs_get_dompath(gc, domid), type); dir = libxl__xs_directory(gc, XBT_NULL, fe_path, &n); if (!dir || !n) goto out; for (i = 0; i < n; i++) { const char *p, *name; libxl_device_channel *tmp; p = libxl__sprintf(gc, \"%s/%s\", fe_path, dir[i]); name = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/name\", p));  if (!name) continue; be_path = libxl__xs_read(gc, XBT_NULL, GCSPRINTF(\"%s/backend\", p)); tmp = realloc(*channels, sizeof(libxl_device_channel) * (*nchannels + devid + 1)); if (!tmp) { rc = ERROR_NOMEM; goto out; } *channels = tmp; next = *channels + *nchannels + devid; rc = libxl__device_channel_from_xs_be(gc, be_path, next); if (rc) goto out; next->devid = devid; devid++; } *nchannels += devid; return 0;  out: return rc; }", "target": 1, "idx": 109358, "project": "Xen"}
{"func": "static int exynos5250_specific_mapping(struct domain *d) {  map_mmio_regions(d, gaddr_to_gfn(EXYNOS5_PA_CHIPID), 1,  maddr_to_mfn(EXYNOS5_PA_CHIPID));  map_mmio_regions(d, gaddr_to_gfn(EXYNOS5_PA_TIMER), 2,  maddr_to_mfn(EXYNOS5_PA_TIMER)); return 0; }", "target": 0, "idx": 101978, "project": "Xen"}
{"func": "pid_t pid, int status); void libxl__destroy_domid(libxl__egc *egc, libxl__destroy_domid_state *dis) { STATE_AO_GC(dis->ao); libxl_ctx *ctx = CTX; uint32_t domid = dis->domid; char *dom_path; int rc, dm_present; libxl__ev_child_init(&dis->destroyer); rc = libxl_domain_info(ctx, NULL, domid); switch(rc) { case 0: break; case ERROR_DOMAIN_NOTFOUND: LOGD(ERROR, domid, \"Non-existant domain\"); default: goto out; } switch (libxl__domain_type(gc, domid)) { case LIBXL_DOMAIN_TYPE_HVM: if (libxl_get_stubdom_id(CTX, domid)) { dm_present = 0; break; }  case LIBXL_DOMAIN_TYPE_PVH: case LIBXL_DOMAIN_TYPE_PV: dm_present = libxl__dm_active(gc, domid); break; case LIBXL_DOMAIN_TYPE_INVALID: rc = ERROR_FAIL; goto out; default: abort(); } dom_path = libxl__xs_get_dompath(gc, domid); if (!dom_path) { rc = ERROR_FAIL; goto out; } if (libxl__device_pci_destroy_all(gc, domid) < 0) LOGD(ERROR, domid, \"Pci shutdown failed\"); rc = xc_domain_pause(ctx->xch, domid); if (rc < 0) { LOGEVD(ERROR, rc, domid, \"xc_domain_pause failed\"); } if (dm_present) { if (libxl__destroy_device_model(gc, domid) < 0) LOGD(ERROR, domid, \"libxl__destroy_device_model failed\"); libxl__qmp_cleanup(gc, domid); } dis->drs.ao = ao; dis->drs.domid = domid; dis->drs.callback = devices_destroy_cb; dis->drs.force = 1; libxl__devices_destroy(egc, &dis->drs); return; out: assert(rc); dis->callback(egc, dis, rc); return; }", "target": 0, "idx": 103544, "project": "Xen"}
{"func": "int compat_update_descriptor(uint32_t pa_lo, uint32_t pa_hi,  uint32_t desc_lo, uint32_t desc_hi) { return do_update_descriptor(pa_lo | ((uint64_t)pa_hi << 32), desc_lo | ((uint64_t)desc_hi << 32)); }", "target": 0, "idx": 101645, "project": "Xen"}
{"func": "static unsigned int get_sleep_length_us(void) { s_time_t us = (this_cpu(timer_deadline) - NOW()) / 1000;  return (us >> 32) ? (unsigned int)-2000 : (unsigned int)us; }", "target": 0, "idx": 101543, "project": "Xen"}
{"func": " */ static int EISA_ELCR(unsigned int irq) { if (platform_legacy_irq(irq)) { unsigned int port = 0x4d0 + (irq >> 3); return (inb(port) >> (irq & 7)) & 1; } apic_printk(APIC_VERBOSE, KERN_INFO \"Broken MPtable reports ISA irq %d\\n\", irq); return 0; }", "target": 0, "idx": 102847, "project": "Xen"}
{"func": "acpi_status __init acpi_tb_verify_checksum(struct acpi_table_header *table, u32 length) { u8 checksum;  checksum = acpi_tb_checksum(ACPI_CAST_PTR(u8, table), length);  if (checksum) { ACPI_WARNING((AE_INFO, \"Incorrect checksum in table [%4.4s] - %2.2X, should be %2.2X\", table->signature, table->checksum, (u8) (table->checksum - checksum))); #if (ACPI_CHECKSUM_ABORT) return (AE_BAD_CHECKSUM); #endif } return (AE_OK); }", "target": 0, "idx": 106313, "project": "Xen"}
{"func": "void *xc_gnttab_map_grant_refs(xc_gnttab *xcg,  uint32_t count,  uint32_t *domids,  uint32_t *refs,  int prot) { return xengnttab_map_grant_refs(xcg, count, domids, refs, prot); }", "target": 0, "idx": 107517, "project": "Xen"}
{"func": "char *libxl__devid_to_localdev(libxl__gc *gc, int devid) {  return NULL; }", "target": 0, "idx": 103774, "project": "Xen"}
{"func": "static int domain_construct_memmap(libxl__gc *gc,  libxl_domain_config *d_config,  uint32_t domid,  struct xc_dom_image *dom) { int rc = 0; unsigned int nr = 0, i;  unsigned int e820_entries = 1; struct e820entry *e820 = NULL; uint64_t highmem_size = dom->highmem_end ? dom->highmem_end - (1ull << 32) : 0; uint32_t lowmem_start = dom->device_model ? GUEST_LOW_MEM_START_DEFAULT : 0; unsigned page_size = XC_DOM_PAGE_SIZE(dom);  for (i = 0; i < d_config->num_rdms; i++) if (d_config->rdms[i].policy != LIBXL_RDM_RESERVE_POLICY_INVALID) e820_entries++;  if (d_config->b_info.type == LIBXL_DOMAIN_TYPE_PVH) e820_entries++;  if (highmem_size) e820_entries++; for (i = 0; i < MAX_ACPI_MODULES; i++) if (dom->acpi_modules[i].length) e820_entries++; if (e820_entries >= E820MAX) { LOGD(ERROR, domid, \"Ooops! Too many entries in the memory map!\"); rc = ERROR_INVAL; goto out; } e820 = libxl__malloc(gc, sizeof(struct e820entry) * e820_entries);  e820[nr].addr = lowmem_start; e820[nr].size = dom->lowmem_end - lowmem_start; e820[nr].type = E820_RAM; nr++;  for (i = 0; i < d_config->num_rdms; i++) { if (d_config->rdms[i].policy == LIBXL_RDM_RESERVE_POLICY_INVALID) continue; e820[nr].addr = d_config->rdms[i].start; e820[nr].size = d_config->rdms[i].size; e820[nr].type = E820_RESERVED; nr++; }  if (d_config->b_info.type == LIBXL_DOMAIN_TYPE_PVH) { e820[nr].addr = (X86_HVM_END_SPECIAL_REGION - X86_HVM_NR_SPECIAL_PAGES) << XC_PAGE_SHIFT; e820[nr].size = X86_HVM_NR_SPECIAL_PAGES << XC_PAGE_SHIFT; e820[nr].type = E820_RESERVED; nr++; } for (i = 0; i < MAX_ACPI_MODULES; i++) { if (dom->acpi_modules[i].length) { e820[nr].addr = dom->acpi_modules[i].guest_addr_out & ~(page_size - 1); e820[nr].size = dom->acpi_modules[i].length + (dom->acpi_modules[i].guest_addr_out & (page_size - 1)); e820[nr].type = E820_ACPI; nr++; } }  if (highmem_size) { e820[nr].addr = ((uint64_t)1 << 32); e820[nr].size = highmem_size; e820[nr].type = E820_RAM; } if (xc_domain_set_memory_map(CTX->xch, domid, e820, e820_entries) != 0) { rc = ERROR_FAIL; goto out; } dom->e820 = e820; dom->e820_entries = e820_entries; out: return rc; }", "target": 0, "idx": 104183, "project": "Xen"}
{"func": "static int __acquire_grant_for_copy( struct domain *rd, unsigned long gref, struct domain *ld, int readonly, unsigned long *frame, unsigned *page_off, unsigned *length, unsigned allow_transitive, struct domain **owning_domain) { grant_entry_v1_t *sha1; grant_entry_v2_t *sha2; grant_entry_header_t *shah; struct active_grant_entry *act; grant_status_t *status; uint32_t old_pin; domid_t trans_domid; grant_ref_t trans_gref; struct domain *rrd; unsigned long gfn; unsigned long grant_frame; unsigned trans_page_off; unsigned trans_length; int is_sub_page; struct domain *ignore; s16 rc = GNTST_okay; *owning_domain = NULL; spin_lock(&rd->grant_table->lock); if ( rd->grant_table->gt_version == 0 ) PIN_FAIL(unlock_out, GNTST_general_error,  \"remote grant table not ready\\n\"); if ( unlikely(gref >= nr_grant_entries(rd->grant_table)) ) PIN_FAIL(unlock_out, GNTST_bad_gntref,  \"Bad grant reference %ld\\n\", gref); act = &active_entry(rd->grant_table, gref); shah = shared_entry_header(rd->grant_table, gref); if ( rd->grant_table->gt_version == 1 ) { sha1 = &shared_entry_v1(rd->grant_table, gref); sha2 = NULL; status = &shah->flags; } else { sha1 = NULL; sha2 = &shared_entry_v2(rd->grant_table, gref); status = &status_entry(rd->grant_table, gref); }  if ( act->pin &&  ((act->domid != ld->domain_id) || (act->pin & 0x80808080U) != 0) ) PIN_FAIL(unlock_out, GNTST_general_error,  \"Bad domain (%d != %d), or risk of counter overflow %08x\\n\",  act->domid, ld->domain_id, act->pin); old_pin = act->pin; if ( !act->pin ||  (!readonly && !(act->pin & (GNTPIN_devw_mask|GNTPIN_hstw_mask))) ) { if ( (rc = _set_status(rd->grant_table->gt_version,  ld->domain_id,  readonly, 0, shah, act,  status) ) != GNTST_okay )  goto unlock_out; trans_domid = ld->domain_id; trans_gref = 0; if ( sha2 && (shah->flags & GTF_type_mask) == GTF_transitive ) { if ( !allow_transitive ) PIN_FAIL(unlock_out, GNTST_general_error,  \"transitive grant when transitivity not allowed\\n\"); trans_domid = sha2->transitive.trans_domid; trans_gref = sha2->transitive.gref; barrier();  if ( trans_domid == rd->domain_id ) PIN_FAIL(unlock_out, GNTST_general_error,  \"transitive grants cannot be self-referential\\n\");  rrd = rcu_lock_domain_by_id(trans_domid); if ( rrd == NULL ) PIN_FAIL(unlock_out, GNTST_general_error,  \"transitive grant referenced bad domain %d\\n\",  trans_domid); spin_unlock(&rd->grant_table->lock); rc = __acquire_grant_for_copy(rrd, trans_gref, rd, readonly, &grant_frame, &trans_page_off, &trans_length, 0, &ignore); spin_lock(&rd->grant_table->lock); if ( rc != GNTST_okay ) { __fixup_status_for_pin(act, status); spin_unlock(&rd->grant_table->lock); return rc; }  if ( act->pin != old_pin ) { __fixup_status_for_pin(act, status); spin_unlock(&rd->grant_table->lock); return __acquire_grant_for_copy(rd, gref, ld, readonly, frame, page_off, length, allow_transitive, owning_domain); }  is_sub_page = 1; *owning_domain = rrd; act->gfn = -1ul; } else if ( sha1 ) { gfn = sha1->frame; rc = __get_paged_frame(gfn, &grant_frame, readonly, rd); if ( rc != GNTST_okay ) goto unlock_out; act->gfn = gfn; is_sub_page = 0; trans_page_off = 0; trans_length = PAGE_SIZE; *owning_domain = rd; } else if ( !(sha2->hdr.flags & GTF_sub_page) ) { gfn = sha2->full_page.frame; rc = __get_paged_frame(gfn, &grant_frame, readonly, rd); if ( rc != GNTST_okay ) goto unlock_out; act->gfn = gfn; is_sub_page = 0; trans_page_off = 0; trans_length = PAGE_SIZE; *owning_domain = rd; } else { gfn = sha2->sub_page.frame; rc = __get_paged_frame(gfn, &grant_frame, readonly, rd); if ( rc != GNTST_okay ) goto unlock_out; act->gfn = gfn; is_sub_page = 1; trans_page_off = sha2->sub_page.page_off; trans_length = sha2->sub_page.length; *owning_domain = rd; } if ( !act->pin ) { act->domid = ld->domain_id; act->is_sub_page = is_sub_page; act->start = trans_page_off; act->length = trans_length; act->trans_dom = trans_domid; act->trans_gref = trans_gref; act->frame = grant_frame; } } else { *owning_domain = rd; } act->pin += readonly ? GNTPIN_hstr_inc : GNTPIN_hstw_inc; *page_off = act->start; *length = act->length; *frame = act->frame;  unlock_out: spin_unlock(&rd->grant_table->lock); return rc; }", "target": 1, "idx": 109113, "project": "Xen"}
{"func": "void free_ioapic_entries(struct IO_APIC_route_entry **ioapic_entries) { int apic; for (apic = 0; apic < nr_ioapics; apic++) xfree(ioapic_entries[apic]); xfree(ioapic_entries); }", "target": 0, "idx": 102856, "project": "Xen"}
{"func": "static bool check_dir(const char *filename) { FILE *f; struct stat stab; bool res; f = fopen(filename, \"r\"); if ( !f ) return false; res = !fstat(fileno(f), &stab) && S_ISDIR(stab.st_mode); fclose(f); return res; }", "target": 0, "idx": 107841, "project": "Xen"}
{"func": " */ static bool_t INIT lzma_props(struct xz_dec_lzma2 *s, uint8_t props) { if (props > (4 * 5 + 4) * 9 + 8) return false; s->lzma.pos_mask = 0; while (props >= 9 * 5) { props -= 9 * 5; ++s->lzma.pos_mask; } s->lzma.pos_mask = (1 << s->lzma.pos_mask) - 1; s->lzma.literal_pos_mask = 0; while (props >= 9) { props -= 9; ++s->lzma.literal_pos_mask; } s->lzma.lc = props; if (s->lzma.lc + s->lzma.literal_pos_mask > 4) return false; s->lzma.literal_pos_mask = (1 << s->lzma.literal_pos_mask) - 1; lzma_reset(s); return true; }", "target": 0, "idx": 101610, "project": "Xen"}
{"func": " */ GtkTreeIter *gtktree_iter_find_node(GtkTreeIter * parent, struct menu *tofind) { GtkTreeIter iter; GtkTreeIter *child = &iter; gboolean valid; GtkTreeIter *ret; valid = gtk_tree_model_iter_children(model2, child, parent); while (valid) { struct menu *menu; gtk_tree_model_get(model2, child, 6, &menu, -1); if (menu == tofind) { memcpy(&found, child, sizeof(GtkTreeIter)); return &found; } ret = gtktree_iter_find_node(child, tofind); if (ret) return ret; valid = gtk_tree_model_iter_next(model2, child); } return NULL; }", "target": 0, "idx": 102278, "project": "Xen"}
{"func": " */ static void print_limit(struct rangeset *r, unsigned long s) { printk((r->flags & RANGESETF_prettyprint_hex) ? \"%lx\" : \"%lu\", s); }", "target": 0, "idx": 105308, "project": "Xen"}
{"func": "static void gicv3_unmask_irq(struct irq_desc *irqd) { gicv3_poke_irq(irqd, GICD_ISENABLER, false); }", "target": 0, "idx": 102540, "project": "Xen"}
{"func": "static LIBXL_DEFINE_DEVICES_ADD(usbdev) static int do_usbdev_remove(libxl__gc *gc, uint32_t domid, libxl_device_usbdev *usbdev) { int rc; char *busid; libxl_device_usbctrl usbctrl; libxl_usbctrlinfo usbctrlinfo; libxl_device_usbctrl_init(&usbctrl); libxl_usbctrlinfo_init(&usbctrlinfo); usbctrl.devid = usbdev->ctrl; rc = libxl_device_usbctrl_getinfo(CTX, domid, &usbctrl, &usbctrlinfo); if (rc) goto out; switch (usbctrlinfo.type) { case LIBXL_USBCTRL_TYPE_PV: busid = usbdev_busid_from_ctrlport(gc, domid, usbdev, usbctrlinfo.type); if (!busid) { rc = ERROR_FAIL; goto out; }  rc = usbback_dev_unassign(gc, busid); if (rc) { LOGD(ERROR, domid, \"Error removing device from guest.\"  \" Try running usbdev-detach again.\"); goto out; } rc = libxl__device_usbdev_remove_xenstore(gc, domid, usbdev, LIBXL_USBCTRL_TYPE_PV); if (rc) { LOGD(ERROR, domid, \"Error removing device from guest.\"  \" Try running usbdev-detach again.\"); goto out; } rc = usbdev_rebind(gc, busid); if (rc) { LOGD(ERROR, domid, \"USB device removed from guest, but couldn't\"  \" re-bind to domain 0. Try removing and re-inserting\"  \" the USB device or reloading the driver modules.\"); goto out; } break; case LIBXL_USBCTRL_TYPE_QUSB: rc = libxl__device_usbdev_remove_xenstore(gc, domid, usbdev, LIBXL_USBCTRL_TYPE_QUSB); if (rc) goto out; break; case LIBXL_USBCTRL_TYPE_DEVICEMODEL: rc = libxl__device_usbdev_remove_xenstore(gc, domid, usbdev, LIBXL_USBCTRL_TYPE_DEVICEMODEL); if (rc) goto out; rc = libxl__device_usbdev_del_hvm(gc, domid, usbdev); if (rc) { libxl__device_usbdev_add_xenstore(gc, domid, usbdev, LIBXL_USBCTRL_TYPE_DEVICEMODEL, false); goto out; } break; default: LOGD(ERROR, domid, \"Unsupported usb controller type\"); rc = ERROR_FAIL; goto out; } rc = 0; out: libxl_device_usbctrl_dispose(&usbctrl); libxl_usbctrlinfo_dispose(&usbctrlinfo); return rc; }", "target": 0, "idx": 104058, "project": "Xen"}
{"func": "static unsigned type_bit_width(struct type_descriptor *type) { return 1 << (type->type_info >> 1); }", "target": 0, "idx": 106523, "project": "Xen"}
{"func": "static toff_t _tiffSizeProc(thandle_t fd) { struct stat sb; return (fstat((int) fd, &sb) < 0 ? 0 : sb.st_size); }", "target": 0, "idx": 100345, "project": "LibTIFF"}
{"func": "static void disk_write_group_itree(struct mem_tpm_mgr *mgr, int base, int nr_entries, struct hash256 *hash, sector_t *loc, int hsize); static void disk_write_group_itree(struct mem_tpm_mgr *mgr, int base, int nr_entries, struct hash256 *hash, sector_t *loc, int hsize) { int i, incr = 1; if (nr_entries <= hsize) { for(i=0; i < mgr->nr_groups; i++) { struct mem_group_hdr *group = mgr->groups + base + i; disk_write_group_sector(group, mgr); loc[i] = group->disk_loc; hash[i] = group->disk_hash; } return; } while (nr_entries > incr * hsize) incr *= NR_ENTRIES_PER_ITREE; for (i = 0; i * incr < nr_entries; i++) { struct disk_itree_sector pt; int child_entries = incr;  if (nr_entries - i * incr < incr) child_entries = nr_entries - i * incr; disk_write_group_itree(mgr, base, child_entries, pt.hash, pt.location, NR_ENTRIES_PER_ITREE); sha256(&hash[i], &pt.hash, sizeof(pt.hash)); disk_write_crypt_sector(&loc[i], &pt, sizeof(pt), mgr); base += incr; } } struct hash256 *hash, sector_t *loc, int hsize); static void disk_write_group_itree(struct mem_tpm_mgr *mgr, int base, int nr_entries, struct hash256 *hash, sector_t *loc, int hsize) { int i, incr = 1; if (nr_entries <= hsize) { for(i=0; i < mgr->nr_groups; i++) { struct mem_group_hdr *group = mgr->groups + base + i; disk_write_group_sector(group, mgr); loc[i] = group->disk_loc; hash[i] = group->disk_hash; } return; } while (nr_entries > incr * hsize) incr *= NR_ENTRIES_PER_ITREE; for (i = 0; i * incr < nr_entries; i++) { struct disk_itree_sector pt; int child_entries = incr;  if (nr_entries - i * incr < incr) child_entries = nr_entries - i * incr; disk_write_group_itree(mgr, base, child_entries, pt.hash, pt.location, NR_ENTRIES_PER_ITREE); sha256(&hash[i], &pt.hash, sizeof(pt.hash)); disk_write_crypt_sector(&loc[i], &pt, sizeof(pt), mgr); base += incr; } }", "target": 0, "idx": 101711, "project": "Xen"}
{"func": "static void keypress_action(unsigned long unused) { handle_keypress(keypress_key, NULL); }", "target": 0, "idx": 102968, "project": "Xen"}
{"func": "static inline void __csched_vcpu_check(struct vcpu *vc) { struct csched_vcpu * const svc = CSCHED_VCPU(vc); struct csched_dom * const sdom = svc->sdom; BUG_ON( svc->vcpu != vc ); BUG_ON( sdom != CSCHED_DOM(vc->domain) ); if ( sdom ) { BUG_ON( is_idle_vcpu(vc) ); BUG_ON( sdom->dom != vc->domain ); } else { BUG_ON( !is_idle_vcpu(vc) ); } SCHED_STAT_CRANK(vcpu_check); }", "target": 0, "idx": 105509, "project": "Xen"}
{"func": "uint64_t elf_note_numeric(struct elf_binary *elf, ELF_HANDLE_DECL(elf_note) note) { elf_ptrval desc = elf_note_desc(elf, note); unsigned descsz = elf_uval(elf, note, descsz); switch (descsz) { case 1: case 2: case 4: case 8: return elf_access_unsigned(elf, desc, 0, descsz); default: return 0; } }", "target": 0, "idx": 103047, "project": "Xen"}
{"func": "static struct page_info *alloc_heap_pages( unsigned int zone_lo, unsigned int zone_hi, unsigned int order, unsigned int memflags, struct domain *d) { unsigned int first_node, i, j, zone = 0, nodemask_retry = 0; unsigned int node = (uint8_t)((memflags >> _MEMF_node) - 1); unsigned long request = 1UL << order; struct page_info *pg; nodemask_t nodemask = (d != NULL ) ? d->node_affinity : node_online_map; bool_t need_tlbflush = 0; uint32_t tlbflush_timestamp = 0; if ( node == NUMA_NO_NODE ) { memflags &= ~MEMF_exact_node; if ( d != NULL ) { node = next_node(d->last_alloc_node, nodemask); if ( node >= MAX_NUMNODES ) node = first_node(nodemask); } if ( node >= MAX_NUMNODES ) node = cpu_to_node(smp_processor_id()); } first_node = node; ASSERT(node >= 0); ASSERT(zone_lo <= zone_hi); ASSERT(zone_hi < NR_ZONES); if ( unlikely(order > MAX_ORDER) ) return NULL; spin_lock(&heap_lock);  if ( (outstanding_claims + request > total_avail_pages + tmem_freeable_pages()) && (d == NULL || d->outstanding_pages < request) ) goto not_found;  if ( opt_tmem && ((order == 0) || (order >= 9)) &&  (total_avail_pages <= midsize_alloc_zone_pages) &&  tmem_freeable_pages() ) goto try_tmem;  for ( ; ; ) { zone = zone_hi; do {  if ( !avail[node] || (avail[node][zone] < request) ) continue;  for ( j = order; j <= MAX_ORDER; j++ ) if ( (pg = page_list_remove_head(&heap(node, zone, j))) ) goto found; } while ( zone-- > zone_lo );  if ( memflags & MEMF_exact_node ) goto not_found;  if ( !node_isset(node, nodemask) ) {  ASSERT(!nodemask_retry); first_node = node = first_node(nodemask); if ( node < MAX_NUMNODES ) continue; } else if ( (node = next_node(node, nodemask)) >= MAX_NUMNODES ) node = first_node(nodemask); if ( node == first_node ) {  if ( nodemask_retry++ ) goto not_found; nodes_andnot(nodemask, node_online_map, nodemask); first_node = node = first_node(nodemask); if ( node >= MAX_NUMNODES ) goto not_found; } }  try_tmem:  if ( (pg = tmem_relinquish_pages(order, memflags)) != NULL ) {  spin_unlock(&heap_lock); return pg; }  not_found:  spin_unlock(&heap_lock); return NULL;  found:   while ( j != order ) { PFN_ORDER(pg) = --j; page_list_add_tail(pg, &heap(node, zone, j)); pg += 1 << j; } ASSERT(avail[node][zone] >= request); avail[node][zone] -= request; total_avail_pages -= request; ASSERT(total_avail_pages >= 0); check_low_mem_virq(); if ( d != NULL ) d->last_alloc_node = node; for ( i = 0; i < (1 << order); i++ ) {  BUG_ON(pg[i].count_info != PGC_state_free); pg[i].count_info = PGC_state_inuse; if ( pg[i].u.free.need_tlbflush &&  (pg[i].tlbflush_timestamp <= tlbflush_current_time()) &&  (!need_tlbflush || (pg[i].tlbflush_timestamp > tlbflush_timestamp)) ) { need_tlbflush = 1; tlbflush_timestamp = pg[i].tlbflush_timestamp; }  pg[i].u.inuse.type_info = 0; page_set_owner(&pg[i], NULL);  flush_page_to_ram(page_to_mfn(&pg[i])); } spin_unlock(&heap_lock); if ( need_tlbflush ) { cpumask_t mask = cpu_online_map; tlbflush_filter(mask, tlbflush_timestamp); if ( !cpumask_empty(&mask) ) { perfc_incr(need_flush_tlb_flush); flush_tlb_mask(&mask); } } return pg; }", "target": 1, "idx": 109498, "project": "Xen"}
{"func": "static void free_no_errno(void *p) { int saved_errno = errno; free(p); errno = saved_errno; }", "target": 0, "idx": 108907, "project": "Xen"}
{"func": "static int hp_mem_query_func(int argc, char *argv[]) { uint32_t status; int ret; unsigned long mfn; if (argc != 1) { show_help(); return -1; } sscanf(argv[0], \"%lx\", &mfn); printf(\"Querying MEMORY mfn %lx status\\n\", mfn); ret = xc_query_page_offline_status(xch, mfn, mfn, &status); if (ret < 0) fprintf(stderr, \"Querying page mfn %lx failed, error %x\", mfn, errno); else { printf(\"Memory Status %x: [\", status); if ( status & PG_OFFLINE_STATUS_OFFLINE_PENDING) printf(\" PAGE_OFFLINE_PENDING \"); if ( status & PG_OFFLINE_STATUS_BROKEN ) printf(\" PAGE_BROKEND\"); if ( status & PG_OFFLINE_STATUS_OFFLINED ) printf(\" PAGE_OFFLINED \"); else printf(\" PAGE_ONLINED \"); printf(\"]\\n\"); } return ret; }", "target": 0, "idx": 107859, "project": "Xen"}
{"func": " */ static void print_position(WINDOW * win) { int percent; wattrset(win, dlg.position_indicator.atr); wbkgdset(win, dlg.position_indicator.atr & A_COLOR); percent = (page - buf) * 100 / strlen(buf); wmove(win, getmaxy(win) - 3, getmaxx(win) - 9); wprintw(win, \"(%3d%%)\", percent); }", "target": 0, "idx": 106425, "project": "Xen"}
{"func": "static void sha1_do(sha1_ctx *ctx, const unsigned char *data32, uint32_t length) { uint32_t offset; uint16_t num; uint32_t bits = 0; uint32_t w[80]; uint32_t tmp;  for (offset = 0; length - offset >= 64; offset += 64) { memcpy(w, data32 + offset, 64); sha1_block((uint32_t *)w, ctx); bits += (64 * 8); }  num = length - offset; bits += (num << 3); memset(w, 0x0, 64); memcpy(w, data32 + offset, num); ((uint8_t *)w)[num] = 0x80; if (num >= 56) {  sha1_block((uint32_t *)w, ctx); memset(w, 0x0, 60); }  tmp = bswap(bits); memcpy(&w[15], &tmp, 4); sha1_block(w, ctx);  for (num = 0; num < 5; num++) ctx->h[num] = bswap(ctx->h[num]); }", "target": 0, "idx": 106332, "project": "Xen"}
{"func": "unsigned int __find_next_bit( const unsigned long *addr, unsigned int size, unsigned int offset) { const unsigned long *p = addr + (offset / BITS_PER_LONG); unsigned int set, bit = offset & (BITS_PER_LONG - 1); ASSERT(offset <= size); if ( bit != 0 ) {  set = __scanbit(*p >> bit, BITS_PER_LONG - bit); if ( set < (BITS_PER_LONG - bit) ) return (offset + set); offset += BITS_PER_LONG - bit; p++; } if ( offset >= size ) return size;  set = __find_first_bit(p, size - offset); return (offset + set); }", "target": 0, "idx": 101017, "project": "Xen"}
{"func": "void emul_test_put_fpu( struct x86_emulate_ctxt *ctxt, enum x86_emulate_fpu_type backout, const struct x86_emul_fpu_aux *aux) {  }", "target": 0, "idx": 107280, "project": "Xen"}
{"func": "int item_is_tag(char tag) { return (item_cur->node.tag == tag); }", "target": 0, "idx": 106589, "project": "Xen"}
{"func": "int write_exact(int fd, const void *data, size_t size) { size_t offset = 0; ssize_t len; while ( offset < size ) { len = write(fd, (const char *)data + offset, size - offset); if ( (len == -1) && (errno == EINTR) ) continue; if ( len <= 0 ) return -1; offset += len; } return 0; }", "target": 0, "idx": 107644, "project": "Xen"}
{"func": "int xc_gnttab_get_version(xc_interface *xch, uint32_t domid) { struct gnttab_get_version query; int rc; query.dom = domid; rc = xc_gnttab_op(xch, GNTTABOP_get_version, &query, sizeof(query), 1); if ( rc < 0 ) return rc; else return query.version; }", "target": 0, "idx": 107506, "project": "Xen"}
{"func": "static void qos_state_runnable(int cpu, int domid, uint64_t now) { int idx; qos_update_thread_stats(cpu, domid, now); if (domain_runnable(domid)) return; idx = indexof(domid); new_qos->domain_info[idx].runnable = 1; update_blocked_time(domid, now); new_qos->domain_info[idx].blocked_start_time = 0;  new_qos->domain_info[idx].runnable_start_time = now;  }", "target": 0, "idx": 108161, "project": "Xen"}
{"func": "static int pack_cfg_list(void* buf, struct mem_group *group) { int i; void *bstart = buf; memcpy(buf, &group->details.cfg_seq, 8); buf += 8; buf = pack_UINT32(buf, group->nr_seals); for(i=0; i < group->nr_seals; i++) { memcpy(buf, &group->seals[i].digest_release, 20); buf += 20; } memcpy(buf, &group->seal_bits.nr_kerns, 4); buf += 4; memcpy(buf, &group->seal_bits.kernels, 20 * be32_native(group->seal_bits.nr_kerns)); return buf - bstart + 20 * be32_native(group->seal_bits.nr_kerns); }", "target": 0, "idx": 107212, "project": "Xen"}
{"func": "void * fsig_fs_buf(fsi_t *fsi) { fsig_data_t *data = fsip_fs_data(fsi); return ((void *)data->fd_buf); }", "target": 0, "idx": 102110, "project": "Xen"}
{"func": "static void decode_featureset(const uint32_t *features, const uint32_t length, const char *name, bool detail) { unsigned int i; printf(\"%-\"COL_ALIGN\"s\", name); for ( i = 0; i < length; ++i ) printf(\"%08x%c\", features[i],  i < length - 1 ? ':' : '\\n'); if ( !detail ) return; for ( i = 0; i < length && i < ARRAY_SIZE(decodes); ++i ) { printf(\"[%02u] %-\"COL_ALIGN\"s\", i, decodes[i].name ?: \"<UNKNOWN>\"); if ( decodes[i].name ) dump_leaf(features[i], decodes[i].strs); printf(\"\\n\"); } }", "target": 0, "idx": 107836, "project": "Xen"}
{"func": "static void ns16550_putc(struct serial_port *port, char c) { struct ns16550 *uart = port->uart; ns_write_reg(uart, UART_THR, c); }", "target": 0, "idx": 104903, "project": "Xen"}
{"func": "static int __init mvebu3700_irq(struct serial_port *port) { struct mvebu3700_uart *uart = port->uart; return uart->irq; }", "target": 0, "idx": 104696, "project": "Xen"}
{"func": "long xc_get_tot_pages(xc_interface *xch, uint32_t domid) { xc_dominfo_t info; if ( (xc_domain_getinfo(xch, domid, 1, &info) != 1) ||  (info.domid != domid) ) return -1; return info.nr_pages; }", "target": 0, "idx": 107656, "project": "Xen"}
{"func": "static int __init cuart_init(struct dt_device_node *dev, const void *data) { const char *config = data; struct cuart *uart; int res; u64 addr, size; if ( strcmp(config, \"\") ) printk(\"WARNING: UART configuration is not supported\\n\"); uart = &cuart_com; res = dt_device_get_address(dev, 0, &addr, &size); if ( res ) { printk(\"cadence: Unable to retrieve the base\"  \" address of the UART\\n\"); return res; } res = platform_get_irq(dev, 0); if ( res < 0 ) { printk(\"cadence: Unable to retrieve the IRQ\\n\"); return -EINVAL; } uart->irq = res; uart->regs = ioremap_nocache(addr, size); if ( !uart->regs ) { printk(\"cadence: Unable to map the UART memory\\n\"); return -ENOMEM; } uart->vuart.base_addr = addr; uart->vuart.size = size; uart->vuart.data_off = R_UART_RX; uart->vuart.status_off = R_UART_SR; uart->vuart.status = UART_SR_INTR_TEMPTY;  serial_register_uart(SERHND_DTUART, &cuart_driver, uart); dt_device_set_used_by(dev, DOMID_XEN); return 0; }", "target": 0, "idx": 101304, "project": "Xen"}
{"func": "static int tdremus_get_parent_id(td_driver_t *driver, td_disk_id_t *id) {  return -EINVAL; }", "target": 0, "idx": 101141, "project": "Xen"}
{"func": "1, HVMSR_PER_VCPU); int vlapic_init(struct vcpu *v) { struct vlapic *vlapic = vcpu_vlapic(v); HVM_DBG_LOG(DBG_LEVEL_VLAPIC, \"%d\", v->vcpu_id); if ( !has_vlapic(v->domain) ) { vlapic->hw.disabled = VLAPIC_HW_DISABLED; return 0; } vlapic->pt.source = PTSRC_lapic; if (vlapic->regs_page == NULL) { vlapic->regs_page = alloc_domheap_page(v->domain, MEMF_no_owner); if ( vlapic->regs_page == NULL ) { dprintk(XENLOG_ERR, \"alloc vlapic regs error: %d/%d\\n\", v->domain->domain_id, v->vcpu_id); return -ENOMEM; } } if (vlapic->regs == NULL)  { vlapic->regs = __map_domain_page_global(vlapic->regs_page); if ( vlapic->regs == NULL ) { dprintk(XENLOG_ERR, \"map vlapic regs error: %d/%d\\n\", v->domain->domain_id, v->vcpu_id); return -ENOMEM; } } clear_page(vlapic->regs); vlapic_reset(vlapic); spin_lock_init(&vlapic->esr_lock); tasklet_init(&vlapic->init_sipi.tasklet,  vlapic_init_sipi_action,  (unsigned long)v); if ( v->vcpu_id == 0 ) register_mmio_handler(v->domain, &vlapic_mmio_ops); return 0; }", "target": 0, "idx": 106941, "project": "Xen"}
{"func": "static int vhd_journal_add_header(vhd_journal_t *j) { int err; off_t off; vhd_context_t *vhd; vhd_header_t header; vhd = &j->vhd; err = vhd_read_header(vhd, &header); if (err) return err; off = vhd->footer.data_offset; vhd_header_out(&header); err = vhd_journal_update(j, off,  (char *)&header,  sizeof(vhd_header_t),  VHD_JOURNAL_ENTRY_TYPE_HEADER); return err; }", "target": 0, "idx": 103064, "project": "Xen"}
{"func": " returning -1,0,1 * for <,=,> */ static int compare_vbd_rd(xenstat_domain *domain1, xenstat_domain *domain2) { return -compare(tot_vbd_reqs(domain1, FIELD_VBD_RD), tot_vbd_reqs(domain2, FIELD_VBD_RD)); }", "target": 0, "idx": 108512, "project": "Xen"}
{"func": " */ static int cpupool_cpu_remove(unsigned int cpu) { int ret = -ENODEV; spin_lock(&cpupool_lock); if ( system_state == SYS_STATE_suspend ) { struct cpupool **c; for_each_cpupool(c) { if ( cpumask_test_cpu(cpu, (*c)->cpu_valid ) ) { cpumask_set_cpu(cpu, (*c)->cpu_suspended); cpumask_clear_cpu(cpu, (*c)->cpu_valid); break; } }  ASSERT(cpumask_test_cpu(cpu, &cpupool_free_cpus) ||  cpumask_test_cpu(cpu, (*c)->cpu_suspended)); ASSERT(cpumask_test_cpu(cpu, &cpu_online_map) ||  cpumask_test_cpu(cpu, cpupool0->cpu_suspended)); ret = 0; } else if ( cpumask_test_cpu(cpu, cpupool0->cpu_valid) ) {  cpumask_clear_cpu(cpu, cpupool0->cpu_valid); ret = 0; } if ( !ret ) cpumask_set_cpu(cpu, &cpupool_locked_cpus); spin_unlock(&cpupool_lock); return ret; }", "target": 0, "idx": 101550, "project": "Xen"}
{"func": "static int _get_vcpu_ctxt(vcpuid_t vcpu_id, union vcpu_guest_context_any *anycp) { int sz = sizeof(union vcpu_guest_context_any); memset(anycp, 0, sz); domctl.u.vcpucontext.vcpu = (uint16_t)vcpu_id; set_xen_guest_handle(domctl.u.vcpucontext.ctxt, &anycp->ctxt); if (_domctl_hcall(XEN_DOMCTL_getvcpucontext, anycp, sz)) { XGERR(\"Failed hcall to get vcpu ctxt. errno:%d\\n\", errno); return 1; } return 0; }", "target": 0, "idx": 108633, "project": "Xen"}
{"func": " */ static void park_vcpu(struct csched2_vcpu *svc) { struct vcpu *v = svc->vcpu; ASSERT(spin_is_locked(&svc->sdom->budget_lock));  __set_bit(_VPF_parked, &v->pause_flags); if ( vcpu_on_runq(svc) ) { runq_remove(svc); update_load(svc->sdom->dom->cpupool->sched, svc->rqd, svc, -1, NOW()); } list_add(&svc->parked_elem, &svc->sdom->parked_vcpus); }", "target": 0, "idx": 105560, "project": "Xen"}
{"func": " */ void vmx_domain_flush_pml_buffers(struct domain *d) { struct vcpu *v; ASSERT(atomic_read(&d->pause_count)); if ( !vmx_domain_pml_enabled(d) ) return; for_each_vcpu ( d, v ) vmx_vcpu_flush_pml_buffer(v); }", "target": 0, "idx": 107030, "project": "Xen"}
{"func": "int xc_flask_op(xc_interface *xch, xen_flask_op_t *op) { int ret = -1; DECLARE_HYPERCALL_BOUNCE(op, sizeof(*op), XC_HYPERCALL_BUFFER_BOUNCE_BOTH); op->interface_version = XEN_FLASK_INTERFACE_VERSION; if ( xc_hypercall_bounce_pre(xch, op) ) { PERROR(\"Could not bounce memory for flask op hypercall\"); goto out; } ret = xencall1(xch->xcall, __HYPERVISOR_xsm_op,  HYPERCALL_BUFFER_AS_ARG(op)); if ( ret < 0 ) { if ( errno == EACCES ) fprintf(stderr, \"XSM operation failed!\\n\"); } xc_hypercall_bounce_post(xch, op);  out: return ret; }", "target": 0, "idx": 107495, "project": "Xen"}
{"func": "static int JPEGSetupEncode(TIFF* tif) { JPEGState* sp = JState(tif); TIFFDirectory *td = &tif->tif_dir; static const char module[] = \"JPEGSetupEncode\"; #if defined(JPEG_DUAL_MODE_8_12) && !defined(TIFFInitJPEG) if( tif->tif_dir.td_bitspersample == 12 ) return TIFFReInitJPEG_12( tif, COMPRESSION_JPEG, 1 ); #endif JPEGInitializeLibJPEG( tif, FALSE ); assert(sp != NULL); assert(!sp->cinfo.comm.is_decompressor); sp->photometric = td->td_photometric;  if (td->td_planarconfig == PLANARCONFIG_CONTIG) { sp->cinfo.c.input_components = td->td_samplesperpixel; if (sp->photometric == PHOTOMETRIC_YCBCR) { if (sp->jpegcolormode == JPEGCOLORMODE_RGB) { sp->cinfo.c.in_color_space = JCS_RGB; } else { sp->cinfo.c.in_color_space = JCS_YCbCr; } } else { if ((td->td_photometric == PHOTOMETRIC_MINISWHITE || td->td_photometric == PHOTOMETRIC_MINISBLACK) && td->td_samplesperpixel == 1) sp->cinfo.c.in_color_space = JCS_GRAYSCALE; else if (td->td_photometric == PHOTOMETRIC_RGB && td->td_samplesperpixel == 3) sp->cinfo.c.in_color_space = JCS_RGB; else if (td->td_photometric == PHOTOMETRIC_SEPARATED && td->td_samplesperpixel == 4) sp->cinfo.c.in_color_space = JCS_CMYK; else sp->cinfo.c.in_color_space = JCS_UNKNOWN; } } else { sp->cinfo.c.input_components = 1; sp->cinfo.c.in_color_space = JCS_UNKNOWN; } if (!TIFFjpeg_set_defaults(sp)) return (0);  switch (sp->photometric) { case PHOTOMETRIC_YCBCR: sp->h_sampling = td->td_ycbcrsubsampling[0]; sp->v_sampling = td->td_ycbcrsubsampling[1];  { float *ref; if (!TIFFGetField(tif, TIFFTAG_REFERENCEBLACKWHITE, &ref)) { float refbw[6]; long top = 1L << td->td_bitspersample; refbw[0] = 0; refbw[1] = (float)(top-1L); refbw[2] = (float)(top>>1); refbw[3] = refbw[1]; refbw[4] = refbw[2]; refbw[5] = refbw[1]; TIFFSetField(tif, TIFFTAG_REFERENCEBLACKWHITE,  refbw); } } break; case PHOTOMETRIC_PALETTE: case PHOTOMETRIC_MASK: TIFFErrorExt(tif->tif_clientdata, module, \"PhotometricInterpretation %d not allowed for JPEG\", (int) sp->photometric); return (0); default:  sp->h_sampling = 1; sp->v_sampling = 1; break; }   #ifdef JPEG_LIB_MK1  if (td->td_bitspersample != 8 && td->td_bitspersample != 12)  #else if (td->td_bitspersample != BITS_IN_JSAMPLE ) #endif { TIFFErrorExt(tif->tif_clientdata, module, \"BitsPerSample %d not allowed for JPEG\", (int) td->td_bitspersample); return (0); } sp->cinfo.c.data_precision = td->td_bitspersample; #ifdef JPEG_LIB_MK1 sp->cinfo.c.bits_in_jsample = td->td_bitspersample; #endif if (isTiled(tif)) { if ((td->td_tilelength % (sp->v_sampling * DCTSIZE)) != 0) { TIFFErrorExt(tif->tif_clientdata, module, \"JPEG tile height must be multiple of %d\", sp->v_sampling * DCTSIZE); return (0); } if ((td->td_tilewidth % (sp->h_sampling * DCTSIZE)) != 0) { TIFFErrorExt(tif->tif_clientdata, module, \"JPEG tile width must be multiple of %d\", sp->h_sampling * DCTSIZE); return (0); } } else { if (td->td_rowsperstrip < td->td_imagelength && (td->td_rowsperstrip % (sp->v_sampling * DCTSIZE)) != 0) { TIFFErrorExt(tif->tif_clientdata, module, \"RowsPerStrip must be multiple of %d for JPEG\", sp->v_sampling * DCTSIZE); return (0); } }  if (sp->jpegtablesmode & (JPEGTABLESMODE_QUANT|JPEGTABLESMODE_HUFF)) { if( sp->jpegtables == NULL || memcmp(sp->jpegtables,\"\\0\\0\\0\\0\\0\\0\\0\\0\\0\",8) == 0 ) { if (!prepare_JPEGTables(tif)) return (0);   tif->tif_flags |= TIFF_DIRTYDIRECT; TIFFSetFieldBit(tif, FIELD_JPEGTABLES); } } else {   TIFFClrFieldBit(tif, FIELD_JPEGTABLES); }  TIFFjpeg_data_dest(sp, tif); return (1); }", "target": 1, "idx": 100830, "project": "LibTIFF"}
{"func": "static int hmp_callback(libxl__qmp_handler *qmp, const libxl__json_object *response, void *opaque) { char **output = opaque; GC_INIT(qmp->ctx); int rc; rc = 0; if (!output) goto out; *output = NULL; if (libxl__json_object_is_string(response)) { *output = libxl__strdup(NOGC, libxl__json_object_get_string(response)); goto out; } LOG(ERROR, \"Response has unexpected format\"); rc = ERROR_FAIL; out: GC_FREE; return rc; }", "target": 0, "idx": 103861, "project": "Xen"}
{"func": " */ XZ_EXTERN enum xz_ret INIT xz_dec_lzma2_run(struct xz_dec_lzma2 *s, struct xz_buf *b) { uint32_t tmp; while (b->in_pos < b->in_size || s->lzma2.sequence == SEQ_LZMA_RUN) { switch (s->lzma2.sequence) { case SEQ_CONTROL:  tmp = b->in[b->in_pos++]; if (tmp == 0x00) return XZ_STREAM_END; if (tmp >= 0xE0 || tmp == 0x01) { s->lzma2.need_props = true; s->lzma2.need_dict_reset = false; dict_reset(&s->dict, b); } else if (s->lzma2.need_dict_reset) { return XZ_DATA_ERROR; } if (tmp >= 0x80) { s->lzma2.uncompressed = (tmp & 0x1F) << 16; s->lzma2.sequence = SEQ_UNCOMPRESSED_1; if (tmp >= 0xC0) {  s->lzma2.need_props = false; s->lzma2.next_sequence = SEQ_PROPERTIES; } else if (s->lzma2.need_props) { return XZ_DATA_ERROR; } else { s->lzma2.next_sequence = SEQ_LZMA_PREPARE; if (tmp >= 0xA0) lzma_reset(s); } } else { if (tmp > 0x02) return XZ_DATA_ERROR; s->lzma2.sequence = SEQ_COMPRESSED_0; s->lzma2.next_sequence = SEQ_COPY; } break; case SEQ_UNCOMPRESSED_1: s->lzma2.uncompressed += (uint32_t)b->in[b->in_pos++] << 8; s->lzma2.sequence = SEQ_UNCOMPRESSED_2; break; case SEQ_UNCOMPRESSED_2: s->lzma2.uncompressed += (uint32_t)b->in[b->in_pos++] + 1; s->lzma2.sequence = SEQ_COMPRESSED_0; break; case SEQ_COMPRESSED_0: s->lzma2.compressed = (uint32_t)b->in[b->in_pos++] << 8; s->lzma2.sequence = SEQ_COMPRESSED_1; break; case SEQ_COMPRESSED_1: s->lzma2.compressed += (uint32_t)b->in[b->in_pos++] + 1; s->lzma2.sequence = s->lzma2.next_sequence; break; case SEQ_PROPERTIES: if (!lzma_props(s, b->in[b->in_pos++])) return XZ_DATA_ERROR; s->lzma2.sequence = SEQ_LZMA_PREPARE;  case SEQ_LZMA_PREPARE: if (s->lzma2.compressed < RC_INIT_BYTES) return XZ_DATA_ERROR; if (!rc_read_init(&s->rc, b)) return XZ_OK; s->lzma2.compressed -= RC_INIT_BYTES; s->lzma2.sequence = SEQ_LZMA_RUN;  case SEQ_LZMA_RUN:  dict_limit(&s->dict, min_t(size_t, b->out_size - b->out_pos, s->lzma2.uncompressed)); if (!lzma2_lzma(s, b)) return XZ_DATA_ERROR; s->lzma2.uncompressed -= dict_flush(&s->dict, b); if (s->lzma2.uncompressed == 0) { if (s->lzma2.compressed > 0 || s->lzma.len > 0 || !rc_is_finished(&s->rc)) return XZ_DATA_ERROR; rc_reset(&s->rc); s->lzma2.sequence = SEQ_CONTROL; } else if (b->out_pos == b->out_size || (b->in_pos == b->in_size && s->temp.size < s->lzma2.compressed)) { return XZ_OK; } break; case SEQ_COPY: dict_uncompressed(&s->dict, b, &s->lzma2.compressed); if (s->lzma2.compressed > 0) return XZ_OK; s->lzma2.sequence = SEQ_CONTROL; break; } } return XZ_OK; }", "target": 0, "idx": 101622, "project": "Xen"}
{"func": "static int conf_string(struct menu *menu) { struct symbol *sym = menu->sym; const char *def; while (1) { printf(\"%*s%s \", indent - 1, \"\", _(menu->prompt->text)); printf(\"(%s) \", sym->name); def = sym_get_string_value(sym); if (sym_get_string_value(sym)) printf(\"[%s] \", def); if (!conf_askvalue(sym, def)) return 0; switch (line[0]) { case '\\n': break; case '?':  if (line[1] == '\\n') { print_help(menu); def = NULL; break; }  default: line[strlen(line)-1] = 0; def = line; } if (def && sym_set_string_value(sym, def)) return 0; } }", "target": 0, "idx": 101365, "project": "Xen"}
{"func": "struct avtab_datum *avtab_search(struct avtab *h, struct avtab_key *key) { int hvalue; struct avtab_node *cur; u16 specified = key->specified & ~(AVTAB_ENABLED|AVTAB_ENABLED_OLD); if ( !h || !h->htable ) return NULL; hvalue = avtab_hash(key, h->mask); for ( cur = h->htable[hvalue]; cur; cur = cur->next ) { if ( key->source_type == cur->key.source_type && key->target_type == cur->key.target_type && key->target_class == cur->key.target_class && (specified & cur->key.specified) ) return &cur->datum; if ( key->source_type < cur->key.source_type ) break; if ( key->source_type == cur->key.source_type && key->target_type < cur->key.target_type ) break; if ( key->source_type == cur->key.source_type && key->target_type == cur->key.target_type && key->target_class < cur->key.target_class ) break; } return NULL; }", "target": 0, "idx": 100939, "project": "Xen"}
{"func": "static void PredictorPrintDir(TIFF* tif, FILE* fd, long flags) { TIFFPredictorState* sp = PredictorState(tif); (void) flags; if (TIFFFieldSet(tif,FIELD_PREDICTOR)) { fprintf(fd, \"Predictor: \"); switch (sp->predictor) { case 1: fprintf(fd, \"none \"); break; case 2: fprintf(fd, \"horizontal differencing \"); break; case 3: fprintf(fd, \"floating point predictor \"); break; } fprintf(fd, \"%d (0x%x)\\n\", sp->predictor, sp->predictor); } if (sp->printdir) (*sp->printdir)(tif, fd, flags); }", "target": 0, "idx": 100625, "project": "LibTIFF"}
